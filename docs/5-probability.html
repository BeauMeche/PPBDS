<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science</title>
  <meta name="description" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="davidkane9/PPBDS" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science" />
  
  
  

<meta name="author" content="David Kane" />


<meta name="date" content="2020-05-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4-functions.html"/>
<link rel="next" href="6-sampling.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="forward.html"><a href="forward.html"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="warning.html"><a href="warning.html"><i class="fa fa-check"></i>Warning</a></li>
<li class="chapter" data-level="" data-path="license.html"><a href="license.html"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="1" data-path="1-viz.html"><a href="1-viz.html"><i class="fa fa-check"></i><b>1</b> Visualization</a><ul>
<li class="chapter" data-level="1.1" data-path="1-viz.html"><a href="1-viz.html#r-rstudio"><i class="fa fa-check"></i><b>1.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-viz.html"><a href="1-viz.html#installing"><i class="fa fa-check"></i><b>1.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-viz.html"><a href="1-viz.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-viz.html"><a href="1-viz.html#code"><i class="fa fa-check"></i><b>1.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-viz.html"><a href="1-viz.html#programming-concepts"><i class="fa fa-check"></i><b>1.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-viz.html"><a href="1-viz.html#messages"><i class="fa fa-check"></i><b>1.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-viz.html"><a href="1-viz.html#tips-code"><i class="fa fa-check"></i><b>1.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-viz.html"><a href="1-viz.html#packages"><i class="fa fa-check"></i><b>1.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-viz.html"><a href="1-viz.html#package-installation"><i class="fa fa-check"></i><b>1.3.1</b> Package installation</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-viz.html"><a href="1-viz.html#package-loading"><i class="fa fa-check"></i><b>1.3.2</b> Package loading</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-viz.html"><a href="1-viz.html#package-use"><i class="fa fa-check"></i><b>1.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-viz.html"><a href="1-viz.html#nycflights13"><i class="fa fa-check"></i><b>1.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-viz.html"><a href="1-viz.html#nycflights13-package"><i class="fa fa-check"></i><b>1.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-viz.html"><a href="1-viz.html#flights-data-frame"><i class="fa fa-check"></i><b>1.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-viz.html"><a href="1-viz.html#exploredataframes"><i class="fa fa-check"></i><b>1.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-viz.html"><a href="1-viz.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>1.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="1-viz.html"><a href="1-viz.html#help-files"><i class="fa fa-check"></i><b>1.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-viz.html"><a href="1-viz.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a><ul>
<li class="chapter" data-level="1.5.1" data-path="1-viz.html"><a href="1-viz.html#additional-resources"><i class="fa fa-check"></i><b>1.5.1</b> Additional resources</a></li>
<li class="chapter" data-level="" data-path="1-viz.html"><a href="1-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="1-viz.html"><a href="1-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>1.6</b> The grammar of graphics</a><ul>
<li class="chapter" data-level="1.6.1" data-path="1-viz.html"><a href="1-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>1.6.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="1.6.2" data-path="1-viz.html"><a href="1-viz.html#gapminder"><i class="fa fa-check"></i><b>1.6.2</b> Gapminder data</a></li>
<li class="chapter" data-level="1.6.3" data-path="1-viz.html"><a href="1-viz.html#other-components"><i class="fa fa-check"></i><b>1.6.3</b> Other components</a></li>
<li class="chapter" data-level="1.6.4" data-path="1-viz.html"><a href="1-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>1.6.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="1-viz.html"><a href="1-viz.html#scatterplots"><i class="fa fa-check"></i><b>1.7</b> Scatterplots</a><ul>
<li class="chapter" data-level="1.7.1" data-path="1-viz.html"><a href="1-viz.html#geompoint"><i class="fa fa-check"></i><b>1.7.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="1.7.2" data-path="1-viz.html"><a href="1-viz.html#overplotting"><i class="fa fa-check"></i><b>1.7.2</b> Overplotting</a></li>
<li class="chapter" data-level="1.7.3" data-path="1-viz.html"><a href="1-viz.html#summary"><i class="fa fa-check"></i><b>1.7.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="1-viz.html"><a href="1-viz.html#linegraphs"><i class="fa fa-check"></i><b>1.8</b> Linegraphs</a><ul>
<li class="chapter" data-level="1.8.1" data-path="1-viz.html"><a href="1-viz.html#geomline"><i class="fa fa-check"></i><b>1.8.1</b> Linegraphs via <code>geom_line</code></a></li>
<li class="chapter" data-level="1.8.2" data-path="1-viz.html"><a href="1-viz.html#summary-1"><i class="fa fa-check"></i><b>1.8.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="1-viz.html"><a href="1-viz.html#histograms"><i class="fa fa-check"></i><b>1.9</b> Histograms</a><ul>
<li class="chapter" data-level="1.9.1" data-path="1-viz.html"><a href="1-viz.html#geomhistogram"><i class="fa fa-check"></i><b>1.9.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="1.9.2" data-path="1-viz.html"><a href="1-viz.html#adjustbins"><i class="fa fa-check"></i><b>1.9.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="1.9.3" data-path="1-viz.html"><a href="1-viz.html#summary-2"><i class="fa fa-check"></i><b>1.9.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="1-viz.html"><a href="1-viz.html#facets"><i class="fa fa-check"></i><b>1.10</b> Facets</a></li>
<li class="chapter" data-level="1.11" data-path="1-viz.html"><a href="1-viz.html#boxplots"><i class="fa fa-check"></i><b>1.11</b> Boxplots</a><ul>
<li class="chapter" data-level="1.11.1" data-path="1-viz.html"><a href="1-viz.html#geomboxplot"><i class="fa fa-check"></i><b>1.11.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="1.11.2" data-path="1-viz.html"><a href="1-viz.html#summary-3"><i class="fa fa-check"></i><b>1.11.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="1-viz.html"><a href="1-viz.html#geombar"><i class="fa fa-check"></i><b>1.12</b> Barplots</a><ul>
<li class="chapter" data-level="1.12.1" data-path="1-viz.html"><a href="1-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>1.12.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="1.12.2" data-path="1-viz.html"><a href="1-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>1.12.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="1.12.3" data-path="1-viz.html"><a href="1-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>1.12.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="1.12.4" data-path="1-viz.html"><a href="1-viz.html#summary-4"><i class="fa fa-check"></i><b>1.12.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.13" data-path="1-viz.html"><a href="1-viz.html#conclusion-1"><i class="fa fa-check"></i><b>1.13</b> Conclusion</a><ul>
<li class="chapter" data-level="1.13.1" data-path="1-viz.html"><a href="1-viz.html#summary-table"><i class="fa fa-check"></i><b>1.13.1</b> Summary table</a></li>
<li class="chapter" data-level="1.13.2" data-path="1-viz.html"><a href="1-viz.html#function-argument-specification"><i class="fa fa-check"></i><b>1.13.2</b> Function argument specification</a></li>
<li class="chapter" data-level="1.13.3" data-path="1-viz.html"><a href="1-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>1.13.3</b> Additional resources</a></li>
<li class="chapter" data-level="1.13.4" data-path="1-viz.html"><a href="1-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>1.13.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-wrangling.html"><a href="2-wrangling.html"><i class="fa fa-check"></i><b>2</b> Tidyverse</a><ul>
<li class="chapter" data-level="2.1" data-path="2-wrangling.html"><a href="2-wrangling.html#piping"><i class="fa fa-check"></i><b>2.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="2.2" data-path="2-wrangling.html"><a href="2-wrangling.html#filter"><i class="fa fa-check"></i><b>2.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="2.3" data-path="2-wrangling.html"><a href="2-wrangling.html#summarize"><i class="fa fa-check"></i><b>2.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="2.4" data-path="2-wrangling.html"><a href="2-wrangling.html#groupby"><i class="fa fa-check"></i><b>2.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-wrangling.html"><a href="2-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>2.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-wrangling.html"><a href="2-wrangling.html#mutate"><i class="fa fa-check"></i><b>2.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="2.6" data-path="2-wrangling.html"><a href="2-wrangling.html#arrange"><i class="fa fa-check"></i><b>2.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="2.7" data-path="2-wrangling.html"><a href="2-wrangling.html#factors"><i class="fa fa-check"></i><b>2.7</b> Factors</a><ul>
<li class="chapter" data-level="2.7.1" data-path="2-wrangling.html"><a href="2-wrangling.html#the-forcats-package"><i class="fa fa-check"></i><b>2.7.1</b> The <strong>forcats</strong> package</a></li>
<li class="chapter" data-level="2.7.2" data-path="2-wrangling.html"><a href="2-wrangling.html#dropping-unused-levels"><i class="fa fa-check"></i><b>2.7.2</b> Dropping unused levels</a></li>
<li class="chapter" data-level="2.7.3" data-path="2-wrangling.html"><a href="2-wrangling.html#reorder-factors"><i class="fa fa-check"></i><b>2.7.3</b> Change order of the levels, principled</a></li>
<li class="chapter" data-level="2.7.4" data-path="2-wrangling.html"><a href="2-wrangling.html#change-order-of-the-levels-because-i-said-so"><i class="fa fa-check"></i><b>2.7.4</b> Change order of the levels, “because I said so”</a></li>
<li class="chapter" data-level="2.7.5" data-path="2-wrangling.html"><a href="2-wrangling.html#recode-the-levels"><i class="fa fa-check"></i><b>2.7.5</b> Recode the levels</a></li>
<li class="chapter" data-level="2.7.6" data-path="2-wrangling.html"><a href="2-wrangling.html#grow-a-factor"><i class="fa fa-check"></i><b>2.7.6</b> Grow a factor</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="2-wrangling.html"><a href="2-wrangling.html#character-vectors"><i class="fa fa-check"></i><b>2.8</b> Character Vectors</a><ul>
<li class="chapter" data-level="2.8.1" data-path="2-wrangling.html"><a href="2-wrangling.html#manipulating-character-vectors"><i class="fa fa-check"></i><b>2.8.1</b> Manipulating character vectors</a></li>
<li class="chapter" data-level="2.8.2" data-path="2-wrangling.html"><a href="2-wrangling.html#regular-expressions-resources"><i class="fa fa-check"></i><b>2.8.2</b> Regular expressions resources</a></li>
<li class="chapter" data-level="2.8.3" data-path="2-wrangling.html"><a href="2-wrangling.html#character-encoding-resources"><i class="fa fa-check"></i><b>2.8.3</b> Character encoding resources</a></li>
<li class="chapter" data-level="2.8.4" data-path="2-wrangling.html"><a href="2-wrangling.html#character-vectors-that-live-in-a-data-frame"><i class="fa fa-check"></i><b>2.8.4</b> Character vectors that live in a data frame</a></li>
<li class="chapter" data-level="2.8.5" data-path="2-wrangling.html"><a href="2-wrangling.html#regex-free-string-manipulation-with-stringr-and-tidyr"><i class="fa fa-check"></i><b>2.8.5</b> Regex-free string manipulation with stringr and tidyr</a></li>
<li class="chapter" data-level="2.8.6" data-path="2-wrangling.html"><a href="2-wrangling.html#detect-or-filter-on-a-target-string"><i class="fa fa-check"></i><b>2.8.6</b> Detect or filter on a target string</a></li>
<li class="chapter" data-level="2.8.7" data-path="2-wrangling.html"><a href="2-wrangling.html#string-splitting-by-delimiter"><i class="fa fa-check"></i><b>2.8.7</b> String splitting by delimiter</a></li>
<li class="chapter" data-level="2.8.8" data-path="2-wrangling.html"><a href="2-wrangling.html#substring-extraction-and-replacement-by-position"><i class="fa fa-check"></i><b>2.8.8</b> Substring extraction (and replacement) by position</a></li>
<li class="chapter" data-level="2.8.9" data-path="2-wrangling.html"><a href="2-wrangling.html#collapse-a-vector"><i class="fa fa-check"></i><b>2.8.9</b> Collapse a vector</a></li>
<li class="chapter" data-level="2.8.10" data-path="2-wrangling.html"><a href="2-wrangling.html#catenate-vectors"><i class="fa fa-check"></i><b>2.8.10</b> Create a character vector by catenating multiple vectors</a></li>
<li class="chapter" data-level="2.8.11" data-path="2-wrangling.html"><a href="2-wrangling.html#substring-replacement"><i class="fa fa-check"></i><b>2.8.11</b> Substring replacement</a></li>
<li class="chapter" data-level="2.8.12" data-path="2-wrangling.html"><a href="2-wrangling.html#regular-expressions-with-stringr"><i class="fa fa-check"></i><b>2.8.12</b> Regular expressions with stringr</a></li>
<li class="chapter" data-level="2.8.13" data-path="2-wrangling.html"><a href="2-wrangling.html#characters-with-special-meaning"><i class="fa fa-check"></i><b>2.8.13</b> Characters with special meaning</a></li>
<li class="chapter" data-level="2.8.14" data-path="2-wrangling.html"><a href="2-wrangling.html#character-classes"><i class="fa fa-check"></i><b>2.8.14</b> Character classes</a></li>
<li class="chapter" data-level="2.8.15" data-path="2-wrangling.html"><a href="2-wrangling.html#quantifiers"><i class="fa fa-check"></i><b>2.8.15</b> Quantifiers</a></li>
<li class="chapter" data-level="2.8.16" data-path="2-wrangling.html"><a href="2-wrangling.html#escaping"><i class="fa fa-check"></i><b>2.8.16</b> Escaping</a></li>
<li class="chapter" data-level="2.8.17" data-path="2-wrangling.html"><a href="2-wrangling.html#groups-and-backreferences"><i class="fa fa-check"></i><b>2.8.17</b> Groups and backreferences</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="2-wrangling.html"><a href="2-wrangling.html#combining-data"><i class="fa fa-check"></i><b>2.9</b> Combining Data</a><ul>
<li class="chapter" data-level="2.9.1" data-path="2-wrangling.html"><a href="2-wrangling.html#bind"><i class="fa fa-check"></i><b>2.9.1</b> Bind</a></li>
<li class="chapter" data-level="2.9.2" data-path="2-wrangling.html"><a href="2-wrangling.html#joins-in-dplyr"><i class="fa fa-check"></i><b>2.9.2</b> Joins in dplyr</a></li>
<li class="chapter" data-level="2.9.3" data-path="2-wrangling.html"><a href="2-wrangling.html#joining"><i class="fa fa-check"></i><b>2.9.3</b> Joining</a></li>
<li class="chapter" data-level="2.9.4" data-path="2-wrangling.html"><a href="2-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>2.9.4</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="2.9.5" data-path="2-wrangling.html"><a href="2-wrangling.html#diff-key"><i class="fa fa-check"></i><b>2.9.5</b> Different “key” variable names</a></li>
<li class="chapter" data-level="2.9.6" data-path="2-wrangling.html"><a href="2-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>2.9.6</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="2.9.7" data-path="2-wrangling.html"><a href="2-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>2.9.7</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="2-wrangling.html"><a href="2-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>2.10</b> Other Verbs</a><ul>
<li class="chapter" data-level="2.10.1" data-path="2-wrangling.html"><a href="2-wrangling.html#select"><i class="fa fa-check"></i><b>2.10.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="2.10.2" data-path="2-wrangling.html"><a href="2-wrangling.html#rename"><i class="fa fa-check"></i><b>2.10.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="2.10.3" data-path="2-wrangling.html"><a href="2-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>2.10.3</b> <code>top_n</code> values of a variable</a></li>
<li class="chapter" data-level="2.10.4" data-path="2-wrangling.html"><a href="2-wrangling.html#slice-and-pull-and"><i class="fa fa-check"></i><b>2.10.4</b> <code>slice</code> and <code>pull</code> and <code>[]</code></a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="2-wrangling.html"><a href="2-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>2.11</b> Conclusion</a><ul>
<li class="chapter" data-level="2.11.1" data-path="2-wrangling.html"><a href="2-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>2.11.1</b> Summary table</a></li>
<li class="chapter" data-level="2.11.2" data-path="2-wrangling.html"><a href="2-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>2.11.2</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="2-wrangling.html"><a href="2-wrangling.html#tidy"><i class="fa fa-check"></i><b>2.12</b> Tidy</a></li>
<li class="chapter" data-level="2.13" data-path="2-wrangling.html"><a href="2-wrangling.html#csv"><i class="fa fa-check"></i><b>2.13</b> Importing data</a></li>
<li class="chapter" data-level="2.14" data-path="2-wrangling.html"><a href="2-wrangling.html#web-scraping"><i class="fa fa-check"></i><b>2.14</b> Web scraping</a><ul>
<li class="chapter" data-level="2.14.1" data-path="2-wrangling.html"><a href="2-wrangling.html#html"><i class="fa fa-check"></i><b>2.14.1</b> HTML</a></li>
<li class="chapter" data-level="2.14.2" data-path="2-wrangling.html"><a href="2-wrangling.html#the-rvest-package"><i class="fa fa-check"></i><b>2.14.2</b> The rvest package</a></li>
<li class="chapter" data-level="2.14.3" data-path="2-wrangling.html"><a href="2-wrangling.html#css-selectors"><i class="fa fa-check"></i><b>2.14.3</b> CSS selectors</a></li>
<li class="chapter" data-level="2.14.4" data-path="2-wrangling.html"><a href="2-wrangling.html#json"><i class="fa fa-check"></i><b>2.14.4</b> JSON</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="2-wrangling.html"><a href="2-wrangling.html#tidy-data-ex"><i class="fa fa-check"></i><b>2.15</b> “Tidy” data</a><ul>
<li class="chapter" data-level="2.15.1" data-path="2-wrangling.html"><a href="2-wrangling.html#tidy-definition"><i class="fa fa-check"></i><b>2.15.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="2.15.2" data-path="2-wrangling.html"><a href="2-wrangling.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>2.15.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="2.15.3" data-path="2-wrangling.html"><a href="2-wrangling.html#nycflights13-package-1"><i class="fa fa-check"></i><b>2.15.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="2.16" data-path="2-wrangling.html"><a href="2-wrangling.html#case-study-tidy"><i class="fa fa-check"></i><b>2.16</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="2.17" data-path="2-wrangling.html"><a href="2-wrangling.html#tidyverse-package"><i class="fa fa-check"></i><b>2.17</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="2.18" data-path="2-wrangling.html"><a href="2-wrangling.html#conclusion-3"><i class="fa fa-check"></i><b>2.18</b> Conclusion</a><ul>
<li class="chapter" data-level="2.18.1" data-path="2-wrangling.html"><a href="2-wrangling.html#additional-resources-3"><i class="fa fa-check"></i><b>2.18.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html"><i class="fa fa-check"></i><b>3</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="3.1" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#what-is-a-causal-effect"><i class="fa fa-check"></i><b>3.1</b> What is a causal effect?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#everything-is-a-missing-data-problem"><i class="fa fa-check"></i><b>3.1.1</b> Everything is a missing data problem</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#potential-outcomes-introduction-to-the-rubin-table"><i class="fa fa-check"></i><b>3.1.2</b> Potential outcomes: introduction to the Rubin Table</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#estimands"><i class="fa fa-check"></i><b>3.1.3</b> Estimands</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#the-infinite-rubin-table-many-kinds-of-missing-data"><i class="fa fa-check"></i><b>3.1.4</b> The infinite Rubin Table: many kinds of missing data</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#how-do-we-fill-in-the-missing-values"><i class="fa fa-check"></i><b>3.2</b> How do we fill in the missing values?</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#average-treatment-effect"><i class="fa fa-check"></i><b>3.2.1</b> Average treatment effect</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#the-assignment-mechanism"><i class="fa fa-check"></i><b>3.2.2</b> The assignment mechanism</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#uncertainty-and-permutation-tests"><i class="fa fa-check"></i><b>3.2.3</b> Uncertainty and permutation tests</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#everything-is-a-missing-data-problem-revisited-internal-and-external-validity"><i class="fa fa-check"></i><b>3.2.4</b> Everything is a missing data problem revisited: Internal and external validity</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#more-complex-models-for-causal-inference"><i class="fa fa-check"></i><b>3.2.5</b> More complex models for causal inference</a></li>
<li class="chapter" data-level="3.2.6" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#causal-inference-and-prediction"><i class="fa fa-check"></i><b>3.2.6</b> Causal inference and prediction</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#other-issues-with-causal-inference"><i class="fa fa-check"></i><b>3.3</b> Other issues with causal inference</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#no-causation-without-manipulation"><i class="fa fa-check"></i><b>3.3.1</b> No causation without manipulation</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>3.3.2</b> Stable unit treatment value assumption (SUTVA)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#conclusion-4"><i class="fa fa-check"></i><b>3.4</b> Conclusion</a></li>
<li class="chapter" data-level="3.5" data-path="3-rubin-causal-model.html"><a href="3-rubin-causal-model.html#references"><i class="fa fa-check"></i><b>3.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-functions.html"><a href="4-functions.html"><i class="fa fa-check"></i><b>4</b> Functions</a><ul>
<li class="chapter" data-level="4.1" data-path="4-functions.html"><a href="4-functions.html#part-1"><i class="fa fa-check"></i><b>4.1</b> Part 1</a><ul>
<li class="chapter" data-level="4.1.1" data-path="4-functions.html"><a href="4-functions.html#get-something-that-works"><i class="fa fa-check"></i><b>4.1.1</b> Get something that works</a></li>
<li class="chapter" data-level="4.1.2" data-path="4-functions.html"><a href="4-functions.html#skateboard-perfectly-formed-rear-view-mirror"><i class="fa fa-check"></i><b>4.1.2</b> Skateboard &gt;&gt; perfectly formed rear-view mirror</a></li>
<li class="chapter" data-level="4.1.3" data-path="4-functions.html"><a href="4-functions.html#turn-the-working-interactive-code-into-a-function"><i class="fa fa-check"></i><b>4.1.3</b> Turn the working interactive code into a function</a></li>
<li class="chapter" data-level="4.1.4" data-path="4-functions.html"><a href="4-functions.html#test-your-function"><i class="fa fa-check"></i><b>4.1.4</b> Test your function</a></li>
<li class="chapter" data-level="4.1.5" data-path="4-functions.html"><a href="4-functions.html#check-the-validity-of-arguments"><i class="fa fa-check"></i><b>4.1.5</b> Check the validity of arguments</a></li>
<li class="chapter" data-level="4.1.6" data-path="4-functions.html"><a href="4-functions.html#wrap-up-and-whats-next"><i class="fa fa-check"></i><b>4.1.6</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-functions.html"><a href="4-functions.html#part-2"><i class="fa fa-check"></i><b>4.2</b> Part 2</a><ul>
<li class="chapter" data-level="4.2.1" data-path="4-functions.html"><a href="4-functions.html#load-the-gapminder-data"><i class="fa fa-check"></i><b>4.2.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="4.2.2" data-path="4-functions.html"><a href="4-functions.html#restore-our-max-minus-min-function"><i class="fa fa-check"></i><b>4.2.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="4.2.3" data-path="4-functions.html"><a href="4-functions.html#generalize-our-function-to-other-quantiles"><i class="fa fa-check"></i><b>4.2.3</b> Generalize our function to other quantiles</a></li>
<li class="chapter" data-level="4.2.4" data-path="4-functions.html"><a href="4-functions.html#get-something-that-works-again"><i class="fa fa-check"></i><b>4.2.4</b> Get something that works, again</a></li>
<li class="chapter" data-level="4.2.5" data-path="4-functions.html"><a href="4-functions.html#turn-the-working-interactive-code-into-a-function-again"><i class="fa fa-check"></i><b>4.2.5</b> Turn the working interactive code into a function, again</a></li>
<li class="chapter" data-level="4.2.6" data-path="4-functions.html"><a href="4-functions.html#argument-names-freedom-and-conventions"><i class="fa fa-check"></i><b>4.2.6</b> Argument names: freedom and conventions</a></li>
<li class="chapter" data-level="4.2.7" data-path="4-functions.html"><a href="4-functions.html#what-a-function-returns"><i class="fa fa-check"></i><b>4.2.7</b> What a function returns</a></li>
<li class="chapter" data-level="4.2.8" data-path="4-functions.html"><a href="4-functions.html#default-values-freedom-to-not-specify-the-arguments"><i class="fa fa-check"></i><b>4.2.8</b> Default values: freedom to NOT specify the arguments</a></li>
<li class="chapter" data-level="4.2.9" data-path="4-functions.html"><a href="4-functions.html#wrap-up-and-whats-next-1"><i class="fa fa-check"></i><b>4.2.9</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-functions.html"><a href="4-functions.html#part-3"><i class="fa fa-check"></i><b>4.3</b> Part 3</a><ul>
<li class="chapter" data-level="4.3.1" data-path="4-functions.html"><a href="4-functions.html#load-the-gapminder-data-1"><i class="fa fa-check"></i><b>4.3.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="4.3.2" data-path="4-functions.html"><a href="4-functions.html#restore-our-max-minus-min-function-1"><i class="fa fa-check"></i><b>4.3.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="4.3.3" data-path="4-functions.html"><a href="4-functions.html#be-proactive-about-nas"><i class="fa fa-check"></i><b>4.3.3</b> Be proactive about <code>NA</code>s</a></li>
<li class="chapter" data-level="4.3.4" data-path="4-functions.html"><a href="4-functions.html#the-useful-but-mysterious-...-argument"><i class="fa fa-check"></i><b>4.3.4</b> The useful but mysterious <code>...</code> argument</a></li>
<li class="chapter" data-level="4.3.5" data-path="4-functions.html"><a href="4-functions.html#use-testthat-for-formal-unit-tests"><i class="fa fa-check"></i><b>4.3.5</b> Use testthat for formal unit tests</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4-functions.html"><a href="4-functions.html#list-columns-and-map_-functions"><i class="fa fa-check"></i><b>4.4</b> List columns and <code>map_*</code> functions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-functions.html"><a href="4-functions.html#what-are-list-columns"><i class="fa fa-check"></i><b>4.4.1</b> What are list columns?</a></li>
<li class="chapter" data-level="4.4.2" data-path="4-functions.html"><a href="4-functions.html#creating-list-columns-with-mutate"><i class="fa fa-check"></i><b>4.4.2</b> Creating list columns with <code>mutate()</code></a></li>
<li class="chapter" data-level="4.4.3" data-path="4-functions.html"><a href="4-functions.html#map_-functions"><i class="fa fa-check"></i><b>4.4.3</b> <code>map_*</code> functions</a></li>
<li class="chapter" data-level="4.4.4" data-path="4-functions.html"><a href="4-functions.html#using-map_-functions-to-create-list-columns"><i class="fa fa-check"></i><b>4.4.4</b> Using <code>map_*</code> functions to create list columns</a></li>
<li class="chapter" data-level="4.4.5" data-path="4-functions.html"><a href="4-functions.html#practice-with-map_-functions-and-list-columns"><i class="fa fa-check"></i><b>4.4.5</b> Practice with <code>map_*</code> functions and list columns</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-probability.html"><a href="5-probability.html"><i class="fa fa-check"></i><b>5</b> Probability</a><ul>
<li class="chapter" data-level="5.1" data-path="5-probability.html"><a href="5-probability.html#basicsOfProbability"><i class="fa fa-check"></i><b>5.1</b> Defining probability</a><ul>
<li class="chapter" data-level="5.1.1" data-path="5-probability.html"><a href="5-probability.html#intro-questions"><i class="fa fa-check"></i><b>5.1.1</b> Intro Questions</a></li>
<li class="chapter" data-level="5.1.2" data-path="5-probability.html"><a href="5-probability.html#probability-1"><i class="fa fa-check"></i><b>5.1.2</b> Probability</a></li>
<li class="chapter" data-level="5.1.3" data-path="5-probability.html"><a href="5-probability.html#disjoint-or-mutually-exclusive-outcomes"><i class="fa fa-check"></i><b>5.1.3</b> Disjoint or mutually exclusive outcomes</a></li>
<li class="chapter" data-level="5.1.4" data-path="5-probability.html"><a href="5-probability.html#probabilities-when-events-are-not-disjoint"><i class="fa fa-check"></i><b>5.1.4</b> Probabilities when events are not disjoint</a></li>
<li class="chapter" data-level="5.1.5" data-path="5-probability.html"><a href="5-probability.html#probability-distributions"><i class="fa fa-check"></i><b>5.1.5</b> Probability distributions</a></li>
<li class="chapter" data-level="5.1.6" data-path="5-probability.html"><a href="5-probability.html#complement-of-an-event"><i class="fa fa-check"></i><b>5.1.6</b> Complement of an event</a></li>
<li class="chapter" data-level="5.1.7" data-path="5-probability.html"><a href="5-probability.html#probabilityIndependence"><i class="fa fa-check"></i><b>5.1.7</b> Independence</a></li>
<li class="chapter" data-level="5.1.8" data-path="5-probability.html"><a href="5-probability.html#conditionalProbabilitySection"><i class="fa fa-check"></i><b>5.1.8</b> Conditional probability</a></li>
<li class="chapter" data-level="5.1.9" data-path="5-probability.html"><a href="5-probability.html#marginalAndJointProbabilities"><i class="fa fa-check"></i><b>5.1.9</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="5.1.10" data-path="5-probability.html"><a href="5-probability.html#defining-conditional-probability"><i class="fa fa-check"></i><b>5.1.10</b> Defining conditional probability</a></li>
<li class="chapter" data-level="5.1.11" data-path="5-probability.html"><a href="5-probability.html#smallpox-in-boston-1721"><i class="fa fa-check"></i><b>5.1.11</b> Smallpox in Boston, 1721</a></li>
<li class="chapter" data-level="5.1.12" data-path="5-probability.html"><a href="5-probability.html#general-multiplication-rule"><i class="fa fa-check"></i><b>5.1.12</b> General multiplication rule</a></li>
<li class="chapter" data-level="5.1.13" data-path="5-probability.html"><a href="5-probability.html#tree-diagrams"><i class="fa fa-check"></i><b>5.1.13</b> Tree diagrams</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5-probability.html"><a href="5-probability.html#randomVariablesSection"><i class="fa fa-check"></i><b>5.2</b> Random variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-probability.html"><a href="5-probability.html#expectation"><i class="fa fa-check"></i><b>5.2.1</b> Expectation</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-probability.html"><a href="5-probability.html#variability-in-random-variables"><i class="fa fa-check"></i><b>5.2.2</b> Variability in random variables</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-probability.html"><a href="5-probability.html#linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>5.2.3</b> Linear combinations of random variables</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-probability.html"><a href="5-probability.html#variability-in-linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>5.2.4</b> Variability in linear combinations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-probability.html"><a href="5-probability.html#appendixA"><i class="fa fa-check"></i><b>5.3</b> Statistical Background</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-probability.html"><a href="5-probability.html#appendix-stat-terms"><i class="fa fa-check"></i><b>5.3.1</b> Basic statistical terms</a></li>
<li class="chapter" data-level="5.3.2" data-path="5-probability.html"><a href="5-probability.html#appendix-normal-curve"><i class="fa fa-check"></i><b>5.3.2</b> Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5-probability.html"><a href="5-probability.html#bayess-theorem"><i class="fa fa-check"></i><b>5.4</b> Bayes’s Theorem</a></li>
<li class="chapter" data-level="5.5" data-path="5-probability.html"><a href="5-probability.html#conditional-probability"><i class="fa fa-check"></i><b>5.5</b> Conditional probability</a></li>
<li class="chapter" data-level="5.6" data-path="5-probability.html"><a href="5-probability.html#conjoint-probability"><i class="fa fa-check"></i><b>5.6</b> Conjoint probability</a></li>
<li class="chapter" data-level="5.7" data-path="5-probability.html"><a href="5-probability.html#the-cookie-problem"><i class="fa fa-check"></i><b>5.7</b> The cookie problem</a></li>
<li class="chapter" data-level="5.8" data-path="5-probability.html"><a href="5-probability.html#bayess-theorem-1"><i class="fa fa-check"></i><b>5.8</b> Bayes’s Theorem</a></li>
<li class="chapter" data-level="5.9" data-path="5-probability.html"><a href="5-probability.html#the-diachronic-interpretation"><i class="fa fa-check"></i><b>5.9</b> The diachronic interpretation</a></li>
<li class="chapter" data-level="5.10" data-path="5-probability.html"><a href="5-probability.html#the-mm-problem"><i class="fa fa-check"></i><b>5.10</b> The M&amp;M problem</a></li>
<li class="chapter" data-level="5.11" data-path="5-probability.html"><a href="5-probability.html#the-monty-hall-problem"><i class="fa fa-check"></i><b>5.11</b> The Monty Hall problem</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-sampling.html"><a href="6-sampling.html"><i class="fa fa-check"></i><b>6</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="6-sampling.html"><a href="6-sampling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="6.1" data-path="6-sampling.html"><a href="6-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>6.1</b> Sampling urn activity</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-sampling.html"><a href="6-sampling.html#what-proportion-of-this-urns-balls-are-red"><i class="fa fa-check"></i><b>6.1.1</b> What proportion of this urn’s balls are red?</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-sampling.html"><a href="6-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>6.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-sampling.html"><a href="6-sampling.html#student-shovels"><i class="fa fa-check"></i><b>6.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-sampling.html"><a href="6-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>6.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-sampling.html"><a href="6-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>6.2</b> Virtual sampling</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-sampling.html"><a href="6-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>6.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-sampling.html"><a href="6-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>6.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-sampling.html"><a href="6-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>6.2.3</b> Using the virtual shovel 1,000 times</a></li>
<li class="chapter" data-level="6.2.4" data-path="6-sampling.html"><a href="6-sampling.html#different-shovels"><i class="fa fa-check"></i><b>6.2.4</b> Using different shovels</a></li>
<li class="chapter" data-level="6.2.5" data-path="6-sampling.html"><a href="6-sampling.html#using-many-shovels-at-once"><i class="fa fa-check"></i><b>6.2.5</b> Using many shovels at once</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-sampling.html"><a href="6-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>6.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-sampling.html"><a href="6-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>6.3.1</b> Terminology and notation</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-sampling.html"><a href="6-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>6.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-sampling.html"><a href="6-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>6.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-sampling.html"><a href="6-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>6.4</b> Case study: Polls</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-sampling.html"><a href="6-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>6.4.1</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-sampling.html"><a href="6-sampling.html#conclusion-5"><i class="fa fa-check"></i><b>6.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html"><i class="fa fa-check"></i><b>7</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="7.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>7.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>7.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>7.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>7.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>7.1.4</b> What did we just do?</a></li>
<li class="chapter" data-level="7.1.5" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>7.1.5</b> Virtually resampling once</a></li>
<li class="chapter" data-level="7.1.6" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#bootstrap-35-replicates"><i class="fa fa-check"></i><b>7.1.6</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="7.1.7" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>7.1.7</b> Virtually resampling 1,000 times</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>7.2</b> Measuring uncertainty with confidence intervals</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>7.2.1</b> Percentile method</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>7.2.2</b> Standard error method</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>7.2.3</b> Interpreting confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>7.3</b> Width of confidence intervals</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#impact-of-confidence-level"><i class="fa fa-check"></i><b>7.3.1</b> Impact of confidence level</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#fitting-multiple-models-using-map"><i class="fa fa-check"></i><b>7.3.2</b> Fitting multiple models using <code>map()</code></a></li>
<li class="chapter" data-level="7.3.3" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#impact-of-sample-size"><i class="fa fa-check"></i><b>7.3.3</b> Impact of sample size</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut"><i class="fa fa-check"></i><b>7.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="7.5" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>7.5</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="7.5.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>7.5.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="7.5.2" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>7.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="7.5.3" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>7.5.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="7.5.4" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut-1"><i class="fa fa-check"></i><b>7.5.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>7.6</b> Conclusion</a><ul>
<li class="chapter" data-level="7.6.1" data-path="7-confidence-intervals.html"><a href="7-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>7.6.1</b> Comparing bootstrap and sampling distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-regression.html"><a href="8-regression.html"><i class="fa fa-check"></i><b>8</b> Regression</a><ul>
<li class="chapter" data-level="" data-path="8-regression.html"><a href="8-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="8.1" data-path="8-regression.html"><a href="8-regression.html#model1"><i class="fa fa-check"></i><b>8.1</b> Teaching evaluations: one numerical explanatory variable</a><ul>
<li class="chapter" data-level="8.1.1" data-path="8-regression.html"><a href="8-regression.html#model1EDA"><i class="fa fa-check"></i><b>8.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="8.1.2" data-path="8-regression.html"><a href="8-regression.html#model1table"><i class="fa fa-check"></i><b>8.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="8.1.3" data-path="8-regression.html"><a href="8-regression.html#interpreting-regression-coefficients"><i class="fa fa-check"></i><b>8.1.3</b> Interpreting regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8-regression.html"><a href="8-regression.html#uncertainty-in-simple-linear-regressions"><i class="fa fa-check"></i><b>8.2</b> Uncertainty in simple linear regressions</a><ul>
<li class="chapter" data-level="8.2.1" data-path="8-regression.html"><a href="8-regression.html#using-lm-and-tidy-as-a-shortcut-2"><i class="fa fa-check"></i><b>8.2.1</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="8.2.2" data-path="8-regression.html"><a href="8-regression.html#model1points"><i class="fa fa-check"></i><b>8.2.2</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8-regression.html"><a href="8-regression.html#model2"><i class="fa fa-check"></i><b>8.3</b> Life expectancy: one categorical explanatory variable</a><ul>
<li class="chapter" data-level="8.3.1" data-path="8-regression.html"><a href="8-regression.html#model2EDA"><i class="fa fa-check"></i><b>8.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="8.3.2" data-path="8-regression.html"><a href="8-regression.html#model2table"><i class="fa fa-check"></i><b>8.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="8.3.3" data-path="8-regression.html"><a href="8-regression.html#model2points"><i class="fa fa-check"></i><b>8.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8-regression.html"><a href="8-regression.html#case-study-2018-gubernatorial-forecasts"><i class="fa fa-check"></i><b>8.4</b> Case study: 2018 gubernatorial forecasts</a><ul>
<li class="chapter" data-level="8.4.1" data-path="8-regression.html"><a href="8-regression.html#fitting-multiple-models-using-map-1"><i class="fa fa-check"></i><b>8.4.1</b> Fitting multiple models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8-regression.html"><a href="8-regression.html#leastsquares"><i class="fa fa-check"></i><b>8.5</b> Appendix: Best-fitting line</a></li>
<li class="chapter" data-level="8.6" data-path="8-regression.html"><a href="8-regression.html#conclusion-6"><i class="fa fa-check"></i><b>8.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html"><i class="fa fa-check"></i><b>9</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model4"><i class="fa fa-check"></i><b>9.1</b> Teaching evaluations revisited: one numerical and one categorical explanatory variable</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>9.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>9.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#interpreting-regression-coefficients-with-interactions"><i class="fa fa-check"></i><b>9.1.3</b> Interpreting regression coefficients with interactions</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>9.1.4</b> Parallel slopes model</a></li>
<li class="chapter" data-level="9.1.5" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>9.1.5</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model3"><i class="fa fa-check"></i><b>9.2</b> Credit card debt: two numerical explanatory variables</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>9.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>9.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>9.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#seattle-house-prices"><i class="fa fa-check"></i><b>9.3</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>9.3.1</b> Exploratory data analysis: Part I</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#house-prices-EDA-II"><i class="fa fa-check"></i><b>9.3.2</b> Exploratory data analysis: Part II</a></li>
<li class="chapter" data-level="9.3.3" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#house-prices-regression"><i class="fa fa-check"></i><b>9.3.3</b> Regression modeling</a></li>
<li class="chapter" data-level="9.3.4" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>9.3.4</b> Making predictions</a></li>
<li class="chapter" data-level="9.3.5" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#fitting-many-models-using-map"><i class="fa fa-check"></i><b>9.3.5</b> Fitting many models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#other-topics"><i class="fa fa-check"></i><b>9.4</b> Other topics</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>9.4.1</b> Model selection</a></li>
<li class="chapter" data-level="9.4.2" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>9.4.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="9.4.3" data-path="9-multiple-regression.html"><a href="9-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>9.4.3</b> Simpson’s Paradox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-classification.html"><a href="10-classification.html"><i class="fa fa-check"></i><b>10</b> Classification</a><ul>
<li class="chapter" data-level="" data-path="10-classification.html"><a href="10-classification.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-classification.html"><a href="10-classification.html#logistic-regression"><i class="fa fa-check"></i><b>10.1</b> Logistic regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-classification.html"><a href="10-classification.html#what-is-logistic-regression"><i class="fa fa-check"></i><b>10.1.1</b> What is logistic regression?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-classification.html"><a href="10-classification.html#house-elections-exploratory-data-analysis"><i class="fa fa-check"></i><b>10.1.2</b> House elections: exploratory data analysis</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-classification.html"><a href="10-classification.html#one-categorical-explanatory-variable"><i class="fa fa-check"></i><b>10.1.3</b> One categorical explanatory variable</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-classification.html"><a href="10-classification.html#observedfitted-values-and-residuals"><i class="fa fa-check"></i><b>10.1.4</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="10.1.5" data-path="10-classification.html"><a href="10-classification.html#one-numerical-explanatory-variable"><i class="fa fa-check"></i><b>10.1.5</b> One numerical explanatory variable</a></li>
<li class="chapter" data-level="10.1.6" data-path="10-classification.html"><a href="10-classification.html#one-numerical-and-one-categorical-explanatory-variable"><i class="fa fa-check"></i><b>10.1.6</b> One numerical and one categorical explanatory variable</a></li>
<li class="chapter" data-level="10.1.7" data-path="10-classification.html"><a href="10-classification.html#fitting-many-models-using-map-1"><i class="fa fa-check"></i><b>10.1.7</b> Fitting many models using <code>map()</code></a></li>
<li class="chapter" data-level="10.1.8" data-path="10-classification.html"><a href="10-classification.html#professional-models"><i class="fa fa-check"></i><b>10.1.8</b> Professional models</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-classification.html"><a href="10-classification.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>10.2</b> Classification and regression trees (CART)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-classification.html"><a href="10-classification.html#what-is-cart"><i class="fa fa-check"></i><b>10.2.1</b> What is CART?</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-classification.html"><a href="10-classification.html#one-categorical-explanatory-variable-1"><i class="fa fa-check"></i><b>10.2.2</b> One categorical explanatory variable</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-classification.html"><a href="10-classification.html#one-numerical-explanatory-variable-1"><i class="fa fa-check"></i><b>10.2.3</b> One numerical explanatory variable</a></li>
<li class="chapter" data-level="10.2.4" data-path="10-classification.html"><a href="10-classification.html#multiple-explanatory-variables"><i class="fa fa-check"></i><b>10.2.4</b> Multiple explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-classification.html"><a href="10-classification.html#random-forests"><i class="fa fa-check"></i><b>10.3</b> Random forests</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-classification.html"><a href="10-classification.html#what-are-random-forests"><i class="fa fa-check"></i><b>10.3.1</b> What are random forests?</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-classification.html"><a href="10-classification.html#fitting-random-forests"><i class="fa fa-check"></i><b>10.3.2</b> Fitting random forests</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-classification.html"><a href="10-classification.html#comparing-the-three-approaches"><i class="fa fa-check"></i><b>10.4</b> Comparing the three approaches</a><ul>
<li class="chapter" data-level="10.4.1" data-path="10-classification.html"><a href="10-classification.html#is-accuracy-the-right-measure"><i class="fa fa-check"></i><b>10.4.1</b> Is accuracy the right measure?</a></li>
<li class="chapter" data-level="10.4.2" data-path="10-classification.html"><a href="10-classification.html#modeling-for-prediction-vs.-explanation"><i class="fa fa-check"></i><b>10.4.2</b> Modeling for prediction vs. explanation</a></li>
<li class="chapter" data-level="10.4.3" data-path="10-classification.html"><a href="10-classification.html#out-of-sample-predictions"><i class="fa fa-check"></i><b>10.4.3</b> Out-of-sample predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-machine-learning.html"><a href="11-machine-learning.html"><i class="fa fa-check"></i><b>11</b> Machine Learning</a><ul>
<li class="chapter" data-level="11.1" data-path="11-machine-learning.html"><a href="11-machine-learning.html#the-process-of-machine-learning"><i class="fa fa-check"></i><b>11.1</b> The process of machine learning</a></li>
<li class="chapter" data-level="11.2" data-path="11-machine-learning.html"><a href="11-machine-learning.html#what-does-it-mean-for-a-model-to-be-good"><i class="fa fa-check"></i><b>11.2</b> What does it mean for a model to be “good?”</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-machine-learning.html"><a href="11-machine-learning.html#training-and-test-sets"><i class="fa fa-check"></i><b>11.2.1</b> Training and test sets</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-machine-learning.html"><a href="11-machine-learning.html#loss-function"><i class="fa fa-check"></i><b>11.2.2</b> The loss function</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-machine-learning.html"><a href="11-machine-learning.html#data-cooperative-congressional-election-study-cces"><i class="fa fa-check"></i><b>11.3</b> Data: Cooperative Congressional Election Study (CCES)</a></li>
<li class="chapter" data-level="11.4" data-path="11-machine-learning.html"><a href="11-machine-learning.html#the-modeling-process-using-tidymodels"><i class="fa fa-check"></i><b>11.4</b> The modeling process using <strong>tidymodels</strong></a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-machine-learning.html"><a href="11-machine-learning.html#parsnip-build-the-model"><i class="fa fa-check"></i><b>11.4.1</b> <strong>parsnip</strong>: build the model</a></li>
<li class="chapter" data-level="11.4.2" data-path="11-machine-learning.html"><a href="11-machine-learning.html#recipes-not-happening-here-folks"><i class="fa fa-check"></i><b>11.4.2</b> <strong>recipes</strong>: not happening here, folks</a></li>
<li class="chapter" data-level="11.4.3" data-path="11-machine-learning.html"><a href="11-machine-learning.html#rsample-initial-split"><i class="fa fa-check"></i><b>11.4.3</b> <strong>rsample</strong>: initial split</a></li>
<li class="chapter" data-level="11.4.4" data-path="11-machine-learning.html"><a href="11-machine-learning.html#fitting-the-model-once"><i class="fa fa-check"></i><b>11.4.4</b> Fitting the model once</a></li>
<li class="chapter" data-level="11.4.5" data-path="11-machine-learning.html"><a href="11-machine-learning.html#fitting-many-models-using-map-2"><i class="fa fa-check"></i><b>11.4.5</b> Fitting many models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-machine-learning.html"><a href="11-machine-learning.html#cross-validation"><i class="fa fa-check"></i><b>11.5</b> Cross validation</a><ul>
<li class="chapter" data-level="11.5.1" data-path="11-machine-learning.html"><a href="11-machine-learning.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>11.5.1</b> K-fold cross validation</a></li>
<li class="chapter" data-level="11.5.2" data-path="11-machine-learning.html"><a href="11-machine-learning.html#implementing-cross-validation-using-rsample"><i class="fa fa-check"></i><b>11.5.2</b> Implementing cross-validation using <strong>rsample</strong></a></li>
<li class="chapter" data-level="11.5.3" data-path="11-machine-learning.html"><a href="11-machine-learning.html#bootstrap"><i class="fa fa-check"></i><b>11.5.3</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="11-machine-learning.html"><a href="11-machine-learning.html#machine-learning-and-classification"><i class="fa fa-check"></i><b>11.6</b> Machine learning and classification</a></li>
<li class="chapter" data-level="11.7" data-path="11-machine-learning.html"><a href="11-machine-learning.html#conclusion-7"><i class="fa fa-check"></i><b>11.7</b> Conclusion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-productivity.html"><a href="A-productivity.html"><i class="fa fa-check"></i><b>A</b> Productivity</a><ul>
<li class="chapter" data-level="A.1" data-path="A-productivity.html"><a href="A-productivity.html#set-up"><i class="fa fa-check"></i><b>A.1</b> Set Up</a><ul>
<li class="chapter" data-level="A.1.1" data-path="A-productivity.html"><a href="A-productivity.html#terminal-on-mac"><i class="fa fa-check"></i><b>A.1.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="A.1.2" data-path="A-productivity.html"><a href="A-productivity.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>A.1.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="A.1.3" data-path="A-productivity.html"><a href="A-productivity.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>A.1.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="A.1.4" data-path="A-productivity.html"><a href="A-productivity.html#terminal-on-windows"><i class="fa fa-check"></i><b>A.1.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="A-productivity.html"><a href="A-productivity.html#unix"><i class="fa fa-check"></i><b>A.2</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="A.2.1" data-path="A-productivity.html"><a href="A-productivity.html#naming-convention"><i class="fa fa-check"></i><b>A.2.1</b> Naming convention</a></li>
<li class="chapter" data-level="A.2.2" data-path="A-productivity.html"><a href="A-productivity.html#the-terminal"><i class="fa fa-check"></i><b>A.2.2</b> The terminal</a></li>
<li class="chapter" data-level="A.2.3" data-path="A-productivity.html"><a href="A-productivity.html#filesystem"><i class="fa fa-check"></i><b>A.2.3</b> The filesystem</a></li>
<li class="chapter" data-level="A.2.4" data-path="A-productivity.html"><a href="A-productivity.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>A.2.4</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="A.2.5" data-path="A-productivity.html"><a href="A-productivity.html#the-home-directory"><i class="fa fa-check"></i><b>A.2.5</b> The home directory</a></li>
<li class="chapter" data-level="A.2.6" data-path="A-productivity.html"><a href="A-productivity.html#working-directory"><i class="fa fa-check"></i><b>A.2.6</b> Working directory</a></li>
<li class="chapter" data-level="A.2.7" data-path="A-productivity.html"><a href="A-productivity.html#paths"><i class="fa fa-check"></i><b>A.2.7</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="A-productivity.html"><a href="A-productivity.html#unix-commands"><i class="fa fa-check"></i><b>A.3</b> Unix commands</a><ul>
<li class="chapter" data-level="A.3.1" data-path="A-productivity.html"><a href="A-productivity.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>A.3.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="A.3.2" data-path="A-productivity.html"><a href="A-productivity.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>A.3.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="A.3.3" data-path="A-productivity.html"><a href="A-productivity.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>A.3.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
<li class="chapter" data-level="A.3.4" data-path="A-productivity.html"><a href="A-productivity.html#some-examples"><i class="fa fa-check"></i><b>A.3.4</b> Some examples</a></li>
<li class="chapter" data-level="A.3.5" data-path="A-productivity.html"><a href="A-productivity.html#more-unix-commands"><i class="fa fa-check"></i><b>A.3.5</b> More Unix commands</a></li>
<li class="chapter" data-level="A.3.6" data-path="A-productivity.html"><a href="A-productivity.html#advanced-unix"><i class="fa fa-check"></i><b>A.3.6</b> Advanced Unix</a></li>
<li class="chapter" data-level="A.3.7" data-path="A-productivity.html"><a href="A-productivity.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>A.3.7</b> File manipulation in R</a></li>
</ul></li>
<li class="chapter" data-level="A.4" data-path="A-productivity.html"><a href="A-productivity.html#git"><i class="fa fa-check"></i><b>A.4</b> Git and GitHub</a><ul>
<li class="chapter" data-level="A.4.1" data-path="A-productivity.html"><a href="A-productivity.html#github-accounts"><i class="fa fa-check"></i><b>A.4.1</b> GitHub accounts</a></li>
<li class="chapter" data-level="A.4.2" data-path="A-productivity.html"><a href="A-productivity.html#github-repos"><i class="fa fa-check"></i><b>A.4.2</b> GitHub repositories</a></li>
<li class="chapter" data-level="A.4.3" data-path="A-productivity.html"><a href="A-productivity.html#git-overview"><i class="fa fa-check"></i><b>A.4.3</b> Overview of Git</a></li>
<li class="chapter" data-level="A.4.4" data-path="A-productivity.html"><a href="A-productivity.html#rstudio-git"><i class="fa fa-check"></i><b>A.4.4</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="A.5" data-path="A-productivity.html"><a href="A-productivity.html#r"><i class="fa fa-check"></i><b>A.5</b> R</a><ul>
<li class="chapter" data-level="A.5.1" data-path="A-productivity.html"><a href="A-productivity.html#rstudio-projects"><i class="fa fa-check"></i><b>A.5.1</b> RStudio projects</a></li>
<li class="chapter" data-level="A.5.2" data-path="A-productivity.html"><a href="A-productivity.html#r-markdown"><i class="fa fa-check"></i><b>A.5.2</b> R markdown</a></li>
<li class="chapter" data-level="A.5.3" data-path="A-productivity.html"><a href="A-productivity.html#help-for-r"><i class="fa fa-check"></i><b>A.5.3</b> Help for R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-shiny.html"><a href="B-shiny.html"><i class="fa fa-check"></i><b>B</b> Shiny</a><ul>
<li class="chapter" data-level="B.1" data-path="B-shiny.html"><a href="B-shiny.html#helpful-resources"><i class="fa fa-check"></i><b>B.1</b> Helpful Resources</a></li>
<li class="chapter" data-level="B.2" data-path="B-shiny.html"><a href="B-shiny.html#set-up-and-getting-started"><i class="fa fa-check"></i><b>B.2</b> Set Up and Getting Started</a></li>
<li class="chapter" data-level="B.3" data-path="B-shiny.html"><a href="B-shiny.html#building-your-basic-app"><i class="fa fa-check"></i><b>B.3</b> Building Your Basic App</a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-shiny.html"><a href="B-shiny.html#setting-up-the-basic-ui"><i class="fa fa-check"></i><b>B.3.1</b> Setting Up the Basic UI</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-shiny.html"><a href="B-shiny.html#setting-up-the-server"><i class="fa fa-check"></i><b>B.3.2</b> Setting up the Server</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-shiny.html"><a href="B-shiny.html#organization"><i class="fa fa-check"></i><b>B.4</b> Organization</a></li>
<li class="chapter" data-level="B.5" data-path="B-shiny.html"><a href="B-shiny.html#customizations"><i class="fa fa-check"></i><b>B.5</b> Customizations</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-maps.html"><a href="C-maps.html"><i class="fa fa-check"></i><b>C</b> Maps</a><ul>
<li class="chapter" data-level="C.1" data-path="C-maps.html"><a href="C-maps.html#tidycensus"><i class="fa fa-check"></i><b>C.1</b> Tidycensus</a></li>
<li class="chapter" data-level="C.2" data-path="C-maps.html"><a href="C-maps.html#conceptual-introduction-to-mapping"><i class="fa fa-check"></i><b>C.2</b> Conceptual introduction to mapping</a><ul>
<li class="chapter" data-level="C.2.1" data-path="C-maps.html"><a href="C-maps.html#vector-versus-spatial-data"><i class="fa fa-check"></i><b>C.2.1</b> Vector versus spatial data</a></li>
<li class="chapter" data-level="C.2.2" data-path="C-maps.html"><a href="C-maps.html#sf-vs-sp"><i class="fa fa-check"></i><b>C.2.2</b> <strong>sf</strong> vs <strong>sp</strong></a></li>
<li class="chapter" data-level="C.2.3" data-path="C-maps.html"><a href="C-maps.html#shapefiles"><i class="fa fa-check"></i><b>C.2.3</b> Shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="C-maps.html"><a href="C-maps.html#mapping-with-tidycensus-and-geom_sf"><i class="fa fa-check"></i><b>C.3</b> Mapping with <strong>tidycensus</strong> and <code>geom_sf()</code></a><ul>
<li class="chapter" data-level="C.3.1" data-path="C-maps.html"><a href="C-maps.html#making-maps-pretty"><i class="fa fa-check"></i><b>C.3.1</b> Making maps pretty</a></li>
<li class="chapter" data-level="C.3.2" data-path="C-maps.html"><a href="C-maps.html#adding-back-alaska-and-hawaii"><i class="fa fa-check"></i><b>C.3.2</b> Adding back Alaska and Hawaii</a></li>
</ul></li>
<li class="chapter" data-level="C.4" data-path="C-maps.html"><a href="C-maps.html#faceting-maps"><i class="fa fa-check"></i><b>C.4</b> Faceting maps</a><ul>
<li class="chapter" data-level="C.4.1" data-path="C-maps.html"><a href="C-maps.html#transforming-and-mapping-the-data"><i class="fa fa-check"></i><b>C.4.1</b> Transforming and mapping the data</a></li>
</ul></li>
<li class="chapter" data-level="C.5" data-path="C-maps.html"><a href="C-maps.html#want-to-explore-further"><i class="fa fa-check"></i><b>C.5</b> Want to explore further?</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-animation.html"><a href="D-animation.html"><i class="fa fa-check"></i><b>D</b> Animation</a><ul>
<li class="chapter" data-level="D.1" data-path="D-animation.html"><a href="D-animation.html#gganimate-how-to-create-plots-with-beautiful-animation-in-r"><i class="fa fa-check"></i><b>D.1</b> gganimate: How to Create Plots with Beautiful Animation in R</a><ul>
<li class="chapter" data-level="D.1.1" data-path="D-animation.html"><a href="D-animation.html#prerequisites"><i class="fa fa-check"></i><b>D.1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="D.1.2" data-path="D-animation.html"><a href="D-animation.html#demo-dataset"><i class="fa fa-check"></i><b>D.1.2</b> Demo dataset</a></li>
<li class="chapter" data-level="D.1.3" data-path="D-animation.html"><a href="D-animation.html#static-plot"><i class="fa fa-check"></i><b>D.1.3</b> Static plot</a></li>
<li class="chapter" data-level="D.1.4" data-path="D-animation.html"><a href="D-animation.html#transition-through-distinct-states-in-time"><i class="fa fa-check"></i><b>D.1.4</b> Transition through distinct states in time</a></li>
<li class="chapter" data-level="D.1.5" data-path="D-animation.html"><a href="D-animation.html#reveal-data-along-a-given-dimension"><i class="fa fa-check"></i><b>D.1.5</b> Reveal data along a given dimension</a></li>
<li class="chapter" data-level="D.1.6" data-path="D-animation.html"><a href="D-animation.html#transition-between-several-distinct-stages-of-the-data"><i class="fa fa-check"></i><b>D.1.6</b> Transition between several distinct stages of the data</a></li>
<li class="chapter" data-level="D.1.7" data-path="D-animation.html"><a href="D-animation.html#read-more"><i class="fa fa-check"></i><b>D.1.7</b> Read more</a></li>
</ul></li>
<li class="chapter" data-level="D.2" data-path="D-animation.html"><a href="D-animation.html#how-to-save-your-animation"><i class="fa fa-check"></i><b>D.2</b> How to save your animation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preceptor’s Primer for Bayesian Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Probability</h1>
<p>Probability forms the foundation for statistics. You might already be
familiar with many aspects of probability, however, formalization of the
concepts is new for most. This chapter aims to introduce probability on
familiar terms using processes most people have seen before.</p>
<div id="basicsOfProbability" class="section level2">
<h2><span class="header-section-number">5.1</span> Defining probability</h2>
<div id="intro-questions" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Intro Questions</h3>
<p><strong>Q1</strong>: A “die”, the singular of dice, is a cube with six faces numbered <em>1</em>,
<em>2</em>, <em>3</em>, <em>4</em>, <em>5</em>, and <em>6</em>. What is the chance of getting <em>1</em> when
rolling a die</p>
<blockquote>
<p><strong>S1</strong>: If the die is
fair, then the chance of a <em>1</em> is as good as the chance of any other
number. Since there are six outcomes, the chance must be 1-in-6 or,
equivalently, <span class="math inline">\(1/6\)</span>.</p>
</blockquote>
<p><strong>Q2</strong>: What is the chance of getting a <em>1</em> or <em>2</em> in the next
roll</p>
<blockquote>
<p><strong>S2</strong>: <em>1</em> and <em>2</em>
constitute two of the six equally likely possible outcomes, so the
chance of getting one of these two outcomes must be <span class="math inline">\(2/6 = 1/3\)</span>.</p>
</blockquote>
<p><strong>Q3</strong>: What is the chance of getting either <em>1</em>, <em>2</em>, <em>3</em>, <em>4</em>, <em>5</em>, or <em>6</em> on
the next roll</p>
<blockquote>
<p><strong>S3</strong>: 100%. The outcome must be one of these numbers.</p>
</blockquote>
<p><strong>Q4</strong>: What is the chance of not rolling a <em>2</em></p>
<blockquote>
<p><strong>S4</strong>: Since the chance of rolling a <em>2</em> is <span class="math inline">\(1/6\)</span> or
<span class="math inline">\(16.\bar{6}\%\)</span>, the chance of not rolling a <em>2</em> must be
<span class="math inline">\(100\% - 16.\bar{6}\%=83.\bar{3}\%\)</span> or <span class="math inline">\(5/6\)</span>.</p>
<p>Alternatively, we could have noticed that not rolling a <em>2</em> is the same
as getting a <em>1</em>, <em>3</em>, <em>4</em>, <em>5</em>, or <em>6</em>, which makes up five of the six
equally likely outcomes and has probability <span class="math inline">\(5/6\)</span>.</p>
</blockquote>
<p><strong>Q5</strong>: Consider rolling two dice. If <span class="math inline">\(1/6^{th}\)</span> of the time the first die is a
<em>1</em> and <span class="math inline">\(1/6^{th}\)</span> of those times the second die is a <em>1</em>, what is the
chance of getting two <em>1</em>s</p>
<blockquote>
<p><strong>S</strong>: If <span class="math inline">\(16.\bar{6}\)</span>% of the time the first die is a <em>1</em>
and <span class="math inline">\(1/6^{th}\)</span> of <em>those</em> times the second die is also a <em>1</em>, then the
chance that both dice are <em>1</em> is <span class="math inline">\((1/6)\times (1/6)\)</span> or <span class="math inline">\(1/36\)</span>.</p>
</blockquote>
</div>
<div id="probability-1" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Probability</h3>
<p>We use probability to build tools to describe and understand apparent randomness. We often frame probability in terms of a <strong>random process</strong> giving rise to an outcome.</p>
<table>
<tbody>
<tr class="odd">
<td align="center">Roll a die</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="right"><em>1</em>, <em>2</em>, <em>3</em>, <em>4</em>, <em>5</em>, or <em>6</em></td>
</tr>
<tr class="even">
<td align="center">Flip a coin</td>
<td align="right"><span class="math inline">\(\rightarrow\)</span></td>
<td align="right"><em>H</em> or <em>T</em></td>
</tr>
</tbody>
</table>
<p>Rolling a die or flipping a coin is a seemingly random process and each
gives rise to an outcome.</p>
<p><strong>Definition of Probability</strong></p>
<blockquote>
<p>The <strong>probability</strong> of an outcome is the proportion of times the outcome would occur if
we observed the random process an infinite number of times.</p>
</blockquote>
<p>Probability is defined as a proportion, and it always takes values
between 0 and 1 (inclusively). It may also be displayed as a percentage
between 0% and 100%.</p>
<p>Probability can be illustrated by rolling a die many times. Let
<span class="math inline">\(\hat{p}_n\)</span> be the proportion of outcomes that are <em>1</em> after the first
<span class="math inline">\(n\)</span> rolls. As the number of rolls increases, <span class="math inline">\(\hat{p}_n\)</span> will converge
to the probability of rolling a <em>1</em>, <span class="math inline">\(p = 1/6\)</span>.
Figure <a href="5-probability.html#dieProp" reference-type="ref" reference="dieProp">1.1</a> shows
this convergence for 100,000 die rolls. The tendency of <span class="math inline">\(\hat{p}_n\)</span> to
stabilize around <span class="math inline">\(p\)</span> is described by the <strong>Law of Large Numbers</strong>.</p>
<div class="figure">
<img src="images/dieProp.png" id="dieProp" style="width:80.0%" alt="" />
<p class="caption">The fraction of die rolls that are 1 at each stage in a simulation.
The proportion tends to get closer to the probability
<span class="math inline">\(1/6 \approx 0.167\)</span> as the number of rolls
increases.<span label="dieProp"></span></p>
</div>
<!-- Replace the above with some R code. Should eventually by an interactive display which allows the reader to try different things. For example, don't some processes converse faster than others? Or is that too advanced for the first page? -->
<p><strong>Definition of Law of Large Numbers</strong></p>
<blockquote>
<p>As more observations are collected, the proportion <span class="math inline">\(\hat{p}_n\)</span> of
occurrences with a particular outcome converges to the probability <span class="math inline">\(p\)</span>
of that outcome.</p>
</blockquote>
<!-- The references in this chapters are different from the references elsewhere. What are current best practices? -->
<p>Occasionally the proportion will veer off from the probability and
appear to defy the Law of Large Numbers, as <span class="math inline">\(\hat{p}_n\)</span> does many times
in Figure <a href="5-probability.html#dieProp" reference-type="ref" reference="dieProp">1.1</a>.
However, these deviations become smaller as the number of rolls
increases.</p>
<p>Above we write <span class="math inline">\(p\)</span> as the probability of rolling a <em>1</em>. We can also
write this probability as <span class="math display">\[\begin{aligned}
P(\text{rolling a 1})\end{aligned}\]</span> As we become more
comfortable with this notation, we will abbreviate it further. For
instance, if it is clear that the process is “rolling a die”, we could
abbreviate <span class="math inline">\(P(\)</span>rolling a <em>1</em><span class="math inline">\()\)</span> as <span class="math inline">\(P(\)</span><em>1</em><span class="math inline">\()\)</span>. It can be helpful to model a process as random even if it is not truly random.</p>
<!-- The above math notation seems to use way too many dollar signs. Are they really necessary? -->
</div>
<div id="disjoint-or-mutually-exclusive-outcomes" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Disjoint or mutually exclusive outcomes</h3>
<p>Two outcomes are called <strong>disjoint</strong> or <strong>mutually exclusive</strong> if they cannot both happen. For instance, if
we roll a die, the outcomes <em>1</em> and <em>2</em> are disjoint since they cannot
both occur. On the other hand, the outcomes <em>1</em> and “rolling an odd
number” are not disjoint since both occur if the outcome of the roll is
a <em>1</em>. The terms <em>disjoint</em> and <em>mutually exclusive</em> are equivalent and
interchangeable.</p>
<p>Calculating the probability of disjoint outcomes is easy. When rolling a
die, the outcomes <em>1</em> and <em>2</em> are disjoint, and we compute the
probability that one of these outcomes will occur by adding their
separate probabilities:</p>
<p><span class="math display">\[\begin{aligned}
P(\text{1 or 2}) = P(\text{1})+P(\text{2}) = 1/6 + 1/6 = 1/3
\end{aligned}\]</span></p>
<p>The <strong>Addition Rule</strong> guarantees the accuracy of this approach when the outcomes are disjoint.</p>
</div>
<div id="probabilities-when-events-are-not-disjoint" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Probabilities when events are not disjoint</h3>
<p>Let’s consider calculations for two events that are not disjoint in the
context of a deck of cards.</p>
<table>
<caption>Representations of the 52 unique cards in a
deck.<span label="deckOfCards"></span></caption>
<tbody>
<tr class="odd">
<td align="center"><em>2<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>3<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>4<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>5<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>6<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>7<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>8<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>9<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>10<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>J<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>Q<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>K<span class="math inline">\(\clubsuit\)</span></em></td>
<td align="center"><em>A<span class="math inline">\(\clubsuit\)</span></em></td>
</tr>
<tr class="even">
<td align="center"><em>2<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>3<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>4<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>5<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>6<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>7<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>8<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>9<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>10<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>J<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>Q<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>K<span class="math inline">\(\diamondsuit\)</span></em></td>
<td align="center"><em>A<span class="math inline">\(\diamondsuit\)</span></em></td>
</tr>
<tr class="odd">
<td align="center"><em>2<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>3<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>4<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>5<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>6<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>7<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>8<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>9<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>10<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>J<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>Q<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>K<span class="math inline">\(\heartsuit\)</span></em></td>
<td align="center"><em>A<span class="math inline">\(\heartsuit\)</span></em></td>
</tr>
<tr class="even">
<td align="center"><em>2<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>3<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>4<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>5<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>6<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>7<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>8<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>9<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>10<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>J<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>Q<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>K<span class="math inline">\(\spadesuit\)</span></em></td>
<td align="center"><em>A<span class="math inline">\(\spadesuit\)</span></em></td>
</tr>
</tbody>
</table>
<p><strong>Venn diagrams</strong> are useful when outcomes can be categorized as “in” or “out” for two or
three variables, attributes, or random processes. The Venn diagram in
Figure <a href="5-probability.html#venn" reference-type="ref" reference="venn">1.3</a> uses a circle
to represent diamonds and another to represent face cards. If a card is
both a diamond and a face card, it falls into the intersection of the
circles. If it is a diamond but not a face card, it will be in part of
the left circle that is not in the right circle (and so on). The total
number of cards that are diamonds is given by the total number of cards
in the diamonds circle: <span class="math inline">\(10+3=13\)</span>. The probabilities are also shown
(e.g. <span class="math inline">\(10/52 = 0.1923\)</span>).</p>
<div class="figure">
<img src="images/venn.png" id="venn" style="height:1.4in" alt="" />
<p class="caption">A Venn diagram for diamonds and face
cards.<span label="venn"></span></p>
</div>
<p>Let <span class="math inline">\(A\)</span> represent the event that a randomly selected card is a diamond
and <span class="math inline">\(B\)</span> represent the event that it is a face card. How do we compute
<span class="math inline">\(P(A\)</span> or <span class="math inline">\(B)\)</span></p>
<p>Events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not disjoint – the cards
<span class="math inline">\(J\diamondsuit\)</span>, <span class="math inline">\(Q\diamondsuit\)</span>, and <span class="math inline">\(K\diamondsuit\)</span> fall into both
categories – so we cannot use the Addition Rule for disjoint events.
Instead we use the Venn diagram. We start by adding the probabilities of
the two events: <span class="math display">\[\begin{aligned}
P(A) + P(B) = P({\color{redcards}\diamondsuit}) + P(\text{face card}) = 12/52 + 13/52
\label{overCountFaceDiamond}\end{aligned}\]</span> However, the three cards
that are in both events were counted twice, once in each probability. We
must correct this double counting: <span class="math display">\[\begin{aligned}
P(A\text{ or } B) &amp;=&amp;P(\text{face card or }{\color{redcards}\diamondsuit})  \notag \\
 &amp;=&amp; P(\text{face card}) + P({\color{redcards}\diamondsuit}) - P(\text{face card and }{\color{redcards}\diamondsuit}) \label{diamondFace} \\
 &amp;=&amp; 12/52 + 13/52 - 3/52 \notag \\
 &amp;=&amp; 22/52 = 11/26 \notag\end{aligned}\]</span>
The Equation above is an example of the <strong>General Addition Rule</strong>.</p>
<p><strong>General Addition Rule</strong></p>
<blockquote>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are any two events, disjoint or not, then the probability
that at least one of them will occur is <span class="math display">\[\begin{aligned}
P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and }B)
\label{generalAdditionRule}\end{aligned}\]</span> where <span class="math inline">\(P(A\)</span> and <span class="math inline">\(B)\)</span> is the
probability that both events occur. When we write “or” in statistics,
we mean “and/or” unless we explicitly
state otherwise. Thus, <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> occurs means <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, or both <span class="math inline">\(A\)</span> and
<span class="math inline">\(B\)</span> occur.</p>
</blockquote>
</div>
<div id="probability-distributions" class="section level3">
<h3><span class="header-section-number">5.1.5</span> Probability distributions</h3>
<p>A <strong>Probability distribution</strong> is a table of all disjoint outcomes and their associated
probabilities. The table below shows the probability distribution for the sum of
two dice.</p>
<table>
<caption>Probability distribution for the sum of two
dice.<span label="diceProb"></span></caption>
<tbody>
<tr class="odd">
<td align="center"> </td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="center">Dice sum</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
</tr>
<tr class="odd">
<td align="center">Probability</td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{3}{36}\)</span></td>
<td><span class="math inline">\(\frac{4}{36}\)</span></td>
<td><span class="math inline">\(\frac{5}{36}\)</span></td>
<td><span class="math inline">\(\frac{6}{36}\)</span></td>
<td><span class="math inline">\(\frac{5}{36}\)</span></td>
<td><span class="math inline">\(\frac{4}{36}\)</span></td>
<td><span class="math inline">\(\frac{3}{36}\)</span></td>
<td><span class="math inline">\(\frac{2}{36}\)</span></td>
<td><span class="math inline">\(\frac{1}{36}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Rules for probability distributions</strong></p>
<blockquote>
<p>A probability distribution is a list of the possible outcomes with
corresponding probabilities that satisfies three rules:</p>
</blockquote>
<blockquote>
<ol style="list-style-type: decimal">
<li>The outcomes listed must be disjoint.</li>
<li>Each probability must be between 0 and 1.</li>
<li>The probabilities must total 1.</li>
</ol>
</blockquote>
<p>Probability distributions can also be
summarized in a bar plot. For instance, the distribution of US household
incomes is shown in
Figure <a href="5-probability.html#usHouseholdIncomeDistBar" reference-type="ref" reference="usHouseholdIncomeDistBar">1.4</a> as a bar plot.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> The
probability distribution for the sum of two dice is shown in
the table at the begining of the probability distributions section and plotted in
Figure <a href="5-probability.html#diceSumDist" reference-type="ref" reference="diceSumDist">1.5</a>.</p>
<!-- These figures should be calculated live. Maybe we can make a theme for the book which makes all the figures look similar and nice. -->
<div class="figure">
<img src="images/usHouseholdIncomeDistBar.png" id="usHouseholdIncomeDistBar" style="width:68.0%" alt="" />
<p class="caption">The probability distribution of US household
income.<span label="usHouseholdIncomeDistBar"></span></p>
</div>
<div class="figure">
<img src="images/diceSumDist.png" id="diceSumDist" style="width:73.0%" alt="" />
<p class="caption">The probability distribution of the sum of two
dice.<span label="diceSumDist"></span></p>
</div>
<p>In these bar plots, the bar heights represent the probabilities of
outcomes. If the outcomes are numerical and discrete, it is usually
(visually) convenient to make a bar plot that resembles a histogram, as
in the case of the sum of two dice.</p>
</div>
<div id="complement-of-an-event" class="section level3">
<h3><span class="header-section-number">5.1.6</span> Complement of an event</h3>
<!-- Cut this section? Do we ever need the complement? -->
<p>Rolling a die produces a value in the set <span class="math inline">\(\{\)</span><em>1</em>, <em>2</em>, <em>3</em>, <em>4</em>, <em>5</em>,
<em>6</em><span class="math inline">\(\}\)</span>. This set of all possible outcomes is called the <strong>sample space</strong> (<span class="math inline">\(S\)</span>) for
rolling a die. We often use the sample space to examine the scenario
where an event does not occur.</p>
<p>Let <span class="math inline">\(D=\{\)</span><em>2</em>, <em>3</em><span class="math inline">\(\}\)</span> represent the event that the outcome of a die
roll is <em>2</em> or <em>3</em>. Then the <strong>complement</strong> of <span class="math inline">\(D\)</span> represents all outcomes in our
sample space that are not in <span class="math inline">\(D\)</span>, which is denoted by <span class="math inline">\(D^c = \{\)</span><em>1</em>,
<em>4</em>, <em>5</em>, <em>6</em><span class="math inline">\(\}\)</span>. That is, <span class="math inline">\(D^c\)</span> is the set of all possible outcomes
not already included in <span class="math inline">\(D\)</span>.
Figure <a href="5-probability.html#complementOfD" reference-type="ref" reference="complementOfD">1.6</a> shows the relationship between <span class="math inline">\(D\)</span>, <span class="math inline">\(D^c\)</span>,
and the sample space <span class="math inline">\(S\)</span>.</p>
<div class="figure">
<img src="images/complementOfD.png" id="complementOfD" style="width:40.0%" alt="" />
<p class="caption">Event <span class="math inline">\(D=\{\)</span><em>2</em>, <em>3</em><span class="math inline">\(\}\)</span> and its complement, <span class="math inline">\(D^c = \{\)</span><em>1</em>, <em>4</em>, <em>5</em>,
<em>6</em><span class="math inline">\(\}\)</span>. <span class="math inline">\(S\)</span> represents the sample space, which is the set of all
possible
events.<span label="complementOfD"></span></p>
</div>
<p>A complement of an event <span class="math inline">\(A\)</span> is constructed to have two very important
properties: (i) every possible outcome not in <span class="math inline">\(A\)</span> is in <span class="math inline">\(A^c\)</span>, and (ii)
<span class="math inline">\(A\)</span> and <span class="math inline">\(A^c\)</span> are disjoint. Property (i) implies <span class="math display">\[\begin{aligned}
P(A\text{ or }A^c) = 1
\label{complementSumTo1}\end{aligned}\]</span> That is, if the outcome is not
in <span class="math inline">\(A\)</span>, it must be represented in <span class="math inline">\(A^c\)</span>.</p>
</div>
<div id="probabilityIndependence" class="section level3">
<h3><span class="header-section-number">5.1.7</span> Independence</h3>
<p>Just as variables and observations can be independent, random processes
can be independent, too. Two processes are <strong>independent</strong> if knowing the outcome of one
provides no useful information about the outcome of the other. For
instance, flipping a coin and rolling a die are two independent
processes – knowing the coin was heads does not help determine the
outcome of a die roll. On the other hand, stock prices usually move up
or down together, so they are not independent.</p>
<p>Rolling two dice is a basic example of independence. We want to determine the probability that
both will be <em>1</em>. Suppose one of the dice is red and the other white. If
the outcome of the red die is a <em>1</em>, it provides no information about
the outcome of the white die. We first encountered this same question in
the beginning of the chapter, where we calculated the probability
using the following reasoning: <span class="math inline">\(1/6^{th}\)</span> of the time the red die is a
<em>1</em>, and <span class="math inline">\(1/6^{th}\)</span> of <em>those</em> times the white die will also be <em>1</em>.
This is illustrated in
Figure <a href="5-probability.html#indepForRollingTwo1s" reference-type="ref" reference="indepForRollingTwo1s">1.7</a>. Because the rolls are independent,
the probabilities of the corresponding outcomes can be multiplied to get
the final answer: <span class="math inline">\((1/6)\times(1/6)=1/36\)</span>. This can be generalized to
many independent processes.</p>
<div class="figure">
<img src="images/indepForRollingTwo1s.png" id="indepForRollingTwo1s" style="width:65.0%" alt="" />
<p class="caption"><span class="math inline">\(1/6^{th}\)</span> of the time, the first roll is a <em>1</em>. Then <span class="math inline">\(1/6^{th}\)</span> of
<em>those</em> times, the second roll will also be a
<em>1</em>.<span label="indepForRollingTwo1s"></span></p>
</div>
<p><strong>Example</strong>
What if there was also a blue die independent of the other two?</p>
<p>What is
the probability of rolling the three dice and getting all
<em>1</em>s?</p>
<p>If <span class="math inline">\(1/36^{th}\)</span> of the time the white and red
dice are both <em>1</em>, then <span class="math inline">\(1/6^{th}\)</span> of <em>those</em> times the blue die will
also be <em>1</em>, so multiply: <span class="math display">\[\begin{aligned}
P(white=\text{1 and } red=\text{1 and } blue=\text{1})
    &amp;= P(white=\text{1})\times P(red=\text{1})\times P(blue=\text{1}) \\
    &amp;= (1/6)\times (1/6)\times (1/6)
    = 1/216\end{aligned}\]</span></p>
<p>The example above illustrate what is called the Multiplication Rule
for independent processes. Sometimes we wonder if one outcome provides
useful information about
another outcome. The question we are asking is, are the occurrences of
the two events independent</p>
<p>We say that two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are
independent if they satisfy
<span class="math display">\[P(A \text{ and }B) = P(A) \times  P(B)\]</span></p>
<p><strong>Example</strong></p>
<p>If we shuffle up a deck of cards and draw one, is the event that the
card is a heart independent of the event that the card is an ace</p>
<p>The
probability the card is a heart is <span class="math inline">\(1/4\)</span> and the probability that it is
an ace is <span class="math inline">\(1/13\)</span>. The probability the card is the ace of hearts is
<span class="math inline">\(1/52\)</span>. We check whether
<span class="math inline">\(P(A \text{ and }B) = P(A) \times P(B)\)</span> is satisfied: <span class="math display">\[\begin{aligned}
P({\color{redcards}\heartsuit})\times P(\text{ace}) = \frac{1}{4}\times \frac{1}{13} = \frac{1}{52} 
                    = P({\color{redcards}\heartsuit}\text{ and ace})\end{aligned}\]</span>
Because the equation holds, the event that the card is a heart and the
event that the card is an ace are independent events.</p>
</div>
<div id="conditionalProbabilitySection" class="section level3">
<h3><span class="header-section-number">5.1.8</span> Conditional probability</h3>
<p>Are students more likely to use marijuana when their parents used drugs?</p>
<p>The data set contains a sample of 445 cases with two variables, students and parents,
and is summarized in the table below.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> The variable is either <em>uses</em>
or <em>not</em>, where a student is labeled as if she has recently used
marijuana. The student variable takes the value <em>used</em> if at least one of the
parents used drugs, including alcohol.</p>
<table>
<caption>Contingency table summarizing the data
set.<span label="contTableOfParStDrugUse"></span></caption>
<thead>
<tr class="header">
<th align="right">u</th>
<th>sed no</th>
<th>t To</th>
<th align="left">tal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">uses</td>
<td>125</td>
<td>94</td>
<td align="left">219</td>
</tr>
<tr class="even">
<td align="right">not</td>
<td>85</td>
<td>141</td>
<td align="left">226</td>
</tr>
<tr class="odd">
<td align="right">Total</td>
<td>210</td>
<td>235</td>
<td align="left">445</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="images/drugUseVenn.png" id="drugUseVenn" style="width:65.0%" alt="" />
<p class="caption">A Venn diagram using boxes for the data
set.<span label="drugUseVenn"></span></p>
</div>
<p><strong>Example</strong></p>
<p>If at least one parent used drugs, what is the chance their child
uses drugs.</p>
<p>We will estimate this probability using the data. Of the 210 cases
in this data set where = <em>used</em>, 125 represent cases where = <em>uses</em>:
<span class="math display">\[\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}\]</span></p>
<p><strong>Example</strong></p>
<p>A student is randomly selected from the study and she does not use
drugs. What is the probability that at least one of her parents
used</p>
<p>If the student does not use
drugs, then she is one of the 226 students in the second row. Of these
226 students, 85 had at least one parent who used drugs:
<span class="math display">\[\begin{aligned}
P(\text{parents = used given student = not}) = \frac{85}{226} = 0.376\end{aligned}\]</span></p>
</div>
<div id="marginalAndJointProbabilities" class="section level3">
<h3><span class="header-section-number">5.1.9</span> Marginal and joint probabilities</h3>
<p>The Table below includes row and column totals for each
variable separately in the data set. These totals represent <strong>marginal probabilities</strong> for the
sample, which are the probabilities based on a single variable without
conditioning on any other variables. For instance, a probability based
solely on the variable is a marginal probability: <span class="math display">\[\begin{aligned}
P(\text{student = uses}) = \frac{219}{445} = 0.492\end{aligned}\]</span>
A probability of outcomes for two or more variables or processes is
called a <strong>joint probability</strong>: <span class="math display">\[\begin{aligned}
P(\text{student = uses and parents = not}) = \frac{94}{445} = 0.21\end{aligned}\]</span>
It is common to substitute a comma for “and” in a joint probability,
although either is acceptable.</p>
<table>
<caption>Probability table summarizing parental and student drug
use.<span label="drugUseProbTable"></span></caption>
<thead>
<tr class="header">
<th align="right">u</th>
<th>sed no</th>
<th>t To</th>
<th align="left">tal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">uses</td>
<td>0.28</td>
<td>0.21</td>
<td align="left">0.49</td>
</tr>
<tr class="even">
<td align="right">not</td>
<td>0.19</td>
<td>0.32</td>
<td align="left">0.51</td>
</tr>
<tr class="odd">
<td align="right">Total</td>
<td>0.47</td>
<td>0.53</td>
<td align="left">1.00</td>
</tr>
</tbody>
</table>
<p><strong>Marginal and joint Probabilities</strong></p>
<blockquote>
<p>If a probability is based on a single variable, it is a <em>marginal
probability</em>. The probability of outcomes for two or more variables or
processes is called a <em>joint probability</em>.</p>
</blockquote>
<p>We use <strong>table proportions</strong> to summarize joint probabilities for the sample. These
proportions are computed by dividing each count in the first table by 445 to obtain the proportions in
the second table. The joint probability distribution of the
and variables is shown in
the table below.</p>
<table>
<caption>A joint probability distribution for the data
set.<span label="drugUseDistribution"></span></caption>
<thead>
<tr class="header">
<th>int outcome P</th>
<th align="left">robability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>= <em>used</em>, = <em>uses</em></td>
<td align="left">0.28</td>
</tr>
<tr class="even">
<td>= <em>used</em>, = <em>not</em></td>
<td align="left">0.19</td>
</tr>
<tr class="odd">
<td>= <em>not</em>, = <em>uses</em></td>
<td align="left">0.21</td>
</tr>
<tr class="even">
<td>= <em>not</em>, = <em>not</em></td>
<td align="left">0.32</td>
</tr>
<tr class="odd">
<td>Total</td>
<td align="left">1.00</td>
</tr>
</tbody>
</table>
<p>We can compute marginal probabilities using joint probabilities in
simple cases. For example, the probability a random student from the
study uses drugs is found by summing the outcomes from
the table above where = <em>uses</em>: <span class="math display">\[\begin{aligned}
&amp;&amp;P(\text{student = uses}) \\
&amp;&amp; \quad =  P(\text{parents = used, student = uses}) + \\
&amp;&amp; \quad \quad \quad \quad P(\text{parents = not, student = uses}) \\
&amp;&amp; \quad = 0.28 + 0.21 = 0.49\end{aligned}\]</span></p>
</div>
<div id="defining-conditional-probability" class="section level3">
<h3><span class="header-section-number">5.1.10</span> Defining conditional probability</h3>
<p>There is some connection between drug use of parents and of the student:
drug use of one is associated with drug use of the other.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> In this
section, we discuss how to use information about associations between
two variables to improve probability estimation.</p>
<p>The probability that a random student from the study uses drugs is 0.49.
Could we update this probability if we knew that this student’s parents
used drugs</p>
<p>Absolutely. To do so, we limit our view to only those 210
cases where parents used drugs and look at the fraction where the
student uses drugs: <span class="math display">\[\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}\]</span>
We call this a <strong>conditional probability</strong> because we computed the probability under a condition: =
<em>used</em>. There are two parts to a conditional probability, <strong>the outcome of interest</strong> and the <strong>condition</strong> . It
is useful to think of the condition as information we know to be true,
and this information usually can be described as a known outcome
or event.</p>
<p>We separate the text inside our probability notation into the outcome of
interest and the condition: <span class="math display">\[\begin{aligned}
&amp;&amp; P(\text{student = uses given parents = used}) \notag \\
&amp;&amp; = P(\text{student = uses } | \text{ parents = used}) = \frac{125}{210} = 0.60
\label{probStudentUsedIfParentsUsedInFormalNotation}\end{aligned}\]</span> The
vertical bar “<span class="math inline">\(|\)</span>” is read as <em>given</em>.</p>
<p>In
the Equation above, we computed
the probability a student uses based on the condition that at least one
parent used as a fraction: <span class="math display">\[\begin{aligned}
&amp;&amp; P(\text{student = uses } | \text{ parents = used}) \notag \\
&amp;&amp;\quad = \frac{\text{#times student = uses and parents = used}}{\text{#times parents = used}} \label{ratioOfBothToRatioOfConditionalForParentsAndStudent} \\
&amp;&amp;\quad = \frac{125}{210} = 0.60 \notag\end{aligned}\]</span> We considered
only those cases that met the condition, = <em>used</em>, and then we computed
the ratio of those cases that satisfied our outcome of interest, the
student uses.</p>
<p>Counts are not always available for data, and instead only marginal and
joint probabilities may be provided. For example, disease rates are
commonly listed in percentages rather than in a count format. We would
like to be able to compute conditional probabilities even when no counts
are available, and we use
the equation above as an
example demonstrating this technique.</p>
<p>We considered only those cases that satisfied the condition, = <em>used</em>.
Of these cases, the conditional probability was the fraction who
represented the outcome of interest, = <em>uses</em>. Suppose we were provided
only the information in
the second table of this section i.e. only probability data. Then if we
took a sample of 1000 people, we would anticipate about 47% or
<span class="math inline">\(0.47\times 1000 = 470\)</span> would meet our information criterion. Similarly,
we would expect about 28% or <span class="math inline">\(0.28\times 1000 = 280\)</span> to meet both the
information criterion and represent our outcome of interest. Thus, the
conditional probability could be computed: <span class="math display">\[\begin{aligned}
P(\text{student = uses } | \text{ parents = used})
    &amp;= \frac{\text{#(student = uses and parents = used)}}{\text{#(parents = used)}} \notag \\
    &amp;= \frac{280}{470} = \frac{0.28}{0.47} = 0.60
\label{stUserPUsedHypSampSize}\end{aligned}\]</span> In
In the equation above, we examine exactly the fraction of
two probabilities, 0.28 and 0.47, which we can write as
<span class="math display">\[\begin{aligned}
P(student = uses\ \text{and}\ parents = used)
    \quad\text{and}\quad
    P(parents = used).\end{aligned}\]</span> The fraction of these
probabilities represents our general formula for conditional
probability.</p>
<p><strong>Conditional Probability</strong></p>
<blockquote>
<p>The conditional probability of the outcome of interest <span class="math inline">\(A\)</span> given
condition <span class="math inline">\(B\)</span> is computed as the following: <span class="math display">\[\begin{aligned}
P(A | B) = \frac{P(A\text{ and }B)}{P(B)}
\label{condProbEq}\end{aligned}\]</span></p>
</blockquote>
</div>
<div id="smallpox-in-boston-1721" class="section level3">
<h3><span class="header-section-number">5.1.11</span> Smallpox in Boston, 1721</h3>
<!-- Could delete this whole example. -->
<p>The data set provides a sample of 6,224 individuals from the year 1721
who were exposed to smallpox in Boston.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Doctors at the time
believed that inoculation, which involves exposing a person to the
disease in a controlled form, could reduce the likelihood of death.</p>
<p>Each case represents one person with two variables: <em>inoculated</em> and <em>result</em>. The first variable
takes two levels: <em>yes</em> or <em>no</em>, indicating whether the person was
inoculated or not. The second variable has outcomes <em>lived</em> or <em>died</em>. These
data are summarized in the tables below.</p>
<table>
<caption>Contingency table for the data
set.<span label="smallpoxContingencyTable"></span></caption>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="right">ye</td>
<td>s n</td>
<td>o Total</td>
</tr>
<tr class="even">
<td></td>
<td>lived</td>
<td align="right">23</td>
<td>8 513</td>
<td>6 5374</td>
</tr>
<tr class="odd">
<td></td>
<td>died</td>
<td align="right"></td>
<td>6 84</td>
<td>4 850</td>
</tr>
<tr class="even">
<td></td>
<td>Total</td>
<td align="right">24</td>
<td>4 598</td>
<td>0 6224</td>
</tr>
</tbody>
</table>
<table>
<caption>Table proportions for the data, computed by dividing each count by
the table total, 6224.<span label="smallpoxProbabilityTable"></span></caption>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="right">ye</td>
<td>s n</td>
<td>o Total</td>
</tr>
<tr class="even">
<td></td>
<td>lived</td>
<td align="right">0.038</td>
<td>2 0.825</td>
<td>2 0.8634</td>
</tr>
<tr class="odd">
<td></td>
<td>died</td>
<td align="right">0.001</td>
<td>0 0.135</td>
<td>6 0.1366</td>
</tr>
<tr class="even">
<td></td>
<td>Total</td>
<td align="right">0.039</td>
<td>2 0.960</td>
<td>8 1.0000</td>
</tr>
</tbody>
</table>
<p>: Table proportions for the data, computed by dividing each count by
the table total, 6224.<span label="smallpoxProbabilityTable"></span></p>
</div>
<div id="general-multiplication-rule" class="section level3">
<h3><span class="header-section-number">5.1.12</span> General multiplication rule</h3>
<p>Section <a href="5-probability.html#probabilityIndependence" reference-type="ref" reference="probabilityIndependence">1.1.6</a> introduced the Multiplication Rule
for independent processes. Here we provide the <strong>General Multiplication rule</strong> for events that might not
be independent.</p>
<p><strong>General Multiplication Rule</strong></p>
<blockquote>
<p>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> represent two outcomes or events, then <span class="math display">\[\begin{aligned}
P(A\text{ and }B) = P(A | B)\times P(B)\end{aligned}\]</span></p>
</blockquote>
<blockquote>
<p>It is useful to think of <span class="math inline">\(A\)</span> as the outcome of interest and <span class="math inline">\(B\)</span> as the
condition.</p>
</blockquote>
<p>This General Multiplication Rule is simply a rearrangement of the
definition for conditional probability.</p>
<p><strong>Example</strong></p>
<p>Consider the smallpox data set. Suppose we are given only two pieces of
information: 96.08% of residents were not inoculated, and 85.88% of the
residents who were not inoculated ended up surviving. How could we
compute the probability that a resident was not inoculated and lived</p>
<p>We
will compute our answer using the General Multiplication Rule and then
verify it using
the smallpox probability table. We want to determine
<span class="math display">\[\begin{aligned}
P(\text{result = lived and inoculated = no})\end{aligned}\]</span>
and we are given that <span class="math display">\[\begin{aligned}
P(\text{result = lived }|\text{ inoculated = no})=0.8588 \\
P(\text{inoculated = no})=0.9608\end{aligned}\]</span> Among the
96.08% of people who were not inoculated, 85.88% survived:
<span class="math display">\[\begin{aligned}
P(\text{result = lived and inoculated = no}) = 0.8588\times 0.9608 = 0.8251\end{aligned}\]</span>
This is equivalent to the General Multiplication Rule. We can confirm
this probability in
the smallpox probability table at the intersection of <em>no</em> and
<em>lived</em> (with a small rounding error).</p>
</div>
<div id="tree-diagrams" class="section level3">
<h3><span class="header-section-number">5.1.13</span> Tree diagrams</h3>
<!-- I think tree diagrams are really, really interesting, not least because they lead so naturally into simulations and code. And they are so Bayesian. Instead of hard-coded image with absurdly too many digits, we ought to create this live. Indeed, might we reconfigure the entire chapter around trees as the basic building block? Everything is a tree. Independence means you get the same answer at each branch of the tree. Conditionality means you don't. -->
<p><strong>Tree diagrams</strong> are a tool to organize outcomes and probabilities around the structure
of the data. They are most useful when two or more processes occur in a
sequence and each process is conditioned on its predecessors.</p>
<p>The data fit this description. We see the population as split by : <em>yes</em>
and <em>no</em>. Following this split, survival rates were observed for each
group. This structure is reflected in the *tree diagram<strong> shown in
Figure <a href="5-probability.html#smallpoxTreeDiagram" reference-type="ref" reference="smallpoxTreeDiagram">1.9</a>. The first branch for is said to be the </strong>primary<strong>
branch while the other branches are </strong>secondary** .</p>
<div class="figure">
<img src="images/smallpoxTreeDiagram.png" id="smallpoxTreeDiagram" style="width:93.0%" alt="" />
<p class="caption">A tree diagram of the data
set.<span label="smallpoxTreeDiagram"></span></p>
</div>
<p>Tree diagrams are annotated with marginal and conditional probabilities,
as shown in Figure <a href="5-probability.html#smallpoxTreeDiagram" reference-type="ref" reference="smallpoxTreeDiagram">1.9</a>. This tree diagram splits the smallpox
data by innoculation into the <em>yes</em> and <em>no</em> groups with respective marginal
probabilities 0.0392 and 0.9608. The secondary branches are conditioned
on the first, so we assign conditional probabilities to these branches.
For example, the top branch in
Figure <a href="5-probability.html#smallpoxTreeDiagram" reference-type="ref" reference="smallpoxTreeDiagram">1.9</a> is the probability that result = <em>lived</em>
conditioned on the information that innoculated = <em>yes</em>. We may (and usually do)
construct joint probabilities at the end of each branch in our tree by
multiplying the numbers we come across as we move from left to right.
These joint probabilities are computed using the General Multiplication
Rule: <span class="math display">\[\begin{aligned}
&amp;&amp; P(\text{inoculated = yes and result = lived}) \\
    &amp;&amp;\quad = P(\text{inoculated = yes})\times P(\text{result = lived}|\text{inoculated = yes}) \\
    &amp;&amp;\quad = 0.0392\times 0.9754=0.0382\end{aligned}\]</span></p>
<p><strong>Example</strong></p>
<p>Consider the midterm and final for a statistics class. Suppose 13% of
students earned an <em>A</em> on the midterm. Of those students who earned an
<em>A</em> on the midterm, 47% received an <em>A</em> on the final, and 11% of the
students who earned lower than an <em>A</em> on the midterm received an <em>A</em> on
the final. You randomly pick up a final exam and notice the student
received an <em>A</em>. What is the probability that this student earned an <em>A</em>
on the midterm</p>
<p>The end-goal is to find
<span class="math inline">\(P(\text{midterm = A} | \text{final = A})\)</span>. To
calculate this conditional probability, we need the following
probabilities: <span class="math display">\[\begin{aligned}
P(\text{midterm = A and final = A}) \qquad\text{and}\qquad
P(\text{final = A})\end{aligned}\]</span></p>
<p>However, this
information is not provided, and it is not obvious how to calculate
these probabilities. Since we aren’t sure how to proceed, it is useful
to organize the information into a tree diagram, as shown in
Figure <a href="5-probability.html#testTree" reference-type="ref" reference="testTree">1.10</a>.
When constructing a tree diagram, variables provided with marginal
probabilities are often used to create the tree’s primary branches; in
this case, the marginal probabilities are provided for midterm grades.
The final grades, which correspond to the conditional probabilities
provided, will be shown on the secondary branches.</p>
<div class="figure">
<img src="images/testTree.png" id="testTree" style="width:87.0%" alt="" />
<p class="caption">A tree diagram describing the and
variables.<span label="testTree"></span></p>
</div>
<p>With the tree diagram constructed, we may compute the required
probabilities: <span class="math display">\[\begin{aligned}
&amp;&amp;P(\text{midterm = A and final = A}) = 0.0611 \\
&amp;&amp;P(\text{final = A})  \\
&amp;&amp; \quad= P(\text{midterm = other and final = A}) + P(\text{midterm = A and final = A}) \\
&amp;&amp; \quad= 0.0611 + 0.0957 = 0.1568\end{aligned}\]</span> The marginal
probability, <span class="math inline">\(P(\)</span> = <em>A</em><span class="math inline">\()\)</span>, was calculated by adding up all the joint
probabilities on the right side of the tree that correspond to = <em>A</em>. We
may now finally take the ratio of the two probabilities:
<span class="math display">\[\begin{aligned}
P(\text{midterm = A} | \text{final = A}) &amp;=&amp; \frac{P(\text{midterm = A and final = A})}{P(\text{final = A})} \\
&amp;=&amp; \frac{0.0611}{0.1568} = 0.3897\end{aligned}\]</span> The probability the
student also earned an A on the midterm is about 0.39.</p>
</div>
</div>
<div id="randomVariablesSection" class="section level2">
<h2><span class="header-section-number">5.2</span> Random variables</h2>
<p><strong>Example</strong></p>
<p>Two books are assigned for a statistics class: a textbook and its
corresponding study guide. The university bookstore determined 20% of
enrolled students do not buy either book, 55% buy the textbook only, and
25% buy both books, and these percentages are relatively constant from
one term to another. If there are 100 students enrolled, how many books
should the bookstore expect to sell to this class</p>
<p><strong>Example</strong></p>
<p>Would you be surprised if the bookstore sold slightly more or less than
105 books?<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p>The textbook costs $137 and the study guide $33. How much revenue
should the bookstore expect from this class of 100 students?</p>
<p>About 55
students will just buy a textbook, providing revenue of
<span class="math display">\[\begin{aligned}
\$137 \times  55 = \$7,535\end{aligned}\]</span> The roughly 25 students who
buy both the textbook and the study guide would pay a total of
<span class="math display">\[\begin{aligned}
(\$137 + \$33) \times  25 = \$170 \times  25 = \$4,250\end{aligned}\]</span>
Thus, the bookstore should expect to generate about
<span class="math inline">\(\$7,535 + \$4,250 = \$11,785\)</span> from these 100 students for this one
class. However, there might be some <em>sampling variability</em> so the actual
amount may differ by a little bit.</p>
<div class="figure">
<img src="images/bookCostDist.png" id="bookCostDist" style="width:69.0%" alt="" />
<p class="caption">Probability distribution for the bookstore’s revenue from a single
student. The distribution balances on a triangle representing the
average revenue per
student.<span label="bookCostDist"></span></p>
</div>
<p><strong>Example</strong></p>
<p>What is the average revenue per student for this
course?</p>
<p>The expected total revenue is $11,785, and there are 100 students.
Therefore the expected revenue per student is
<span class="math inline">\(\$11,785/100 = \$117.85\)</span>.</p>
<div id="expectation" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Expectation</h3>
<p>We call a variable or process with a numerical outcome a random variable, and we
usually represent this random variable with a capital letter such as
<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, or <span class="math inline">\(Z\)</span>. The amount of money a single student will spend on her
statistics books is a random variable, and we represent it by <span class="math inline">\(X\)</span>.</p>
<p><strong>Random Variable</strong>
&gt; A random process or variable with a numerical outcome.</p>
<p>The possible outcomes of <span class="math inline">\(X\)</span> are labeled with a corresponding lower case
letter <span class="math inline">\(x\)</span> and subscripts. For example, we write <span class="math inline">\(x_1=\$0\)</span>, <span class="math inline">\(x_2=\$137\)</span>,
and <span class="math inline">\(x_3=\$170\)</span>, which occur with probabilities <span class="math inline">\(0.20\)</span>, <span class="math inline">\(0.55\)</span>, and
<span class="math inline">\(0.25\)</span>. The distribution of <span class="math inline">\(X\)</span> is summarized in
Figure <a href="5-probability.html#bookCostDist" reference-type="ref" reference="bookCostDist">1.11</a> and
the table below</p>
<table>
<caption>The probability distribution for the random variable <span class="math inline">\(X\)</span>,
representing the bookstore’s revenue from a single
student.<span label="statSpendDist"></span></caption>
<thead>
<tr class="header">
<th align="left">$</th>
<th align="left">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="left">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x_i\)</span></td>
<td align="left">$0</td>
<td align="center">$137</td>
<td align="center">$170</td>
<td align="left">–</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(P(X=x_i)\)</span></td>
<td align="left">0.20</td>
<td align="center">0.55</td>
<td align="center">0.25</td>
<td align="left">1.00</td>
</tr>
</tbody>
</table>
<p>We computed the average outcome of <span class="math inline">\(X\)</span> as $117.85 in
dealing with the revenue per student. We call this average the <strong>expected value</strong> of <span class="math inline">\(X\)</span>, denoted by
<span class="math inline">\(E(X)\)</span>. The expected value of a random variable is computed by adding
each outcome weighted by its probability: <span class="math display">\[\begin{aligned}
E(X) &amp;= 0 \times  P(X=0) + 137 \times  P(X=137) + 170 \times  P(X=170) \\
    &amp;= 0 \times  0.20 + 137 \times  0.55 + 170 \times  0.25 = 117.85\end{aligned}\]</span></p>
<p><strong>Expected value of a Discrete Random Variable</strong></p>
<blockquote>
<p>If <span class="math inline">\(X\)</span> takes outcomes <span class="math inline">\(x_1\)</span>, ..., <span class="math inline">\(x_k\)</span> with probabilities <span class="math inline">\(P(X=x_1)\)</span>,
..., <span class="math inline">\(P(X=x_k)\)</span>, the expected value of <span class="math inline">\(X\)</span> is the sum of each outcome
multiplied by its corresponding probability: <span class="math display">\[\begin{aligned}
E(X)    &amp;= x_1\times P(X=x_1) + \cdots + x_k\times P(X=x_k) \notag \\
&amp;= \sum_{i=1}^{k}x_iP(X=x_i)\end{aligned}\]</span> The Greek letter <span class="math inline">\(\mu\)</span>
may be used in place of the notation <span class="math inline">\(E(X)\)</span>.</p>
</blockquote>
<p>The expected value for a random variable represents the average outcome.
For example, <span class="math inline">\(E(X)=117.85\)</span> represents the average amount the bookstore
expects to make from a single student, which we could also write as
<span class="math inline">\(\mu=117.85\)</span>.</p>
<p>It is also possible to compute the expected value of a continuous random
variable using calculus. We are lazy (smart?), so we will just use our computer.</p>
</div>
<div id="variability-in-random-variables" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Variability in random variables</h3>
<p>Suppose you ran the university bookstore. Besides how much revenue you
expect to generate, you might also want to know the volatility
(variability) in your revenue.</p>
<p>The variance and standard deviation can be used to describe the variability of a random variable. We first computed deviations from
the mean (<span class="math inline">\(x_i - \mu\)</span>), squared those deviations, and took an average to
get the variance. In the case of a random variable, we again compute
squared deviations. However, we take their sum weighted by their
corresponding probabilities, just like we did for the expectation. This
weighted sum of squared deviations equals the variance, and we calculate
the standard deviation by taking the square root of the variance.</p>
<p><strong>General variance formula</strong></p>
<blockquote>
<p>If <span class="math inline">\(X\)</span> takes outcomes <span class="math inline">\(x_1\)</span>, ..., <span class="math inline">\(x_k\)</span> with probabilities <span class="math inline">\(P(X=x_1)\)</span>,
..., <span class="math inline">\(P(X=x_k)\)</span> and expected value <span class="math inline">\(\mu=E(X)\)</span>, then the variance of
<span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(Var(X)\)</span> or the symbol <span class="math inline">\(\sigma^2\)</span>, is <span class="math display">\[\begin{aligned}
\sigma^2 &amp;= (x_1-\mu)^2\times P(X=x_1) + \cdots \notag \\
&amp; \qquad\quad\cdots+ (x_k-\mu)^2\times P(X=x_k) \notag \\
&amp;= \sum_{j=1}^{k} (x_j - \mu)^2 P(X=x_j)\end{aligned}\]</span> The standard
deviation of <span class="math inline">\(X\)</span>, labeled <span class="math inline">\(\sigma\)</span>, is the square root of the variance.</p>
</blockquote>
<p><strong>Example</strong></p>
<p>Compute the expected value, variance, and standard deviation of <span class="math inline">\(X\)</span>, the
revenue of a single statistics student for the bookstore. It is useful
to construct a table that holds computations for each outcome
separately, then add up the results.</p>
<table>
<thead>
<tr class="header">
<th align="left">$</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x_i\)</span></td>
<td align="center">$0</td>
<td align="center">$137</td>
<td align="center">$170</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(P(X=x_i)\)</span></td>
<td align="center">0.20</td>
<td align="center">0.55</td>
<td align="center">0.25</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(x_i \times P(X=x_i)\)</span></td>
<td align="center">0</td>
<td align="center">75.35</td>
<td align="center">42.50</td>
<td align="center">117.85</td>
</tr>
</tbody>
</table>
<p>Thus, the expected value is <span class="math inline">\(\mu=117.85\)</span>, which we computed earlier. The
variance can be constructed by extending this table:</p>
<table>
<thead>
<tr class="header">
<th align="left">$</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(x_i\)</span></td>
<td align="center">$0</td>
<td align="center">$137</td>
<td align="center">$170</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(P(X=x_i)\)</span></td>
<td align="center">0.20</td>
<td align="center">0.55</td>
<td align="center">0.25</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(x_i \times P(X=x_i)\)</span></td>
<td align="center">0</td>
<td align="center">75.35</td>
<td align="center">42.50</td>
<td align="center">117.85</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(x_i - \mu\)</span></td>
<td align="center">-117.85</td>
<td align="center">19.15</td>
<td align="center">52.15</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\((x_i-\mu)^2\)</span></td>
<td align="center">13888.62</td>
<td align="center">366.72</td>
<td align="center">2719.62</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\((x_i-\mu)^2\times P(X=x_i)\)</span></td>
<td align="center">2777.7</td>
<td align="center">201.7</td>
<td align="center">679.9</td>
<td align="center">3659.3</td>
</tr>
</tbody>
</table>
<p>The variance of <span class="math inline">\(X\)</span> is <span class="math inline">\(\sigma^2 = 3659.3\)</span>, which means the standard
deviation is <span class="math inline">\(\sigma = \sqrt{3659.3} = \$60.49\)</span>.</p>
</div>
<div id="linear-combinations-of-random-variables" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Linear combinations of random variables</h3>
<p>So far, we have thought of each variable as being a complete story in
and of itself. Sometimes it is more appropriate to use a combination of
variables. For instance, the amount of time a person spends commuting to
work each week can be broken down into several daily commutes.
Similarly, the total gain or loss in a stock portfolio is the sum of the
gains and losses in its components.</p>
<p><strong>Example</strong></p>
<p>John travels to work five days a week. We will use <span class="math inline">\(X_1\)</span> to represent
his travel time on Monday, <span class="math inline">\(X_2\)</span> to represent his travel time on
Tuesday, and so on. Write an equation using <span class="math inline">\(X_1\)</span>, ..., <span class="math inline">\(X_5\)</span> that
represents his travel time for the week, denoted by <span class="math inline">\(W\)</span>. His total
weekly travel time is the sum of the five daily values:
<span class="math display">\[W = X_1 + X_2 + X_3 + X_4 + X_5\]</span> Breaking the weekly travel time <span class="math inline">\(W\)</span>
into pieces provides a framework for understanding each source of
randomness and is useful for modeling <span class="math inline">\(W\)</span>.</p>
<p><strong>Example</strong></p>
<p>It takes John an average of 18 minutes each day to commute to work. What
would you expect his average commute time to be for the week</p>
<p>We were
told that the average (i.e. expected value) of the commute time is 18
minutes per day: <span class="math inline">\(E(X_i) = 18\)</span>. To get the expected time for the sum of
the five days, we can add up the expected time for each individual day:
<span class="math display">\[\begin{aligned}
E(W) &amp;= E(X_1 + X_2 + X_3 + X_4 + X_5) \\
    &amp;= E(X_1) + E(X_2) + E(X_3) + E(X_4) + E(X_5) \\
    &amp;= 18 + 18 + 18 + 18 + 18 = 90\text{ minutes}\end{aligned}\]</span> The
expectation of the total time is equal to the sum of the expected
individual times. More generally, the expectation of a sum of random
variables is always the sum of the expectation for each random variable.</p>
<p>Two important concepts concerning combinations of random variables have
so far been introduced. First, a final value can sometimes be described
as the sum of its parts in an equation. Second, intuition suggests that
putting the individual average values into this equation gives the
average value we would expect in total. This second point needs
clarification – it is guaranteed to be true in what are called <em>linear
combinations of random variables</em>.</p>
<p>A <strong>Linear Combination</strong> of two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is a fancy phrase to describe a
combination <span class="math display">\[aX + bY\]</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are some fixed and known
numbers. For John’s commute time, there were five random variables –
one for each work day – and each random variable could be written as
having a fixed coefficient of 1:
<span class="math display">\[1X_1 + 1 X_2 + 1 X_3 + 1 X_4 + 1 X_5\]</span> For Elena’s net gain or loss,
the <span class="math inline">\(X\)</span> random variable had a coefficient of +1 and the <span class="math inline">\(Y\)</span> random
variable had a coefficient of -1.</p>
<p>When considering the average of a linear combination of random
variables, it is safe to plug in the mean of each random variable and
then compute the final result. For a few examples of nonlinear
combinations of random variables – cases where we cannot simply plug in
the means – see the footnote.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<p><strong>Linear combinations of random variables and the average result</strong></p>
<blockquote>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variables, then a linear combination of the
random variables is given by <span class="math display">\[\begin{aligned}
\label{linComboOfRandomVariablesXAndY}
aX + bY\end{aligned}\]</span> where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are some fixed numbers. To
compute the average value of a linear combination of random variables,
plug in the average of each individual random variable and compute the
result: <span class="math display">\[\begin{aligned}
a\times E(X) + b\times E(Y)\end{aligned}\]</span> Recall that the expected
value is the same as the mean, e.g. <span class="math inline">\(E(X) = \mu_X\)</span>.</p>
</blockquote>
<p><strong>Example</strong></p>
<p>Leonard has invested $6000 in Google Inc. (stock ticker: GOOG) and
$2000 in Exxon Mobil Corp. (XOM). If <span class="math inline">\(X\)</span> represents the change in
Google’s stock next month and <span class="math inline">\(Y\)</span> represents the change in Exxon Mobil
stock next month, write an equation that describes how much money will
be made or lost in Leonard’s stocks for the month. For simplicity, we
will suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not in percents but are in decimal form
(e.g. if Google’s stock increases 1%, then <span class="math inline">\(X=0.01\)</span>; or if it loses 1%,
then <span class="math inline">\(X=-0.01\)</span>). Then we can write an equation for Leonard’s gain as
<span class="math display">\[\begin{aligned}
\$6000\times X + \$2000\times Y\end{aligned}\]</span> If we plug in the change
in the stock value for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, this equation gives the change in
value of Leonard’s stock portfolio for the month. A positive value
represents a gain, and a negative value represents a loss.</p>
</div>
<div id="variability-in-linear-combinations-of-random-variables" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Variability in linear combinations of random variables</h3>
<p>Quantifying the average outcome from a linear combination of random
variables is helpful, but it is also important to have some sense of the
uncertainty associated with the total outcome of that combination of
random variables. We calculated the expected net gain or loss of Leonard’s stock
portfolio was considered in Guided
Practice. However, there was
no quantitative discussion of the volatility of this portfolio. For
instance, while the average monthly gain might be about $134 according
to the data, that gain is not guaranteed.
Figure <a href="5-probability.html#changeInLeonardsStockPortfolioFor36Months" reference-type="ref" reference="changeInLeonardsStockPortfolioFor36Months">1.14</a> shows the monthly
changes in a portfolio like Leonard’s during the 36 months from 2009 to
2011. The gains and losses vary widely, and quantifying these
fluctuations is important when investing in stocks.</p>
<div class="figure">
<img src="images/changeInLeonardsStockPortfolioFor36Months.png" id="changeInLeonardsStockPortfolioFor36Months" style="width:65.0%" alt="" />
<p class="caption">The change in a portfolio like Leonard’s for the 36 months from 2009
to 2011, where $6000 is in Google’s stock and $2000 is in Exxon
Mobil’s.<span label="changeInLeonardsStockPortfolioFor36Months"></span></p>
</div>
<p>Just as we have done in many previous cases, we use the variance and
standard deviation to describe the uncertainty associated with Leonard’s
monthly returns. To do so, the variances of each stock’s monthly return
will be useful, and these are shown in
the table below. The stocks’ returns are nearly
independent.</p>
<table>
<caption>The mean, standard deviation, and variance of the GOOG and XOM
stocks. These statistics were estimated from historical stock data, so
notation used for sample statistics has been
used.<span label="sumStatOfGOOGXOM"></span></caption>
<thead>
<tr class="header">
<th align="right">M</th>
<th>ean (<span class="math inline">\(\bar{x}\)</span>) S</th>
<th>tandard deviation (<span class="math inline">\(s\)</span>) V</th>
<th align="left">ariance (<span class="math inline">\(s^2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">GOOG</td>
<td>0.0210</td>
<td>0.0846</td>
<td align="left">0.0072</td>
</tr>
<tr class="even">
<td align="right">XOM</td>
<td>0.0038</td>
<td>0.0519</td>
<td align="left">0.0027</td>
</tr>
</tbody>
</table>
<p>Here we use an equation from probability theory to describe the
uncertainty of Leonard’s monthly returns; we leave the proof of this
method to a dedicated probability course. The variance of a linear
combination of random variables can be computed by plugging in the
variances of the individual random variables and squaring the
coefficients of the random variables: <span class="math display">\[\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}\]</span> It is
important to note that this equality assumes the random variables are
independent; if independence doesn’t hold, then more advanced methods
are necessary. This equation can be used to compute the variance of
Leonard’s monthly return: <span class="math display">\[\begin{aligned}
Var(6000\times X + 2000\times Y)
    &amp;= 6000^2\times Var(X) + 2000^2\times Var(Y) \\
    &amp;= 36,000,000\times 0.0072 + 4,000,000\times 0.0027 \\
    &amp;= 270,000\end{aligned}\]</span> The standard deviation is computed as the
square root of the variance: <span class="math inline">\(\sqrt{270,000} = \$520\)</span>. While an average
monthly return of $134 on an $8000 investment is nothing to scoff at,
the monthly returns are so volatile that Leonard should not expect this
income to be very stable.</p>
<p><strong>Variability of linear combinations of random variables</strong></p>
<p>The variance of a linear combination of random variables may be computed
by squaring the constants, substituting in the variances for the random
variables, and computing the result: <span class="math display">\[\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}\]</span> This
equation is valid as long as the random variables are independent of
each other. The standard deviation of the linear combination may be
found by taking the square root of the variance.</p>
<p><strong>Example</strong></p>
<p>Suppose John’s daily commute has a standard deviation of 4 minutes. What
is the uncertainty in his total commute time for the week</p>
<p>The expression for John’s commute
time was <span class="math display">\[\begin{aligned}
X_1 + X_2 + X_3 + X_4 + X_5\end{aligned}\]</span> Each coefficient is 1, and
the variance of each day’s time is <span class="math inline">\(4^2=16\)</span>. Thus, the variance of the
total weekly commute time is <span class="math display">\[\begin{aligned}
&amp;\text{variance }= 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 = 5\times 16 = 80 \\
&amp;\text{standard deviation } = \sqrt{\text{variance}} = \sqrt{80} = 8.94\end{aligned}\]</span>
The standard deviation for John’s weekly work commute time is about 9
minutes.</p>
<p>The negative coefficient for <span class="math inline">\(Y\)</span> in the linear combination was
eliminated when we squared the coefficients. This generally holds true:
negatives in a linear combination will have no impact on the variability
computed for a linear combination, but they do impact the expected value
computations.</p>
</div>
</div>
<div id="appendixA" class="section level2">
<h2><span class="header-section-number">5.3</span> Statistical Background</h2>
<div id="appendix-stat-terms" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Basic statistical terms</h3>
<p>Note that all the following statistical terms apply only to <em>numerical</em> variables, except the <em>distribution</em> which can exist for both numerical and categorical variables.</p>
<div id="mean" class="section level4">
<h4><span class="header-section-number">5.3.1.1</span> Mean</h4>
<p>The <em>mean</em> is the most commonly reported measure of center. It is commonly called the <em>average</em> though this term can be a little ambiguous. The mean is the sum of all of the data elements divided by how many elements there are. If we have <span class="math inline">\(n\)</span> data points, the mean is given by:</p>
<p><span class="math display">\[Mean = \frac{x_1 + x_2 + \cdots + x_n}{n}\]</span></p>
</div>
<div id="median" class="section level4">
<h4><span class="header-section-number">5.3.1.2</span> Median</h4>
<p>The median is calculated by first sorting a variable’s data from smallest to largest. After sorting the data, the middle element in the list is the <em>median</em>. If the middle falls between two values, then the median is the mean of those two middle values.</p>
</div>
<div id="standard-deviation" class="section level4">
<h4><span class="header-section-number">5.3.1.3</span> Standard deviation</h4>
<p>We will next discuss the <em>standard deviation</em> (<span class="math inline">\(sd\)</span>) of a variable. The formula can be a little intimidating at first but it is important to remember that it is essentially a measure of how far we expect a given data value will be from its mean:</p>
<p><span class="math display">\[sd = \sqrt{\frac{(x_1 - Mean)^2 + (x_2 - Mean)^2 + \cdots + (x_n - Mean)^2}{n - 1}}\]</span></p>
</div>
<div id="five-number-summary" class="section level4">
<h4><span class="header-section-number">5.3.1.4</span> Five-number summary</h4>
<p>The <em>five-number summary</em> consists of five summary statistics: the minimum, the first quantile AKA 25th percentile, the second quantile AKA median or 50th percentile, the third quantile AKA 75th, and the maximum. The five-number summary of a variable is used when constructing boxplots, as seen in Section <a href="1-viz.html#boxplots">1.11</a>.</p>
<p>The quantiles are calculated as</p>
<ul>
<li>first quantile (<span class="math inline">\(Q_1\)</span>): the median of the first half of the sorted data</li>
<li>third quantile (<span class="math inline">\(Q_3\)</span>): the median of the second half of the sorted data</li>
</ul>
<p>The <em>interquartile range (IQR)</em> is defined as <span class="math inline">\(Q_3 - Q_1\)</span> and is a measure of how spread out the middle 50% of values are. The IQR corresponds to the length of the box in a boxplot.</p>
<p>The median and the IQR are not influenced by the presence of outliers in the ways that the mean and standard deviation are. They are, thus, recommended for skewed datasets. We say in this case that the median and IQR are more <em>robust to outliers</em>.</p>
</div>
<div id="distribution" class="section level4">
<h4><span class="header-section-number">5.3.1.5</span> Distribution</h4>
<p>The <em>distribution</em> of a variable shows how frequently different values of a variable occur. Looking at the visualization of a distribution can show where the values are centered, show how the values vary, and give some information about where a typical value might fall. It can also alert you to the presence of outliers.</p>
<p>Recall from Chapter <a href="1-viz.html#viz">1</a> that we can visualize the distribution of a numerical variable using binning in a histogram and that we can visualize the distribution of a categorical variable using a barplot.</p>
</div>
<div id="outliers" class="section level4">
<h4><span class="header-section-number">5.3.1.6</span> Outliers</h4>
<p><em>Outliers</em> correspond to values in the dataset that fall far outside the range of “ordinary” values. In the context of a boxplot, by default they correspond to values below <span class="math inline">\(Q_1 - (1.5 \cdot IQR)\)</span> or above <span class="math inline">\(Q_3 + (1.5 \cdot IQR)\)</span>.</p>
</div>
</div>
<div id="appendix-normal-curve" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Normal distribution</h3>
<p>Let’s next discuss one particular kind of distribution:  <em>normal distributions</em>. Such bell-shaped distributions are defined by two values: (1) the <em>mean</em> <span class="math inline">\(\mu\)</span> (“mu”) which locates the center of the distribution and (2) the <em>standard deviation</em> <span class="math inline">\(\sigma\)</span> (“sigma”) which determines the variation of the distribution. In Figure <a href="5-probability.html#fig:normal-curves">5.1</a>, we plot three normal distributions where:</p>
<ol style="list-style-type: decimal">
<li>The solid normal curve has mean <span class="math inline">\(\mu = 5\)</span> &amp; standard deviation <span class="math inline">\(\sigma = 2\)</span>.</li>
<li>The dotted normal curve has mean <span class="math inline">\(\mu = 5\)</span> &amp; standard deviation <span class="math inline">\(\sigma = 5\)</span>.</li>
<li>The dashed normal curve has mean <span class="math inline">\(\mu = 15\)</span> &amp; standard deviation <span class="math inline">\(\sigma = 2\)</span>.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:normal-curves"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/normal-curves-1.png" alt="Three normal distributions." width="90%" />
<p class="caption">
FIGURE 5.1: Three normal distributions.
</p>
</div>
<p>Notice how the solid and dotted line normal curves have the same center due to their common mean <span class="math inline">\(\mu\)</span> = 5. However, the dotted line normal curve is wider due to its larger standard deviation of <span class="math inline">\(\sigma\)</span> = 5. On the other hand, the solid and dashed line normal curves have the same variation due to their common standard deviation <span class="math inline">\(\sigma\)</span> = 2. However, they are centered at different locations.</p>
<p>When the mean <span class="math inline">\(\mu\)</span> = 0 and the standard deviation <span class="math inline">\(\sigma\)</span> = 1, the normal distribution has a special name. It’s called the <em>standard normal distribution</em> or the <em><span class="math inline">\(z\)</span>-curve</em>.</p>
<p>Furthermore, if a variable follows a normal curve, there are <em>three rules of thumb</em> we can use:</p>
<ol style="list-style-type: decimal">
<li>68% of values will lie within <span class="math inline">\(\pm\)</span> 1 standard deviation of the mean.</li>
<li>95% of values will lie within <span class="math inline">\(\pm\)</span> 1.96 <span class="math inline">\(\approx\)</span> 2 standard deviations of the mean.</li>
<li>99.7% of values will lie within <span class="math inline">\(\pm\)</span> 3 standard deviations of the mean.</li>
</ol>
<p>Let’s illustrate this on a standard normal curve in Figure <a href="5-probability.html#fig:normal-rule-of-thumb">5.2</a>. The dashed lines are at -3, -1.96, -1, 0, 1, 1.96, and 3. These 7 lines cut up the x-axis into 8 segments. The areas under the normal curve for each of the 8 segments are marked and add up to 100%. For example:</p>
<ol style="list-style-type: decimal">
<li>The middle two segments represent the interval -1 to 1. The shaded area above this interval represents 34% + 34% = 68% of the area under the curve. In other words, 68% of values.</li>
<li>The middle four segments represent the interval -1.96 to 1.96. The shaded area above this interval represents 13.5% + 34% + 34% + 13.5%= 95% of the area under the curve. In other words, 95% of values.</li>
<li>The middle six segments represent the interval -3 to 3. The shaded area above this interval represents 2.35% + 13.5% + 34% + 34% + 13.5% + 2.35% = 99.7% of the area under the curve. In other words, 99.7% of values.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:normal-rule-of-thumb"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/normal-rule-of-thumb-1.png" alt="Rules of thumb about areas under normal curves." width="80%" />
<p class="caption">
FIGURE 5.2: Rules of thumb about areas under normal curves.
</p>
</div>
</div>
</div>
<div id="bayess-theorem" class="section level2">
<h2><span class="header-section-number">5.4</span> Bayes’s Theorem</h2>
<!-- Add material from: Chapter 2 in *Doing Bayesian Data Analysis* ([pdf](https://sites.google.com/site/doingbayesiandataanalysis/sample-chapter/DoingBayesianDataAnalysisChapter2.pdf?attredirects=0&d=1)) by John Kruschke. -->
</div>
<div id="conditional-probability" class="section level2">
<h2><span class="header-section-number">5.5</span> Conditional probability</h2>
<p>The fundamental idea behind all Bayesian statistics is Bayes’s theorem, which is surprisingly easy to derive, provided that you understand conditional probability. So we’ll start with probability, then conditional probability, then Bayes’s theorem, and on to Bayesian statistics.</p>
<p>A probability is a number between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> (including both) that represents a degree of belief in a fact or prediction. The value 1 represents certainty that a fact is true, or that a prediction will come true. The value <span class="math inline">\(0\)</span> represents certainty that the fact is false.</p>
<p>Intermediate values represent degrees of certainty. The value <span class="math inline">\(0.5\)</span>, often written as <span class="math inline">\(50\%\)</span>, means that a predicted outcome is as likely to happen as not. For example, the probability that a tossed coin lands face up is very close to <span class="math inline">\(50\%\)</span>.</p>
<p>A conditional probability is a probability based on some background information. What is the probability that you will have a heart attack in the next year? According to the CDC, “Every year about <span class="math inline">\(785,000\)</span> Americans have a first coronary attack. (<a href="http://www.cdc.gov/heartdisease/facts.htm" class="uri">http://www.cdc.gov/heartdisease/facts.htm</a>)”</p>
<p>The U.S. population is about <span class="math inline">\(311\)</span> million, so the probability that a randomly chosen American will have a heart attack in the next year is roughly <span class="math inline">\(0.3\%\)</span>.</p>
<p>But you are not a randomly chosen American. Epidemiologists have identified many factors that affect the risk of heart attacks; depending on those factors, your risk might be higher or lower than average.</p>
<p>Plug your information into the online calculator at <a href="http://cvdrisk.nhlbi.nih.gov/calculator.asp" class="uri">http://cvdrisk.nhlbi.nih.gov/calculator.asp</a>. Your risk is unlikely to be <span class="math inline">\(0.3\%\)</span>. Whatever the number is, that value is a conditional probability, because it is based on a number of factors that make up your “condition.”</p>
<p>The usual notation for conditional probability is <span class="math inline">\(p(A|B)\)</span>, which is the probability of <span class="math inline">\(A\)</span> given that <span class="math inline">\(B\)</span> is true. In this example, A represents the prediction that you will have a heart attack in the next year, and B is the set of conditions which you entered in the calculator.</p>
</div>
<div id="conjoint-probability" class="section level2">
<h2><span class="header-section-number">5.6</span> Conjoint probability</h2>
<p>Conjoint probability is a fancy way to say the probability that two things are true. Write <span class="math inline">\(p(A \cap B)\)</span> to mean the probability that <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are both
true.</p>
<p>If you learned about probability in the context of coin tosses and dice, you might have learned the following formula:</p>
<p><span class="math display">\[p(A \cap B) = p(A) p(B) \text{    WARNING: Only true when A and B are independent}\]</span>
For example, if you toss two coins, and A means the first coin lands face up, and <span class="math inline">\(B\)</span> means the second coin lands face up, then <span class="math inline">\(p(A) = p(B) = 0.5\)</span>, and sure enough, <span class="math inline">\(p(A \cap B) = p(A) p(B) = 0.25\)</span>.</p>
<p>But this formula only works because in this case <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent; that is, knowing the outcome of the first event does not change the probability of the second. Or, more formally, <span class="math inline">\(p(B|A) = p(B)\)</span>.</p>
<p>Here is a different example where the events are not independent. Suppose that <span class="math inline">\(A\)</span> means that it rains today and <span class="math inline">\(B\)</span> means that it rains tomorrow. If you know that it rained today, it is more likely that it will rain tomorrow, so <span class="math inline">\(p(B|A) &gt; p(B)\)</span>.</p>
<p>In general, the probability of a conjunction is
<span class="math display">\[p(A \cap B) = p(A) p(B|A)\]</span></p>
<p>for any <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. So if the chance of rain on any given day is <span class="math inline">\(0.5\)</span>, the chance
of rain on two consecutive days is not <span class="math inline">\(0.25\)</span>, but probably a bit higher.</p>
</div>
<div id="the-cookie-problem" class="section level2">
<h2><span class="header-section-number">5.7</span> The cookie problem</h2>
<p>We’ll get to Bayes’s theorem soon, but first consider the cookie problem. Suppose there are two bowls of cookies. <span class="math inline">\(\text{Bowl 1}\)</span> contains <span class="math inline">\(30\)</span> vanilla cookies and <span class="math inline">\(10\)</span> chocolate cookies. <span class="math inline">\(\text{Bowl 2}\)</span> contains <span class="math inline">\(20\)</span> of each.</p>
<p>Now suppose you choose one of the bowls at random and, without looking,
select a cookie at random. The cookie is vanilla. What is the probability that
it came from <span class="math inline">\(\text{Bowl 1}\)</span>?</p>
<p>This is a conditional probability; we want <span class="math inline">\(p(\text{Bowl 1 | vanilla})\)</span>, but it is not
obvious how to compute it. If you asked a different question — the probability
of a vanilla cookie given <span class="math inline">\(\text{Bowl 1}\)</span> — it would be easy:</p>
<p><span class="math display">\[p(\text{vanilla | Bowl 1}) = \frac{3}{4}\]</span></p>
<p>Sadly, <span class="math inline">\(p(A|B)\)</span> is not the same as <span class="math inline">\(p(B|A)\)</span>, but there is a way to get from one
to the other: Bayes’s theorem.</p>
</div>
<div id="bayess-theorem-1" class="section level2">
<h2><span class="header-section-number">5.8</span> Bayes’s Theorem</h2>
<p>At this point we have everything we need to derive Bayes’s theorem. We’ll start with the observation that conjunction is commutative; that is
<span class="math display">\[p(A \cap B) = p(B \cap A)\]</span>
for any events A and B.</p>
<p>Next, we write the probability of a conjunction:
<span class="math display">\[p(A \cap B) = p(A) p(B|A)\]</span></p>
<p>Since we have not said anything about what A and B mean, they are interchangeable. Interchanging them yields</p>
<p><span class="math display">\[p(B \cap A) = p(B) p(A|B)\]</span>
That’s all we need. Pulling those pieces together, we get</p>
<p><span class="math display">\[p(B) p(A|B) = p(A) p(B|A)\]</span></p>
<p>Which means there are two ways to compute the conjunction. If you have
<span class="math inline">\(p(A)\)</span>, you multiply by the conditional probability <span class="math inline">\(p(B|A)\)</span>. Or you can do
it the other way around; if you know <span class="math inline">\(p(B)\)</span>, you multiply by <span class="math inline">\(p(A|B)\)</span>. Either
way you should get the same thing.</p>
<p>Finally we can divide through by <span class="math inline">\(p(B)\)</span>:</p>
<p><span class="math display">\[p(A|B) = \frac{p(A) p(B|A)}{p(B)}\]</span></p>
<p>And that’s Bayes’s theorem! It might not look like much, but it turns out to
be surprisingly powerful.</p>
<p>For example, we can use it to solve the cookie problem. I’ll write <span class="math inline">\(\text{Bowl 1}\)</span> for the
hypothesis that the cookie came from <span class="math inline">\(\text{Bowl 1}\)</span> and <span class="math inline">\(V\)</span> for the vanilla cookie.
Plugging in Bayes’s theorem we get</p>
<p><span class="math display">\[p(B_1|V) = \frac{p(B_1) p(V|B1)}{p(V)}\]</span></p>
<p>The term on the left is what we want: the probability of <span class="math inline">\(\text{Bowl 1}\)</span>, given that
we chose a vanilla cookie. The terms on the right are:</p>
<ul>
<li><span class="math inline">\(p(B_1)\)</span>: This is the probability that we chose <span class="math inline">\(\text{Bowl 1}\)</span>, unconditioned by what kind of cookie we got. Since the problem says we chose a bowl
at random, we can assume <span class="math inline">\(p(B_1) = 1/2\)</span>.</li>
<li><span class="math inline">\(p(V|B_1)\)</span>: This is the probability of getting a vanilla cookie from <span class="math inline">\(\text{Bowl 1}\)</span>, which is <span class="math inline">\(3/4\)</span>.</li>
<li><span class="math inline">\(p(V)\)</span>: This is the probability of drawing a vanilla cookie from either bowl. Since we had an equal chance of choosing either bowl and the bowls contain the same number of cookies, we had the same chance of choosing any cookie. Between the two bowls there are <span class="math inline">\(50\)</span> vanilla and <span class="math inline">\(30\)</span> chocolate cookies, so <span class="math inline">\(p(V) = 5/8\)</span>.</li>
</ul>
<p>Putting it together, we have</p>
<p><span class="math display">\[p(B_1|V) = \frac{(1/2) (3/4)}
{5/8}\]</span></p>
<p>which reduces to <span class="math inline">\(3/5\)</span>. So the vanilla cookie is evidence in favor of the hypothesis that we chose <span class="math inline">\(\text{Bowl 1}\)</span>, because vanilla cookies are more likely to come from <span class="math inline">\(\text{Bowl 1}\)</span>.</p>
<p>This example demonstrates one use of Bayes’s theorem: it provides a strategy to get from <span class="math inline">\(p(B|A)\)</span> to <span class="math inline">\(p(A|B)\)</span>. This strategy is useful in cases, like the cookie problem, where it is easier to compute the terms on the right side of Bayes’s theorem than the term on the left</p>
</div>
<div id="the-diachronic-interpretation" class="section level2">
<h2><span class="header-section-number">5.9</span> The diachronic interpretation</h2>
<p>There is another way to think of Bayes’s theorem: it gives us a way to update the probability of a hypothesis, <span class="math inline">\(H\)</span>, in light of some body of data, <span class="math inline">\(D\)</span>.</p>
<p>This way of thinking about Bayes’s theorem is called the <strong>diachronic interpretation</strong>. “Diachronic” means that something is happening over time; in this case the probability of the hypotheses changes, over time, as we see new data.</p>
<p>Rewriting Bayes’s theorem with <span class="math inline">\(H\)</span> and <span class="math inline">\(D\)</span> yields:</p>
<p><span class="math display">\[p(H|D) = \frac{p(H) p(D|H)}{p(D)}\]</span>
In this interpretation, each term has a name:</p>
<ul>
<li><span class="math inline">\(p(H)\)</span> is the probability of the hypothesis before we see the data, called the prior probability, or just <strong>prior</strong>.</li>
<li><span class="math inline">\(p(H|D)\)</span> is what we want to compute, the probability of the hypothesis after we see the data, called the <strong>posterior</strong>.</li>
<li><span class="math inline">\(p(D|H)\)</span> is the probability of the data under the hypothesis, called the <strong>likelihood</strong>.</li>
<li><span class="math inline">\(p(D)\)</span> is the probability of the data under any hypothesis, called the <strong>normalizing constant</strong>.</li>
</ul>
<p>Sometimes we can compute the prior based on background information.
For example, the cookie problem specifies that we choose a bowl at random
with equal probability.</p>
<p>In other cases the prior is subjective; that is, reasonable people might disagree, either because they use different background information or because they interpret the same information differently.</p>
<p>The likelihood is usually the easiest part to compute. In the cookie problem, if we know which bowl the cookie came from, we find the probability of a vanilla cookie by counting.</p>
<p>The normalizing constant can be tricky. It is supposed to be the probability of seeing the data under any hypothesis at all, but in the most general case it is hard to nail down what that means.</p>
<p>Most often we simplify things by specifying a set of hypotheses that are</p>
<p><strong>Mutually exclusive</strong>: At most one hypothesis in the set can be true, and</p>
<p><strong>Collectively exhaustive</strong>: There are no other possibilities; at least one of the hypotheses has to be true.</p>
<p>Use the word <strong>suite</strong> for a set of hypotheses that has these properties.</p>
<p>In the cookie problem, there are only two hypotheses—the cookie came
from <span class="math inline">\(\text{Bowl 1}\)</span> or <span class="math inline">\(\text{Bowl 2}\)</span>—and they are mutually exclusive and collectively
exhaustive.</p>
<p>In that case we can compute <span class="math inline">\(p(D)\)</span> using the law of total probability, which says that if there are two exclusive ways that something might happen, you can add up the probabilities like this:</p>
<p><span class="math display">\[p(D) = p(B_1) p(D|B_1) + p(B_2) p(D|B_2)\]</span>
Plugging in the values from the cookie problem, we have</p>
<p><span class="math display">\[p(D) = (1/2) (3/4) + (1/2) (1/2) = 5/8\]</span></p>
<p>which is what we computed earlier by mentally combining the two bowls.</p>
</div>
<div id="the-mm-problem" class="section level2">
<h2><span class="header-section-number">5.10</span> The M&amp;M problem</h2>
<p>M&amp;M’s are small candy-coated chocolates that come in a variety of colors.
Mars, Inc., which makes M&amp;M’s, changes the mixture of colors from time
to time.</p>
<p>In 1995, they introduced blue M&amp;M’s. Before then, the color mix in a bag
of plain M&amp;M’s was <span class="math inline">\(30\%\)</span> Brown, <span class="math inline">\(20\%\)</span> Yellow, <span class="math inline">\(20\%\)</span> Red, <span class="math inline">\(10\%\)</span> Green, <span class="math inline">\(10\%\)</span> Orange, <span class="math inline">\(10\%\)</span> Tan. Afterward it was <span class="math inline">\(24\%\)</span> Blue , <span class="math inline">\(20\%\)</span> Green, <span class="math inline">\(16\%\)</span> Orange, <span class="math inline">\(14\%\)</span> Yellow, <span class="math inline">\(13\%\)</span> Red, <span class="math inline">\(13\%\)</span> Brown.</p>
<p>Suppose a friend of mine has two bags of M&amp;M’s, and he tells me that one
is from 1994 and one from 1996. He won’t tell me which is which, but he
gives me one M&amp;M from each bag. One is yellow and one is green. What is
the probability that the yellow one came from the 1994 bag?</p>
<p>This problem is similar to the cookie problem, with the twist that we draw
one sample from each bowl/bag. This problem also gives me a chance to
demonstrate the table method, which is useful for solving problems like this on paper. In the next chapter we will solve them computationally.</p>
<p>The first step is to enumerate the hypotheses. The bag the yellow
M&amp;M came from I’ll call Bag 1; I’ll call the other Bag 2. So the hypotheses are:</p>
<ul>
<li>A: Bag 1 is from 1994, which implies that Bag 2 is from 1996.</li>
<li>B: Bag 1 is from 1996 and Bag 2 from 1994</li>
</ul>
<p>Let <span class="math inline">\(H\)</span> be the hypothesis, and let <span class="math inline">\(D\)</span> be the event of the outcome. Note that <span class="math inline">\(p(D) = 1\)</span> since there is a 100 percent chance that we have this outcome since it has already happened</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Prior <span class="math inline">\(p(H)\)</span></th>
<th>Likelihood <span class="math inline">\(P(D|H)\)</span></th>
<th><span class="math inline">\(p(H)p(D|H)\)</span></th>
<th>Posterior <span class="math inline">\(p(H|D)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>1/2</td>
<td>(20)(20)</td>
<td>200</td>
<td>20/27</td>
</tr>
<tr class="even">
<td>B</td>
<td>1/2</td>
<td>(14)(10)</td>
<td>70</td>
<td>7/27</td>
</tr>
</tbody>
</table>
<p>The first column has the priors. Based on the statement of the problem, it is reasonable to choose <span class="math inline">\(p(A) = p(B) = 1/2\)</span>.</p>
<p>The second column has the likelihoods, which follow from the information in the problem. For example, if A is true, the yellow M&amp;M came from the 1994 bag with probability <span class="math inline">\(20\%\)</span>, and the green came from the 1996 bag with probability <span class="math inline">\(20\%\)</span>. If <span class="math inline">\(B\)</span> is true, the yellow M&amp;M came from the 1996 bag with probability <span class="math inline">\(14\%\)</span>, and the green came from the 1994 bag with probability <span class="math inline">\(10\%\)</span>. Because the selections are independent, we get the conjoint probability by multiplying.</p>
<p>The third column is just the product of the previous two. The sum of this column, <span class="math inline">\(270\)</span>, is the normalizing constant. To get the last column, which</p>
<p>contains the posteriors, we divide the third column by the normalizing constant.</p>
<p>That’s it. Simple, right?</p>
<p>Well, you might be bothered by one detail. We write <span class="math inline">\(p(D|H)\)</span> in terms of percentages, not probabilities, which means it is off by a factor of <span class="math inline">\(10,000\)</span>. But that cancels out when we divide through by the normalizing constant, so it doesn’t affect the result.</p>
<p>When the set of hypotheses is mutually exclusive and collectively exhaustive, you can multiply the likelihoods by any factor, if it is convenient, as long as you apply the same factor to the entire column</p>
</div>
<div id="the-monty-hall-problem" class="section level2">
<h2><span class="header-section-number">5.11</span> The Monty Hall problem</h2>
<p>The Monty Hall problem might be the most contentious question in the history of probability. The scenario is simple, but the correct answer is so counterintuitive that many people just can’t accept it, and many smart people have embarrassed themselves not just by getting it wrong but by arguing the wrong side, aggressively, in public.</p>
<p>Monty Hall was the original host of the game show Let’s Make a Deal. The Monty Hall problem is based on one of the regular games on the show. If you are on the show, here’s what happens:</p>
<ul>
<li>Monty shows you three closed doors and tells you that there is a prize behind each door: one prize is a car, the other two are less valuable prizes like peanut butter and fake finger nails. The prizes are arranged at random.</li>
<li>The object of the game is to guess which door has the car. If you guess right, you get to keep the car.</li>
<li>You pick a door, which we will call Door <span class="math inline">\(A\)</span>. We’ll call the other doors <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>.</li>
<li>Before opening the door you chose, Monty increases the suspense by opening either Door <span class="math inline">\(B\)</span> or <span class="math inline">\(C\)</span>, whichever does not have the car. (If the car is actually behind Door <span class="math inline">\(A\)</span>, Monty can safely open <span class="math inline">\(B\)</span> or <span class="math inline">\(C\)</span>, so he chooses one at random.)</li>
<li>Then Monty offers you the option to stick with your original choice or switch to the one remaining unopened door.</li>
</ul>
<p>Now the hard part is over; the rest is just arithmetic. The sum of the third column is <span class="math inline">\(1/2\)</span>. Dividing through yields <span class="math inline">\(p(A|D) = 1/3\)</span> and <span class="math inline">\(p(C|D) = 2/3\)</span>. So you are better off switching</p>
<p>The question is, should you “stick” or “switch” or does it make no difference?</p>
<p>Most people have the strong intuition that it makes no difference. There are two doors left, they reason, so the chance that the car is behind Door <span class="math inline">\(A\)</span> is <span class="math inline">\(50\%\)</span>.</p>
<p>But that is wrong. In fact, the chance of winning if you stick with Door <span class="math inline">\(A\)</span> is only <span class="math inline">\(1/3\)</span>; if you switch, your chances are <span class="math inline">\(2/3\)</span>.</p>
<p>By applying Bayes’s theorem, we can break this problem into simple pieces, and maybe convince ourselves that the correct answer is, in fact, correct.</p>
<p>To start, we should make a careful statement of the data. In this case <span class="math inline">\(D\)</span> consists of two parts: Monty chooses Door <span class="math inline">\(B\)</span> and there is no car there.</p>
<p>Next we define three hypotheses: <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, and <span class="math inline">\(C\)</span> represent the hypothesis that the car is behind Door <span class="math inline">\(A\)</span>, Door <span class="math inline">\(B\)</span>, or Door <span class="math inline">\(C\)</span>. Again, let’s apply the table method:</p>
<p>Filling in the priors is easy because we are told that the prizes are arranged at random, which suggests that the car is equally likely to be behind any door.</p>
<p>Figuring out the likelihoods takes some thought, but with reasonable care we can be confident that we have it right:</p>
<ul>
<li><p>If the car is actually behind <span class="math inline">\(A\)</span>, Monty could safely open Doors <span class="math inline">\(B\)</span> or <span class="math inline">\(C\)</span>. So the probability that he chooses <span class="math inline">\(B\)</span> is <span class="math inline">\(1/2\)</span>. And since the car is actually behind <span class="math inline">\(A\)</span>, the probability that the car is not behind <span class="math inline">\(B\)</span> is <span class="math inline">\(1\)</span>.</p></li>
<li><p>If the car is actually behind <span class="math inline">\(B\)</span>, Monty has to open door <span class="math inline">\(C\)</span>, so the probability that he opens door <span class="math inline">\(B\)</span> is <span class="math inline">\(0\)</span>.</p></li>
<li><p>Finally, if the car is behind Door <span class="math inline">\(C\)</span>, Monty opens <span class="math inline">\(B\)</span> with probability <span class="math inline">\(1\)</span> and finds no car there with probability <span class="math inline">\(1\)</span>.</p></li>
</ul>
<p>Now the hard part is over; the rest is just arithmetic. The sum of the third column is <span class="math inline">\(1/2\)</span>. Dividing through yields <span class="math inline">\(p(A|D) = 1/3\)</span> and <span class="math inline">\(p(C|D) = 2/3\)</span>. So you are better off switching.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Prior <span class="math inline">\(p(H)\)</span></th>
<th>Likelihood <span class="math inline">\(P(D|H)\)</span></th>
<th><span class="math inline">\(p(H)p(D|H)\)</span></th>
<th>Posterior <span class="math inline">\(p(H|D)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>1/3</td>
<td>1/2</td>
<td>1/6</td>
<td>1/3</td>
</tr>
<tr class="even">
<td>B</td>
<td>1/3</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>C</td>
<td>1/3</td>
<td>1</td>
<td>1/3</td>
<td>2/3</td>
</tr>
</tbody>
</table>
<p>Filling in the priors is easy because we are told that the prizes are arranged at random, which suggests that the car is equally likely to be behind any door.</p>
<p>Figuring out the likelihoods takes some thought, but with reasonable care we can be confident that we have it right:</p>
<ul>
<li>If the car is actually behind <span class="math inline">\(A\)</span>, Monty could safely open Doors <span class="math inline">\(B\)</span> or <span class="math inline">\(C\)</span>. So the probability that he chooses <span class="math inline">\(B\)</span> is <span class="math inline">\(1/2\)</span>. And since the car is actually behind <span class="math inline">\(A\)</span>, the probability that the car is not behind <span class="math inline">\(B\)</span> is <span class="math inline">\(1\)</span>.</li>
<li>If the car is actually behind <span class="math inline">\(B\)</span>, Monty has to open door <span class="math inline">\(C\)</span>, so the probability that he opens door <span class="math inline">\(B\)</span> is <span class="math inline">\(0\)</span>.</li>
<li>Finally, if the car is behind Door <span class="math inline">\(C\)</span>, Monty opens <span class="math inline">\(B\)</span> with probability <span class="math inline">\(1\)</span> and finds no car there with probability <span class="math inline">\(1\)</span>.</li>
</ul>
<p>Now the hard part is over; the rest is just arithmetic. The sum of the third column is <span class="math inline">\(1/2\)</span>. Dividing through yields <span class="math inline">\(p(A|D) = 1/3\)</span> and <span class="math inline">\(p(C|D) = 2/3\)</span>.
So you are better off switching.</p>
<p>There are many variations of the Monty Hall problem. One of the strengths of the Bayesian approach is that it generalizes to handle these variations.</p>
<p>For example, suppose that Monty always chooses <span class="math inline">\(B\)</span> if he can, and onlychooses <span class="math inline">\(C\)</span> if he has to (because the car is behind <span class="math inline">\(B\)</span>). In that case the revised table is:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Prior <span class="math inline">\(p(H)\)</span></th>
<th>Likelihood <span class="math inline">\(P(D|H)\)</span></th>
<th><span class="math inline">\(p(H)p(D|H)\)</span></th>
<th>Posterior <span class="math inline">\(p(H|D)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A</td>
<td>1/3</td>
<td>1</td>
<td>1/3</td>
<td>1/2</td>
</tr>
<tr class="even">
<td>B</td>
<td>1/3</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td>C</td>
<td>1/3</td>
<td>1</td>
<td>1/3</td>
<td>1/2</td>
</tr>
</tbody>
</table>
<p>The only change is <span class="math inline">\(p(D|A)\)</span>. If the car is behind <span class="math inline">\(A\)</span>, Monty can choose to open <span class="math inline">\(B\)</span> or <span class="math inline">\(C\)</span>. But in this variation he always chooses <span class="math inline">\(B\)</span>, so <span class="math inline">\(p(D|A) = 1\)</span>.</p>
<p>As a result, the likelihoods are the same for <span class="math inline">\(A\)</span> and <span class="math inline">\(C\)</span>, and the posteriors are the same: <span class="math inline">\(p(A|D) = p(C|D) = 1/2\)</span>. In this case, the fact that Monty chose <span class="math inline">\(B\)</span> reveals no information about the location of the car, so it doesn’t matter whether the contestant sticks or switches.</p>
<p>On the other hand, if he had opened <span class="math inline">\(C\)</span>, we would know <span class="math inline">\(p(B|D) = 1\)</span>.</p>
<p>For many problems involving conditional probability, Bayes’s theorem provides a divide-and-conquer strategy. If <span class="math inline">\(p(A|B)\)</span> is hard to compute, or hard to measure experimentally, check whether it might be easier to compute the other terms in Bayes’s theorem, <span class="math inline">\(p(B|A)\)</span>, <span class="math inline">\(p(A)\)</span> and <span class="math inline">\(p(B)\)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4-functions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="6-sampling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
