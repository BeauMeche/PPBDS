<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Confidence Intervals | Preceptor’s Primer for Bayesian Data Science</title>
  <meta name="description" content="Chapter 10 Confidence Intervals | Preceptor’s Primer for Bayesian Data Science" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Confidence Intervals | Preceptor’s Primer for Bayesian Data Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="davidkane9/PPBDS" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Confidence Intervals | Preceptor’s Primer for Bayesian Data Science" />
  
  
  

<meta name="author" content="David Kane" />


<meta name="date" content="2020-04-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="9-sampling.html"/>
<link rel="next" href="11-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="forward.html"><a href="forward.html"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="warning.html"><a href="warning.html"><i class="fa fa-check"></i>Warning</a></li>
<li class="chapter" data-level="" data-path="license.html"><a href="license.html"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="1" data-path="1-getting-started.html"><a href="1-getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting Started</a><ul>
<li class="chapter" data-level="1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>1.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#installing"><i class="fa fa-check"></i><b>1.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#code"><i class="fa fa-check"></i><b>1.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-getting-started.html"><a href="1-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>1.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-getting-started.html"><a href="1-getting-started.html#messages"><i class="fa fa-check"></i><b>1.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-getting-started.html"><a href="1-getting-started.html#tips-code"><i class="fa fa-check"></i><b>1.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-getting-started.html"><a href="1-getting-started.html#packages"><i class="fa fa-check"></i><b>1.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-getting-started.html"><a href="1-getting-started.html#package-installation"><i class="fa fa-check"></i><b>1.3.1</b> Package installation</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-getting-started.html"><a href="1-getting-started.html#package-loading"><i class="fa fa-check"></i><b>1.3.2</b> Package loading</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-getting-started.html"><a href="1-getting-started.html#package-use"><i class="fa fa-check"></i><b>1.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>1.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>1.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-getting-started.html"><a href="1-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>1.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-getting-started.html"><a href="1-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>1.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-getting-started.html"><a href="1-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>1.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="1-getting-started.html"><a href="1-getting-started.html#help-files"><i class="fa fa-check"></i><b>1.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-getting-started.html"><a href="1-getting-started.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a><ul>
<li class="chapter" data-level="1.5.1" data-path="1-getting-started.html"><a href="1-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>1.5.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-viz.html"><a href="2-viz.html"><i class="fa fa-check"></i><b>2</b> Visualization</a><ul>
<li class="chapter" data-level="" data-path="2-viz.html"><a href="2-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="2.1" data-path="2-viz.html"><a href="2-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>2.1</b> The grammar of graphics</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-viz.html"><a href="2-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>2.1.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-viz.html"><a href="2-viz.html#gapminder"><i class="fa fa-check"></i><b>2.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-viz.html"><a href="2-viz.html#other-components"><i class="fa fa-check"></i><b>2.1.3</b> Other components</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-viz.html"><a href="2-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>2.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-viz.html"><a href="2-viz.html#scatterplots"><i class="fa fa-check"></i><b>2.2</b> Scatterplots</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-viz.html"><a href="2-viz.html#geompoint"><i class="fa fa-check"></i><b>2.2.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="2.2.2" data-path="2-viz.html"><a href="2-viz.html#overplotting"><i class="fa fa-check"></i><b>2.2.2</b> Overplotting</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-viz.html"><a href="2-viz.html#summary"><i class="fa fa-check"></i><b>2.2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-viz.html"><a href="2-viz.html#linegraphs"><i class="fa fa-check"></i><b>2.3</b> Linegraphs</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-viz.html"><a href="2-viz.html#geomline"><i class="fa fa-check"></i><b>2.3.1</b> Linegraphs via <code>geom_line</code></a></li>
<li class="chapter" data-level="2.3.2" data-path="2-viz.html"><a href="2-viz.html#summary-1"><i class="fa fa-check"></i><b>2.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-viz.html"><a href="2-viz.html#histograms"><i class="fa fa-check"></i><b>2.4</b> Histograms</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-viz.html"><a href="2-viz.html#geomhistogram"><i class="fa fa-check"></i><b>2.4.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="2.4.2" data-path="2-viz.html"><a href="2-viz.html#adjustbins"><i class="fa fa-check"></i><b>2.4.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-viz.html"><a href="2-viz.html#summary-2"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-viz.html"><a href="2-viz.html#facets"><i class="fa fa-check"></i><b>2.5</b> Facets</a></li>
<li class="chapter" data-level="2.6" data-path="2-viz.html"><a href="2-viz.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a><ul>
<li class="chapter" data-level="2.6.1" data-path="2-viz.html"><a href="2-viz.html#geomboxplot"><i class="fa fa-check"></i><b>2.6.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="2-viz.html"><a href="2-viz.html#summary-3"><i class="fa fa-check"></i><b>2.6.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2-viz.html"><a href="2-viz.html#geombar"><i class="fa fa-check"></i><b>2.7</b> Barplots</a><ul>
<li class="chapter" data-level="2.7.1" data-path="2-viz.html"><a href="2-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>2.7.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="2.7.2" data-path="2-viz.html"><a href="2-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>2.7.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="2.7.3" data-path="2-viz.html"><a href="2-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>2.7.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="2.7.4" data-path="2-viz.html"><a href="2-viz.html#summary-4"><i class="fa fa-check"></i><b>2.7.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="2-viz.html"><a href="2-viz.html#conclusion-1"><i class="fa fa-check"></i><b>2.8</b> Conclusion</a><ul>
<li class="chapter" data-level="2.8.1" data-path="2-viz.html"><a href="2-viz.html#summary-table"><i class="fa fa-check"></i><b>2.8.1</b> Summary table</a></li>
<li class="chapter" data-level="2.8.2" data-path="2-viz.html"><a href="2-viz.html#function-argument-specification"><i class="fa fa-check"></i><b>2.8.2</b> Function argument specification</a></li>
<li class="chapter" data-level="2.8.3" data-path="2-viz.html"><a href="2-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>2.8.3</b> Additional resources</a></li>
<li class="chapter" data-level="2.8.4" data-path="2-viz.html"><a href="2-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>2.8.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-productivity.html"><a href="3-productivity.html"><i class="fa fa-check"></i><b>3</b> Productivity</a><ul>
<li class="chapter" data-level="3.1" data-path="3-productivity.html"><a href="3-productivity.html#set-up"><i class="fa fa-check"></i><b>3.1</b> Set Up</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-mac"><i class="fa fa-check"></i><b>3.1.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>3.1.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>3.1.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-windows"><i class="fa fa-check"></i><b>3.1.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-productivity.html"><a href="3-productivity.html#unix"><i class="fa fa-check"></i><b>3.2</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-productivity.html"><a href="3-productivity.html#naming-convention"><i class="fa fa-check"></i><b>3.2.1</b> Naming convention</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-productivity.html"><a href="3-productivity.html#the-terminal"><i class="fa fa-check"></i><b>3.2.2</b> The terminal</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-productivity.html"><a href="3-productivity.html#filesystem"><i class="fa fa-check"></i><b>3.2.3</b> The filesystem</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-productivity.html"><a href="3-productivity.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>3.2.4</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-productivity.html"><a href="3-productivity.html#the-home-directory"><i class="fa fa-check"></i><b>3.2.5</b> The home directory</a></li>
<li class="chapter" data-level="3.2.6" data-path="3-productivity.html"><a href="3-productivity.html#working-directory"><i class="fa fa-check"></i><b>3.2.6</b> Working directory</a></li>
<li class="chapter" data-level="3.2.7" data-path="3-productivity.html"><a href="3-productivity.html#paths"><i class="fa fa-check"></i><b>3.2.7</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-productivity.html"><a href="3-productivity.html#unix-commands"><i class="fa fa-check"></i><b>3.3</b> Unix commands</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-productivity.html"><a href="3-productivity.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>3.3.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-productivity.html"><a href="3-productivity.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>3.3.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-productivity.html"><a href="3-productivity.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>3.3.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-productivity.html"><a href="3-productivity.html#some-examples"><i class="fa fa-check"></i><b>3.3.4</b> Some examples</a></li>
<li class="chapter" data-level="3.3.5" data-path="3-productivity.html"><a href="3-productivity.html#more-unix-commands"><i class="fa fa-check"></i><b>3.3.5</b> More Unix commands</a></li>
<li class="chapter" data-level="3.3.6" data-path="3-productivity.html"><a href="3-productivity.html#advanced-unix"><i class="fa fa-check"></i><b>3.3.6</b> Advanced Unix</a></li>
<li class="chapter" data-level="3.3.7" data-path="3-productivity.html"><a href="3-productivity.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>3.3.7</b> File manipulation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-productivity.html"><a href="3-productivity.html#git"><i class="fa fa-check"></i><b>3.4</b> Git and GitHub</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-productivity.html"><a href="3-productivity.html#github-accounts"><i class="fa fa-check"></i><b>3.4.1</b> GitHub accounts</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-productivity.html"><a href="3-productivity.html#github-repos"><i class="fa fa-check"></i><b>3.4.2</b> GitHub repositories</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-productivity.html"><a href="3-productivity.html#git-overview"><i class="fa fa-check"></i><b>3.4.3</b> Overview of Git</a></li>
<li class="chapter" data-level="3.4.4" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-git"><i class="fa fa-check"></i><b>3.4.4</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-productivity.html"><a href="3-productivity.html#r"><i class="fa fa-check"></i><b>3.5</b> R</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-projects"><i class="fa fa-check"></i><b>3.5.1</b> RStudio projects</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-productivity.html"><a href="3-productivity.html#r-markdown"><i class="fa fa-check"></i><b>3.5.2</b> R markdown</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-productivity.html"><a href="3-productivity.html#help-for-r"><i class="fa fa-check"></i><b>3.5.3</b> Help for R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#factors"><i class="fa fa-check"></i><b>4.7</b> Factors</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#the-forcats-package"><i class="fa fa-check"></i><b>4.7.1</b> The <strong>forcats</strong> package</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#dropping-unused-levels"><i class="fa fa-check"></i><b>4.7.2</b> Dropping unused levels</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#reorder-factors"><i class="fa fa-check"></i><b>4.7.3</b> Change order of the levels, principled</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#change-order-of-the-levels-because-i-said-so"><i class="fa fa-check"></i><b>4.7.4</b> Change order of the levels, “because I said so”</a></li>
<li class="chapter" data-level="4.7.5" data-path="4-wrangling.html"><a href="4-wrangling.html#recode-the-levels"><i class="fa fa-check"></i><b>4.7.5</b> Recode the levels</a></li>
<li class="chapter" data-level="4.7.6" data-path="4-wrangling.html"><a href="4-wrangling.html#grow-a-factor"><i class="fa fa-check"></i><b>4.7.6</b> Grow a factor</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors"><i class="fa fa-check"></i><b>4.8</b> Character Vectors</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#manipulating-character-vectors"><i class="fa fa-check"></i><b>4.8.1</b> Manipulating character vectors</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-resources"><i class="fa fa-check"></i><b>4.8.2</b> Regular expressions resources</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#character-encoding-resources"><i class="fa fa-check"></i><b>4.8.3</b> Character encoding resources</a></li>
<li class="chapter" data-level="4.8.4" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors-that-live-in-a-data-frame"><i class="fa fa-check"></i><b>4.8.4</b> Character vectors that live in a data frame</a></li>
<li class="chapter" data-level="4.8.5" data-path="4-wrangling.html"><a href="4-wrangling.html#regex-free-string-manipulation-with-stringr-and-tidyr"><i class="fa fa-check"></i><b>4.8.5</b> Regex-free string manipulation with stringr and tidyr</a></li>
<li class="chapter" data-level="4.8.6" data-path="4-wrangling.html"><a href="4-wrangling.html#detect-or-filter-on-a-target-string"><i class="fa fa-check"></i><b>4.8.6</b> Detect or filter on a target string</a></li>
<li class="chapter" data-level="4.8.7" data-path="4-wrangling.html"><a href="4-wrangling.html#string-splitting-by-delimiter"><i class="fa fa-check"></i><b>4.8.7</b> String splitting by delimiter</a></li>
<li class="chapter" data-level="4.8.8" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-extraction-and-replacement-by-position"><i class="fa fa-check"></i><b>4.8.8</b> Substring extraction (and replacement) by position</a></li>
<li class="chapter" data-level="4.8.9" data-path="4-wrangling.html"><a href="4-wrangling.html#collapse-a-vector"><i class="fa fa-check"></i><b>4.8.9</b> Collapse a vector</a></li>
<li class="chapter" data-level="4.8.10" data-path="4-wrangling.html"><a href="4-wrangling.html#catenate-vectors"><i class="fa fa-check"></i><b>4.8.10</b> Create a character vector by catenating multiple vectors</a></li>
<li class="chapter" data-level="4.8.11" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-replacement"><i class="fa fa-check"></i><b>4.8.11</b> Substring replacement</a></li>
<li class="chapter" data-level="4.8.12" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-with-stringr"><i class="fa fa-check"></i><b>4.8.12</b> Regular expressions with stringr</a></li>
<li class="chapter" data-level="4.8.13" data-path="4-wrangling.html"><a href="4-wrangling.html#characters-with-special-meaning"><i class="fa fa-check"></i><b>4.8.13</b> Characters with special meaning</a></li>
<li class="chapter" data-level="4.8.14" data-path="4-wrangling.html"><a href="4-wrangling.html#character-classes"><i class="fa fa-check"></i><b>4.8.14</b> Character classes</a></li>
<li class="chapter" data-level="4.8.15" data-path="4-wrangling.html"><a href="4-wrangling.html#quantifiers"><i class="fa fa-check"></i><b>4.8.15</b> Quantifiers</a></li>
<li class="chapter" data-level="4.8.16" data-path="4-wrangling.html"><a href="4-wrangling.html#escaping"><i class="fa fa-check"></i><b>4.8.16</b> Escaping</a></li>
<li class="chapter" data-level="4.8.17" data-path="4-wrangling.html"><a href="4-wrangling.html#groups-and-backreferences"><i class="fa fa-check"></i><b>4.8.17</b> Groups and backreferences</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#combining-data"><i class="fa fa-check"></i><b>4.9</b> Combining Data</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#bind"><i class="fa fa-check"></i><b>4.9.1</b> Bind</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#joins-in-dplyr"><i class="fa fa-check"></i><b>4.9.2</b> Joins in dplyr</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#joining"><i class="fa fa-check"></i><b>4.9.3</b> Joining</a></li>
<li class="chapter" data-level="4.9.4" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.9.4</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.9.5" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.9.5</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.9.6" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.9.6</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.9.7" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.9.7</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.10</b> Other Verbs</a><ul>
<li class="chapter" data-level="4.10.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.10.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.10.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.10.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.10.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.10.3</b> <code>top_n</code> values of a variable</a></li>
<li class="chapter" data-level="4.10.4" data-path="4-wrangling.html"><a href="4-wrangling.html#slice-and-pull-and"><i class="fa fa-check"></i><b>4.10.4</b> <code>slice</code> and <code>pull</code> and <code>[]</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.11</b> Conclusion</a><ul>
<li class="chapter" data-level="4.11.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.11.1</b> Summary table</a></li>
<li class="chapter" data-level="4.11.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.11.2</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Tidy</a><ul>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#web-scraping"><i class="fa fa-check"></i><b>5.2</b> Web scraping</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#html"><i class="fa fa-check"></i><b>5.2.1</b> HTML</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#the-rvest-package"><i class="fa fa-check"></i><b>5.2.2</b> The rvest package</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#css-selectors"><i class="fa fa-check"></i><b>5.2.3</b> CSS selectors</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-tidy.html"><a href="5-tidy.html#json"><i class="fa fa-check"></i><b>5.2.4</b> JSON</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.3</b> “Tidy” data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-tidy.html"><a href="5-tidy.html#tidy-definition"><i class="fa fa-check"></i><b>5.3.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.3.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.3.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.3.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.3.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.4</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.5" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.5</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.6" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.6</b> Conclusion</a><ul>
<li class="chapter" data-level="5.6.1" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.6.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-functions.html"><a href="6-functions.html"><i class="fa fa-check"></i><b>6</b> Functions</a><ul>
<li class="chapter" data-level="6.1" data-path="6-functions.html"><a href="6-functions.html#part-1"><i class="fa fa-check"></i><b>6.1</b> Part 1</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works"><i class="fa fa-check"></i><b>6.1.1</b> Get something that works</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-functions.html"><a href="6-functions.html#skateboard-perfectly-formed-rear-view-mirror"><i class="fa fa-check"></i><b>6.1.2</b> Skateboard &gt;&gt; perfectly formed rear-view mirror</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function"><i class="fa fa-check"></i><b>6.1.3</b> Turn the working interactive code into a function</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-functions.html"><a href="6-functions.html#test-your-function"><i class="fa fa-check"></i><b>6.1.4</b> Test your function</a></li>
<li class="chapter" data-level="6.1.5" data-path="6-functions.html"><a href="6-functions.html#check-the-validity-of-arguments"><i class="fa fa-check"></i><b>6.1.5</b> Check the validity of arguments</a></li>
<li class="chapter" data-level="6.1.6" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next"><i class="fa fa-check"></i><b>6.1.6</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-functions.html"><a href="6-functions.html#part-2"><i class="fa fa-check"></i><b>6.2</b> Part 2</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-functions.html"><a href="6-functions.html#load-the-gapminder-data"><i class="fa fa-check"></i><b>6.2.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function"><i class="fa fa-check"></i><b>6.2.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-functions.html"><a href="6-functions.html#generalize-our-function-to-other-quantiles"><i class="fa fa-check"></i><b>6.2.3</b> Generalize our function to other quantiles</a></li>
<li class="chapter" data-level="6.2.4" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works-again"><i class="fa fa-check"></i><b>6.2.4</b> Get something that works, again</a></li>
<li class="chapter" data-level="6.2.5" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function-again"><i class="fa fa-check"></i><b>6.2.5</b> Turn the working interactive code into a function, again</a></li>
<li class="chapter" data-level="6.2.6" data-path="6-functions.html"><a href="6-functions.html#argument-names-freedom-and-conventions"><i class="fa fa-check"></i><b>6.2.6</b> Argument names: freedom and conventions</a></li>
<li class="chapter" data-level="6.2.7" data-path="6-functions.html"><a href="6-functions.html#what-a-function-returns"><i class="fa fa-check"></i><b>6.2.7</b> What a function returns</a></li>
<li class="chapter" data-level="6.2.8" data-path="6-functions.html"><a href="6-functions.html#default-values-freedom-to-not-specify-the-arguments"><i class="fa fa-check"></i><b>6.2.8</b> Default values: freedom to NOT specify the arguments</a></li>
<li class="chapter" data-level="6.2.9" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next-1"><i class="fa fa-check"></i><b>6.2.9</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-functions.html"><a href="6-functions.html#part-3"><i class="fa fa-check"></i><b>6.3</b> Part 3</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-functions.html"><a href="6-functions.html#load-the-gapminder-data-1"><i class="fa fa-check"></i><b>6.3.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function-1"><i class="fa fa-check"></i><b>6.3.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-functions.html"><a href="6-functions.html#be-proactive-about-nas"><i class="fa fa-check"></i><b>6.3.3</b> Be proactive about <code>NA</code>s</a></li>
<li class="chapter" data-level="6.3.4" data-path="6-functions.html"><a href="6-functions.html#the-useful-but-mysterious-...-argument"><i class="fa fa-check"></i><b>6.3.4</b> The useful but mysterious <code>...</code> argument</a></li>
<li class="chapter" data-level="6.3.5" data-path="6-functions.html"><a href="6-functions.html#use-testthat-for-formal-unit-tests"><i class="fa fa-check"></i><b>6.3.5</b> Use testthat for formal unit tests</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-functions.html"><a href="6-functions.html#list-columns-and-map_-functions"><i class="fa fa-check"></i><b>6.4</b> List columns and <code>map_*</code> functions</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-functions.html"><a href="6-functions.html#what-are-list-columns"><i class="fa fa-check"></i><b>6.4.1</b> What are list columns?</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-functions.html"><a href="6-functions.html#creating-list-columns-with-mutate"><i class="fa fa-check"></i><b>6.4.2</b> Creating list columns with <code>mutate()</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="6-functions.html"><a href="6-functions.html#map_-functions"><i class="fa fa-check"></i><b>6.4.3</b> <code>map_*</code> functions</a></li>
<li class="chapter" data-level="6.4.4" data-path="6-functions.html"><a href="6-functions.html#using-map_-functions-to-create-list-columns"><i class="fa fa-check"></i><b>6.4.4</b> Using <code>map_*</code> functions to create list columns</a></li>
<li class="chapter" data-level="6.4.5" data-path="6-functions.html"><a href="6-functions.html#practice-with-map_-functions-and-list-columns"><i class="fa fa-check"></i><b>6.4.5</b> Practice with <code>map_*</code> functions and list columns</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-probability.html"><a href="7-probability.html"><i class="fa fa-check"></i><b>7</b> Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="7-probability.html"><a href="7-probability.html#basicsOfProbability"><i class="fa fa-check"></i><b>7.1</b> Defining probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-probability.html"><a href="7-probability.html#intro-questions"><i class="fa fa-check"></i><b>7.1.1</b> Intro Questions</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-probability.html"><a href="7-probability.html#probability-1"><i class="fa fa-check"></i><b>7.1.2</b> Probability</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-probability.html"><a href="7-probability.html#disjoint-or-mutually-exclusive-outcomes"><i class="fa fa-check"></i><b>7.1.3</b> Disjoint or mutually exclusive outcomes</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-probability.html"><a href="7-probability.html#probabilities-when-events-are-not-disjoint"><i class="fa fa-check"></i><b>7.1.4</b> Probabilities when events are not disjoint</a></li>
<li class="chapter" data-level="7.1.5" data-path="7-probability.html"><a href="7-probability.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.5</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.6" data-path="7-probability.html"><a href="7-probability.html#complement-of-an-event"><i class="fa fa-check"></i><b>7.1.6</b> Complement of an event</a></li>
<li class="chapter" data-level="7.1.7" data-path="7-probability.html"><a href="7-probability.html#probabilityIndependence"><i class="fa fa-check"></i><b>7.1.7</b> Independence</a></li>
<li class="chapter" data-level="7.1.8" data-path="7-probability.html"><a href="7-probability.html#conditionalProbabilitySection"><i class="fa fa-check"></i><b>7.1.8</b> Conditional probability</a></li>
<li class="chapter" data-level="7.1.9" data-path="7-probability.html"><a href="7-probability.html#marginalAndJointProbabilities"><i class="fa fa-check"></i><b>7.1.9</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="7.1.10" data-path="7-probability.html"><a href="7-probability.html#defining-conditional-probability"><i class="fa fa-check"></i><b>7.1.10</b> Defining conditional probability</a></li>
<li class="chapter" data-level="7.1.11" data-path="7-probability.html"><a href="7-probability.html#smallpox-in-boston-1721"><i class="fa fa-check"></i><b>7.1.11</b> Smallpox in Boston, 1721</a></li>
<li class="chapter" data-level="7.1.12" data-path="7-probability.html"><a href="7-probability.html#general-multiplication-rule"><i class="fa fa-check"></i><b>7.1.12</b> General multiplication rule</a></li>
<li class="chapter" data-level="7.1.13" data-path="7-probability.html"><a href="7-probability.html#tree-diagrams"><i class="fa fa-check"></i><b>7.1.13</b> Tree diagrams</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-probability.html"><a href="7-probability.html#randomVariablesSection"><i class="fa fa-check"></i><b>7.2</b> Random variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-probability.html"><a href="7-probability.html#expectation"><i class="fa fa-check"></i><b>7.2.1</b> Expectation</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-probability.html"><a href="7-probability.html#variability-in-random-variables"><i class="fa fa-check"></i><b>7.2.2</b> Variability in random variables</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-probability.html"><a href="7-probability.html#linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.2.3</b> Linear combinations of random variables</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-probability.html"><a href="7-probability.html#variability-in-linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.2.4</b> Variability in linear combinations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-probability.html"><a href="7-probability.html#appendixA"><i class="fa fa-check"></i><b>7.3</b> Statistical Background</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-probability.html"><a href="7-probability.html#appendix-stat-terms"><i class="fa fa-check"></i><b>7.3.1</b> Basic statistical terms</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-probability.html"><a href="7-probability.html#appendix-normal-curve"><i class="fa fa-check"></i><b>7.3.2</b> Normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html"><i class="fa fa-check"></i><b>8</b> Bayes’s Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conditional-probability"><i class="fa fa-check"></i><b>8.1</b> Conditional probability</a></li>
<li class="chapter" data-level="8.2" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conjoint-probability"><i class="fa fa-check"></i><b>8.2</b> Conjoint probability</a></li>
<li class="chapter" data-level="8.3" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-cookie-problem"><i class="fa fa-check"></i><b>8.3</b> The cookie problem</a></li>
<li class="chapter" data-level="8.4" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#bayess-theorem-1"><i class="fa fa-check"></i><b>8.4</b> Bayes’s Theorem</a></li>
<li class="chapter" data-level="8.5" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-diachronic-interpretation"><i class="fa fa-check"></i><b>8.5</b> The diachronic interpretation</a></li>
<li class="chapter" data-level="8.6" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-mm-problem"><i class="fa fa-check"></i><b>8.6</b> The M&amp;M problem</a></li>
<li class="chapter" data-level="8.7" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-monty-hall-problem"><i class="fa fa-check"></i><b>8.7</b> The Monty Hall problem</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-sampling.html"><a href="9-sampling.html"><i class="fa fa-check"></i><b>9</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="9-sampling.html"><a href="9-sampling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>9.1</b> Sampling urn activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-sampling.html"><a href="9-sampling.html#what-proportion-of-this-urns-balls-are-red"><i class="fa fa-check"></i><b>9.1.1</b> What proportion of this urn’s balls are red?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>9.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-sampling.html"><a href="9-sampling.html#student-shovels"><i class="fa fa-check"></i><b>9.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-sampling.html"><a href="9-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>9.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Virtual sampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>9.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>9.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-sampling.html"><a href="9-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>9.2.3</b> Using the virtual shovel 1,000 times</a></li>
<li class="chapter" data-level="9.2.4" data-path="9-sampling.html"><a href="9-sampling.html#different-shovels"><i class="fa fa-check"></i><b>9.2.4</b> Using different shovels</a></li>
<li class="chapter" data-level="9.2.5" data-path="9-sampling.html"><a href="9-sampling.html#using-many-shovels-at-once"><i class="fa fa-check"></i><b>9.2.5</b> Using many shovels at once</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-sampling.html"><a href="9-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>9.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-sampling.html"><a href="9-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>9.3.1</b> Terminology and notation</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>9.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="9.3.3" data-path="9-sampling.html"><a href="9-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>9.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-sampling.html"><a href="9-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>9.4</b> Case study: Polls</a><ul>
<li class="chapter" data-level="9.4.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>9.4.1</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9-sampling.html"><a href="9-sampling.html#conclusion-4"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>10.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>10.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>10.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>10.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>10.1.4</b> What did we just do?</a></li>
<li class="chapter" data-level="10.1.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>10.1.5</b> Virtually resampling once</a></li>
<li class="chapter" data-level="10.1.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-35-replicates"><i class="fa fa-check"></i><b>10.1.6</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="10.1.7" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>10.1.7</b> Virtually resampling 1,000 times</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>10.2</b> Measuring uncertainty with confidence intervals</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>10.2.1</b> Percentile method</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>10.2.2</b> Standard error method</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>10.2.3</b> Interpreting confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>10.3</b> Width of confidence intervals</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-confidence-level"><i class="fa fa-check"></i><b>10.3.1</b> Impact of confidence level</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#fitting-multiple-models-using-map"><i class="fa fa-check"></i><b>10.3.2</b> Fitting multiple models using <code>map()</code></a></li>
<li class="chapter" data-level="10.3.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-sample-size"><i class="fa fa-check"></i><b>10.3.3</b> Impact of sample size</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut"><i class="fa fa-check"></i><b>10.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="10.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>10.5</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>10.5.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>10.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>10.5.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="10.5.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut-1"><i class="fa fa-check"></i><b>10.5.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>10.6.1</b> Comparing bootstrap and sampling distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-regression.html"><a href="11-regression.html"><i class="fa fa-check"></i><b>11</b> Regression</a><ul>
<li class="chapter" data-level="" data-path="11-regression.html"><a href="11-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-regression.html"><a href="11-regression.html#model1"><i class="fa fa-check"></i><b>11.1</b> Teaching evaluations: one numerical explanatory variable</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-regression.html"><a href="11-regression.html#model1EDA"><i class="fa fa-check"></i><b>11.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-regression.html"><a href="11-regression.html#model1table"><i class="fa fa-check"></i><b>11.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="11.1.3" data-path="11-regression.html"><a href="11-regression.html#interpreting-regression-coefficients"><i class="fa fa-check"></i><b>11.1.3</b> Interpreting regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-regression.html"><a href="11-regression.html#uncertainty-in-simple-linear-regressions"><i class="fa fa-check"></i><b>11.2</b> Uncertainty in simple linear regressions</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-regression.html"><a href="11-regression.html#using-lm-and-tidy-as-a-shortcut-2"><i class="fa fa-check"></i><b>11.2.1</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-regression.html"><a href="11-regression.html#model1points"><i class="fa fa-check"></i><b>11.2.2</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-regression.html"><a href="11-regression.html#model2"><i class="fa fa-check"></i><b>11.3</b> Life expectancy: one categorical explanatory variable</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-regression.html"><a href="11-regression.html#model2EDA"><i class="fa fa-check"></i><b>11.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-regression.html"><a href="11-regression.html#model2table"><i class="fa fa-check"></i><b>11.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-regression.html"><a href="11-regression.html#model2points"><i class="fa fa-check"></i><b>11.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-regression.html"><a href="11-regression.html#case-study-2018-gubernatorial-forecasts"><i class="fa fa-check"></i><b>11.4</b> Case study: 2018 gubernatorial forecasts</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-regression.html"><a href="11-regression.html#fitting-multiple-models-using-map-1"><i class="fa fa-check"></i><b>11.4.1</b> Fitting multiple models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-regression.html"><a href="11-regression.html#leastsquares"><i class="fa fa-check"></i><b>11.5</b> Appendix: Best-fitting line</a></li>
<li class="chapter" data-level="11.6" data-path="11-regression.html"><a href="11-regression.html#conclusion-5"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html"><i class="fa fa-check"></i><b>12</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4"><i class="fa fa-check"></i><b>12.1</b> Teaching evaluations revisited: one numerical and one categorical explanatory variable</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>12.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#interpreting-regression-coefficients-with-interactions"><i class="fa fa-check"></i><b>12.1.3</b> Interpreting regression coefficients with interactions</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>12.1.4</b> Parallel slopes model</a></li>
<li class="chapter" data-level="12.1.5" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>12.1.5</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3"><i class="fa fa-check"></i><b>12.2</b> Credit card debt: two numerical explanatory variables</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>12.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>12.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>12.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.3</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.3.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.3.1</b> Exploratory data analysis: Part I</a></li>
<li class="chapter" data-level="12.3.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-II"><i class="fa fa-check"></i><b>12.3.2</b> Exploratory data analysis: Part II</a></li>
<li class="chapter" data-level="12.3.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-regression"><i class="fa fa-check"></i><b>12.3.3</b> Regression modeling</a></li>
<li class="chapter" data-level="12.3.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.3.4</b> Making predictions</a></li>
<li class="chapter" data-level="12.3.5" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#fitting-many-models-using-map"><i class="fa fa-check"></i><b>12.3.5</b> Fitting many models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#other-topics"><i class="fa fa-check"></i><b>12.4</b> Other topics</a><ul>
<li class="chapter" data-level="12.4.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>12.4.1</b> Model selection</a></li>
<li class="chapter" data-level="12.4.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>12.4.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="12.4.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>12.4.3</b> Simpson’s Paradox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-classification.html"><a href="13-classification.html"><i class="fa fa-check"></i><b>13</b> Classification</a><ul>
<li class="chapter" data-level="" data-path="13-classification.html"><a href="13-classification.html#needed-packages-5"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="13.1" data-path="13-classification.html"><a href="13-classification.html#logistic-regression"><i class="fa fa-check"></i><b>13.1</b> Logistic regression</a><ul>
<li class="chapter" data-level="13.1.1" data-path="13-classification.html"><a href="13-classification.html#what-is-logistic-regression"><i class="fa fa-check"></i><b>13.1.1</b> What is logistic regression?</a></li>
<li class="chapter" data-level="13.1.2" data-path="13-classification.html"><a href="13-classification.html#house-elections-exploratory-data-analysis"><i class="fa fa-check"></i><b>13.1.2</b> House elections: exploratory data analysis</a></li>
<li class="chapter" data-level="13.1.3" data-path="13-classification.html"><a href="13-classification.html#one-categorical-explanatory-variable"><i class="fa fa-check"></i><b>13.1.3</b> One categorical explanatory variable</a></li>
<li class="chapter" data-level="13.1.4" data-path="13-classification.html"><a href="13-classification.html#observedfitted-values-and-residuals"><i class="fa fa-check"></i><b>13.1.4</b> Observed/fitted values and residuals</a></li>
<li class="chapter" data-level="13.1.5" data-path="13-classification.html"><a href="13-classification.html#one-numerical-explanatory-variable"><i class="fa fa-check"></i><b>13.1.5</b> One numerical explanatory variable</a></li>
<li class="chapter" data-level="13.1.6" data-path="13-classification.html"><a href="13-classification.html#one-numerical-and-one-categorical-explanatory-variable"><i class="fa fa-check"></i><b>13.1.6</b> One numerical and one categorical explanatory variable</a></li>
<li class="chapter" data-level="13.1.7" data-path="13-classification.html"><a href="13-classification.html#fitting-many-models-using-map-1"><i class="fa fa-check"></i><b>13.1.7</b> Fitting many models using <code>map()</code></a></li>
<li class="chapter" data-level="13.1.8" data-path="13-classification.html"><a href="13-classification.html#professional-models"><i class="fa fa-check"></i><b>13.1.8</b> Professional models</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="13-classification.html"><a href="13-classification.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>13.2</b> Classification and regression trees (CART)</a><ul>
<li class="chapter" data-level="13.2.1" data-path="13-classification.html"><a href="13-classification.html#what-is-cart"><i class="fa fa-check"></i><b>13.2.1</b> What is CART?</a></li>
<li class="chapter" data-level="13.2.2" data-path="13-classification.html"><a href="13-classification.html#one-categorical-explanatory-variable-1"><i class="fa fa-check"></i><b>13.2.2</b> One categorical explanatory variable</a></li>
<li class="chapter" data-level="13.2.3" data-path="13-classification.html"><a href="13-classification.html#one-numerical-explanatory-variable-1"><i class="fa fa-check"></i><b>13.2.3</b> One numerical explanatory variable</a></li>
<li class="chapter" data-level="13.2.4" data-path="13-classification.html"><a href="13-classification.html#multiple-explanatory-variables"><i class="fa fa-check"></i><b>13.2.4</b> Multiple explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13-classification.html"><a href="13-classification.html#random-forests"><i class="fa fa-check"></i><b>13.3</b> Random forests</a><ul>
<li class="chapter" data-level="13.3.1" data-path="13-classification.html"><a href="13-classification.html#what-are-random-forests"><i class="fa fa-check"></i><b>13.3.1</b> What are random forests?</a></li>
<li class="chapter" data-level="13.3.2" data-path="13-classification.html"><a href="13-classification.html#fitting-random-forests"><i class="fa fa-check"></i><b>13.3.2</b> Fitting random forests</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="13-classification.html"><a href="13-classification.html#comparing-the-three-approaches"><i class="fa fa-check"></i><b>13.4</b> Comparing the three approaches</a><ul>
<li class="chapter" data-level="13.4.1" data-path="13-classification.html"><a href="13-classification.html#is-accuracy-the-right-measure"><i class="fa fa-check"></i><b>13.4.1</b> Is accuracy the right measure?</a></li>
<li class="chapter" data-level="13.4.2" data-path="13-classification.html"><a href="13-classification.html#modeling-for-prediction-vs.-explanation"><i class="fa fa-check"></i><b>13.4.2</b> Modeling for prediction vs. explanation</a></li>
<li class="chapter" data-level="13.4.3" data-path="13-classification.html"><a href="13-classification.html#out-of-sample-predictions"><i class="fa fa-check"></i><b>13.4.3</b> Out-of-sample predictions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-machine-learning.html"><a href="14-machine-learning.html"><i class="fa fa-check"></i><b>14</b> Machine Learning</a><ul>
<li class="chapter" data-level="14.1" data-path="14-machine-learning.html"><a href="14-machine-learning.html#the-process-of-machine-learning"><i class="fa fa-check"></i><b>14.1</b> The process of machine learning</a></li>
<li class="chapter" data-level="14.2" data-path="14-machine-learning.html"><a href="14-machine-learning.html#what-does-it-mean-for-a-model-to-be-good"><i class="fa fa-check"></i><b>14.2</b> What does it mean for a model to be “good?”</a><ul>
<li class="chapter" data-level="14.2.1" data-path="14-machine-learning.html"><a href="14-machine-learning.html#training-and-test-sets"><i class="fa fa-check"></i><b>14.2.1</b> Training and test sets</a></li>
<li class="chapter" data-level="14.2.2" data-path="14-machine-learning.html"><a href="14-machine-learning.html#loss-function"><i class="fa fa-check"></i><b>14.2.2</b> The loss function</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="14-machine-learning.html"><a href="14-machine-learning.html#data-cooperative-congressional-election-study-cces"><i class="fa fa-check"></i><b>14.3</b> Data: Cooperative Congressional Election Study (CCES)</a></li>
<li class="chapter" data-level="14.4" data-path="14-machine-learning.html"><a href="14-machine-learning.html#the-modeling-process-using-tidymodels"><i class="fa fa-check"></i><b>14.4</b> The modeling process using <strong>tidymodels</strong></a><ul>
<li class="chapter" data-level="14.4.1" data-path="14-machine-learning.html"><a href="14-machine-learning.html#parsnip-build-the-model"><i class="fa fa-check"></i><b>14.4.1</b> <strong>parsnip</strong>: build the model</a></li>
<li class="chapter" data-level="14.4.2" data-path="14-machine-learning.html"><a href="14-machine-learning.html#recipes-not-happening-here-folks"><i class="fa fa-check"></i><b>14.4.2</b> <strong>recipes</strong>: not happening here, folks</a></li>
<li class="chapter" data-level="14.4.3" data-path="14-machine-learning.html"><a href="14-machine-learning.html#rsample-initial-split"><i class="fa fa-check"></i><b>14.4.3</b> <strong>rsample</strong>: initial split</a></li>
<li class="chapter" data-level="14.4.4" data-path="14-machine-learning.html"><a href="14-machine-learning.html#fitting-the-model-once"><i class="fa fa-check"></i><b>14.4.4</b> Fitting the model once</a></li>
<li class="chapter" data-level="14.4.5" data-path="14-machine-learning.html"><a href="14-machine-learning.html#fitting-many-models-using-map-2"><i class="fa fa-check"></i><b>14.4.5</b> Fitting many models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="14-machine-learning.html"><a href="14-machine-learning.html#cross-validation"><i class="fa fa-check"></i><b>14.5</b> Cross validation</a><ul>
<li class="chapter" data-level="14.5.1" data-path="14-machine-learning.html"><a href="14-machine-learning.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>14.5.1</b> K-fold cross validation</a></li>
<li class="chapter" data-level="14.5.2" data-path="14-machine-learning.html"><a href="14-machine-learning.html#implementing-cross-validation-using-rsample"><i class="fa fa-check"></i><b>14.5.2</b> Implementing cross-validation using <strong>rsample</strong></a></li>
<li class="chapter" data-level="14.5.3" data-path="14-machine-learning.html"><a href="14-machine-learning.html#bootstrap"><i class="fa fa-check"></i><b>14.5.3</b> Bootstrap</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html"><i class="fa fa-check"></i><b>A</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="A.1" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#causal-effects"><i class="fa fa-check"></i><b>A.1</b> Causal effects</a></li>
<li class="chapter" data-level="A.2" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#potential-outcomes"><i class="fa fa-check"></i><b>A.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="A.3" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#no-causation-without-manipulation"><i class="fa fa-check"></i><b>A.3</b> No causation without manipulation</a></li>
<li class="chapter" data-level="A.4" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#average-treatment-effect"><i class="fa fa-check"></i><b>A.4</b> Average treatment effect</a></li>
<li class="chapter" data-level="A.5" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>A.5</b> Stable unit treatment value assumption (SUTVA)</a></li>
<li class="chapter" data-level="A.6" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>A.6</b> The fundamental problem of causal inference</a></li>
<li class="chapter" data-level="A.7" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-assignment-mechanism"><i class="fa fa-check"></i><b>A.7</b> The assignment mechanism</a></li>
<li class="chapter" data-level="A.8" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#permutation-tests"><i class="fa fa-check"></i><b>A.8</b> Permutation tests</a></li>
<li class="chapter" data-level="A.9" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#confounding-and-selection-bias"><i class="fa fa-check"></i><b>A.9</b> Confounding and selection bias</a></li>
<li class="chapter" data-level="A.10" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#internal-and-external-validity"><i class="fa fa-check"></i><b>A.10</b> Internal and external validity</a></li>
<li class="chapter" data-level="A.11" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#survey-research-and-external-validity"><i class="fa fa-check"></i><b>A.11</b> Survey research and external validity</a></li>
<li class="chapter" data-level="A.12" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#conclusion-6"><i class="fa fa-check"></i><b>A.12</b> Conclusion</a></li>
<li class="chapter" data-level="A.13" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#references"><i class="fa fa-check"></i><b>A.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-maps.html"><a href="B-maps.html"><i class="fa fa-check"></i><b>B</b> Maps</a><ul>
<li class="chapter" data-level="B.1" data-path="B-maps.html"><a href="B-maps.html#tidycensus"><i class="fa fa-check"></i><b>B.1</b> Tidycensus</a></li>
<li class="chapter" data-level="B.2" data-path="B-maps.html"><a href="B-maps.html#conceptual-introduction-to-mapping"><i class="fa fa-check"></i><b>B.2</b> Conceptual introduction to mapping</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-maps.html"><a href="B-maps.html#vector-versus-spatial-data"><i class="fa fa-check"></i><b>B.2.1</b> Vector versus spatial data</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-maps.html"><a href="B-maps.html#sf-vs-sp"><i class="fa fa-check"></i><b>B.2.2</b> <strong>sf</strong> vs <strong>sp</strong></a></li>
<li class="chapter" data-level="B.2.3" data-path="B-maps.html"><a href="B-maps.html#shapefiles"><i class="fa fa-check"></i><b>B.2.3</b> Shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-maps.html"><a href="B-maps.html#mapping-with-tidycensus-and-geom_sf"><i class="fa fa-check"></i><b>B.3</b> Mapping with <strong>tidycensus</strong> and <code>geom_sf()</code></a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-maps.html"><a href="B-maps.html#making-maps-pretty"><i class="fa fa-check"></i><b>B.3.1</b> Making maps pretty</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-maps.html"><a href="B-maps.html#adding-back-alaska-and-hawaii"><i class="fa fa-check"></i><b>B.3.2</b> Adding back Alaska and Hawaii</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-maps.html"><a href="B-maps.html#faceting-maps"><i class="fa fa-check"></i><b>B.4</b> Faceting maps</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-maps.html"><a href="B-maps.html#transforming-and-mapping-the-data"><i class="fa fa-check"></i><b>B.4.1</b> Transforming and mapping the data</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-maps.html"><a href="B-maps.html#want-to-explore-further"><i class="fa fa-check"></i><b>B.5</b> Want to explore further?</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-animation.html"><a href="C-animation.html"><i class="fa fa-check"></i><b>C</b> Animation</a><ul>
<li class="chapter" data-level="C.1" data-path="C-animation.html"><a href="C-animation.html#gganimate-how-to-create-plots-with-beautiful-animation-in-r"><i class="fa fa-check"></i><b>C.1</b> gganimate: How to Create Plots with Beautiful Animation in R</a><ul>
<li class="chapter" data-level="C.1.1" data-path="C-animation.html"><a href="C-animation.html#prerequisites"><i class="fa fa-check"></i><b>C.1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="C.1.2" data-path="C-animation.html"><a href="C-animation.html#demo-dataset"><i class="fa fa-check"></i><b>C.1.2</b> Demo dataset</a></li>
<li class="chapter" data-level="C.1.3" data-path="C-animation.html"><a href="C-animation.html#static-plot"><i class="fa fa-check"></i><b>C.1.3</b> Static plot</a></li>
<li class="chapter" data-level="C.1.4" data-path="C-animation.html"><a href="C-animation.html#transition-through-distinct-states-in-time"><i class="fa fa-check"></i><b>C.1.4</b> Transition through distinct states in time</a></li>
<li class="chapter" data-level="C.1.5" data-path="C-animation.html"><a href="C-animation.html#reveal-data-along-a-given-dimension"><i class="fa fa-check"></i><b>C.1.5</b> Reveal data along a given dimension</a></li>
<li class="chapter" data-level="C.1.6" data-path="C-animation.html"><a href="C-animation.html#transition-between-several-distinct-stages-of-the-data"><i class="fa fa-check"></i><b>C.1.6</b> Transition between several distinct stages of the data</a></li>
<li class="chapter" data-level="C.1.7" data-path="C-animation.html"><a href="C-animation.html#read-more"><i class="fa fa-check"></i><b>C.1.7</b> Read more</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="C-animation.html"><a href="C-animation.html#how-to-save-your-animation"><i class="fa fa-check"></i><b>C.2</b> How to save your animation</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-shiny.html"><a href="D-shiny.html"><i class="fa fa-check"></i><b>D</b> Shiny</a><ul>
<li class="chapter" data-level="D.1" data-path="D-shiny.html"><a href="D-shiny.html#helpful-resources"><i class="fa fa-check"></i><b>D.1</b> Helpful Resources</a></li>
<li class="chapter" data-level="D.2" data-path="D-shiny.html"><a href="D-shiny.html#set-up-and-getting-started"><i class="fa fa-check"></i><b>D.2</b> Set Up and Getting Started</a></li>
<li class="chapter" data-level="D.3" data-path="D-shiny.html"><a href="D-shiny.html#building-your-basic-app"><i class="fa fa-check"></i><b>D.3</b> Building Your Basic App</a><ul>
<li class="chapter" data-level="D.3.1" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-basic-ui"><i class="fa fa-check"></i><b>D.3.1</b> Setting Up the Basic UI</a></li>
<li class="chapter" data-level="D.3.2" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-server"><i class="fa fa-check"></i><b>D.3.2</b> Setting up the Server</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="D-shiny.html"><a href="D-shiny.html#organization"><i class="fa fa-check"></i><b>D.4</b> Organization</a></li>
<li class="chapter" data-level="D.5" data-path="D-shiny.html"><a href="D-shiny.html#customizations"><i class="fa fa-check"></i><b>D.5</b> Customizations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preceptor’s Primer for Bayesian Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="confidence-intervals" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> Confidence Intervals</h1>
<p>In Chapter <a href="9-sampling.html#sampling">9</a>, we studied sampling. We started with a “tactile” exercise where we wanted to know the proportion of balls in the urn in Figure <a href="9-sampling.html#fig:sampling-exercise-1">9.1</a> that are red. While we could have performed an exhaustive count, this would have been a tedious process. So instead, we used a shovel to extract a sample of 50 balls and used the resulting proportion that were red as an <em>estimate</em>. Furthermore, we made sure to mix the urn’s contents before every use of the shovel. Because of the randomness created by the mixing, different uses of the shovel yielded different proportions red and hence different estimates of the proportion of the urn’s balls that are red.</p>
<p>Remember: There is a <em>truth</em> here. There is an urn. It has red and white balls in it. An exact, but unknown, number of the balls are red. An exact, but unknown, number of the balls are white. An exact, but unknown, percentage of the balls are red – defined as the number red divided by the sum of the number red and the number white. Our goal is to estimate that unknown percentage. We want to make statements about the world, even if we can never be certain that those statements are <em>true</em>. We will never have the time or inclination to actually count all the balls. We use the term <em>parameter</em> for things that exist but which are unknown. We use statistics to estimate the true values of parameters.</p>
<p>We then mimicked this <em>physical</em> sampling exercise with an equivalent <em>virtual</em> sampling exercise using the computer. In Subsection <a href="9-sampling.html#different-shovels">9.2.4</a>, we repeated this sampling procedure 1,000 times, using three different virtual shovels with 25, 50, and 100 slots. We visualized these three sets of 1,000 estimates in Figure <a href="9-sampling.html#fig:comparing-sampling-distributions-3">9.18</a> and saw that as the sample size increased, the variation in the estimates decreased. We then expanded this for all sample sizes from 1 to 100.</p>
<p>In doing so, we constructed <em>sampling distributions</em>. The motivation for taking a 1,000 repeated samples and visualizing the resulting estimates was to study how these estimates varied from one sample to another; in other words, we wanted to study the effect of <em>sampling variation</em>. We quantified the variation of these estimates using their standard deviation, which has a special name: the <em>standard error</em>. In particular, we saw that as the sample size increased from 1 to 100, the standard error decreased and thus the sampling distributions narrowed. Larger sample sizes led to more <em>precise</em> estimates that varied less around the center.</p>
<p>We then tied these sampling exercises to terminology and mathematical notation related to sampling in Subsection <a href="9-sampling.html#terminology-and-notation">9.3.1</a>. Our <em>study population</em> was the large urn with <span class="math inline">\(N\)</span> = 2,400 balls, while the <em>population parameter</em>, the unknown quantity of interest, was the population proportion <span class="math inline">\(p\)</span> of the urn’s balls that were red. Since performing a <em>census</em> would be expensive in terms of time and energy, we instead extracted a <em>sample</em> of size <span class="math inline">\(n\)</span> = 50. The <em>point estimate</em>, also known as a <em>sample statistic</em>, used to estimate <span class="math inline">\(p\)</span> was the sample proportion <span class="math inline">\(\widehat{p}\)</span> of these 50 sampled balls that were red. Furthermore, since the sample was obtained at <em>random</em>, it can be considered as <em>unbiased</em> and as <em>representative</em> of the population. Thus any results based on the sample could be <em>generalized</em> to the population. Therefore, the proportion of the shovel’s balls that were red was a “good guess” of the proportion of the urn’s balls that are red. In other words, we used the sample to draw <em>inferences</em> about the population.</p>
<p>However, as described in Section <a href="9-sampling.html#sampling-simulation">9.2</a>, both the physical and virtual sampling exercises are not what one would do in real life. This was merely an activity used to study the effects of sampling variation. In a real life situation, we would not take 1,000 samples of size <span class="math inline">\(n\)</span>, but rather take a <em>single</em> representative sample that’s as large as possible. Additionally, we knew that the true proportion of the urn’s balls that were red was 37.5%. In a real-life situation, we will not know what this value is. Because if we did, then why would we take a sample to estimate it?</p>
<p>An example of a realistic sampling situation would be a poll, like the <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Obama poll</a> you saw in Section <a href="9-sampling.html#sampling-case-study">9.4</a>. Pollsters did not know the true proportion of <em>all</em> young Americans who supported President Obama in 2013, and thus they took a single sample of size <span class="math inline">\(n\)</span> = 2,089 young Americans to estimate this value.</p>
<p>So how does one quantify the effects of sampling variation when you only have a <em>single sample</em> to work with? You cannot directly study the effects of sampling variation when you only have one sample. One common method to study this is <em>bootstrapping resampling</em>.</p>
<p>What if we would like, not only a single estimate of the unknown population parameter, but also a <em>range of highly plausible</em> values? Going back to the Obama poll article, it stated that the pollsters’ estimate of the proportion of all young Americans who supported President Obama was 41%. But in addition it stated that the poll’s “margin of error was plus or minus 2.1 percentage points.” This “plausible range” was [41% - 2.1%, 41% + 2.1%] = [38.9%, 43.1%]. This range of plausible values is what’s known as a <em>confidence interval</em>, which will be the focus of the later sections of this chapter.</p>
<!--
Create graphic illustrating two-step process of 1) construct bootstrap distribution
and then 2) based on bootstrap dist'n create CI?
-->
<div id="needed-packages-2" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.5</a> that loading the <strong>tidyverse</strong> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><strong>ggplot2</strong> for data visualization</li>
<li><strong>dplyr</strong> for data wrangling</li>
<li><strong>tidyr</strong> for converting data to tidy format</li>
<li><strong>readr</strong> for importing spreadsheet data into R</li>
<li>As well as the more advanced <strong>purrr</strong>, <strong>tibble</strong>, <strong>stringr</strong>, and <strong>forcats</strong> packages</li>
</ul>
<p>If needed, read Section <a href="1-getting-started.html#packages">1.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb652-1"><a href="10-confidence-intervals.html#cb652-1"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
</div>
<div id="resampling-tactile" class="section level2">
<h2><span class="header-section-number">10.1</span> Pennies activity</h2>
<p>As we did in Chapter <a href="9-sampling.html#sampling">9</a>, we’ll begin with a hands-on tactile activity.</p>
<div id="what-is-the-average-year-on-us-pennies-in-2019" class="section level3">
<h3><span class="header-section-number">10.1.1</span> What is the average year on US pennies in 2019?</h3>
<p>Try to imagine all the pennies being used in the United States in 2019. That’s a lot of pennies! Now say we’re interested in the average year of minting of <em>all</em> these pennies. One way to compute this value would be to gather up all pennies being used in the US, record the year, and compute the average. However, this would be near impossible! So instead, let’s collect a <em>sample</em> of 50 pennies from a local bank in downtown Northampton, Massachusetts, USA as seen in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-a">10.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-a"></span>
<img src="images/sampling/pennies/bank.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="40%" /><img src="images/sampling/pennies/roll.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="40%" />
<p class="caption">
FIGURE 10.1: Collecting a sample of 50 US pennies from a local bank.
</p>
</div>
<p>An image of these 50 pennies can be seen in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-c">10.2</a>. For each of the 50 pennies starting in the top left, progressing row-by-row, and ending in the bottom right, note there is an “ID” identification variable printed in black and the year of minting printed in white.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-c"></span>
<img src="images/sampling/pennies/deliverable/3.jpg" alt="50 US pennies labelled." width="100%" />
<p class="caption">
FIGURE 10.2: 50 US pennies labelled.
</p>
</div>
<p>The <strong>moderndive</strong>  package contains this data on our 50 sampled pennies in the <code>pennies_sample</code> data frame:</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="10-confidence-intervals.html#cb653-1"></a><span class="kw">library</span>(moderndive)</span>
<span id="cb653-2"><a href="10-confidence-intervals.html#cb653-2"></a></span>
<span id="cb653-3"><a href="10-confidence-intervals.html#cb653-3"></a>pennies_sample</span></code></pre></div>
<pre><code># A tibble: 50 x 2
      ID  year
   &lt;int&gt; &lt;dbl&gt;
 1     1  2002
 2     2  1986
 3     3  2017
 4     4  1988
 5     5  2008
 6     6  1983
 7     7  2008
 8     8  1996
 9     9  2004
10    10  2000
# … with 40 more rows</code></pre>
<p>The <code>pennies_sample</code> data frame has 50 rows corresponding to each penny with two variables. The first variable <code>ID</code> corresponds to the ID labels in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-c">10.2</a>, whereas the second variable <code>year</code> corresponds to the year of minting saved as a numeric variable, also known as a double (<code>dbl</code>).</p>
<p>Based on these 50 sampled pennies, what can we say about <em>all</em> US pennies in 2019? Let’s study some properties of our sample by performing an exploratory data analysis. Let’s first visualize the distribution of the year of these 50 pennies using our data visualization tools from Chapter <a href="2-viz.html#viz">2</a>. Since <code>year</code> is a numerical variable, we use a histogram in Figure <a href="10-confidence-intervals.html#fig:pennies-sample-histogram">10.3</a> to visualize its distribution.</p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="10-confidence-intervals.html#cb655-1"></a>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb655-2"><a href="10-confidence-intervals.html#cb655-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb655-3"><a href="10-confidence-intervals.html#cb655-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pennies-sample-histogram"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/pennies-sample-histogram-1.png" alt="Distribution of year on 50 US pennies." width="\textwidth" />
<p class="caption">
FIGURE 10.3: Distribution of year on 50 US pennies.
</p>
</div>
<p>Observe a slightly left-skewed  distribution, since most pennies fall between 1980 and 2010 with only a few pennies older than 1970. What is the average year for the 50 sampled pennies? Eyeballing the histogram it appears to be around 1990. Let’s now compute this value exactly using our data wrangling tools from Chapter <a href="4-wrangling.html#wrangling">4</a>.</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="10-confidence-intervals.html#cb656-1"></a>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb656-2"><a href="10-confidence-intervals.html#cb656-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
  mean_year
      &lt;dbl&gt;
1   1995.44</code></pre>
<p>Thus, if we’re willing to assume that <code>pennies_sample</code> is a representative sample from <em>all</em> US pennies, a “good guess” of the average year of minting of all US pennies would be 1995.44. In other words, around 1995. This should all start sounding similar to what we did previously in Chapter <a href="9-sampling.html#sampling">9</a>!</p>
<p>In Chapter <a href="9-sampling.html#sampling">9</a>, our <em>study population</em> was the urn of <span class="math inline">\(N\)</span> = 2400 balls. Our <em>population parameter</em> was the <em>population proportion</em> of these balls that were red, denoted by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel. We then computed the relevant <em>point estimate</em>: the <em>sample proportion</em> of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Here our population is <span class="math inline">\(N\)</span> = whatever the number of pennies are being used in the US, a value which we don’t know and probably never will. The population parameter of interest is now the <em>population mean</em> year of all these pennies, a value denoted mathematically by the Greek letter <span class="math inline">\(\mu\)</span> (pronounced “mu”). In order to estimate <span class="math inline">\(\mu\)</span>, we went to the bank and obtained a sample of 50 pennies and computed the relevant point estimate: the <em>sample mean</em> year of these 50 pennies, denoted mathematically by <span class="math inline">\(\overline{x}\)</span> (pronounced “x-bar”). An alternative and more intuitive notation for the sample mean is <span class="math inline">\(\widehat{\mu}\)</span>. However, this is unfortunately not as commonly used, so in this book we’ll stick with convention and always denote the sample mean as <span class="math inline">\(\overline{x}\)</span>.</p>
<p>We summarize the correspondence between the sampling urn exercise in Chapter <a href="9-sampling.html#sampling">9</a> and our pennies exercise in Table <a href="10-confidence-intervals.html#tab:table-ch8-b">10.1</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8-b">TABLE 10.1: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Symbol(s)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 0.7in; ">
Population proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample proportion
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 0.7in; ">
Population mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.1in; ">
Sample mean
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Going back to our 50 sampled pennies in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-c">10.2</a>, the point estimate of interest is the sample mean <span class="math inline">\(\overline{x}\)</span> of 1995.44. This quantity is an <em>estimate</em> of the population mean year of <em>all</em> US pennies <span class="math inline">\(\mu\)</span>.</p>
<p>Recall that we also saw in Chapter <a href="9-sampling.html#sampling">9</a> that such estimates are prone to <em>sampling variation</em>. For example, in this particular sample in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-c">10.2</a>, we observed three pennies with the year 1999. If we sampled another 50 pennies, would we observe exactly three pennies with the year 1999 again? More than likely not. We might observe none, one, two, or maybe even all 50! The same can be said for the other 26 unique years that are represented in our sample of 50 pennies.</p>
<p>To study the effects of <em>sampling variation</em> in Chapter <a href="9-sampling.html#sampling">9</a>, we took many samples, something we could easily do with our shovel. In our case with pennies, however, how would we obtain another sample? By going to the bank and getting another roll of 50 pennies.</p>
<p>Say we’re feeling lazy, however, and don’t want to go back to the bank. How can we study the effects of sampling variation using our <em>single sample</em>? We will do so using a technique known as <em>bootstrap resampling with replacement</em>, which we now illustrate.</p>
</div>
<div id="resampling-once" class="section level3">
<h3><span class="header-section-number">10.1.2</span> Resampling once</h3>
<p><strong>Step 1</strong>: Let’s print out identically sized slips of paper representing our 50 pennies as seen in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-1">10.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-1"></span>
<img src="images/sampling/pennies/tactile_simulation/1_paper_slips.png" alt="Step 1: 50 slips of paper representing 50 US pennies." width="100%" />
<p class="caption">
FIGURE 10.4: Step 1: 50 slips of paper representing 50 US pennies.
</p>
</div>
<p><strong>Step 2</strong>: Put the 50 slips of paper into a hat or tuque as seen in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-2">10.5</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-2"></span>
<img src="images/sampling/pennies/tactile_simulation/2_insert_in_hat.png" alt="Step 2: Putting 50 slips of paper in a hat." width="60%" />
<p class="caption">
FIGURE 10.5: Step 2: Putting 50 slips of paper in a hat.
</p>
</div>
<p><strong>Step 3</strong>: Mix the hat’s contents and draw one slip of paper at random as seen in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-3">10.6</a>. Record the year.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-3"></span>
<img src="images/sampling/pennies/tactile_simulation/3_draw_at_random.png" alt="Step 3: Drawing one slip of paper at random." width="60%" />
<p class="caption">
FIGURE 10.6: Step 3: Drawing one slip of paper at random.
</p>
</div>
<p><strong>Step 4</strong>: Put the slip of paper back in the hat! In other words, replace it as seen in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-4">10.7</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-4"></span>
<img src="images/sampling/pennies/tactile_simulation/4_put_it_back.png" alt="Step 4: Replacing slip of paper." width="50%" />
<p class="caption">
FIGURE 10.7: Step 4: Replacing slip of paper.
</p>
</div>
<p><strong>Step 5</strong>: Repeat Steps 3 and 4 a total of 49 more times, resulting in 50 recorded years.</p>
<p>What we just performed was a <em>resampling</em>  of the original sample of 50 pennies. We are not sampling 50 pennies from the population of all US pennies as we did in our trip to the bank. Instead, we are mimicking this act by resampling 50 pennies from our original sample of 50 pennies.</p>
<p>Now ask yourselves, why did we replace our resampled slip of paper back into the hat in Step 4? Because if we left the slip of paper out of the hat each time we performed Step 4, we would end up with the same 50 original pennies! In other words, replacing the slips of paper induces <em>sampling variation</em>.</p>
<p>Being more precise with our terminology, we just performed a <em>resampling with replacement</em> from the original sample of 50 pennies. Had we left the slip of paper out of the hat each time we performed Step 4, this would be <em>resampling without replacement</em>.</p>
<p>Let’s study our 50 resampled pennies via an exploratory data analysis. First, let’s load the data into R by manually creating a data frame <code>pennies_resample</code> of our 50 resampled values. We’ll do this using the <code>tibble()</code> command from the <strong>dplyr</strong> package. Note that the 50 values you resample will almost certainly not be the same as ours given the inherent randomness.</p>
<div class="sourceCode" id="cb658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb658-1"><a href="10-confidence-intervals.html#cb658-1"></a>pennies_resample &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb658-2"><a href="10-confidence-intervals.html#cb658-2"></a>  <span class="dt">year =</span> <span class="kw">c</span>(<span class="dv">1976</span>, <span class="dv">1962</span>, <span class="dv">1976</span>, <span class="dv">1983</span>, <span class="dv">2017</span>, <span class="dv">2015</span>, <span class="dv">2015</span>, <span class="dv">1962</span>, <span class="dv">2016</span>, <span class="dv">1976</span>, </span>
<span id="cb658-3"><a href="10-confidence-intervals.html#cb658-3"></a>           <span class="dv">2006</span>, <span class="dv">1997</span>, <span class="dv">1988</span>, <span class="dv">2015</span>, <span class="dv">2015</span>, <span class="dv">1988</span>, <span class="dv">2016</span>, <span class="dv">1978</span>, <span class="dv">1979</span>, <span class="dv">1997</span>, </span>
<span id="cb658-4"><a href="10-confidence-intervals.html#cb658-4"></a>           <span class="dv">1974</span>, <span class="dv">2013</span>, <span class="dv">1978</span>, <span class="dv">2015</span>, <span class="dv">2008</span>, <span class="dv">1982</span>, <span class="dv">1986</span>, <span class="dv">1979</span>, <span class="dv">1981</span>, <span class="dv">2004</span>, </span>
<span id="cb658-5"><a href="10-confidence-intervals.html#cb658-5"></a>           <span class="dv">2000</span>, <span class="dv">1995</span>, <span class="dv">1999</span>, <span class="dv">2006</span>, <span class="dv">1979</span>, <span class="dv">2015</span>, <span class="dv">1979</span>, <span class="dv">1998</span>, <span class="dv">1981</span>, <span class="dv">2015</span>, </span>
<span id="cb658-6"><a href="10-confidence-intervals.html#cb658-6"></a>           <span class="dv">2000</span>, <span class="dv">1999</span>, <span class="dv">1988</span>, <span class="dv">2017</span>, <span class="dv">1992</span>, <span class="dv">1997</span>, <span class="dv">1990</span>, <span class="dv">1988</span>, <span class="dv">2006</span>, <span class="dv">2000</span>)</span>
<span id="cb658-7"><a href="10-confidence-intervals.html#cb658-7"></a>)</span></code></pre></div>
<p>The 50 values of <code>year</code> in <code>pennies_resample</code> represent a resample of size 50 from the original sample of 50 pennies. We display the 50 resampled pennies in Figure <a href="10-confidence-intervals.html#fig:resampling-exercise-d">10.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:resampling-exercise-d"></span>
<img src="images/sampling/pennies/deliverable/4.jpg" alt="50 resampled US pennies labelled." width="100%" />
<p class="caption">
FIGURE 10.8: 50 resampled US pennies labelled.
</p>
</div>
<p>Let’s compare the distribution of the numerical variable <code>year</code> of our 50 resampled pennies with the distribution of the numerical variable <code>year</code> of our original sample of 50 pennies in Figure <a href="10-confidence-intervals.html#fig:origandresample">10.9</a>.</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="10-confidence-intervals.html#cb659-1"></a>pennies_resample <span class="op">%&gt;%</span></span>
<span id="cb659-2"><a href="10-confidence-intervals.html#cb659-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb659-3"><a href="10-confidence-intervals.html#cb659-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb659-4"><a href="10-confidence-intervals.html#cb659-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Resample of 50 pennies&quot;</span>)</span>
<span id="cb659-5"><a href="10-confidence-intervals.html#cb659-5"></a></span>
<span id="cb659-6"><a href="10-confidence-intervals.html#cb659-6"></a>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb659-7"><a href="10-confidence-intervals.html#cb659-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb659-8"><a href="10-confidence-intervals.html#cb659-8"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb659-9"><a href="10-confidence-intervals.html#cb659-9"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Original sample of 50 pennies&quot;</span>)</span></code></pre></div>

<div class="figure" style="text-align: center"><span id="fig:origandresample"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/origandresample-1.png" alt="Comparing year in the resampled pennies_resample with the original sample pennies_sample." width="\textwidth" />
<p class="caption">
FIGURE 10.9: Comparing <code>year</code> in the resampled <code>pennies_resample</code> with the original sample <code>pennies_sample</code>.
</p>
</div>
<p>Observe in Figure <a href="10-confidence-intervals.html#fig:origandresample">10.9</a> that while the general shapes of both distributions of <code>year</code> are roughly similar, they are not identical.</p>
<p>Recall from the previous section that the sample mean of the original sample of 50 pennies from the bank was 1995.44. What about for our resample? Any guesses? Let’s have <strong>dplyr</strong> help us out as before:</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="10-confidence-intervals.html#cb660-1"></a>pennies_resample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb660-2"><a href="10-confidence-intervals.html#cb660-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
  mean_year
      &lt;dbl&gt;
1      1996</code></pre>
<p>We obtained a different mean year of 1996. This variation is induced by the resampling <em>with replacement</em> we performed earlier.</p>
<p>What if we repeated this resampling exercise many times? Would we obtain the same mean <code>year</code> each time? In other words, would our guess at the mean year of all pennies in the US in 2019 be exactly 1996 every time? Just as we did in Chapter <a href="9-sampling.html#sampling">9</a>, let’s perform this resampling activity with the help of some of our friends: 35 friends in total.</p>
</div>
<div id="student-resamples" class="section level3">
<h3><span class="header-section-number">10.1.3</span> Resampling 35 times</h3>
<p>Each of our 35 friends will repeat the same five steps:</p>
<ol style="list-style-type: decimal">
<li>Start with 50 identically sized slips of paper representing the 50 pennies.</li>
<li>Put the 50 small pieces of paper into a hat or beanie cap.</li>
<li>Mix the hat’s contents and draw one slip of paper at random. Record the year in a spreadsheet.</li>
<li>Replace the slip of paper back in the hat!</li>
<li>Repeat Steps 3 and 4 a total of 49 more times, resulting in 50 recorded years.</li>
</ol>
<p>Since we had 35 of our friends perform this task, we will end up with <span class="math inline">\(35 \cdot 50 = 1750\)</span> values. These values are recorded in a <a href="https://docs.google.com/spreadsheets/d/1y3kOsU_wDrDd5eiJbEtLeHT9L5SvpZb_TrzwFBsouk0/">shared spreadsheet</a> with 50 rows (plus a header row) and 35 columns. We display a snapshot of the first 10 rows and five columns of this shared spreadsheet in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-5">10.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-5"></span>
<img src="images/sampling/pennies/tactile_simulation/5_shared_spreadsheet.png" alt="Snapshot of shared spreadsheet of resampled pennies." width="70%" />
<p class="caption">
FIGURE 10.10: Snapshot of shared spreadsheet of resampled pennies.
</p>
</div>
<p>These 35 <span class="math inline">\(\cdot\)</span> 50 = 1750 values are saved in <code>pennies_resamples</code>, a “tidy” data frame included in the <strong>moderndive</strong> package. We saw what it means for a data frame to be “tidy” in Subsection <a href="5-tidy.html#tidy-definition">5.3.1</a>.</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="10-confidence-intervals.html#cb662-1"></a>pennies_resamples</span></code></pre></div>
<pre><code># A tibble: 1,750 x 3
# Groups:   name [35]
   replicate name     year
       &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;
 1         1 Arianna  1988
 2         1 Arianna  2002
 3         1 Arianna  2015
 4         1 Arianna  1998
 5         1 Arianna  1979
 6         1 Arianna  1971
 7         1 Arianna  1971
 8         1 Arianna  2015
 9         1 Arianna  1988
10         1 Arianna  1979
# … with 1,740 more rows</code></pre>
<p>What did each of our 35 friends obtain as the mean year? Once again, <strong>dplyr</strong> to the rescue! After grouping the rows by <code>name</code>, we summarize each group of 50 rows by their mean <code>year</code>:</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="10-confidence-intervals.html#cb664-1"></a>resampled_means &lt;-<span class="st"> </span>pennies_resamples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb664-2"><a href="10-confidence-intervals.html#cb664-2"></a><span class="st">  </span><span class="kw">group_by</span>(name) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb664-3"><a href="10-confidence-intervals.html#cb664-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span>
<span id="cb664-4"><a href="10-confidence-intervals.html#cb664-4"></a>resampled_means</span></code></pre></div>
<pre><code># A tibble: 35 x 2
   name      mean_year
   &lt;chr&gt;         &lt;dbl&gt;
 1 Arianna     1992.5 
 2 Artemis     1996.42
 3 Bea         1996.32
 4 Camryn      1996.9 
 5 Cassandra   1991.22
 6 Cindy       1995.48
 7 Claire      1995.52
 8 Dahlia      1998.48
 9 Dan         1993.86
10 Eindra      1993.56
# … with 25 more rows</code></pre>
<p>Observe that <code>resampled_means</code> has 35 rows corresponding to the 35 means based on the 35 resamples. Furthermore, observe the variation in the 35 values in the variable <code>mean_year</code>. Let’s visualize this variation using a histogram in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-6">10.11</a>. Recall that adding the argument <code>boundary = 1990</code> to the <code>geom_histogram()</code> sets the binning structure so that one of the bin boundaries is at 1990 exactly.</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="10-confidence-intervals.html#cb666-1"></a><span class="kw">ggplot</span>(resampled_means, <span class="kw">aes</span>(<span class="dt">x =</span> mean_year)) <span class="op">+</span></span>
<span id="cb666-2"><a href="10-confidence-intervals.html#cb666-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span></span>
<span id="cb666-3"><a href="10-confidence-intervals.html#cb666-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Sampled mean year&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-6"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/tactile-resampling-6-1.png" alt="Distribution of 35 sample means from 35 resamples." width="\textwidth" />
<p class="caption">
FIGURE 10.11: Distribution of 35 sample means from 35 resamples.
</p>
</div>
<p>Observe in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-6">10.11</a> that the distribution looks roughly normal and that we rarely observe sample mean years less than 1992 or greater than 2000. Also observe how the distribution is roughly centered at 1995, which is close to the sample mean of 1995.44 of the <em>original sample</em> of 50 pennies from the bank.</p>
</div>
<div id="what-did-we-just-do-1" class="section level3">
<h3><span class="header-section-number">10.1.4</span> What did we just do?</h3>
<p>What we just demonstrated in this activity is the statistical procedure known as  <em>bootstrap resampling with replacement</em>. We used <em>resampling</em> to mimic the sampling variation we studied in Chapter <a href="9-sampling.html#sampling">9</a> on sampling. However, in this case, we did so using only a <em>single</em> sample from the population.</p>
<p>In fact, the histogram of sample means from 35 resamples in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-6">10.11</a> is called the  <em>bootstrap distribution</em>. It is an <em>approximation</em> to the <em>sampling distribution</em> of the sample mean, in the sense that both distributions will have a similar shape and similar spread. In fact in the upcoming Section <a href="10-confidence-intervals.html#ci-conclusion">10.6</a>, we’ll show you that this is the case. Using this bootstrap distribution, we can study the effect of sampling variation on our estimates. In particular, we’ll study the typical “error” of our estimates, known as the  <em>standard error</em>.</p>
<p>Starting in Subsection <a href="10-confidence-intervals.html#resampling-simulation">10.1.5</a>, we’ll mimic our tactile resampling activity virtually on the computer, allowing us to quickly perform the resampling many more than 35 times. In Section <a href="10-confidence-intervals.html#ci-build-up">10.2</a> we’ll define the statistical concept of a <em>confidence interval</em>, which builds off the concept of bootstrap distributions.</p>
<p>As we did in Chapter <a href="9-sampling.html#sampling">9</a>, we’ll tie all these ideas together with a real-life case study in Section <a href="10-confidence-intervals.html#case-study-two-prop-ci">10.5</a>. This time we’ll look at data from an experiment about yawning from the US television show <em>Mythbusters</em>.</p>
<p>Let’s now mimic our tactile resampling activity virtually with a computer.</p>
</div>
<div id="resampling-simulation" class="section level3">
<h3><span class="header-section-number">10.1.5</span> Virtually resampling once</h3>
<p>First, let’s perform the virtual analog of resampling once. Recall that the <code>pennies_sample</code> data frame included in the <strong>moderndive</strong> package contains the years of our original sample of 50 pennies from the bank. Furthermore, recall in Chapter <a href="9-sampling.html#sampling">9</a> on sampling that we used the <code>rep_sample_n()</code> function in the <strong>infer</strong> package as a virtual shovel to sample balls from our virtual urn of 2400 balls as follows:</p>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="10-confidence-intervals.html#cb667-1"></a><span class="kw">library</span>(infer)</span>
<span id="cb667-2"><a href="10-confidence-intervals.html#cb667-2"></a></span>
<span id="cb667-3"><a href="10-confidence-intervals.html#cb667-3"></a>virtual_shovel &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb667-4"><a href="10-confidence-intervals.html#cb667-4"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)</span></code></pre></div>
<p>Let’s modify this code to perform the resampling with replacement of the 50 slips of paper representing our original sample of 50 pennies:</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="10-confidence-intervals.html#cb668-1"></a>virtual_resample &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb668-2"><a href="10-confidence-intervals.html#cb668-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p>Observe how we explicitly set the <code>replace</code> argument to <code>TRUE</code> in order to tell <code>rep_sample_n()</code> that we would like to sample pennies  <em>with</em> replacement. Had we not set <code>replace = TRUE</code>, the function would’ve assumed the default value of <code>FALSE</code> and hence done resampling <em>without</em> replacement. Additionally, since we didn’t specify the number of replicates via the <code>reps</code> argument, the function assumes the default of one replicate <code>reps = 1</code>. Lastly, observe also that the <code>size</code> argument is set to match the original sample size of 50 pennies.</p>
<p>Let’s look at only the first 10 out of 50 rows of <code>virtual_resample</code>:</p>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="10-confidence-intervals.html#cb669-1"></a>virtual_resample</span></code></pre></div>
<pre><code># A tibble: 50 x 3
# Groups:   replicate [1]
   replicate    ID  year
       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
 1         1    37  1962
 2         1     1  2002
 3         1    45  1997
 4         1    28  2006
 5         1    50  2017
 6         1    10  2000
 7         1    16  2015
 8         1    47  1982
 9         1    23  1998
10         1    44  2015
# … with 40 more rows</code></pre>
<p>The <code>replicate</code> variable only takes on the value of 1 corresponding to us only having <code>reps = 1</code>, the <code>ID</code> variable indicates which of the 50 pennies from <code>pennies_sample</code> was resampled, and <code>year</code> denotes the year of minting. Let’s now compute the mean <code>year</code> in our virtual resample of size 50 using data wrangling functions included in the <strong>dplyr</strong> package:</p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="10-confidence-intervals.html#cb671-1"></a>virtual_resample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb671-2"><a href="10-confidence-intervals.html#cb671-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">resample_mean =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<pre><code># A tibble: 1 x 2
  replicate resample_mean
      &lt;int&gt;         &lt;dbl&gt;
1         1          1996</code></pre>
<p>As we saw when we did our tactile resampling exercise, the resulting mean year is different than the mean year of our 50 originally sampled pennies of 1995.44.</p>
<!-- 
Chester: Not sure if needed, but those trying to follow along may be mystified if we don't include this. 

Note that tibbles will try to print as pretty as possible which may result in numbers being rounded. In this chapter, we have set the default number of values to be printed to six in tibbles with `options(pillar.sigfig = 6)`.

Albert: We'll need to explain that command and why tidyverse opts for 3 sigfigs.
-->
</div>
<div id="bootstrap-35-replicates" class="section level3">
<h3><span class="header-section-number">10.1.6</span> Virtually resampling 35 times</h3>
<p>Let’s now perform the virtual analog of our 35 friends’ resampling. Using these results, we’ll be able to study the variability in the sample means from 35 resamples of size 50. Let’s first add a <code>reps = 35</code> argument to <code>rep_sample_n()</code>  to indicate we would like 35 replicates. Thus, we want to repeat the resampling with the replacement of 50 pennies 35 times.</p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="10-confidence-intervals.html#cb673-1"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb673-2"><a href="10-confidence-intervals.html#cb673-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">35</span>)</span>
<span id="cb673-3"><a href="10-confidence-intervals.html#cb673-3"></a>virtual_resamples</span></code></pre></div>
<pre><code># A tibble: 1,750 x 3
# Groups:   replicate [35]
   replicate    ID  year
       &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
 1         1    21  1981
 2         1    34  1985
 3         1     4  1988
 4         1    11  1994
 5         1    26  1979
 6         1     8  1996
 7         1    19  1983
 8         1    21  1981
 9         1    49  2006
10         1     2  1986
# … with 1,740 more rows</code></pre>
<p>The resulting <code>virtual_resamples</code> data frame has 35 <span class="math inline">\(\cdot\)</span> 50 = 1750 rows corresponding to 35 resamples of 50 pennies. Let’s now compute the resulting 35 sample means using the same <strong>dplyr</strong> code as we did in the previous section, but this time adding a <code>group_by(replicate)</code>:</p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="10-confidence-intervals.html#cb675-1"></a>virtual_resampled_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb675-2"><a href="10-confidence-intervals.html#cb675-2"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb675-3"><a href="10-confidence-intervals.html#cb675-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span>
<span id="cb675-4"><a href="10-confidence-intervals.html#cb675-4"></a>virtual_resampled_means</span></code></pre></div>
<pre><code># A tibble: 35 x 2
   replicate mean_year
       &lt;int&gt;     &lt;dbl&gt;
 1         1   1995.58
 2         2   1999.74
 3         3   1993.7 
 4         4   1997.1 
 5         5   1999.42
 6         6   1995.12
 7         7   1994.94
 8         8   1997.78
 9         9   1991.26
10        10   1996.88
# … with 25 more rows</code></pre>
<p>Observe that <code>virtual_resampled_means</code> has 35 rows, corresponding to the 35 resampled means. Furthermore, observe that the values of <code>mean_year</code> vary. Let’s visualize this variation using a histogram in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-7">10.12</a>.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="10-confidence-intervals.html#cb677-1"></a><span class="kw">ggplot</span>(virtual_resampled_means, <span class="kw">aes</span>(<span class="dt">x =</span> mean_year)) <span class="op">+</span></span>
<span id="cb677-2"><a href="10-confidence-intervals.html#cb677-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span></span>
<span id="cb677-3"><a href="10-confidence-intervals.html#cb677-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Resample mean year&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:tactile-resampling-7"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/tactile-resampling-7-1.png" alt="Distribution of 35 sample means from 35 resamples." width="\textwidth" />
<p class="caption">
FIGURE 10.12: Distribution of 35 sample means from 35 resamples.
</p>
</div>
<p>Let’s compare our virtually constructed bootstrap distribution with the one our 35 friends constructed via our tactile resampling exercise in Figure <a href="10-confidence-intervals.html#fig:orig-and-resample-means">10.13</a>. Observe how they are somewhat similar, but not identical.</p>
<div class="figure" style="text-align: center"><span id="fig:orig-and-resample-means"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/orig-and-resample-means-1.png" alt="Comparing distributions of means from resamples." width="\textwidth" />
<p class="caption">
FIGURE 10.13: Comparing distributions of means from resamples.
</p>
</div>
<p>Recall that in the “resampling with replacement” scenario we are illustrating here, both of these histograms have a special name: the <em>bootstrap distribution of the sample mean</em>. Furthermore, recall they are an approximation to the <em>sampling distribution</em> of the sample mean, a concept you saw in Chapter <a href="9-sampling.html#sampling">9</a> on sampling. These distributions allow us to study the effect of sampling variation on our estimates of the true population mean, in this case the true mean year for <em>all</em> US pennies. However, unlike in Chapter <a href="9-sampling.html#sampling">9</a> where we took multiple samples (something one would never do in practice), bootstrap distributions are constructed by taking multiple resamples from a <em>single</em> sample: in this case, the 50 original pennies from the bank.</p>
</div>
<div id="bootstrap-1000-replicates" class="section level3">
<h3><span class="header-section-number">10.1.7</span> Virtually resampling 1,000 times</h3>
<p>Remember that one of the goals of resampling with replacement is to construct the bootstrap distribution, which is an approximation of the sampling distribution. However, the bootstrap distribution in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-7">10.12</a> is based only on 35 resamples and hence looks a little coarse. Let’s increase the number of resamples to 1,000, so that we can hopefully better see the shape and the variability between different resamples.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="10-confidence-intervals.html#cb678-1"></a><span class="co"># Repeat resampling 1,000 times</span></span>
<span id="cb678-2"><a href="10-confidence-intervals.html#cb678-2"></a></span>
<span id="cb678-3"><a href="10-confidence-intervals.html#cb678-3"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb678-4"><a href="10-confidence-intervals.html#cb678-4"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb678-5"><a href="10-confidence-intervals.html#cb678-5"></a></span>
<span id="cb678-6"><a href="10-confidence-intervals.html#cb678-6"></a><span class="co"># Compute 1,000 sample means</span></span>
<span id="cb678-7"><a href="10-confidence-intervals.html#cb678-7"></a></span>
<span id="cb678-8"><a href="10-confidence-intervals.html#cb678-8"></a>virtual_resampled_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb678-9"><a href="10-confidence-intervals.html#cb678-9"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb678-10"><a href="10-confidence-intervals.html#cb678-10"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<p>However, in the interest of brevity, going forward let’s combine these two operations into a single chain of pipe (<code>%&gt;%</code>) operators:</p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="10-confidence-intervals.html#cb679-1"></a>virtual_resampled_means &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb679-2"><a href="10-confidence-intervals.html#cb679-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb679-3"><a href="10-confidence-intervals.html#cb679-3"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb679-4"><a href="10-confidence-intervals.html#cb679-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span>
<span id="cb679-5"><a href="10-confidence-intervals.html#cb679-5"></a>virtual_resampled_means</span></code></pre></div>
<pre><code># A tibble: 1,000 x 2
   replicate mean_year
       &lt;int&gt;     &lt;dbl&gt;
 1         1   1992.6 
 2         2   1994.78
 3         3   1994.74
 4         4   1997.88
 5         5   1990   
 6         6   1999.48
 7         7   1990.26
 8         8   1993.2 
 9         9   1994.88
10        10   1996.3 
# … with 990 more rows</code></pre>
<p>In Figure <a href="10-confidence-intervals.html#fig:one-thousand-sample-means">10.14</a> let’s visualize the bootstrap distribution of these 1,000 means based on 1,000 virtual resamples:</p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb681-1"><a href="10-confidence-intervals.html#cb681-1"></a>virtual_resampled_means <span class="op">%&gt;%</span></span>
<span id="cb681-2"><a href="10-confidence-intervals.html#cb681-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mean_year)) <span class="op">+</span></span>
<span id="cb681-3"><a href="10-confidence-intervals.html#cb681-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">boundary =</span> <span class="dv">1990</span>) <span class="op">+</span></span>
<span id="cb681-4"><a href="10-confidence-intervals.html#cb681-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;sample mean&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:one-thousand-sample-means"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/one-thousand-sample-means-1.png" alt="Bootstrap resampling distribution based on 1000 resamples." width="\textwidth" />
<p class="caption">
FIGURE 10.14: Bootstrap resampling distribution based on 1000 resamples.
</p>
</div>
<p>Note here that the bell shape is starting to become much more apparent. We now have a general sense for the range of values that the sample mean may take on. But where is this histogram centered? Let’s compute the mean of the 1,000 resample means:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="10-confidence-intervals.html#cb682-1"></a>virtual_resampled_means <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb682-2"><a href="10-confidence-intervals.html#cb682-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_means =</span> <span class="kw">mean</span>(mean_year))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
  mean_of_means
          &lt;dbl&gt;
1       1995.36</code></pre>
<p>The mean of these 1,000 means is 1995.36, which is quite close to the mean of our original sample of 50 pennies of 1995.44. This is the case since each of the 1,000 resamples is based on the original sample of 50 pennies.</p>
<p>Congratulations! You’ve just constructed your first bootstrap distribution! In the next section, you’ll see how to use this bootstrap distribution to construct <em>confidence intervals</em>.</p>
</div>
</div>
<div id="ci-build-up" class="section level2">
<h2><span class="header-section-number">10.2</span> Measuring uncertainty with confidence intervals</h2>
<p>Let’s start this section with an analogy involving fishing. Say you are trying to catch a fish. On the one hand, you could use a spear, while on the other you could use a net. Using the net will probably allow you to catch more fish!</p>
<p>Now think back to our pennies exercise where you are trying to estimate the true population mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies.  Think of the value of <span class="math inline">\(\mu\)</span> as a fish.</p>
<p>On the one hand, we could use the appropriate <em>point estimate/sample statistic</em> to estimate <span class="math inline">\(\mu\)</span>, which we saw in Table <a href="10-confidence-intervals.html#tab:table-ch8-b">10.1</a> is the sample mean <span class="math inline">\(\overline{x}\)</span>. Based on our sample of 50 pennies from the bank, the sample mean was 1995.44. Think of using this value as “fishing with a spear.”</p>
<p>What would “fishing with a net” correspond to? Look at the bootstrap distribution in Figure <a href="10-confidence-intervals.html#fig:one-thousand-sample-means">10.14</a> once more. Between which two years would you say that “most” sample means lie? While this question is somewhat subjective, saying that most sample means lie between 1992 and 2000 would not be unreasonable. Think of this interval as the “net.”</p>
<p>What we’ve just illustrated is the concept of a <em>confidence interval</em>, which we’ll abbreviate with “CI” throughout this book. As opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a <em>confidence interval</em>  gives what can be interpreted as a range of plausible values. Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.</p>
<!--
Point estimate           |  Confidence interval
:-------------------------:|:-------------------------:
![](images/shutterstock/shutterstock_149730074_cropped.jpg){ height=2.5in } |  ![](images/shutterstock/shutterstock_176684936.jpg){ height=2.5in }
-->
<div class="figure" style="text-align: center"><span id="fig:point-estimate-vs-conf-int"></span>
<img src="images/shutterstock/point_estimate_vs_conf_int.png" alt="Analogy of difference between point estimates and confidence intervals." width="100%" />
<p class="caption">
FIGURE 10.15: Analogy of difference between point estimates and confidence intervals.
</p>
</div>
<p>Our proposed interval of 1992 to 2000 was constructed by eye and was thus somewhat subjective. We now introduce two methods for constructing such intervals in a more exact fashion: the <em>percentile method</em> and the <em>standard error method</em>.</p>
<p>Both methods for confidence interval construction share some commonalities. First, they are both constructed from a bootstrap distribution, as you constructed in Subsection <a href="10-confidence-intervals.html#bootstrap-1000-replicates">10.1.7</a> and visualized in Figure <a href="10-confidence-intervals.html#fig:one-thousand-sample-means">10.14</a>.</p>
<p>Second, they both require you to specify the  <em>confidence level</em>. Commonly used confidence levels include 90%, 95%, and 99%. All other things being equal, higher confidence levels correspond to wider confidence intervals, and lower confidence levels correspond to narrower confidence intervals. In this book, we’ll be mostly using 95% and hence constructing “95% confidence intervals for <span class="math inline">\(\mu\)</span>” for our pennies activity.</p>
<div id="percentile-method" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Percentile method</h3>
<p>One method to construct a confidence interval is to use the middle 95% of values of the bootstrap distribution. We can do this by computing the 2.5th and 97.5th percentiles, which are 1991.059 and 1999.283, respectively. This is known as the <em>percentile method</em> for constructing confidence intervals. You can get these values using the <code>quantile()</code> function on the <code>mean_year</code> column of <code>virtual_resampled_means</code>:</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="10-confidence-intervals.html#cb684-1"></a>virtual_resampled_means <span class="op">%&gt;%</span></span>
<span id="cb684-2"><a href="10-confidence-intervals.html#cb684-2"></a><span class="st">  </span><span class="kw">pull</span>(mean_year) <span class="op">%&gt;%</span></span>
<span id="cb684-3"><a href="10-confidence-intervals.html#cb684-3"></a><span class="st">  </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code> 2.5% 97.5% 
 1991  1999 </code></pre>
<p>Let’s mark these percentiles on the bootstrap distribution with vertical lines in Figure <a href="10-confidence-intervals.html#fig:percentile-method">10.16</a>. About 95% of the <code>mean_year</code> variable values in <code>virtual_resampled_means</code> fall between 1991.059 and 1999.283, with 2.5% to the left of the leftmost line and 2.5% to the right of the rightmost line.</p>

<div class="figure" style="text-align: center"><span id="fig:percentile-method"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/percentile-method-1.png" alt="Percentile method 95% confidence interval. Interval endpoints marked by vertical lines." width="\textwidth" />
<p class="caption">
FIGURE 10.16: Percentile method 95% confidence interval. Interval endpoints marked by vertical lines.
</p>
</div>
</div>
<div id="se-method" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Standard error method</h3>
<p>If a numerical variable follows a normal distribution, or, in other words, the histogram of this variable is bell-shaped, then roughly 95% of values fall between <span class="math inline">\(\pm\)</span> 1.96 standard deviations of the mean. Given that our bootstrap distribution based on 1,000 resamples with replacement in Figure <a href="10-confidence-intervals.html#fig:one-thousand-sample-means">10.14</a> is normally shaped, let’s use this fact about normal distributions to construct a confidence interval in a different way.</p>
<p>First, recall the bootstrap distribution has a mean equal to 1995.36. This value almost coincides exactly with the value of the sample mean <span class="math inline">\(\overline{x}\)</span> of our original 50 pennies of 1995.44. Second, let’s compute the standard deviation of the bootstrap distribution using the values of <code>mean_year</code> in the <code>virtual_resampled_means</code> data frame:</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="10-confidence-intervals.html#cb686-1"></a>virtual_resampled_means <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb686-2"><a href="10-confidence-intervals.html#cb686-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">SE =</span> <span class="kw">sd</span>(mean_year))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
       SE
    &lt;dbl&gt;
1 2.15466</code></pre>
<p>What is this value? Recall that the bootstrap distribution is an approximation to the sampling distribution. Recall also that the standard deviation of a sampling distribution has a special name: the <em>standard error</em>. Putting these two facts together, we can say that 2.155 is an approximation of the standard error of <span class="math inline">\(\overline{x}\)</span>.</p>
<p>Thus, using our 95% rule of thumb about normal distributions, we can use the following formula to determine the lower and upper endpoints of a 95% confidence interval for <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\overline{x} \pm 1.96 \cdot SE &amp;= (\overline{x} - 1.96 \cdot SE, \overline{x} + 1.96 \cdot SE)\\
&amp;= (1995.44 - 1.96 \cdot 2.15, 1995.44 + 1.96 \cdot 2.15)\\
&amp;= (1991.15, 1999.73)
\end{aligned}
\]</span></p>
<p>Let’s now add the SE method confidence interval with dashed lines in Figure <a href="10-confidence-intervals.html#fig:percentile-and-se-method">10.17</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:percentile-and-se-method"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/percentile-and-se-method-1.png" alt="Comparing two 95% confidence interval methods." width="\textwidth" />
<p class="caption">
FIGURE 10.17: Comparing two 95% confidence interval methods.
</p>
</div>
<p>We see that both methods produce nearly identical 95% confidence intervals for <span class="math inline">\(\mu\)</span> with the percentile method yielding <span class="math inline">\((1991.06, 1999.28)\)</span> while the standard error method produces <span class="math inline">\((1991.22, 1999.66)\)</span>. Thus, the standard error method can be a good quick way to construct confidence intervals when you already have an estimate of the standard error and don’t want to go through the steps to obtain a confidence interval by the percentile method. It is particularly handy since <span class="math inline">\(1.96 \approx 2\)</span>, and thus it is easy to calculate in one’s head. However, recall that we can only use the standard error rule when the bootstrap distribution is roughly normally shaped. If you have an unusually shaped distribution, it is better to use the percentile method.</p>
</div>
<div id="one-prop-ci" class="section level3">
<h3><span class="header-section-number">10.2.3</span> Interpreting confidence intervals</h3>
<p>Now that we’ve shown you how to construct confidence intervals using a sample drawn from a population, let’s now focus on how to interpret them.</p>
<p>The traditional approach is referred to as either “Frequentist” or “Classical.” In this interpretation, 95% of the time that you perform this exercise, the <em>intervals</em> constructed will contain the true but unknown population parameter. You are making a claim about how well this approach — bootstrap resampling — works if you do it many, many times. You do not know anything about how well it worked this time.</p>
<p>In this book, we use a “Bayesian” interpretation. There is a true, but unknown, average year of minting for all the pennies in the world. In theory, we could find all those pennies and then calculate this number. The Bayesian interpretation of a 95% confidence interval is that we are 95% certain that the true value is within the CI limits. It would be a fair wager to bet, at 19:1 odds, that the true value is outside those limits because there is a 5% chance that it is.</p>
<p>Note that these are just <em>interpretations</em>. The reality of what we did is the same in both cases. The computer code is the same. This Bayesian interpretation of the bootstrap confidence interval is often called a <a href="https://en.wikipedia.org/wiki/Credible_interval">credible interval</a> in the academic literature. You may find yourself in a statistics class that uses the phrase “confidence interval” to refer only to the <a href="https://en.wikipedia.org/wiki/Frequentist_inference">frequentist</a> concept.</p>
<p>Does our percentile-based confidence interval of (1991.06, 1999.28) “capture” the true mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies? Alas, we’ll never know, because we don’t know what the true value of <span class="math inline">\(\mu\)</span> is. After all, we’re sampling to estimate it!</p>
<p>However, we can answer a different question. Given that we’ve observed the 50 pennies that we did, what’s the <em>chance</em> that the true value falls within (1991.06, 1999.28)? If the answer is 95%, then we can call this a 95% interval.</p>
<p>This is a statement about <em>probability</em>. We thus can think of the mean year of the pennies as a random variable that has its own <em>probability distribution</em>. Of course, we don’t know exactly what that distribution is. The bootstrap resampling procedure, however, generates a distribution of values for the mean. Since the bootstrap distribution is a good approximation of the <em>sampling</em> distribution we learned about in the last chapter (see Subsection <a href="10-confidence-intervals.html#bootstrap-vs-sampling">10.6.1</a>), this is a reasonable thing to do. Then, if we take the bootstrap distribution as our “best guess” of the probability distribution of the variable we are interested in, we can guess that the variable has a 95% chance of lying between the 2.5th and 97.5th percentiles of the bootstrap distribution.</p>
<!-- AR: took this language from the regression chapter.  Maybe OK to repeat it
-->
<p>Instead of looking at confidence intervals, a common alternative approach is to conduct <em>hypothesis tests</em>, where one hypothesis is called the “null hypothesis” (often that a value, such as a mean, is equal to zero) and the result of the test is either <em>rejecting</em> the null hypothesis (so you’d conclude that the mean is not zero) or <em>failing to reject</em> the null hypothesis. The decision whether to reject the null hypothesis is generally made with reference to a <em>p-value</em>, a measure of how likely one would be, if the null hypothesis were true, to observe results at least as extreme as the results actually observed. A <em>p</em>-value cutoff, often 0.05, is employed: if the <em>p</em>-value is lower, the null hypothesis is rejected, otherwise the hypothesis is not rejected.</p>
<p>We think this is a bad way to make decisions. Two very similar datasets could produce <em>p</em>-values of <span class="math inline">\(p = 0.04\)</span> and <span class="math inline">\(p = 0.06\)</span> for a quantity of interest. If you would make one decision in the former case and a totally different decision in the latter case, then there’s something wrong with your decision-making process! Rather, we think it is more sensible to look at the data, construct models to summarize important features of the data, and make decisions based on those models that take into account the uncertainty in the models’ estimates.</p>
<!-- The above is not bad, but we need more, more, more. Every chapter should repeat this and provide examples. Maybe, each chapter, we need a specific example of the stupidity of NHST. (And maybe an actual decision problem.) And then show how a model summary helps us. -->
</div>
</div>
<div id="ci-width" class="section level2">
<h2><span class="header-section-number">10.3</span> Width of confidence intervals</h2>
<p>Now that we know how to interpret confidence intervals, let’s go over some factors that determine their width.</p>
<div id="impact-of-confidence-level" class="section level3">
<h3><span class="header-section-number">10.3.1</span> Impact of confidence level</h3>
<p>One factor that determines confidence interval widths is the pre-specified <em>confidence level</em>. The quantification of the confidence level should match what many expect of the word “confident.” In order to be more confident in our best guess of a range of values, we need to widen the range of values.</p>
<p>Imagine we want to forecast the high temperature in Seoul, South Korea on August 15th. Given Seoul’s temperate climate with four distinct seasons, we could say somewhat confidently that the high temperature would be between 50°F - 95°F (10°C - 35°C). However, if we wanted a temperature range we were <em>absolutely</em> confident about, we would need to widen it.</p>
<p>We need this wider range to allow for the possibility of anomalous weather, like a freak cold spell or an extreme heat wave. So a range of temperatures we could be near certain about would be between 32°F - 110°F (0°C - 43°C). On the other hand, if we could tolerate being a little less confident, we could narrow this range to between 70°F - 85°F (21°C - 30°C).</p>
<!-- DK: Is it a good idea to go back to the urn example here? Why not just stick with pennies? Or perhaps it is important to connect the previous chapter to this one, to see how our new knowledge of confidence intervals applies in the urn case. Even if we do keep it, this part definitely goes much too fast. First, remind people about the urn. Then, do one sample and show how we can build a confidence interval from that, at a given confidence level. Then show how we build it for different confidence levels. Then do it 10 times for each confidence level. Or something like that. -->
<p>Let’s revisit our sampling urn from Chapter <a href="9-sampling.html#sampling">9</a>. Let’s compare <span class="math inline">\(10 \cdot 3 = 30\)</span> confidence intervals for <span class="math inline">\(p\)</span> based on three different confidence levels: 80%, 95%, and 99%.</p>
<p>Specifically, we’ll first take 30 different random samples of size <span class="math inline">\(n = 50\)</span> balls from the urn. Then we’ll construct ten percentile-based confidence intervals using each of the three different confidence levels.</p>
<p>Finally, we’ll compare the widths of these intervals.</p>
<p>We’ll start by walking through the process for the 80% confidence intervals. We begin by taking 10 random samples from the urn of size <span class="math inline">\(n = 50\)</span>:</p>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="10-confidence-intervals.html#cb688-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb688-2"><a href="10-confidence-intervals.html#cb688-2"></a></span>
<span id="cb688-3"><a href="10-confidence-intervals.html#cb688-3"></a><span class="co"># Compute 80% confidence intervals</span></span>
<span id="cb688-4"><a href="10-confidence-intervals.html#cb688-4"></a></span>
<span id="cb688-5"><a href="10-confidence-intervals.html#cb688-5"></a><span class="co"># Get 10 random samples</span></span>
<span id="cb688-6"><a href="10-confidence-intervals.html#cb688-6"></a></span>
<span id="cb688-7"><a href="10-confidence-intervals.html#cb688-7"></a>perc_cis_<span class="dv">80</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span></span>
<span id="cb688-8"><a href="10-confidence-intervals.html#cb688-8"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">10</span>)</span>
<span id="cb688-9"><a href="10-confidence-intervals.html#cb688-9"></a>perc_cis_<span class="dv">80</span></span></code></pre></div>
<pre><code># A tibble: 500 x 3
# Groups:   replicate [10]
   replicate ball_ID color
       &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
 1         1    2235 red  
 2         1    1589 white
 3         1    1286 white
 4         1    1851 white
 5         1     408 red  
 6         1     595 red  
 7         1    1027 red  
 8         1     556 red  
 9         1     549 white
10         1      42 red  
# … with 490 more rows</code></pre>
<!-- DK: Is this the first time we are using nest? If so, it is going way too fast! -->
<p>Next, we’ll construct a confidence interval for each one. This will require <code>nest</code>ing the data by sample and then <code>map</code>ping to construct each confidence interval. Let’s grab 1,000 bootstrap replicates for each sample:</p>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="10-confidence-intervals.html#cb690-1"></a>perc_cis_<span class="dv">80</span> &lt;-<span class="st"> </span>perc_cis_<span class="dv">80</span> <span class="op">%&gt;%</span></span>
<span id="cb690-2"><a href="10-confidence-intervals.html#cb690-2"></a><span class="st">  </span></span>
<span id="cb690-3"><a href="10-confidence-intervals.html#cb690-3"></a><span class="st">  </span><span class="co"># For each one, construct a CI</span></span>
<span id="cb690-4"><a href="10-confidence-intervals.html#cb690-4"></a><span class="st">  </span></span>
<span id="cb690-5"><a href="10-confidence-intervals.html#cb690-5"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb690-6"><a href="10-confidence-intervals.html#cb690-6"></a><span class="st">  </span><span class="kw">nest</span>() <span class="op">%&gt;%</span></span>
<span id="cb690-7"><a href="10-confidence-intervals.html#cb690-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boots =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">rep_sample_n</span>(., <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)))</span>
<span id="cb690-8"><a href="10-confidence-intervals.html#cb690-8"></a></span>
<span id="cb690-9"><a href="10-confidence-intervals.html#cb690-9"></a>perc_cis_<span class="dv">80</span></span></code></pre></div>
<pre><code># A tibble: 10 x 3
# Groups:   replicate [10]
   replicate data              boots                
       &lt;int&gt; &lt;list&gt;            &lt;list&gt;               
 1         1 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 2         2 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 3         3 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 4         4 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 5         5 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 6         6 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 7         7 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 8         8 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
 9         9 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;
10        10 &lt;tibble [50 × 2]&gt; &lt;tibble [50,000 × 3]&gt;</code></pre>
<!-- DK: Need to make variable name choice, like `boots` more consistent across chapters. Wouldn't `data` be better? Also, the next chunk of code is very confusing! Isn't there an easier way? We do something like this in each of the next few chapters. Worth getting right! -->
<p>Now that we have a list column called <code>boots</code> for each of our original 10 samples, we can now get 1,000 estimates per sample of <code>prop_red</code> from the bootstrap:</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="10-confidence-intervals.html#cb692-1"></a>perc_cis_<span class="dv">80</span> &lt;-<span class="st"> </span>perc_cis_<span class="dv">80</span> <span class="op">%&gt;%</span></span>
<span id="cb692-2"><a href="10-confidence-intervals.html#cb692-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_results =</span> <span class="kw">map</span>(boots, <span class="op">~</span><span class="st"> </span><span class="kw">group_by</span>(., replicate) <span class="op">%&gt;%</span></span>
<span id="cb692-3"><a href="10-confidence-intervals.html#cb692-3"></a><span class="st">                                            </span><span class="kw">summarize</span>(<span class="dt">prop_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))),</span>
<span id="cb692-4"><a href="10-confidence-intervals.html#cb692-4"></a>         <span class="dt">prop_red =</span> <span class="kw">map</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red)))</span>
<span id="cb692-5"><a href="10-confidence-intervals.html#cb692-5"></a>perc_cis_<span class="dv">80</span></span></code></pre></div>
<pre><code># A tibble: 10 x 5
# Groups:   replicate [10]
   replicate data            boots              prop_red_results    prop_red    
       &lt;int&gt; &lt;list&gt;          &lt;list&gt;             &lt;list&gt;              &lt;list&gt;      
 1         1 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 2         2 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 3         3 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 4         4 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 5         5 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 6         6 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 7         7 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 8         8 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
 9         9 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…
10        10 &lt;tibble [50 × … &lt;tibble [50,000 ×… &lt;tibble [1,000 × 2… &lt;dbl [1,000…</code></pre>
<p>Finally, we will use the list column <code>prop_red</code> to get the lower and upper bounds of our confidence intervals and note the level of confidence we used:</p>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="10-confidence-intervals.html#cb694-1"></a>perc_cis_<span class="dv">80</span> &lt;-<span class="st"> </span>perc_cis_<span class="dv">80</span> <span class="op">%&gt;%</span></span>
<span id="cb694-2"><a href="10-confidence-intervals.html#cb694-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">lower =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.1</span>)),</span>
<span id="cb694-3"><a href="10-confidence-intervals.html#cb694-3"></a>         <span class="dt">upper =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.9</span>)),</span>
<span id="cb694-4"><a href="10-confidence-intervals.html#cb694-4"></a>         <span class="dt">confidence_level =</span> <span class="st">&quot;80%&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb694-5"><a href="10-confidence-intervals.html#cb694-5"></a><span class="st">  </span><span class="kw">select</span>(replicate, lower, upper, confidence_level)</span>
<span id="cb694-6"><a href="10-confidence-intervals.html#cb694-6"></a>perc_cis_<span class="dv">80</span></span></code></pre></div>
<pre><code># A tibble: 10 x 4
# Groups:   replicate [10]
   replicate lower upper confidence_level
       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           
 1         1  0.36  0.54 80%             
 2         2  0.3   0.48 80%             
 3         3  0.22  0.38 80%             
 4         4  0.26  0.42 80%             
 5         5  0.32  0.5  80%             
 6         6  0.3   0.5  80%             
 7         7  0.32  0.5  80%             
 8         8  0.32  0.48 80%             
 9         9  0.32  0.48 80%             
10        10  0.26  0.42 80%             </code></pre>
<p>Now we can do the same for the 95% and 99% confidence intervals:</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="10-confidence-intervals.html#cb696-1"></a><span class="co"># Compute 95% confidence intervals</span></span>
<span id="cb696-2"><a href="10-confidence-intervals.html#cb696-2"></a></span>
<span id="cb696-3"><a href="10-confidence-intervals.html#cb696-3"></a><span class="co"># Get 10 random samples</span></span>
<span id="cb696-4"><a href="10-confidence-intervals.html#cb696-4"></a></span>
<span id="cb696-5"><a href="10-confidence-intervals.html#cb696-5"></a>perc_cis_<span class="dv">95</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span></span>
<span id="cb696-6"><a href="10-confidence-intervals.html#cb696-6"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb696-7"><a href="10-confidence-intervals.html#cb696-7"></a><span class="st">  </span></span>
<span id="cb696-8"><a href="10-confidence-intervals.html#cb696-8"></a><span class="st">  </span><span class="co"># For each one, construct a CI</span></span>
<span id="cb696-9"><a href="10-confidence-intervals.html#cb696-9"></a><span class="st">  </span></span>
<span id="cb696-10"><a href="10-confidence-intervals.html#cb696-10"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb696-11"><a href="10-confidence-intervals.html#cb696-11"></a><span class="st">  </span><span class="kw">nest</span>() <span class="op">%&gt;%</span></span>
<span id="cb696-12"><a href="10-confidence-intervals.html#cb696-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boots =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">rep_sample_n</span>(., <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)),</span>
<span id="cb696-13"><a href="10-confidence-intervals.html#cb696-13"></a>         <span class="dt">prop_red_results =</span> <span class="kw">map</span>(boots, <span class="op">~</span><span class="st"> </span><span class="kw">group_by</span>(., replicate) <span class="op">%&gt;%</span></span>
<span id="cb696-14"><a href="10-confidence-intervals.html#cb696-14"></a><span class="st">                                  </span><span class="kw">summarize</span>(<span class="dt">prop_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))),</span>
<span id="cb696-15"><a href="10-confidence-intervals.html#cb696-15"></a>         <span class="dt">prop_red =</span> <span class="kw">map</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red)),</span>
<span id="cb696-16"><a href="10-confidence-intervals.html#cb696-16"></a>         <span class="dt">lower =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.025</span>)),</span>
<span id="cb696-17"><a href="10-confidence-intervals.html#cb696-17"></a>         <span class="dt">upper =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.975</span>)),</span>
<span id="cb696-18"><a href="10-confidence-intervals.html#cb696-18"></a>         <span class="dt">confidence_level =</span> <span class="st">&quot;95%&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb696-19"><a href="10-confidence-intervals.html#cb696-19"></a><span class="st">  </span><span class="kw">select</span>(replicate, lower, upper, confidence_level)</span>
<span id="cb696-20"><a href="10-confidence-intervals.html#cb696-20"></a></span>
<span id="cb696-21"><a href="10-confidence-intervals.html#cb696-21"></a></span>
<span id="cb696-22"><a href="10-confidence-intervals.html#cb696-22"></a><span class="co"># Compute 99% confidence intervals</span></span>
<span id="cb696-23"><a href="10-confidence-intervals.html#cb696-23"></a></span>
<span id="cb696-24"><a href="10-confidence-intervals.html#cb696-24"></a><span class="co"># Get 10 random samples</span></span>
<span id="cb696-25"><a href="10-confidence-intervals.html#cb696-25"></a></span>
<span id="cb696-26"><a href="10-confidence-intervals.html#cb696-26"></a>perc_cis_<span class="dv">99</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span></span>
<span id="cb696-27"><a href="10-confidence-intervals.html#cb696-27"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb696-28"><a href="10-confidence-intervals.html#cb696-28"></a><span class="st">  </span></span>
<span id="cb696-29"><a href="10-confidence-intervals.html#cb696-29"></a><span class="st">  </span><span class="co"># For each one, construct a CI</span></span>
<span id="cb696-30"><a href="10-confidence-intervals.html#cb696-30"></a><span class="st">  </span></span>
<span id="cb696-31"><a href="10-confidence-intervals.html#cb696-31"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb696-32"><a href="10-confidence-intervals.html#cb696-32"></a><span class="st">  </span><span class="kw">nest</span>() <span class="op">%&gt;%</span></span>
<span id="cb696-33"><a href="10-confidence-intervals.html#cb696-33"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boots =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">rep_sample_n</span>(., <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)),</span>
<span id="cb696-34"><a href="10-confidence-intervals.html#cb696-34"></a>         <span class="dt">prop_red_results =</span> <span class="kw">map</span>(boots, <span class="op">~</span><span class="st"> </span><span class="kw">group_by</span>(., replicate) <span class="op">%&gt;%</span></span>
<span id="cb696-35"><a href="10-confidence-intervals.html#cb696-35"></a><span class="st">                                  </span><span class="kw">summarize</span>(<span class="dt">prop_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))),</span>
<span id="cb696-36"><a href="10-confidence-intervals.html#cb696-36"></a>         <span class="dt">prop_red =</span> <span class="kw">map</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red)),</span>
<span id="cb696-37"><a href="10-confidence-intervals.html#cb696-37"></a>         <span class="dt">lower =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.005</span>)),</span>
<span id="cb696-38"><a href="10-confidence-intervals.html#cb696-38"></a>         <span class="dt">upper =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.995</span>)),</span>
<span id="cb696-39"><a href="10-confidence-intervals.html#cb696-39"></a>         <span class="dt">confidence_level =</span> <span class="st">&quot;99%&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb696-40"><a href="10-confidence-intervals.html#cb696-40"></a><span class="st">  </span><span class="kw">select</span>(replicate, lower, upper, confidence_level)</span>
<span id="cb696-41"><a href="10-confidence-intervals.html#cb696-41"></a></span>
<span id="cb696-42"><a href="10-confidence-intervals.html#cb696-42"></a><span class="co"># Combine into single data frame</span></span>
<span id="cb696-43"><a href="10-confidence-intervals.html#cb696-43"></a></span>
<span id="cb696-44"><a href="10-confidence-intervals.html#cb696-44"></a>percentile_cis_by_level &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(perc_cis_<span class="dv">80</span>, perc_cis_<span class="dv">95</span>, perc_cis_<span class="dv">99</span>)</span></code></pre></div>
<p>Observe that as the confidence level increases from 80% to 95% to 99%, the confidence intervals tend to get wider as seen in Table <a href="10-confidence-intervals.html#tab:perc-cis-average-width">10.2</a> where we compare their average widths.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:perc-cis-average-width">TABLE 10.2: </span>Average width of 80, 95, and 99% confidence intervals
</caption>
<thead>
<tr>
<th style="text-align:left;">
Confidence level
</th>
<th style="text-align:right;">
Mean width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
80%
</td>
<td style="text-align:right;">
0.172
</td>
</tr>
<tr>
<td style="text-align:left;">
95%
</td>
<td style="text-align:right;">
0.268
</td>
</tr>
<tr>
<td style="text-align:left;">
99%
</td>
<td style="text-align:right;">
0.348
</td>
</tr>
</tbody>
</table>
<p>So in order to have a higher confidence level, our confidence intervals must be wider. Ideally, we would have both a high confidence level and narrow confidence intervals. However, we cannot have it both ways. If we want to <em>be more confident</em>, we need to allow for wider intervals. Conversely, if we would like a narrow interval, we must tolerate a lower confidence level.</p>
<p>The moral of the story is:  <strong>Higher confidence levels tend to produce wider confidence intervals.</strong> When looking at Table <a href="10-confidence-intervals.html#tab:perc-cis-average-width">10.2</a> it is important to keep in mind that we kept the sample size fixed at <span class="math inline">\(n = 50\)</span>. Thus, all <span class="math inline">\(10 \cdot 3 = 30\)</span> random samples from the <code>urn</code> had the same sample size. What happens if instead we took samples of different sizes? Recall that we did this in Subsection <a href="9-sampling.html#different-shovels">9.2.4</a> using virtual shovels with 25, 50, and 100 slots.</p>
</div>
<div id="fitting-multiple-models-using-map" class="section level3">
<h3><span class="header-section-number">10.3.2</span> Fitting multiple models using <code>map()</code></h3>
<p>Note that we have used the same code three times. That means we should write a function! Let’s adapt the code from the last section to take 10 samples of an arbitrary size and then construct confidence intervals of an arbitrary level:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="10-confidence-intervals.html#cb697-1"></a>urn_confidence &lt;-<span class="st"> </span><span class="cf">function</span>(bowl, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> <span class="fl">0.95</span>) {</span>
<span id="cb697-2"><a href="10-confidence-intervals.html#cb697-2"></a>  </span>
<span id="cb697-3"><a href="10-confidence-intervals.html#cb697-3"></a>  <span class="co"># Get lower and upper probabilities</span></span>
<span id="cb697-4"><a href="10-confidence-intervals.html#cb697-4"></a>  </span>
<span id="cb697-5"><a href="10-confidence-intervals.html#cb697-5"></a>  lower_prob =<span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>level) <span class="op">/</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb697-6"><a href="10-confidence-intervals.html#cb697-6"></a>  upper_prob =<span class="st"> </span>level <span class="op">+</span><span class="st"> </span>lower_prob</span>
<span id="cb697-7"><a href="10-confidence-intervals.html#cb697-7"></a>  </span>
<span id="cb697-8"><a href="10-confidence-intervals.html#cb697-8"></a>  <span class="co"># Get 10 random samples</span></span>
<span id="cb697-9"><a href="10-confidence-intervals.html#cb697-9"></a>  </span>
<span id="cb697-10"><a href="10-confidence-intervals.html#cb697-10"></a>  bowl <span class="op">%&gt;%</span></span>
<span id="cb697-11"><a href="10-confidence-intervals.html#cb697-11"></a><span class="st">    </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> n, <span class="dt">reps =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span></span>
<span id="cb697-12"><a href="10-confidence-intervals.html#cb697-12"></a><span class="st">    </span></span>
<span id="cb697-13"><a href="10-confidence-intervals.html#cb697-13"></a><span class="st">      </span><span class="co"># For each one, construct a CI</span></span>
<span id="cb697-14"><a href="10-confidence-intervals.html#cb697-14"></a><span class="st">    </span></span>
<span id="cb697-15"><a href="10-confidence-intervals.html#cb697-15"></a><span class="st">    </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb697-16"><a href="10-confidence-intervals.html#cb697-16"></a><span class="st">    </span><span class="kw">nest</span>() <span class="op">%&gt;%</span></span>
<span id="cb697-17"><a href="10-confidence-intervals.html#cb697-17"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">boots =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">rep_sample_n</span>(., <span class="dt">size =</span> n, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)),</span>
<span id="cb697-18"><a href="10-confidence-intervals.html#cb697-18"></a>           <span class="dt">prop_red_results =</span> <span class="kw">map</span>(boots, <span class="op">~</span><span class="st"> </span><span class="kw">group_by</span>(., replicate) <span class="op">%&gt;%</span></span>
<span id="cb697-19"><a href="10-confidence-intervals.html#cb697-19"></a><span class="st">                                    </span><span class="kw">summarize</span>(<span class="dt">prop_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))),</span>
<span id="cb697-20"><a href="10-confidence-intervals.html#cb697-20"></a>           <span class="dt">prop_red =</span> <span class="kw">map</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red)),</span>
<span id="cb697-21"><a href="10-confidence-intervals.html#cb697-21"></a>           <span class="dt">lower =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> lower_prob)),</span>
<span id="cb697-22"><a href="10-confidence-intervals.html#cb697-22"></a>           <span class="dt">upper =</span> <span class="kw">map_dbl</span>(prop_red, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> upper_prob)),</span>
<span id="cb697-23"><a href="10-confidence-intervals.html#cb697-23"></a>           <span class="dt">sample_size =</span> n,</span>
<span id="cb697-24"><a href="10-confidence-intervals.html#cb697-24"></a>           <span class="dt">confidence_level =</span> level) <span class="op">%&gt;%</span></span>
<span id="cb697-25"><a href="10-confidence-intervals.html#cb697-25"></a><span class="st">    </span><span class="kw">select</span>(replicate, lower, upper, sample_size, confidence_level)</span>
<span id="cb697-26"><a href="10-confidence-intervals.html#cb697-26"></a>}</span></code></pre></div>
<p>Note that we saved the sample size as <code>sample_size</code> and the confidence level as <code>confidence_level</code> for convenient display later.</p>
<p>So we now could create our objects like so:</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="10-confidence-intervals.html#cb698-1"></a>perc_cis_<span class="dv">80</span> &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> <span class="fl">0.80</span>)</span>
<span id="cb698-2"><a href="10-confidence-intervals.html#cb698-2"></a>perc_cis_<span class="dv">95</span> &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb698-3"><a href="10-confidence-intervals.html#cb698-3"></a>perc_cis_<span class="dv">99</span> &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> <span class="fl">0.99</span>)</span>
<span id="cb698-4"><a href="10-confidence-intervals.html#cb698-4"></a></span>
<span id="cb698-5"><a href="10-confidence-intervals.html#cb698-5"></a><span class="co"># Combine into single data frame</span></span>
<span id="cb698-6"><a href="10-confidence-intervals.html#cb698-6"></a></span>
<span id="cb698-7"><a href="10-confidence-intervals.html#cb698-7"></a>percentile_cis_by_level &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(perc_cis_<span class="dv">80</span>, perc_cis_<span class="dv">95</span>, perc_cis_<span class="dv">99</span>)</span>
<span id="cb698-8"><a href="10-confidence-intervals.html#cb698-8"></a>percentile_cis_by_level</span></code></pre></div>
<pre><code># A tibble: 30 x 5
# Groups:   replicate [10]
   replicate lower upper sample_size confidence_level
       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;
 1         1  0.36  0.54          50              0.8
 2         2  0.26  0.42          50              0.8
 3         3  0.34  0.52          50              0.8
 4         4  0.28  0.46          50              0.8
 5         5  0.36  0.52          50              0.8
 6         6  0.3   0.48          50              0.8
 7         7  0.28  0.44          50              0.8
 8         8  0.28  0.46          50              0.8
 9         9  0.3   0.46          50              0.8
10        10  0.28  0.44          50              0.8
# … with 20 more rows</code></pre>
<p>But this still isn’t the best way. Note that we have three objects we need to deal with. Furthermore, we don’t actually know that the names are accurate! Perhaps we made a mistake and created <code>perc_cis_99</code> with the code <code>perc_cis_99 &lt;- urn_confidence(urn, 50, 0.95)</code>; our object name will now be misleading as to what’s actually in the object.</p>
<p>Instead, let’s store our results in a single tibble by using <code>map()</code> to create a list column.</p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="10-confidence-intervals.html#cb700-1"></a><span class="kw">tibble</span>(<span class="dt">level =</span> <span class="kw">c</span>(<span class="fl">0.80</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>)) <span class="op">%&gt;%</span></span>
<span id="cb700-2"><a href="10-confidence-intervals.html#cb700-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="kw">map</span>(level, <span class="op">~</span><span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> .)))</span></code></pre></div>
<pre><code># A tibble: 3 x 2
  level data             
  &lt;dbl&gt; &lt;list&gt;           
1  0.8  &lt;tibble [10 × 5]&gt;
2  0.95 &lt;tibble [10 × 5]&gt;
3  0.99 &lt;tibble [10 × 5]&gt;</code></pre>
<p>Now that we have a list column, we want to <code>unnest()</code> it so we can see our actual data. Further, we won’t need the redundant column <code>level</code> any more:</p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="10-confidence-intervals.html#cb702-1"></a><span class="kw">tibble</span>(<span class="dt">level =</span> <span class="kw">c</span>(<span class="fl">0.80</span>, <span class="fl">0.95</span>, <span class="fl">0.99</span>)) <span class="op">%&gt;%</span></span>
<span id="cb702-2"><a href="10-confidence-intervals.html#cb702-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="kw">map</span>(level, <span class="op">~</span><span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> .))) <span class="op">%&gt;%</span></span>
<span id="cb702-3"><a href="10-confidence-intervals.html#cb702-3"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb702-4"><a href="10-confidence-intervals.html#cb702-4"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>level)</span></code></pre></div>
<pre><code># A tibble: 30 x 5
   replicate lower upper sample_size confidence_level
       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;
 1         1  0.26  0.42          50              0.8
 2         2  0.26  0.44          50              0.8
 3         3  0.3   0.48          50              0.8
 4         4  0.12  0.26          50              0.8
 5         5  0.28  0.44          50              0.8
 6         6  0.3   0.48          50              0.8
 7         7  0.28  0.44          50              0.8
 8         8  0.14  0.3           50              0.8
 9         9  0.38  0.56          50              0.8
10        10  0.28  0.44          50              0.8
# … with 20 more rows</code></pre>
<p>Now that we can create an object with any confidence level we please, why not calculate the widths for confidence levels from 0.50 to 0.99 and plot the results?</p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb704-1"><a href="10-confidence-intervals.html#cb704-1"></a><span class="co"># Same code as before, but for more levels</span></span>
<span id="cb704-2"><a href="10-confidence-intervals.html#cb704-2"></a></span>
<span id="cb704-3"><a href="10-confidence-intervals.html#cb704-3"></a><span class="kw">tibble</span>(<span class="dt">level =</span> <span class="kw">seq</span>(<span class="fl">0.50</span>, <span class="fl">0.99</span>, <span class="dt">by =</span> <span class="fl">0.01</span>)) <span class="op">%&gt;%</span></span>
<span id="cb704-4"><a href="10-confidence-intervals.html#cb704-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="kw">map</span>(level, <span class="op">~</span><span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> .))) <span class="op">%&gt;%</span></span>
<span id="cb704-5"><a href="10-confidence-intervals.html#cb704-5"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb704-6"><a href="10-confidence-intervals.html#cb704-6"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>level) <span class="op">%&gt;%</span></span>
<span id="cb704-7"><a href="10-confidence-intervals.html#cb704-7"></a><span class="st">  </span></span>
<span id="cb704-8"><a href="10-confidence-intervals.html#cb704-8"></a><span class="st">  </span><span class="co"># Calculate mean widths</span></span>
<span id="cb704-9"><a href="10-confidence-intervals.html#cb704-9"></a><span class="st">  </span></span>
<span id="cb704-10"><a href="10-confidence-intervals.html#cb704-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">width =</span> upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">%&gt;%</span></span>
<span id="cb704-11"><a href="10-confidence-intervals.html#cb704-11"></a><span class="st">  </span><span class="kw">group_by</span>(confidence_level) <span class="op">%&gt;%</span></span>
<span id="cb704-12"><a href="10-confidence-intervals.html#cb704-12"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_width =</span> <span class="kw">mean</span>(width)) <span class="op">%&gt;%</span></span>
<span id="cb704-13"><a href="10-confidence-intervals.html#cb704-13"></a><span class="st">  </span></span>
<span id="cb704-14"><a href="10-confidence-intervals.html#cb704-14"></a><span class="st">  </span><span class="co"># Plot results</span></span>
<span id="cb704-15"><a href="10-confidence-intervals.html#cb704-15"></a><span class="st">  </span></span>
<span id="cb704-16"><a href="10-confidence-intervals.html#cb704-16"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> confidence_level, <span class="dt">y =</span> mean_width)) <span class="op">+</span></span>
<span id="cb704-17"><a href="10-confidence-intervals.html#cb704-17"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb704-18"><a href="10-confidence-intervals.html#cb704-18"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Confidence level&quot;</span>,</span>
<span id="cb704-19"><a href="10-confidence-intervals.html#cb704-19"></a>       <span class="dt">y =</span> <span class="st">&quot;Mean width&quot;</span>,</span>
<span id="cb704-20"><a href="10-confidence-intervals.html#cb704-20"></a>       <span class="dt">title =</span> <span class="st">&quot;Change in mean width of CI as level increase&quot;</span>)</span></code></pre></div>
<p><img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-433-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>As the confidence level gets larger, the width of the interval gets larger too.</p>
</div>
<div id="impact-of-sample-size" class="section level3">
<h3><span class="header-section-number">10.3.3</span> Impact of sample size</h3>
<p>This time, let’s fix the confidence level at 95%, but consider three different sample sizes for <span class="math inline">\(n\)</span>: 25, 50, and 100. Specifically, we’ll first take 10 different random samples of size 25, 10 different random samples of size 50, and 10 different random samples of size 100. We’ll then construct 95% percentile-based confidence intervals for each sample. Finally, we’ll compare the widths of these intervals.</p>
<p>Note that now that we have a function, <code>urn_confidence()</code>, we can do this very easily!</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="10-confidence-intervals.html#cb705-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb705-2"><a href="10-confidence-intervals.html#cb705-2"></a></span>
<span id="cb705-3"><a href="10-confidence-intervals.html#cb705-3"></a></span>
<span id="cb705-4"><a href="10-confidence-intervals.html#cb705-4"></a>perc_cis_n_<span class="dv">25</span>  &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">25</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb705-5"><a href="10-confidence-intervals.html#cb705-5"></a>perc_cis_n_<span class="dv">50</span>  &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">50</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb705-6"><a href="10-confidence-intervals.html#cb705-6"></a>perc_cis_n_<span class="dv">100</span> &lt;-<span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb705-7"><a href="10-confidence-intervals.html#cb705-7"></a></span>
<span id="cb705-8"><a href="10-confidence-intervals.html#cb705-8"></a><span class="co"># Combine into single data frame</span></span>
<span id="cb705-9"><a href="10-confidence-intervals.html#cb705-9"></a></span>
<span id="cb705-10"><a href="10-confidence-intervals.html#cb705-10"></a>percentile_cis_by_n &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(perc_cis_n_<span class="dv">25</span>, perc_cis_n_<span class="dv">50</span>, perc_cis_n_<span class="dv">100</span>)</span></code></pre></div>
<p>Let’s compare the average widths in Table <a href="10-confidence-intervals.html#tab:perc-cis-average-width-2">10.3</a>. Observe that as the confidence intervals are constructed from larger and larger sample sizes, they tend to get narrower.</p>
<!-- Should switch all kable() tables to gt(), I think. Perhaps with a theme! Or at least with standard formatting. -->
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:perc-cis-average-width-2">TABLE 10.3: </span>Average width of 95% confidence intervals based on <span class="math inline">\(n = 25\)</span>, <span class="math inline">\(50\)</span>, and <span class="math inline">\(100\)</span>
</caption>
<thead>
<tr>
<th style="text-align:right;">
Sample size
</th>
<th style="text-align:right;">
Mean width
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
0.364
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0.274
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.186
</td>
</tr>
</tbody>
</table>
<p>The moral of the story is:  <strong>Larger sample sizes tend to produce narrower confidence intervals.</strong> Recall that this was a key message in Subsection <a href="9-sampling.html#moral-of-the-story">9.3.3</a>. As we used larger and larger shovels for our samples, the sample proportions red, <span class="math inline">\(\widehat{p}\)</span>, tended to vary less. In other words, our estimates got more and more <em>precise</em>.</p>
<p>Recall that we visualized these results in Figure <a href="9-sampling.html#fig:comparing-sampling-distributions-3">9.18</a>, where we compared the <em>sampling distributions</em> for <span class="math inline">\(\widehat{p}\)</span> based on samples of size <span class="math inline">\(n\)</span> equal to 25, 50, and 100. We also quantified the sampling variation of these sampling distributions using their standard deviation, which has that special name: the <em>standard error</em>. So as the sample size increases, the standard error decreases.</p>
<p>Let’s do this again, but creating everything in a single tibble so we can look at sample sizes from 25 to 200:</p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="10-confidence-intervals.html#cb706-1"></a><span class="co"># Same code as before, but for more sample sizes</span></span>
<span id="cb706-2"><a href="10-confidence-intervals.html#cb706-2"></a></span>
<span id="cb706-3"><a href="10-confidence-intervals.html#cb706-3"></a><span class="kw">tibble</span>(<span class="dt">n =</span> <span class="kw">seq</span>(<span class="dv">25</span>, <span class="dv">200</span>, <span class="dt">by =</span> <span class="dv">5</span>)) <span class="op">%&gt;%</span></span>
<span id="cb706-4"><a href="10-confidence-intervals.html#cb706-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">data =</span> <span class="kw">map</span>(n, <span class="op">~</span><span class="st"> </span><span class="kw">urn_confidence</span>(<span class="dt">bowl =</span> urn, <span class="dt">n =</span> ., <span class="dt">level =</span> <span class="fl">0.95</span>))) <span class="op">%&gt;%</span></span>
<span id="cb706-5"><a href="10-confidence-intervals.html#cb706-5"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb706-6"><a href="10-confidence-intervals.html#cb706-6"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>n) <span class="op">%&gt;%</span></span>
<span id="cb706-7"><a href="10-confidence-intervals.html#cb706-7"></a><span class="st">  </span></span>
<span id="cb706-8"><a href="10-confidence-intervals.html#cb706-8"></a><span class="st">  </span><span class="co"># Calculate mean widths</span></span>
<span id="cb706-9"><a href="10-confidence-intervals.html#cb706-9"></a><span class="st">  </span></span>
<span id="cb706-10"><a href="10-confidence-intervals.html#cb706-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">width =</span> upper <span class="op">-</span><span class="st"> </span>lower) <span class="op">%&gt;%</span></span>
<span id="cb706-11"><a href="10-confidence-intervals.html#cb706-11"></a><span class="st">  </span><span class="kw">group_by</span>(sample_size) <span class="op">%&gt;%</span></span>
<span id="cb706-12"><a href="10-confidence-intervals.html#cb706-12"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_width =</span> <span class="kw">mean</span>(width)) <span class="op">%&gt;%</span></span>
<span id="cb706-13"><a href="10-confidence-intervals.html#cb706-13"></a><span class="st">  </span></span>
<span id="cb706-14"><a href="10-confidence-intervals.html#cb706-14"></a><span class="st">  </span><span class="co"># Plot results</span></span>
<span id="cb706-15"><a href="10-confidence-intervals.html#cb706-15"></a><span class="st">  </span></span>
<span id="cb706-16"><a href="10-confidence-intervals.html#cb706-16"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sample_size, <span class="dt">y =</span> mean_width)) <span class="op">+</span></span>
<span id="cb706-17"><a href="10-confidence-intervals.html#cb706-17"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb706-18"><a href="10-confidence-intervals.html#cb706-18"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Sample size&quot;</span>,</span>
<span id="cb706-19"><a href="10-confidence-intervals.html#cb706-19"></a>       <span class="dt">y =</span> <span class="st">&quot;Mean width&quot;</span>,</span>
<span id="cb706-20"><a href="10-confidence-intervals.html#cb706-20"></a>       <span class="dt">title =</span> <span class="st">&quot;Change in mean width of CI as sample size decreases&quot;</span>)</span></code></pre></div>
<p><img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-435-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>As the sample size gets larger, the width of the interval gets smaller.</p>
<!-- 
A good Learning check might be to have the readers calculate confidence intervals when n = 1000, 2000, 2400. To their astonishment (maybe), they'll see that the size of the confidence interval is 0 when they get to 2400. 
-->
<!-- DK: None of the above is bad, but it is all based on the urn. Why not do the same thing for the mean year of pennies? Could be quicker. Maybe with all the analysis combined. Or mayube that is what is about to happen now. -->
</div>
</div>
<div id="using-lm-and-tidy-as-a-shortcut" class="section level2">
<h2><span class="header-section-number">10.4</span> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</h2>
<p>Recall the confidence interval we constructed for the mean year of the pennies using the percentile method:</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="10-confidence-intervals.html#cb707-1"></a>virtual_resampled_means <span class="op">%&gt;%</span></span>
<span id="cb707-2"><a href="10-confidence-intervals.html#cb707-2"></a><span class="st">  </span><span class="kw">pull</span>(mean_year) <span class="op">%&gt;%</span></span>
<span id="cb707-3"><a href="10-confidence-intervals.html#cb707-3"></a><span class="st">  </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code> 2.5% 97.5% 
 1991  1999 </code></pre>
<p>Is there a way to construct that interval <em>without</em> engaging in the bootstrap resampling? That is, can we approximate this by using the <code>pennies_sample</code> tibble directly?</p>
<p>It turns out that we can, using the <code>lm()</code> function. <code>lm()</code> stands for <code>l</code>inear <code>m</code>odel, and we will be using it in the next two chapters. This function can get the mean of a variable using the following syntax:</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="10-confidence-intervals.html#cb709-1"></a><span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample)</span></code></pre></div>
<pre><code>
Call:
lm(formula = year ~ 1, data = pennies_sample)

Coefficients:
(Intercept)  
       1995  </code></pre>
<!-- DK: Do we explain this later? If so, provide a link here. -->
<p>Once we learn about regression, we’ll learn why this is labeled the “intercept.” The key thing to note right now is that <code>lm()</code> takes two main arguments, <code>formula</code> and <code>data</code>. The notation <code>year ~ 1</code> will get the mean of <code>year</code>.</p>
<p>The <strong>broom</strong> package makes it easier to work with <code>lm()</code> model objects. In particular, the function <code>tidy()</code> has the option <code>conf.int = TRUE</code>, which we can use to get a confidence interval:</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="10-confidence-intervals.html#cb711-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb711-2"><a href="10-confidence-intervals.html#cb711-2"></a></span>
<span id="cb711-3"><a href="10-confidence-intervals.html#cb711-3"></a><span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample) <span class="op">%&gt;%</span></span>
<span id="cb711-4"><a href="10-confidence-intervals.html#cb711-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code># A tibble: 1 x 7
  term        estimate std.error statistic      p.value conf.low conf.high
  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept)  1995.44   2.14612   929.788 1.03044e-105  1991.13   1999.75</code></pre>
<p>This presents a lot of columns that we don’t care about, so we will <code>select()</code> the relevant ones:</p>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="10-confidence-intervals.html#cb713-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb713-2"><a href="10-confidence-intervals.html#cb713-2"></a></span>
<span id="cb713-3"><a href="10-confidence-intervals.html#cb713-3"></a><span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample) <span class="op">%&gt;%</span></span>
<span id="cb713-4"><a href="10-confidence-intervals.html#cb713-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb713-5"><a href="10-confidence-intervals.html#cb713-5"></a><span class="st">  </span><span class="kw">select</span>(estimate, conf.low, conf.high)</span></code></pre></div>
<pre><code># A tibble: 1 x 3
  estimate conf.low conf.high
     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
1  1995.44  1991.13   1999.75</code></pre>
<!-- DK: Do we need more discussion here? In what sense is this approximation "close enough?" -->
<p>These are not identical to our bootstrap confidence interval estimates, but they are close enough. Thus, if you are interested in constructing a confidence interval for a mean, you can use <code>lm()</code> and <code>tidy()</code> as a shortcut. <code>tidy()</code> also has an argument, <code>conf.level</code>, which allows us to specify the confidence level. By default, it is 0.95.</p>
</div>
<div id="case-study-two-prop-ci" class="section level2">
<h2><span class="header-section-number">10.5</span> Case study: Is yawning contagious?</h2>
<p>Let’s apply our knowledge of confidence intervals to answer the question: “Is yawning contagious?” If you see someone else yawn, are you more likely to yawn? In an episode of the US show <a href="http://www.discovery.com/tv-shows/mythbusters/mythbusters-database/yawning-contagious/"><em>Mythbusters</em></a>, the hosts conducted an experiment to answer this question. The episode is available to view in the United States on the Discovery Network website <a href="https://www.discovery.com/tv-shows/mythbusters/videos/is-yawning-contagious">here</a> and more information about the episode is also available on <a href="https://www.imdb.com/title/tt0768479/">IMDb</a>.</p>
<div id="mythbusters-study-data" class="section level3">
<h3><span class="header-section-number">10.5.1</span> <em>Mythbusters</em> study data</h3>
<!-- DK: Let's try to replace this data. First, we want to get rid of Modern Dive. Second, we need more political science. Also, ought to use the same terminology, at least for the first few chapters. So, instead of "seed", it should be treated, or whatever. I also don't think that "group" is a good variable name since it is a common argument in plotting. Also, need to re-visit RCM in every single chapter. -->
<p>Fifty adult participants who thought they were being considered for an appearance on the show were interviewed by a show recruiter. In the interview, the recruiter either yawned or did not. Participants then sat by themselves in a large van and were asked to wait. While in the van, the <em>Mythbusters</em> team watched the participants using a hidden camera to see if they yawned. The data frame containing the results of their experiment is available in the <code>mythbusters_yawn</code> data frame included in the <strong>moderndive</strong> package: </p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="10-confidence-intervals.html#cb715-1"></a>mythbusters_yawn</span></code></pre></div>
<pre><code># A tibble: 50 x 3
    subj group   yawn 
   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     1 seed    yes  
 2     2 control yes  
 3     3 seed    no   
 4     4 seed    yes  
 5     5 seed    no   
 6     6 control no   
 7     7 seed    yes  
 8     8 control no   
 9     9 control no   
10    10 seed    no   
# … with 40 more rows</code></pre>
<p>The variables are:</p>
<ul>
<li><code>subj</code>: The participant ID with values 1 through 50.</li>
<li><code>group</code>: A binary <em>treatment</em> variable indicating whether the participant was exposed to yawning. <code>"seed"</code> indicates the participant was exposed to yawning while <code>"control"</code> indicates the participant was not.</li>
<li><code>yawn</code>: A binary <em>response</em> variable indicating whether the participant ultimately yawned.</li>
</ul>
<p>Recall that you learned about treatment and response variables in Appendix <a href="A-rubin-causal-model.html#rubin-causal-model">A</a>.</p>
<p>Let’s use some data wrangling to obtain counts of the four possible outcomes:</p>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="10-confidence-intervals.html#cb717-1"></a>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb717-2"><a href="10-confidence-intervals.html#cb717-2"></a><span class="st">  </span><span class="kw">group_by</span>(group, yawn) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb717-3"><a href="10-confidence-intervals.html#cb717-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>())</span></code></pre></div>
<pre><code># A tibble: 4 x 3
# Groups:   group [2]
  group   yawn  count
  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
1 control no       12
2 control yes       4
3 seed    no       24
4 seed    yes      10</code></pre>
<p>Let’s first focus on the <code>"control"</code> group participants who were not exposed to yawning. 12 such participants did not yawn, while 4 such participants did. So out of the 16 people who were not exposed to yawning, 4/16 = 0.25 = 25% did yawn.</p>
<p>Let’s now focus on the <code>"seed"</code> group participants who were exposed to yawning. Of these, 24 participants did not yawn, while 10 participants did yawn. So out of the 34 people who were exposed to yawning, 10/34 = 0.294 = 29.4% did yawn. Comparing these two percentages, the participants who were exposed to yawning yawned 29.4% - 25% = 4.4% more often than those who were not.</p>
</div>
<div id="sampling-scenario" class="section level3">
<h3><span class="header-section-number">10.5.2</span> Sampling scenario</h3>
<p>Let’s review the terminology and notation related to sampling we studied in Subsection <a href="9-sampling.html#terminology-and-notation">9.3.1</a>. In Chapter <a href="9-sampling.html#sampling">9</a> our <em>study population</em> was the urn of <span class="math inline">\(N = 2400\)</span> balls. Our <em>population parameter</em> of interest was the <em>population proportion</em> of these balls that were red, denoted mathematically by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel and computed the relevant <em>point estimate</em>: the <em>sample proportion</em> that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Who is the study population here? All humans? All the people who watch the show <em>Mythbusters</em>? It’s hard to say! This question can only be answered if we know how the show’s hosts recruited participants! In other words, what was the <em>sampling methodology</em> used by the <em>Mythbusters</em> to recruit participants? We alas are not provided with this information. Only for the purposes of this case study, however, we’ll <em>assume</em> that the 50 participants are a representative sample of all Americans given the popularity of this show. Thus, we’ll be assuming that any results of this experiment will generalize to all <span class="math inline">\(N = 327\)</span> million Americans (2018 population).</p>
<p>Just like with our sampling urn, the population parameter here will involve proportions. However, in this case it will be the <em>difference in population proportions</em> <span class="math inline">\(p_{seed} - p_{control}\)</span>, where <span class="math inline">\(p_{seed}\)</span> is the proportion of <em>all</em> Americans who if exposed to yawning will yawn themselves, and <span class="math inline">\(p_{control}\)</span> is the proportion of <em>all</em> Americans who, if not exposed to yawning, still yawn themselves. Correspondingly, the point estimate/sample statistic based the <em>Mythbusters</em>’ sample of participants will be the <em>difference in sample proportions</em> <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span>. Let’s extend our table of scenarios of sampling for inference to include our latest scenario.</p>
<!-- DK: This seems like a great deal of work --- and weird work at that --- to make a simple table. Is this Google doc and/or rds used elsewhere? It is worth thinking about the collection of tables like this which appear in the book. How can they be made as similar as possible across the book? How can they be easily changed? Repitition is key. Indeed, a table like this every chapter should be matched to a problem set question and, eventually, to an exam. In this case, we need to apply this terminology to new cases. -->
<!-- This connects to the issue of similarity in terminology across chapters. seed is bad to use -->
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8-c">TABLE 10.4: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Symbol(s)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 1.5in; ">
Population proportion
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Sample proportion
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 1.5in; ">
Population mean
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Sample mean
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 1.5in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
</tbody>
</table>
<p>This is known as a <em>two-sample</em> inference situation since we have two separate samples. Based on their two-samples of size <span class="math inline">\(n_{seed}\)</span> = 34 and <span class="math inline">\(n_{control}\)</span> = 16, the point estimate is</p>
<p><span class="math display">\[
\widehat{p}_{seed} - \widehat{p}_{control} = \frac{24}{34} - \frac{12}{16} = 0.04411765 \approx 4.4\%
\]</span></p>
<p>However, what if the <em>Mythbusters</em> repeated this experiment? Assume that they recruited 50 new participants and exposed 34 of them to yawning and 16 not. Would they obtain the exact same estimated difference of 4.4%? Probably not, again, because of <em>sampling variation</em>.</p>
<!-- DK: A suble point is whether or not we take the 34/16 split as given. That might not be worth even mentioning in this version, but if we had more advanced chapters, it should be. Similarly, we don't take about assumptions like SUTVA here, but that would belong elsewhere. Also, we need more explicit RCM discussion. Show a table of potential outcomes. -->
<!-- DK: Reading below, I see that we don't take 34/16 as given! Instead, we resample and individual groups of 50 can have very different splits. Should we discuss in the text? Should we have instructor notes throughout the text which over issues like this? Maybe the first version of the 1006 additional chapters starts with instructor notes in this book. Maybe the instructor notes start with comments like this? Note also, that, if initial split were more lopsided, we might get replicates which did not include data from both groups. How to handle that? -->
<p>How does this sampling variation affect their estimate of 4.4%? In other words, what would be a plausible range of values for this difference that accounts for this sampling variation? We can answer this question with confidence intervals! We will construct a 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using <em>bootstrap resampling with replacement</em>.</p>
<p>We make a couple of important notes. First, for the comparison between the <code>"seed"</code> and <code>"control"</code> groups to make sense, however, both groups need to be <em>independent</em> from each other. Otherwise, they could influence each other’s results. This means that a participant being selected for the <code>"seed"</code> or <code>"control"</code> group has no influence on another participant being assigned to one of the two groups. As an example, if there were a mother and her child as participants in the study, they wouldn’t necessarily be in the same group. They would each be assigned randomly to one of the two groups of the explanatory variable.</p>
<p>Second, the order of the subtraction in the difference doesn’t matter so long as you are consistent and tailor your interpretations accordingly. In other words, using a point estimate of <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> or <span class="math inline">\(\widehat{p}_{control} - \widehat{p}_{seed}\)</span> does not make a material difference, you just need to stay consistent and interpret your results accordingly.</p>
</div>
<div id="ci-build" class="section level3">
<h3><span class="header-section-number">10.5.3</span> Constructing the confidence interval</h3>
<p>Let’s first construct the bootstrap distribution for <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> and then use this to construct 95% confidence intervals for <span class="math inline">\(p_{seed} - p_{control}\)</span>.</p>
<p>Our first step is to perform <em>bootstrap resampling with replacement</em> like we did with the slips of paper in our pennies activity in Section <a href="10-confidence-intervals.html#resampling-tactile">10.1</a>. However, instead of calculating a mean, we are now calculating a difference in means. As we’ll see, the basic process remains the same, which is one of the reasons the bootstrap is such a powerful tool.</p>
<p>We start by using <code>rep_sample_n()</code> to get 1,000 replicates, or, in other words, we bootstrap resample the 50 participants with replacement 1,000 times.</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="10-confidence-intervals.html#cb719-1"></a>mythbusters_yawn <span class="op">%&gt;%</span></span>
<span id="cb719-2"><a href="10-confidence-intervals.html#cb719-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code># A tibble: 50,000 x 4
# Groups:   replicate [1,000]
   replicate  subj group   yawn 
       &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1         1    35 seed    yes  
 2         1    13 control no   
 3         1    17 seed    no   
 4         1    25 control yes  
 5         1     4 seed    yes  
 6         1    38 seed    no   
 7         1    41 seed    no   
 8         1    41 seed    no   
 9         1    44 seed    no   
10         1    18 seed    no   
# … with 49,990 more rows</code></pre>
<p>Observe that the resulting data frame has 50,000 rows. This is because we performed resampling of 50 participants with replacement 1,000 times and 50,000 = 1,000 <span class="math inline">\(\cdot\)</span> 50. The variable <code>replicate</code> indicates which resample each row belongs to. So it has the value <code>1</code> 50 times, the value <code>2</code> 50 times, all the way through to the value <code>1000</code> 50 times.</p>
<p>After we generate many replicates of bootstrap resampling with replacement, we next want to summarize the bootstrap resamples of size 50 with a single summary statistic, the difference in proportions. All this requires is taking the proportion of “yes” outcomes for both groups (control and seed) and then subtracting those proportions from one another. To do this, we will <code>group_by()</code> both <code>replicate</code> and <code>group</code>:</p>
<!-- DK: I think that we need more discussion of group_by() in all these examples, highlighting how we decide what goes in there. In fact, we need more of an attempt to find out what students find confusing and to help fix it in the book. -->
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="10-confidence-intervals.html#cb721-1"></a>mythbusters_yawn <span class="op">%&gt;%</span></span>
<span id="cb721-2"><a href="10-confidence-intervals.html#cb721-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb721-3"><a href="10-confidence-intervals.html#cb721-3"></a><span class="st">  </span><span class="kw">group_by</span>(replicate, group) <span class="op">%&gt;%</span></span>
<span id="cb721-4"><a href="10-confidence-intervals.html#cb721-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop_yawn =</span> <span class="kw">mean</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>))</span></code></pre></div>
<pre><code># A tibble: 2,000 x 3
# Groups:   replicate [1,000]
   replicate group   prop_yawn
       &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;
 1         1 control 0.0588235
 2         1 seed    0.181818 
 3         2 control 0.3      
 4         2 seed    0.275    
 5         3 control 0.315789 
 6         3 seed    0.258065 
 7         4 control 0.388889 
 8         4 seed    0.3125   
 9         5 control 0.384615 
10         5 seed    0.162162 
# … with 1,990 more rows</code></pre>
<p>We now have two rows per <code>replicate</code>, the first being <code>control</code> and the second being <code>seed</code>. That means we can construct our difference in proportions by <code>group</code>ing <code>by</code> <code>replicate</code> and subtracting one <code>prop_yawn</code> from the other:</p>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="10-confidence-intervals.html#cb723-1"></a>mythbusters_yawn <span class="op">%&gt;%</span></span>
<span id="cb723-2"><a href="10-confidence-intervals.html#cb723-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb723-3"><a href="10-confidence-intervals.html#cb723-3"></a><span class="st">  </span><span class="kw">group_by</span>(replicate, group) <span class="op">%&gt;%</span></span>
<span id="cb723-4"><a href="10-confidence-intervals.html#cb723-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop_yawn =</span> <span class="kw">mean</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb723-5"><a href="10-confidence-intervals.html#cb723-5"></a><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> group, <span class="dt">values_from =</span> prop_yawn) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb723-6"><a href="10-confidence-intervals.html#cb723-6"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb723-7"><a href="10-confidence-intervals.html#cb723-7"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">diff_prop_yawn =</span> seed <span class="op">-</span><span class="st"> </span>control)</span></code></pre></div>
<pre><code># A tibble: 1,000 x 2
   replicate diff_prop_yawn
       &lt;int&gt;          &lt;dbl&gt;
 1         1     0.0347222 
 2         2    -0.0145530 
 3         3     0.149123  
 4         4    -0.0492360 
 5         5     0.132428  
 6         6     0.0921053 
 7         7    -0.00793651
 8         8    -0.0190476 
 9         9     0.0152801 
10        10     0.0745921 
# … with 990 more rows</code></pre>
<p>There are two important coding tricks. First, we use <code>group_by()</code> twice, once to perform a calculation for each <code>replicate</code> and <code>group</code>, and once to perform a calculation just for each <code>replicate</code>. Failure to keep track of exactly what is currently being <code>group_by()</code>’d is a common cause of bugs. Second, <code>pivot_wider()</code> helps us to bring values into the same row, this making later calculations (like subtraction) easier.</p>
<p>Observe that the resulting data frame has 1,000 rows and 2 columns corresponding to the 1,000 <code>replicate</code> ID’s and the 1,000 differences in proportions, one for each bootstrap resample, in <code>diff_prop_yawn</code>.</p>
<p>Next, let’s compute the 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using the percentile method, in other words, by identifying the 2.5th and 97.5th percentiles which include the middle 95% of values. Recall that this method does not require the bootstrap distribution to be normally shaped.</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="10-confidence-intervals.html#cb725-1"></a>mythbusters_yawn <span class="op">%&gt;%</span></span>
<span id="cb725-2"><a href="10-confidence-intervals.html#cb725-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb725-3"><a href="10-confidence-intervals.html#cb725-3"></a><span class="st">  </span><span class="kw">group_by</span>(replicate, group) <span class="op">%&gt;%</span></span>
<span id="cb725-4"><a href="10-confidence-intervals.html#cb725-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop_yawn =</span> <span class="kw">mean</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb725-5"><a href="10-confidence-intervals.html#cb725-5"></a><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> group, <span class="dt">values_from =</span> prop_yawn) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb725-6"><a href="10-confidence-intervals.html#cb725-6"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb725-7"><a href="10-confidence-intervals.html#cb725-7"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">diff_prop_yawn =</span> seed <span class="op">-</span><span class="st"> </span>control) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb725-8"><a href="10-confidence-intervals.html#cb725-8"></a><span class="st">  </span><span class="kw">pull</span>(diff_prop_yawn) <span class="op">%&gt;%</span></span>
<span id="cb725-9"><a href="10-confidence-intervals.html#cb725-9"></a><span class="st">  </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>  2.5%  97.5% 
-0.202  0.314 </code></pre>
<p>There is one value of particular interest that this 95% confidence interval contains: zero. If <span class="math inline">\(p_{seed} - p_{control}\)</span> were equal to 0, then there would be no difference in proportion yawning between the two groups. This would suggest that there is no associated effect of being exposed to a yawning recruiter on whether you yawn yourself.</p>
<p>In our case, since the 95% confidence interval includes 0, we cannot conclusively say if either proportion is larger. Of our 1,000 bootstrap resamples with replacement, sometimes <span class="math inline">\(\widehat{p}_{seed}\)</span> was higher and thus those exposed to yawning yawned themselves more often. At other times, the reverse happened.</p>
<p>Say, on the other hand, the 95% confidence interval was entirely above zero. This would suggest that <span class="math inline">\(p_{seed} - p_{control} &gt; 0\)</span>, or, in other words <span class="math inline">\(p_{seed} &gt; p_{control}\)</span>, and thus we’d have evidence suggesting those exposed to yawning do yawn more often.</p>
<p>Furthermore, if the 50 participants were randomly allocated to the <code>"seed"</code> and <code>"control"</code> groups, then this would be suggestive that being exposed to yawning doesn’t not <em>cause</em> yawning. In other words, yawning is not contagious. However, no information on how participants were assigned to be exposed to yawning or not could be found, so we cannot make such a causal statement.</p>
<!-- DK: The above discussion is not bad. But we should, each chapter, show an example of an NHST and then explain clearly why it is bad and stupid. -->
</div>
<div id="using-lm-and-tidy-as-a-shortcut-1" class="section level3">
<h3><span class="header-section-number">10.5.4</span> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</h3>
<p>We have learned that you can use <code>lm()</code> as a shortcut to construct confidence interval for a mean. You can also use it to construct a confidence interval for a difference in means. Recall that you’ll need the <strong>broom</strong> package loaded in order to use the <code>tidy()</code> function. Let’s start by considering the <code>lm()</code> syntax:</p>
<!-- DK: The prior syntax, creating a logical value on the fly as our lefthand side variable, was problematic. This is not much better. Perhaps we should just have the yawn variable be 0/1 from the start? Also, is there a more natural way to use lm() within a pipe. -->
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="10-confidence-intervals.html#cb727-1"></a>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb727-2"><a href="10-confidence-intervals.html#cb727-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">yawn_numeric =</span> <span class="kw">ifelse</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb727-3"><a href="10-confidence-intervals.html#cb727-3"></a><span class="st">  </span><span class="kw">lm</span>(<span class="dt">formula =</span> yawn_numeric <span class="op">~</span><span class="st"> </span>group)</span></code></pre></div>
<pre><code>
Call:
lm(formula = yawn_numeric ~ group, data = .)

Coefficients:
(Intercept)    groupseed  
     0.2500       0.0441  </code></pre>
<p>There are three differences from what we’ve seen before. First, since <code>yawn</code> is a character variable, we had to create a new variable, <code>yawn_numeric</code>, which would take on the value 1 if there was a yawn and zero otherwise. Working with <code>lm()</code> requires numbers. Second, since we are interested in the difference in means by group, we used <code>group</code> instead of <code>1</code> on the right side of the <code>~</code>. Third, because we are using <code>lm()</code> within a pipe, we need to explicitly declare our formula. If, instead, we had used the <code>data</code> argument, this would not have been necessary.</p>
<p>Next, let’s <code>tidy()</code> this object:</p>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="10-confidence-intervals.html#cb729-1"></a>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb729-2"><a href="10-confidence-intervals.html#cb729-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">yawn_numeric =</span> <span class="kw">ifelse</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb729-3"><a href="10-confidence-intervals.html#cb729-3"></a><span class="st">  </span><span class="kw">lm</span>(<span class="dt">formula =</span> yawn_numeric <span class="op">~</span><span class="st"> </span>group) <span class="op">%&gt;%</span></span>
<span id="cb729-4"><a href="10-confidence-intervals.html#cb729-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb729-5"><a href="10-confidence-intervals.html#cb729-5"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<pre><code># A tibble: 2 x 4
  term         estimate   conf.low conf.high
  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
1 (Intercept) 0.25       0.0198949  0.480105
2 groupseed   0.0441176 -0.234926   0.323161</code></pre>
<p>We are also <code>select</code>ing the <code>term</code> column, since now <code>lm()</code> gives estimates for two terms: <code>(Intercept)</code> and <code>groupseed</code>. We will hold off on interpreting <code>lm()</code> model objects until the next chapter, but, for now, all you need to know is that <code>groupseed</code> is the <code>term</code> that represents our difference in means. Let’s <code>filter()</code> to that <code>term</code>:</p>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="10-confidence-intervals.html#cb731-1"></a>mythbusters_yawn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb731-2"><a href="10-confidence-intervals.html#cb731-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">yawn_numeric =</span> <span class="kw">ifelse</span>(yawn <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb731-3"><a href="10-confidence-intervals.html#cb731-3"></a><span class="st">  </span><span class="kw">lm</span>(<span class="dt">formula =</span> yawn_numeric <span class="op">~</span><span class="st"> </span>group) <span class="op">%&gt;%</span></span>
<span id="cb731-4"><a href="10-confidence-intervals.html#cb731-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb731-5"><a href="10-confidence-intervals.html#cb731-5"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb731-6"><a href="10-confidence-intervals.html#cb731-6"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;groupseed&quot;</span>)</span></code></pre></div>
<pre><code># A tibble: 1 x 4
  term       estimate  conf.low conf.high
  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 groupseed 0.0441176 -0.234926  0.323161</code></pre>
<p>Again, the confidence interval using <code>lm()</code> and <code>tidy()</code> is similar to what we saw using the bootstrap method, but <code>lm()</code> often runs much faster.</p>
</div>
</div>
<div id="ci-conclusion" class="section level2">
<h2><span class="header-section-number">10.6</span> Conclusion</h2>
<!-- DK: This section --- and, indeed, the conclusion to each chapter --- are very important. This is a real chance to hit all the highlights. Everything here should be considered fair game for the exam. Indeed, everything here should be covered in the exam. This one is not bad. But it could be cleaned up a bit, with much nicer plots. Maybe a table which directly compares bootstrap and sampling distributions. Need to remind people about why we bootstrap. (We do it because it proves that the lm() simple approaches make sense. It is the justification for our shortcuts. And, indeed, whenever those shortcuts don't work --- which is often! --- a bootstrap still will work.) -->
<div id="bootstrap-vs-sampling" class="section level3">
<h3><span class="header-section-number">10.6.1</span> Comparing bootstrap and sampling distributions</h3>
<p>Let’s talk more about the relationship between <em>sampling distributions</em> and <em>bootstrap distributions</em>.</p>
<p>Recall back in Subsection <a href="9-sampling.html#shovel-1000-times">9.2.3</a>, we took 1,000 virtual samples from the <code>urn</code> using a virtual shovel, computed 1,000 values of the sample proportion red <span class="math inline">\(\widehat{p}\)</span>, then visualized their distribution in a histogram. Recall that this distribution is called the <em>sampling distribution of</em> <span class="math inline">\(\widehat{p}\)</span> . Furthermore, the standard deviation of the sampling distribution has a special name: the <em>standard error</em>.</p>
<p>We also mentioned that this sampling activity does not reflect how sampling is done in real life. Rather, it was an <em>idealized version</em> of sampling so that we could study the effects of sampling variation on estimates, like the proportion of the shovel’s balls that are red. In real life, however, one would take a single sample that’s as large as possible, much like in the Obama poll we saw in Section <a href="9-sampling.html#sampling-case-study">9.4</a>. But how can we get a sense of the effect of sampling variation on estimates if we only have one sample and thus only one estimate? Don’t we need many samples and hence many estimates?</p>
<!-- DK: There is nothing wrong with this text, but I don't like it. We need a more coherent story connecting sampling to the bootstrap. Randomization is magic and these are two forms of randomization. Maybe each chapter after this should mention three types of randomization. These two and then assignment to treatment. Indeed, all of statistics is dealing with situations in which we could not use all three randomization techniques, or approximations thereto. -->
<p>The workaround to having a <em>single</em> sample was to perform <em>bootstrap resampling with replacement</em> from the single sample. We did this in the resampling activity in Section <a href="10-confidence-intervals.html#resampling-tactile">10.1</a> where we focused on the mean year of minting of pennies. We used pieces of paper representing the original sample of 50 pennies from the bank and resampled them with replacement from a hat. We had 35 of our friends perform this activity and visualized the resulting 35 sample means <span class="math inline">\(\overline{x}\)</span> in a histogram in Figure <a href="10-confidence-intervals.html#fig:tactile-resampling-6">10.11</a>.</p>
<p>This distribution was called the <em>bootstrap distribution</em> of <span class="math inline">\(\overline{x}\)</span>. We stated at the time that the bootstrap distribution is an <em>approximation</em> to the sampling distribution of <span class="math inline">\(\overline{x}\)</span> in the sense that both distributions will have a similar shape and similar spread.  Thus the <em>standard error</em> of the bootstrap distribution can be used as an approximation to the <em>standard error</em> of the sampling distribution.
<!-- DK: The below seems useful, but does it belong in a Conclusion? Probably not. Perhaps each chapter ends with some stats nonsense (like CLT in sampling chapter) before we get to the real conclusion. --></p>
<p>Let’s show you that this is the case by now comparing these two types of distributions. Specifically, we’ll compare</p>
<ol style="list-style-type: decimal">
<li>the sampling distribution of <span class="math inline">\(\widehat{p}\)</span> based on 1,000 virtual samples from the <code>urn</code> from Subsection <a href="9-sampling.html#shovel-1000-times">9.2.3</a> to</li>
<li>the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> based on 1,000 virtual resamples with replacement from Ilyas and Yohan’s single sample <code>urn_sample_1</code>.</li>
</ol>
<div id="sampling-distribution" class="section level4 unnumbered">
<h4>Sampling distribution</h4>
<p>Here is the code you saw in Subsection <a href="9-sampling.html#shovel-1000-times">9.2.3</a> to construct the sampling distribution of <span class="math inline">\(\widehat{p}\)</span> shown again in Figure <a href="10-confidence-intervals.html#fig:sampling-distribution-part-deux">10.18</a>, with some changes to incorporate the statistical terminology relating to sampling from Subsection <a href="9-sampling.html#terminology-and-notation">9.3.1</a>.</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="10-confidence-intervals.html#cb733-1"></a><span class="co"># Take 1000 virtual samples of size 50 from the urn.</span></span>
<span id="cb733-2"><a href="10-confidence-intervals.html#cb733-2"></a></span>
<span id="cb733-3"><a href="10-confidence-intervals.html#cb733-3"></a><span class="co"># DK: Need to do a better job of ensuring that this is the same as the one</span></span>
<span id="cb733-4"><a href="10-confidence-intervals.html#cb733-4"></a><span class="co"># &quot;seen&quot; before.</span></span>
<span id="cb733-5"><a href="10-confidence-intervals.html#cb733-5"></a></span>
<span id="cb733-6"><a href="10-confidence-intervals.html#cb733-6"></a><span class="kw">set.seed</span>(<span class="dv">76</span>)</span>
<span id="cb733-7"><a href="10-confidence-intervals.html#cb733-7"></a></span>
<span id="cb733-8"><a href="10-confidence-intervals.html#cb733-8"></a>virtual_samples &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb733-9"><a href="10-confidence-intervals.html#cb733-9"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb733-10"><a href="10-confidence-intervals.html#cb733-10"></a></span>
<span id="cb733-11"><a href="10-confidence-intervals.html#cb733-11"></a><span class="co"># Compute the sampling distribution of 1000 values of p-hat</span></span>
<span id="cb733-12"><a href="10-confidence-intervals.html#cb733-12"></a></span>
<span id="cb733-13"><a href="10-confidence-intervals.html#cb733-13"></a>sampling_distribution &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb733-14"><a href="10-confidence-intervals.html#cb733-14"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb733-15"><a href="10-confidence-intervals.html#cb733-15"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb733-16"><a href="10-confidence-intervals.html#cb733-16"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span>
<span id="cb733-17"><a href="10-confidence-intervals.html#cb733-17"></a></span>
<span id="cb733-18"><a href="10-confidence-intervals.html#cb733-18"></a><span class="co"># Visualize sampling distribution of p-hat</span></span>
<span id="cb733-19"><a href="10-confidence-intervals.html#cb733-19"></a></span>
<span id="cb733-20"><a href="10-confidence-intervals.html#cb733-20"></a>sampling_distribution <span class="op">%&gt;%</span></span>
<span id="cb733-21"><a href="10-confidence-intervals.html#cb733-21"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb733-22"><a href="10-confidence-intervals.html#cb733-22"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb733-23"><a href="10-confidence-intervals.html#cb733-23"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, </span>
<span id="cb733-24"><a href="10-confidence-intervals.html#cb733-24"></a>       <span class="dt">title =</span> <span class="st">&quot;Sampling distribution&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:sampling-distribution-part-deux"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/sampling-distribution-part-deux-1.png" alt="Previously seen sampling distribution of sample proportion red for $n = 1000$." width="\textwidth" />
<p class="caption">
FIGURE 10.18: Previously seen sampling distribution of sample proportion red for <span class="math inline">\(n = 1000\)</span>.
</p>
</div>
<p>An important thing to keep in mind is the default value for <code>replace</code> is <code>FALSE</code> when using <code>rep_sample_n()</code>. This is because when sampling 50 balls with a shovel, we are extracting 50 balls one-by-one <em>without</em> replacing them. This is in contrast to bootstrap resampling <em>with</em> replacement, where we resample a ball and put it back, and repeat this process 50 times.</p>
<p>Let’s quantify the variability in this sampling distribution by calculating the standard deviation of the <code>prop_red</code> variable representing 1,000 values of the sample proportion <span class="math inline">\(\widehat{p}\)</span>. Remember that the standard deviation of the sampling distribution is the <em>standard error</em>, frequently denoted as <code>se</code>.</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="10-confidence-intervals.html#cb734-1"></a>sampling_distribution <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0667201</code></pre>
</div>
<div id="bootstrap-distribution" class="section level4 unnumbered">
<h4>Bootstrap distribution</h4>
<p>Here is the code to construct the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> based on Ilyas and Yohan’s original sample of 50 balls saved in <code>urn_sample_1</code>.</p>
<!-- DK: This is still ugly. Might also be nice to show this exercise with sampling of 100, 1000, 10000 and then 100000, in order to show how things smooth out and look more normal as n increases. -->
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="10-confidence-intervals.html#cb736-1"></a><span class="kw">set.seed</span>(<span class="dv">14</span>)</span>
<span id="cb736-2"><a href="10-confidence-intervals.html#cb736-2"></a>bootstrap_distribution &lt;-<span class="st"> </span>urn_sample_<span class="dv">1</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb736-3"><a href="10-confidence-intervals.html#cb736-3"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb736-4"><a href="10-confidence-intervals.html#cb736-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">prop_red =</span> <span class="kw">mean</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="10-confidence-intervals.html#cb737-1"></a>bootstrap_distribution <span class="op">%&gt;%</span></span>
<span id="cb737-2"><a href="10-confidence-intervals.html#cb737-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb737-3"><a href="10-confidence-intervals.html#cb737-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb737-4"><a href="10-confidence-intervals.html#cb737-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>,</span>
<span id="cb737-5"><a href="10-confidence-intervals.html#cb737-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Bootstrap distribution&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bootstrap-distribution-part-deux"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/bootstrap-distribution-part-deux-1.png" alt="Bootstrap distribution of proportion red for $n = 1000$." width="\textwidth" />
<p class="caption">
FIGURE 10.19: Bootstrap distribution of proportion red for <span class="math inline">\(n = 1000\)</span>.
</p>
</div>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="10-confidence-intervals.html#cb738-1"></a>bootstrap_distribution <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">se =</span> <span class="kw">sd</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
         se
      &lt;dbl&gt;
1 0.0674993</code></pre>
</div>
<div id="comparison" class="section level4 unnumbered">
<h4>Comparison</h4>
<p>Now that we have computed both the sampling distribution and the bootstrap distributions, let’s compare them side-by-side in Figure <a href="10-confidence-intervals.html#fig:side-by-side">10.20</a>. We’ll make both histograms have matching scales on the x- and y-axes to make them more comparable. Furthermore, we’ll add:</p>
<ol style="list-style-type: decimal">
<li>To the sampling distribution on the top: a solid line denoting the proportion of the urn’s balls that are red <span class="math inline">\(p\)</span> = 0.375.</li>
<li>To the bootstrap distribution on the bottom: a dashed line at the sample proportion <span class="math inline">\(\widehat{p}\)</span> = 21/50 = 0.42 = 42% that Ilyas and Yohan observed.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:side-by-side"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/side-by-side-1.png" alt="Comparing the sampling and bootstrap distributions of $\widehat{p}$." width="\textwidth" />
<p class="caption">
FIGURE 10.20: Comparing the sampling and bootstrap distributions of <span class="math inline">\(\widehat{p}\)</span>.
</p>
</div>
<p>There is a lot going on in Figure <a href="10-confidence-intervals.html#fig:side-by-side">10.20</a>, so let’s break down all the comparisons slowly. First, observe how the sampling distribution on top is centered at <span class="math inline">\(p\)</span> = 0.375. This is because the sampling is done at random and in an unbiased fashion. So the estimates <span class="math inline">\(\widehat{p}\)</span> are centered at the true value of <span class="math inline">\(p\)</span>.</p>
<p>However, this is not the case with the following bootstrap distribution. The bootstrap distribution is centered at 0.42, which is the proportion red of Ilyas and Yohan’s 50 sampled balls. This is because we are resampling from the same sample over and over again. Since the bootstrap distribution is centered at the original sample’s proportion, it doesn’t necessarily provide a better estimate of <span class="math inline">\(p\)</span> = 0.375. This leads us to our first lesson about bootstrapping:</p>
<blockquote>
<p>The bootstrap distribution will likely not have the same center as the sampling distribution. In other words, bootstrapping cannot improve the quality of an estimate.</p>
</blockquote>
<p>Second, let’s now compare the spread of the two distributions: they are somewhat similar. In the previous code, we computed the standard deviations of both distributions as well. Recall that such standard deviations have a special name: <em>standard errors</em>. Let’s compare them in Table <a href="10-confidence-intervals.html#tab:comparing-se">10.5</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:comparing-se">TABLE 10.5: </span>Comparing standard errors
</caption>
<thead>
<tr>
<th style="text-align:left;">
Distribution type
</th>
<th style="text-align:right;">
Standard error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Sampling distribution
</td>
<td style="text-align:right;">
0.067
</td>
</tr>
<tr>
<td style="text-align:left;">
Bootstrap distribution
</td>
<td style="text-align:right;">
0.067
</td>
</tr>
</tbody>
</table>
<p>Notice that the bootstrap distribution’s standard error is a rather good <em>approximation</em> to the sampling distribution’s standard error. This leads us to our second lesson about bootstrapping:</p>
<blockquote>
<p>Even if the bootstrap distribution might not have the same center as the sampling distribution, it will likely have very similar shape and spread. In other words, bootstrapping will give you a good estimate of the <em>standard error</em>.</p>
</blockquote>
<p>Thus, using the fact that the bootstrap distribution and sampling distributions have similar spreads, we can build confidence intervals using bootstrapping as we’ve done all throughout this chapter!</p>
<!--
Other stuff which might be added

The kind of computer-based statistical inference we've seen so far has a particular name in the field of statistics: *simulation-based inference*. This is because we are performing statistical inference using computer simulations.\index{simulation-based inference} In our opinion, two large benefits of simulation-based methods over theory-based methods are that (1) they are easier for people new to statistical inference to understand and (2) they also work in situations where theory-based methods and mathematical formulas don't exist.


#### Confidence intervals based on 100 virtual samples {-}

Let's say, however, we repeated this 100 times, not tactilely, but virtually. Let's do this only 100 times instead of 1000 like we did before so that the results can fit on the screen. Again, the steps for compute a 95% confidence interval for $p$ are:

1. Collect a sample of size $n = 50$ as we did in Chapter \@ref(sampling)
1. Compute $\widehat{p}$: the sample proportion red of these $n$ = 50 balls
1. Compute the standard error $\text{SE} = \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute the margin of error $\text{MoE} = 1.96 \cdot \text{SE} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute both end points of the confidence interval:
    + `lower_ci`: $\widehat{p} - \text{MoE} = \widehat{p} - 1.96 \cdot \text{SE} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
    + `upper_ci`: $\widehat{p} + \text{MoE} = \widehat{p} + 1.96 \cdot \text{SE} = \widehat{p} +1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$

Run the following three steps, being sure to `View()` the resulting data frame after each step so you can convince yourself of what's going on:


```r
# First: Take 100 virtual samples of n=50 balls
virtual_samples <- urn %>% 
  rep_sample_n(size = 50, reps = 100)

# Second: For each virtual sample compute the proportion red
virtual_prop_red <- virtual_samples %>% 
  group_by(replicate) %>% 
  summarize(red = sum(color == "red")) %>% 
  mutate(prop_red = red / 50)

# Third: Compute the 95% confidence interval as before
virtual_prop_red <- virtual_prop_red %>% 
  rename(p_hat = prop_red) %>% 
  mutate(
    n = 50,
    SE = sqrt(p_hat*(1-p_hat)/n),
    MoE = 1.96 * SE,
    lower_ci = p_hat - MoE,
    upper_ci = p_hat + MoE
  )
```

Here are the results:



We see that of our 100 confidence intervals based on samples of size $n$ = 50, `sum(virtual_prop_red[["captured"]])` of them captured the true $p = 900/2400$, whereas `100 - sum(virtual_prop_red[["captured"]])` of them missed. As we create more and more confidence intervals based on more and more samples, about 95% of these intervals will capture. In other words, our procedure is "95% reliable." 
-->

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="9-sampling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="11-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
