[
["index.html", "Preceptor’s Primer for Bayesian Data Science Cover", " Preceptor’s Primer for Bayesian Data Science David Kane January 27, 2020 Cover "],
["forward.html", "Forward", " Forward The world confronts us. Make decisions we must. "],
["warning.html", "Warning", " Warning This book is not the book you are looking for. First, the book is for students in Gov 1005: Data, a course offered in the Government Department at Harvard University. Everything about the book is designed to make the experience of those students better. Some of the material here may be useful to students outside of this class, but I don’t really care if it is. Second, the book changes all the time. It is as up-to-date as possible. Third, I am highly opinionated about what matters and what does not. It is unlikely that you share my views. "],
["license.html", "License", " License This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["acknowledgements.html", "Acknowledgements", " Acknowledgements This work builds on the contributions of many people in the R and Open Source communities. In particular, I would like to acknowledge extensive material taken from Introduction to Data Science: Data Analysis and Prediction Algorithms with R by Rafael A. Irizarry, ModernDive: Statistical Inference via Data Science by Chester Ismay and Albert Y. Kim, STAT 545: Data wrangling, exploration, and analysis with R by Jenny Bryan, Intro Stat with Randomization and Simulation by David M. Diez, Christopher D. Barr and Mine Cetinkaya-Rundel, Think Bayes: Bayesian Statistics Made Simple by Allen B. Downey, R for Data Science by Garrett Grolemund and Hadley Wickham, and Broadening Your Statistical Horizons: Generalized Linear Models and Multilevel Models by Julie Legler and Paul Roback. Alboukadel Kassambara and others kindly allowed for the re-use and/or modification of their work. Thanks to contributions from Harvard students and colleagues: Nicholas Dow, Albert Rivero, Celine Vendler and Sophia Zheng. "],
["dedication.html", "Dedication", " Dedication And what is romantic, Kay — And what is love? Need we ask anyone to tell us these things? "],
["1-functions.html", "Chapter 1 Functions 1.1 Part 1 1.2 Part 2 1.3 Part 3 1.4 List columns and map_* functions 1.5 Resources", " Chapter 1 Functions My goal here is to reveal the process a long-time useR employs for writing functions. I also want to illustrate why the process is the way it is. Merely looking at the finished product, e.g. source code for R packages, can be extremely deceiving. Reality is generally much uglier … but more interesting! Why are we covering this now, smack in the middle of data aggregation? Powerful machines like dplyr, purrr, and the built-in “apply” family of functions, are ready and waiting to apply your purpose-built functions to various bits of your data. If you can express your analytical wishes in a function, these tools will give you great power. 1.1 Part 1 As usual, load gapminder. library(gapminder) str(gapminder) Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1704 obs. of 6 variables: $ country : Factor w/ 142 levels &quot;Afghanistan&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... $ continent: Factor w/ 5 levels &quot;Africa&quot;,&quot;Americas&quot;,..: 3 3 3 3 3 3 3 3 3 3 ... $ year : int 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ... $ lifeExp : num 28.8 30.3 32 34 36.1 ... $ pop : int 8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ... $ gdpPercap: num 779 821 853 836 740 ... Say you’ve got a numeric vector, and you want to compute the difference between its max and min. lifeExp or pop or gdpPercap are great examples of a typical input. You can imagine wanting to get this statistic after we slice up the Gapminder data by year, country, continent, or combinations thereof. 1.1.1 Get something that works First, develop some working code for interactive use, using a representative input. I’ll use Gapminder’s life expectancy variable. R functions that will be useful: min(), max(), range(). (Read their documentation: [here][rdocs-extremes] and [here][rdocs-range]) ## get to know the functions mentioned above min(gapminder$lifeExp) [1] 23.599 max(gapminder$lifeExp) [1] 82.603 range(gapminder$lifeExp) [1] 23.599 82.603 ## some natural solutions max(gapminder$lifeExp) - min(gapminder$lifeExp) [1] 59.004 with(gapminder, max(lifeExp) - min(lifeExp)) [1] 59.004 range(gapminder$lifeExp)[2] - range(gapminder$lifeExp)[1] [1] 59.004 with(gapminder, range(lifeExp)[2] - range(lifeExp)[1]) [1] 59.004 diff(range(gapminder$lifeExp)) [1] 59.004 Internalize this “answer” because our informal testing relies on you noticing departures from this. 1.1.2 Skateboard &gt;&gt; perfectly formed rear-view mirror This image [widely attributed to the Spotify development team][min-viable-product] conveys an important point. FIGURE 1.1: From Your ultimate guide to Minimum Viable Product (+great examples) Build that skateboard before you build the car or some fancy car part. A limited-but-functioning thing is very useful. It also keeps the spirits high. This is related to the valuable [Telescope Rule][telescope-rule]: It is faster to make a four-inch mirror then a six-inch mirror than to make a six-inch mirror. 1.1.3 Turn the working interactive code into a function Add NO new functionality! Just write your very first R function. max_minus_min &lt;- function(x) max(x) - min(x) max_minus_min(gapminder$lifeExp) [1] 59.004 Check that you’re getting the same answer as you did with your interactive code. Test it eyeball-o-metrically at this point. 1.1.4 Test your function 1.1.4.1 Test on new inputs Pick some new artificial inputs where you know (at least approximately) what your function should return. max_minus_min(1:10) [1] 9 max_minus_min(runif(1000)) [1] 0.998543 I know that 10 minus 1 is 9. I know that random uniform [0, 1] variates will be between 0 and 1. Therefore max - min should be less than 1. If I take LOTS of them, max - min should be pretty close to 1. It is intentional that I tested on integer input as well as floating point. Likewise, I like to use valid-but-random data for this sort of check. 1.1.4.2 Test on real data but different real data Back to the real world now. Two other quantitative variables are lying around: gdpPercap and pop. Let’s have a go. max_minus_min(gapminder$gdpPercap) [1] 113282 max_minus_min(gapminder$pop) [1] 1318623085 Either check these results “by hand” or apply the “does that even make sense?” test. 1.1.4.3 Test on weird stuff Now we try to break our function. Don’t get truly diabolical (yet). Just make the kind of mistakes you can imagine making at 2am when, 3 years from now, you rediscover this useful function you wrote. Give your function inputs it’s not expecting. max_minus_min(gapminder) ## hey sometimes things &quot;just work&quot; on data.frames! Error in FUN(X[[i]], ...): only defined on a data frame with all numeric variables max_minus_min(gapminder$country) ## factors are kind of like integer vectors, no? Error in Summary.factor(structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, : &#39;max&#39; not meaningful for factors max_minus_min(&quot;eggplants are purple&quot;) ## i have no excuse for this one Error in max(x) - min(x): non-numeric argument to binary operator How happy are you with those error messages? You must imagine that some entire script has failed and that you were hoping to just source() it without re-reading it. If a colleague or future you encountered these errors, do you run screaming from the room? How hard is it to pinpoint the usage problem? 1.1.4.4 I will scare you now Here are some great examples STAT545 students devised during class where the function should break but it does not. max_minus_min(gapminder[c(&#39;lifeExp&#39;, &#39;gdpPercap&#39;, &#39;pop&#39;)]) [1] 1318683072 max_minus_min(c(TRUE, TRUE, FALSE, TRUE, TRUE)) [1] 1 In both cases, R’s eagerness to make sense of our requests is unfortunately successful. In the first case, a data.frame containing just the quantitative variables is eventually coerced into numeric vector. We can compute max minus min, even though it makes absolutely no sense at all. In the second case, a logical vector is converted to zeroes and ones, which might merit an error or at least a warning. 1.1.5 Check the validity of arguments For functions that will be used again – which is not all of them! – it is good to check the validity of arguments. This implements a rule from [the Unix philosophy][unix-philosophy]: Rule of Repair: When you must fail, fail noisily and as soon as possible. 1.1.5.1 stop if not stopifnot() is the entry level solution. I use it here to make sure the input x is a numeric vector. mmm &lt;- function(x) { stopifnot(is.numeric(x)) max(x) - min(x) } mmm(gapminder) Error in mmm(gapminder): is.numeric(x) is not TRUE mmm(gapminder$country) Error in mmm(gapminder$country): is.numeric(x) is not TRUE mmm(&quot;eggplants are purple&quot;) Error in mmm(&quot;eggplants are purple&quot;): is.numeric(x) is not TRUE mmm(gapminder[c(&#39;lifeExp&#39;, &#39;gdpPercap&#39;, &#39;pop&#39;)]) Error in mmm(gapminder[c(&quot;lifeExp&quot;, &quot;gdpPercap&quot;, &quot;pop&quot;)]): is.numeric(x) is not TRUE mmm(c(TRUE, TRUE, FALSE, TRUE, TRUE)) Error in mmm(c(TRUE, TRUE, FALSE, TRUE, TRUE)): is.numeric(x) is not TRUE And we see that it catches all of the self-inflicted damage we would like to avoid. 1.1.5.2 if then stop stopifnot() doesn’t provide a very good error message. The next approach is very widely used. Put your validity check inside an if() statement and call stop() yourself, with a custom error message, in the body. mmm2 &lt;- function(x) { if(!is.numeric(x)) { stop(&#39;I am so sorry, but this function only works for numeric input!\\n&#39;, &#39;You have provided an object of class: &#39;, class(x)[1]) } max(x) - min(x) } mmm2(gapminder) Error in mmm2(gapminder): I am so sorry, but this function only works for numeric input! You have provided an object of class: tbl_df In addition to a gratuitous apology, the error raised also contains two more pieces of helpful info: Which function threw the error. Hints on how to fix things: expected class of input vs actual class. If it is easy to do so, I highly recommend this template: “you gave me THIS, but I need THAT”. The tidyverse style guide has a very useful chapter on how to construct error messages. 1.1.5.3 Sidebar: non-programming uses for assertions Another good use of this pattern is to leave checks behind in data analytical scripts. Consider our repetitive use of Gapminder in this course. Every time we load it, we inspect it, hoping to see the usual stuff. If we were loading from file (vs. a stable data package), we might want to formalize our expectations about the number of rows and columns, the names and flavors of the variables, etc. This would alert us if the data suddenly changed, which can be a useful wake-up call in scripts that you re-run ad nauseam on auto-pilot or non-interactively. 1.1.6 Wrap-up and what’s next? Here’s the function we’ve written so far: mmm2 function(x) { if(!is.numeric(x)) { stop(&#39;I am so sorry, but this function only works for numeric input!\\n&#39;, &#39;You have provided an object of class: &#39;, class(x)[1]) } max(x) - min(x) } What we’ve accomplished: We’ve written our first function. We are checking the validity of its input, argument x. We’ve done a good amount of informal testing. 1.2 Part 2 1.2.1 Resources Packages for runtime assertions (the last 3 seem to be under more active development than assertthat): assertthat on [CRAN][assertthat-cran] and [GitHub][assertthat-github] - the Hadleyverse option ensurer on [CRAN][ensurer-cran] and [GitHub][ensurer-github] - general purpose, pipe-friendly assertr on [CRAN][assertr-cran] and [GitHub][assertr-github] - explicitly data pipeline oriented assertive on [CRAN][assertive-cran] and [Bitbucket][assertive-bitbucket] - rich set of built-in functions Hadley Wickham’s book [Advanced R][adv-r] (???): Section on [defensive programming][adv-r-defensive-programming] 1.2.2 Where were we? Where are we going? In part 1, we wrote our first R function to compute the difference between the max and min of a numeric vector. We checked the validity of the function’s only argument and, informally, we verified that it worked pretty well. In this part, we generalize this function, learn more technical details about R functions, and set default values for some arguments. ##E Load the Gapminder data As usual, load gapminder. library(gapminder) 1.2.3 Restore our max minus min function Let’s keep our previous function around as a baseline. mmm &lt;- function(x) { stopifnot(is.numeric(x)) max(x) - min(x) } 1.2.4 Generalize our function to other quantiles The max and the min are special cases of a quantile. Here are other special cases you may have heard of: median = 0.5 quantile 1st quartile = 0.25 quantile 3rd quartile = 0.75 quantile If you’re familiar with [box plots][wiki-boxplot], the rectangle typically runs from the 1st quartile to the 3rd quartile, with a line at the median. If \\(q\\) is the \\(p\\)-th quantile of a set of \\(n\\) observations, what does that mean? Approximately \\(pn\\) of the observations are less than \\(q\\) and \\((1 - p)n\\) are greater than \\(q\\). Yeah, you need to worry about rounding to an integer and less/greater than or equal to, but these details aren’t critical here. Let’s generalize our function to take the difference between any two quantiles. We can still consider the max and min, if we like, but we’re not limited to that. 1.2.5 Get something that works, again The eventual inputs to our new function will be the data x and two probabilities. First, play around with the quantile() function. Convince yourself you know how to use it, for example, by cross-checking your results with other built-in functions. quantile(gapminder$lifeExp) 0% 25% 50% 75% 100% 23.5990 48.1980 60.7125 70.8455 82.6030 quantile(gapminder$lifeExp, probs = 0.5) 50% 60.7125 median(gapminder$lifeExp) [1] 60.7125 quantile(gapminder$lifeExp, probs = c(0.25, 0.75)) 25% 75% 48.1980 70.8455 boxplot(gapminder$lifeExp, plot = FALSE)$stats [,1] [1,] 23.5990 [2,] 48.1850 [3,] 60.7125 [4,] 70.8460 [5,] 82.6030 Now write a code snippet that takes the difference between two quantiles. the_probs &lt;- c(0.25, 0.75) the_quantiles &lt;- quantile(gapminder$lifeExp, probs = the_probs) max(the_quantiles) - min(the_quantiles) [1] 22.6475 1.2.6 Turn the working interactive code into a function, again I’ll use qdiff as the base of our function’s name. I copy the overall structure from our previous “max minus min” work but replace the guts of the function with the more general code we just developed. qdiff1 &lt;- function(x, probs) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x = x, probs = probs) max(the_quantiles) - min(the_quantiles) } qdiff1(gapminder$lifeExp, probs = c(0.25, 0.75)) [1] 22.6475 IQR(gapminder$lifeExp) # hey, we&#39;ve reinvented IQR [1] 22.6475 qdiff1(gapminder$lifeExp, probs = c(0, 1)) [1] 59.004 mmm(gapminder$lifeExp) [1] 59.004 Again we do some informal tests against familiar results and external implementations. 1.2.7 Argument names: freedom and conventions I want you to understand the importance of argument names. I can name my arguments almost anything I like. Proof: qdiff2 &lt;- function(zeus, hera) { stopifnot(is.numeric(zeus)) the_quantiles &lt;- quantile(x = zeus, probs = hera) max(the_quantiles) - min(the_quantiles) } qdiff2(zeus = gapminder$lifeExp, hera = 0:1) [1] 59.004 While I can name my arguments after Greek gods, it’s usually a bad idea. Take all opportunities to make things more self-explanatory via meaningful names. If you are going to pass the arguments of your function as arguments of a built-in function, consider copying the argument names. Unless you have a good reason to do your own thing (some argument names are bad!), be consistent with the existing function. Again, the reason is to reduce your cognitive load. This is what I’ve been doing all along and now you know why: qdiff1 function(x, probs) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x = x, probs = probs) max(the_quantiles) - min(the_quantiles) } &lt;bytecode: 0x7fa74c0d2ba0&gt; We took this detour so you could see there is no structural relationship between my arguments (x and probs) and those of quantile() (also x and probs). The similarity or equivalence of the names accomplishes nothing as far as R is concerned; it is solely for the benefit of humans reading, writing, and using the code. Which is very important! 1.2.8 What a function returns By this point, I expect someone will have asked about the last line in my function’s body. Look above for a reminder of the function’s definition. By default, a function returns the result of the last line of the body. I am just letting that happen with the line max(the_quantiles) - min(the_quantiles). However, there is an explicit function for this: return(). I could just as easily make this the last line of my function’s body: return(max(the_quantiles) - min(the_quantiles)) You absolutely must use return() if you want to return early based on some condition, i.e. before execution gets to the last line of the body. Otherwise, you can decide your own conventions about when you use return() and when you don’t. 1.2.9 Default values: freedom to NOT specify the arguments What happens if we call our function but neglect to specify the probabilities? qdiff1(gapminder$lifeExp) Error in quantile(x = x, probs = probs): argument &quot;probs&quot; is missing, with no default Oops! At the moment, this causes a fatal error. It can be nice to provide some reasonable default values for certain arguments. In our case, it would be crazy to specify a default value for the primary input x, but very kind to specify a default for probs. We started by focusing on the max and the min, so I think those make reasonable defaults. Here’s how to specify that in a function definition. qdiff3 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs) max(the_quantiles) - min(the_quantiles) } Again we check how the function works, in old examples and new, specifying the probs argument and not. qdiff3(gapminder$lifeExp) [1] 59.004 mmm(gapminder$lifeExp) [1] 59.004 qdiff3(gapminder$lifeExp, c(0.1, 0.9)) [1] 33.5862 1.2.10 Check the validity of arguments, again Exercise: upgrade our argument validity checks in light of the new argument probs. ## problems identified during class ## we&#39;re not checking that probs is numeric ## we&#39;re not checking that probs is length 2 ## we&#39;re not checking that probs are in [0,1] 1.2.11 Wrap-up and what’s next? Here’s the function we’ve written so far: qdiff3 function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs) max(the_quantiles) - min(the_quantiles) } &lt;bytecode: 0x7fa749e6e0d8&gt; What we’ve accomplished: We’ve generalized our first function to take a difference between arbitrary quantiles. We’ve specified default values for the probabilities that set the quantiles. 1.3 Part 3 1.3.1 Resources Hadley Wickham’s book [Advanced R][adv-r] (???): Section on [function arguments][adv-r-fxn-args] Section on [return values][adv-r-return-values] 1.3.2 Where were we? Where are we going? In part 2 we generalized our first R function so it could take the difference between any two quantiles of a numeric vector. We also set default values for the underlying probabilities, so that, by default, we compute the max minus the min. In this part, we tackle NAs, the special argument ... and formal testing. 1.3.3 Load the Gapminder data As usual, load gapminder. library(gapminder) 1.3.4 Restore our max minus min function Let’s keep our previous function around as a baseline. qdiff3 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs) max(the_quantiles) - min(the_quantiles) } 1.3.5 Be proactive about NAs I am being gentle by letting you practice with the Gapminder data. In real life, missing data will make your life a living hell. If you are lucky, it will be properly indicated by the special value NA, but don’t hold your breath. Many built-in R functions have an na.rm = argument through which you can specify how you want to handle NAs. Typically the default value is na.rm = FALSE and typical default behavior is to either let NAs propagate or to raise an error. Let’s see how quantile() handles NAs: z &lt;- gapminder$lifeExp z[3] &lt;- NA quantile(gapminder$lifeExp) 0% 25% 50% 75% 100% 23.5990 48.1980 60.7125 70.8455 82.6030 quantile(z) Error in quantile.default(z): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE quantile(z, na.rm = TRUE) 0% 25% 50% 75% 100% 23.599 48.228 60.765 70.846 82.603 So quantile() simply will not operate in the presence of NAs unless na.rm = TRUE. How shall we modify our function? If we wanted to hardwire na.rm = TRUE, we could. Focus on our call to quantile() inside our function definition. qdiff4 &lt;- function(x, probs = c(0, 1)) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs, na.rm = TRUE) max(the_quantiles) - min(the_quantiles) } qdiff4(gapminder$lifeExp) [1] 59.004 qdiff4(z) [1] 59.004 This works but it is dangerous to invert the default behavior of a well-known built-in function and to provide the user with no way to override this. We could add an na.rm = argument to our own function. We might even enforce our preferred default – but at least we’re giving the user a way to control the behavior around NAs. qdiff5 &lt;- function(x, probs = c(0, 1), na.rm = TRUE) { stopifnot(is.numeric(x)) the_quantiles &lt;- quantile(x, probs, na.rm = na.rm) max(the_quantiles) - min(the_quantiles) } qdiff5(gapminder$lifeExp) [1] 59.004 qdiff5(z) [1] 59.004 qdiff5(z, na.rm = FALSE) Error in quantile.default(x, probs, na.rm = na.rm): missing values and NaN&#39;s not allowed if &#39;na.rm&#39; is FALSE 1.3.6 The useful but mysterious ... argument You probably could have lived a long and happy life without knowing there are at least 9 different algorithms for computing quantiles. [Go read about the type argument][rdocs-quantile] of quantile(). TLDR: If a quantile is not unambiguously equal to an observed data point, you must somehow average two data points. You can weight this average different ways, depending on the rest of the data, and type = controls this. Let’s say we want to give the user of our function the ability to specify how the quantiles are computed, but we want to accomplish with as little fuss as possible. In fact, we don’t even want to clutter our function’s interface with this! This calls for the very special ... argument. In English, this set of three dots is frequently called an “ellipsis”. qdiff6 &lt;- function(x, probs = c(0, 1), na.rm = TRUE, ...) { the_quantiles &lt;- quantile(x = x, probs = probs, na.rm = na.rm, ...) max(the_quantiles) - min(the_quantiles) } The practical significance of the type = argument is virtually nonexistent, so we can’t demo with the Gapminder data. Thanks to [@wrathematics][twitter-wrathematics], here’s a small example where we can (barely) detect a difference due to type. set.seed(1234) z &lt;- rnorm(10) quantile(z, type = 1) 0% 25% 50% 75% 100% -2.3456977 -0.8900378 -0.5644520 0.4291247 1.0844412 quantile(z, type = 4) 0% 25% 50% 75% 100% -2.345698 -1.048552 -0.564452 0.353277 1.084441 all.equal(quantile(z, type = 1), quantile(z, type = 4)) [1] &quot;Mean relative difference: 0.1776594&quot; Now we can call our function, requesting that quantiles be computed in different ways. qdiff6(z, probs = c(0.25, 0.75), type = 1) [1] 1.319163 qdiff6(z, probs = c(0.25, 0.75), type = 4) [1] 1.401829 While the difference may be subtle, it’s there. Marvel at the fact that we have passed type = 1 through to quantile() even though it was not a formal argument of our own function. The special argument ... is very useful when you want the ability to pass arbitrary arguments down to another function, but without constantly expanding the formal arguments to your function. This leaves you with a less cluttered function definition and gives you future flexibility to specify these arguments only when you need to. You will also encounter the ... argument in many built-in functions – read up on [c()][rdocs-c] or [list()][rdocs-list] – and now you have a better sense of what it means. It is not a breezy “and so on and so forth.” There are also downsides to ..., so use it with intention. In a package, you will have to work harder to create truly informative documentation for your user. Also, the quiet, absorbent properties of ... mean it can sometimes silently swallow other named arguments, when the user has a typo in the name. Depending on whether or how this fails, it can be a little tricky to find out what went wrong. The ellipsis package provides tools that help package developers use ... more safely. The in-progress tidyverse principles guide provides further guidance on the design of functions that take ... in Data, dots, details. 1.3.7 Use testthat for formal unit tests Until now, we’ve relied on informal tests of our evolving function. If you are going to use a function a lot, especially if it is part of a package, it is wise to use formal unit tests. The [testthat][testthat-web] package ([CRAN][testthat-cran]; [GitHub][testthat-github]) provides excellent facilities for this, with a distinct emphasis on automated unit testing of entire packages. However, we can take it out for a test drive even with our one measly function. We will construct a test with test_that() and, within it, we put one or more expectations that check actual against expected results. You simply harden your informal, interactive tests into formal unit tests. Here are some examples of tests and indicative expectations. library(testthat) test_that(&#39;invalid args are detected&#39;, { expect_error(qdiff6(&quot;eggplants are purple&quot;)) expect_error(qdiff6(iris)) }) test_that(&#39;NA handling works&#39;, { expect_error(qdiff6(c(1:5, NA), na.rm = FALSE)) expect_equal(qdiff6(c(1:5, NA)), 4) }) No news is good news! Let’s see what test failure would look like. Let’s revert to a version of our function that does no NA handling, then test for proper NA handling. We can watch it fail. qdiff_no_NA &lt;- function(x, probs = c(0, 1)) { the_quantiles &lt;- quantile(x = x, probs = probs) max(the_quantiles) - min(the_quantiles) } test_that(&#39;NA handling works&#39;, { expect_that(qdiff_no_NA(c(1:5, NA)), equals(4)) }) Similar to the advice to use assertions in data analytical scripts, I recommend you use unit tests to monitor the behavior of functions you (or others) will use often. If your tests cover the function’s important behavior, then you can edit the internals freely. You’ll rest easy in the knowledge that, if you broke anything important, the tests will fail and alert you to the problem. A function that is important enough for unit tests probably also belongs in a package, where there are obvious mechanisms for running the tests as part of overall package checks. 1.4 List columns and map_* functions We are now going to learn about list columns and map_* functions, powerful tools that we will be using throughout the book.1 1.4.1 What are list columns? A list column is a column of your data which is a list rather than an atomic vector. Atomic vectors are familiar to us; each element of the vector has one value, and thus if an atomic vector is a column in your dataset, each observation gets a single value. Lists, however, can contain vectors as elements. The best way to understand this is by creating a list column yourself and inspecting the results. str() is a helpful function for looking at the contents of a tibble with list columns: library(tidyverse) tibble(new_col = list(1:2, 3:5)) %&gt;% str() Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 2 obs. of 1 variable: $ new_col:List of 2 ..$ : int 1 2 ..$ : int 3 4 5 Here we see that our tibble has one column (new_col) and one observation, which is a list with two elements. The first element in the list is a vector of the integers 1 and 2 and the second element is a vector of the integers 3, 4, and 5. The tibble only has one row because there is only one value for new_col. Note that this is a case where it is crucial to use tibble(), not data.frame()! If we had used data.frame() in the last example, it wouldn’t have worked: data.frame(new_col = list(1:2, 3:5)) %&gt;% str() Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, : arguments imply differing number of rows: 2, 3 Lists are very flexible. For example, each element of a list can have its own data type: tibble(new_col = list(1:2, c(&quot;Alice&quot;, &quot;Bob&quot;))) %&gt;% str() Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 2 obs. of 1 variable: $ new_col:List of 2 ..$ : int 1 2 ..$ : chr &quot;Alice&quot; &quot;Bob&quot; Now the first element consists of the integers 1 and 2 while the second is a character vector containing “Alice” and “Bob”. We wrapped “Alice” and “Bob” in c() in order to make it clear that this is a vector. If we hadn’t done that, we would have three elements in our list: the vector with 1 and 2, “Alice”, and “Bob”: tibble(new_col = list(1:2, &quot;Alice&quot;, &quot;Bob&quot;)) %&gt;% str() Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 3 obs. of 1 variable: $ new_col:List of 3 ..$ : int 1 2 ..$ : chr &quot;Alice&quot; ..$ : chr &quot;Bob&quot; 1.4.2 Creating list columns with mutate() Any function that returns multiple values can be used to create a list column. For example, consider the following tibble: tibble(col_1 = c(&quot;Alice and Bob&quot;, &quot;Carol and Dan&quot;)) col_1 is a character vector with two observations: “Alice and Bob” and “Carol and Dan”. The tibble has two rows. It may be more useful to present these as vectors of names, without the annoying “and” in between. That’s exactly what we can do with str_split(): tibble(col_1 = c(&quot;Alice and Bob&quot;, &quot;Carol and Dan&quot;)) %&gt;% mutate(col_2 = str_split(col_1, &quot; and &quot;)) %&gt;% str() Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 2 obs. of 2 variables: $ col_1: chr &quot;Alice and Bob&quot; &quot;Carol and Dan&quot; $ col_2:List of 2 ..$ : chr &quot;Alice&quot; &quot;Bob&quot; ..$ : chr &quot;Carol&quot; &quot;Dan&quot; After using str_split() within mutate(), we have created a new column, and that new column is a list column. This is often how we will go about creating list columns. Let’s practice with the gapminder dataset. How could we add a column to the dataset that included the quantiles of the lifeExp variable? gapminder %&gt;% group_by(year) %&gt;% mutate(lifeExpQuantile = list(quantile(lifeExp))) # A tibble: 1,704 x 7 # Groups: year [12] country continent year lifeExp pop gdpPercap lifeExpQuantile &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;list&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. &lt;dbl [5]&gt; 2 Afghanistan Asia 1957 30.3 9240934 821. &lt;dbl [5]&gt; 3 Afghanistan Asia 1962 32.0 10267083 853. &lt;dbl [5]&gt; 4 Afghanistan Asia 1967 34.0 11537966 836. &lt;dbl [5]&gt; 5 Afghanistan Asia 1972 36.1 13079460 740. &lt;dbl [5]&gt; 6 Afghanistan Asia 1977 38.4 14880372 786. &lt;dbl [5]&gt; 7 Afghanistan Asia 1982 39.9 12881816 978. &lt;dbl [5]&gt; 8 Afghanistan Asia 1987 40.8 13867957 852. &lt;dbl [5]&gt; 9 Afghanistan Asia 1992 41.7 16317921 649. &lt;dbl [5]&gt; 10 Afghanistan Asia 1997 41.8 22227415 635. &lt;dbl [5]&gt; # … with 1,694 more rows Note: str_split() was a particularly easy function for using with mutate() and summarize() because it returns a list. You can check this by running typeof() on the output of str_split(): e.g., str_split(&quot;Alice and Bob&quot;, &quot; and &quot;) %&gt;% typeof(). If a function returns multiple values as a vector, like quantile() does, you can’t use it directly in mutate() or summarize(), but you can wrap list() around it in order to get the same behavior. Or let’s say that we wanted 1) to subset the dataset to the most recent year, 2) group by continent, and 3) get a summary() of the gdpPercap variable by continent: gapminder %&gt;% filter(year == max(year)) %&gt;% group_by(continent) %&gt;% summarize(gdpSummary = list(summary(gdpPercap))) # A tibble: 5 x 2 continent gdpSummary &lt;fct&gt; &lt;list&gt; 1 Africa &lt;smmryDfl&gt; 2 Americas &lt;smmryDfl&gt; 3 Asia &lt;smmryDfl&gt; 4 Europe &lt;smmryDfl&gt; 5 Oceania &lt;smmryDfl&gt; 1.4.3 map_* functions What can we do with a list column? That is tricky! Lists are hard to work with. But the most natural thing to do with a list is to feed it to a map_* function. What are these functions? Let’s say that you want to add 1 to row of a variable in a tibble, storing the result in x. You could accomplish this with mutate: tibble(start = c(3, 2, 6)) %&gt;% mutate(new = start + 1) # A tibble: 3 x 2 start new &lt;dbl&gt; &lt;dbl&gt; 1 3 4 2 2 3 3 6 7 We could instead create a function that adds 1 to a number. Then, we can use map_dbl() to apply this to our input variable. map_dbl() — pronounced “map double” — comes from the purrr package, which you will have loaded if you have loaded tidyverse. map_dbl() is just one member of a family of map_* functions which applies the same function to every row in a tibble. The “dbl” suffix indicates that the function returns a “double,” meaning a numeric value. increment &lt;- function(x) return(x + 1) tibble(start = c(3, 2, 6)) %&gt;% mutate(new = map_dbl(start, increment)) # A tibble: 3 x 2 start new &lt;dbl&gt; &lt;dbl&gt; 1 3 4 2 2 3 3 6 7 What happened is that map_dbl() took the function increment() and applied it to each element of start. The syntax can get even simpler than this if we use anonymous functions. The following code snippet shows two ways to use anonymous functions. The first one, using base R, creates a function within map_dbl() using function(). The second, using the purrr package (from where we get map_dbl()), starts with the ~ operator and then uses . to represent the current element: tibble(start = c(3, 2, 6)) %&gt;% mutate(new = map_dbl(start, function(x) x + 1)) # A tibble: 3 x 2 start new &lt;dbl&gt; &lt;dbl&gt; 1 3 4 2 2 3 3 6 7 tibble(start = c(3, 2, 6)) %&gt;% mutate(new = map_dbl(start, ~ . + 1)) # A tibble: 3 x 2 start new &lt;dbl&gt; &lt;dbl&gt; 1 3 4 2 2 3 3 6 7 The latter shorthand is very convenient once you get used to it. Note that we are piping start directly into map_dbl(), which we can do because like other tidyverse functions, map_dbl() takes its data as the first argument. We called these map_* functions (plural) before. If you know the expected output of your function, you can specify that kind of vector: map(): list map_lgl(): logical map_int(): integer map_dbl(): double (numeric) map_chr(): character map_df(): data frame So, since our above code produces numeric output, we use map_dbl() instead of map():2 1.4.4 Using map_* functions to create list columns Now that we understand map_* functions, we can also use them to create list columns. We’ll use the weather dataset in the nycflights13 package. First, let’s wrangle the data so each observation is a day rather than an hour. We’ll create a list column temps_F that consists of all the temperatures recorded that day at a particular origin. weather %&gt;% group_by(origin, year, month, day) %&gt;% summarize(temps_F = list(c(temp))) Now that we have a list column, we can use it as the input to map(), outputting another list column. Let’s say we wanted a new list column, temps_C, which records the temperature in Celsius: weather %&gt;% group_by(origin, year, month, day) %&gt;% summarize(temps_F = list(c(temp))) %&gt;% mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9)) Note that we took the list column temps_F and, by applying an anonymous function to it with map(), created another list column temps_C. This is a very common process. It is similar to taking a tibble and piping it into a dplyr function (such as mutate()) which gives you a new tibble that you can work with. You can also use map_* functions to take a list column as an input and return an atomic vector – a column with a single value per observation – as an output. For instance, let’s say we now wanted the mean of the recorded temperatures per day in Celsius: weather %&gt;% group_by(origin, year, month, day) %&gt;% summarize(temps_F = list(c(temp))) %&gt;% mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9), mean_C = map_dbl(temps_C, mean, na.rm = TRUE)) Here, we also see that the map_* functions have the ... argument, which allows na.rm = TRUE to be passed along to mean(). What if we wanted to know the proportion of temperatures recorded per day per airport that were below freezing? weather %&gt;% group_by(origin, year, month, day) %&gt;% summarize(temps_F = list(c(temp))) %&gt;% mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9), is_freezing = map(temps_C, ~ . &lt; 0), prop_freezing = map_dbl(is_freezing, mean, na.rm = TRUE)) See how we chained the map_* functions: temps_F was used as the input to map() to create temps_C temps_C was used as the input to map() to create is_freezing is_freezing was used as the input to map_dbl() to create prop_freezing Or let’s say we wanted to know the top 5 temperatures recorded at each airport each day: weather %&gt;% group_by(origin, year, month, day) %&gt;% summarize(temps_F = list(c(temp))) %&gt;% mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9), sorted_C = map(temps_C, ~ sort(., decreasing = TRUE)), top5_C = map(temps_C, ~ .[1:5])) 1.4.5 Practice with map_* functions and list columns Let’s practice map_* functions and list columns! We will give step by step instructions; we recommend that you follow along so that you understand how each part works. We’ll also be introducing some important conditional functions (ifelse(), any(), all(), and case_when()). Write a function called roll_dice(), which will throw a pair of dice as many times as the user specifies. For clarity, we will begin by creating an intermediate function add_dice() which throws n dice and adds the results: add_dice &lt;- function(n = 1) { stopifnot(is.numeric(n)) sum(sample(1:6, n, replace = TRUE)) } Next, we will create roll_dice(), which calls add_dice(n = 2) as many times as the user specifies: roll_dice &lt;- function(n = 1) { stopifnot(is.numeric(n)) map_int(rep(2, n), add_dice) } rep() is a useful input to map_* when you want to call a function with the same input multiple times. rep(2, n) creates a vector of length n where every element is 2. We use that as the input to map_int() because we want the input to add_dice() to be 2 every time (we are always throwing a pair of dice) and we want to perform the operation n times, chosen by the user. Create a tibble named x with one variable: throws. throws is a list column, each element of which is three throws of the dice pair, i.e., the result of calling roll_dice(n = 3). Thus, our tibble will have ten rows and two columns. x &lt;- tibble(throws = map(rep(3, 10), roll_dice)) Add a variable to x called first_seven which is TRUE if the first roll in throws is a 7. library(magrittr) # The magrittr package allows us to use %&lt;&gt;%, the compound assignment pipe # operator, which (as its name suggests) both assigns and pipes x %&lt;&gt;% mutate(first_seven = map_lgl(throws, ~ ifelse(.[[1]] == 7, TRUE, FALSE))) We see here that [[1]] is how we extract the first element of a list, just like [1] extracts the first element of an atomic vector. ifelse() takes as its first argument a condition; if it is TRUE it returns the second argument (here TRUE) and if not the third (here FALSE). Add a variable to x called a_winner which is TRUE if at least one of the three throws is a 7 or an 11 and is FALSE otherwise. x %&lt;&gt;% mutate(a_winner = map_lgl(throws, ~ ifelse(any(c(7, 11) %in% .), TRUE, FALSE))) Here we use any(): any() checks if any element in its input is TRUE. So, let’s say a particular throw was 4, 6, and 7: c(7, 11) %in% c(4, 6, 7) returns the vector TRUE FALSE (since 7 is in the vector but 11 isn’t); then, any(c(7, 11) %in% c(4, 6, 7)) returns TRUE because one of the conditions is TRUE. Run str() on x and show the results. str(x) Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 10 obs. of 3 variables: $ throws :List of 10 ..$ : int 12 10 9 ..$ : int 7 9 7 ..$ : int 8 7 7 ..$ : int 4 10 5 ..$ : int 7 7 9 ..$ : int 7 6 3 ..$ : int 4 8 4 ..$ : int 9 3 11 ..$ : int 4 5 7 ..$ : int 10 5 8 $ first_seven: logi FALSE TRUE FALSE FALSE TRUE TRUE ... $ a_winner : logi FALSE TRUE TRUE FALSE TRUE TRUE ... Calculate how “surpised” you should be if someone rolls three winners in a row. First, create a tibble with 10,000 rows. Include a throws list column with three throws of our dice, just as in part a). Second, create a column called perfection which is TRUE if all three of the throws are either 7 or 11. surprised &lt;- tibble(throws = map(rep(3, 10000), roll_dice)) %&gt;% mutate(perfection = map_lgl(throws, ~ ifelse(all(. %in% c(7, 11)), TRUE, FALSE))) surprised %&gt;% pull(perfection) %&gt;% mean() [1] 0.0112 Here, we use all(), which has the same structure as any(), but checks whether all the elements in the input are TRUE. Approximately 1.1% of three rolls of a pair of fair dice are all equal to either 7 or 11. Your friend proposes the following bet. You will roll a pair of fair dice 10 times. Side A gets the second highest of the first 4 rolls. Side B gets 1 plus the the median of the remaining 6 rolls. Which side is more likely to win? What’s the chance of a tie? bet &lt;- tibble(throws = map(rep(10, 10000), roll_dice)) %&gt;% mutate(A = map_dbl(throws, ~ sort(.[1:4])[3]), B = map_dbl(throws, ~ 1 + median(.[5:10])), winner = case_when(A &gt; B ~ &quot;A&quot;, B &gt; A ~ &quot;B&quot;, TRUE ~ &quot;tie&quot;)) case_when(sum(bet$winner == &quot;A&quot;) &gt; sum(bet$winner == &quot;B&quot;) ~ &quot;A&quot;, sum(bet$winner == &quot;B&quot;) &gt; sum(bet$winner == &quot;A&quot;) ~ &quot;B&quot;, TRUE ~ &quot;Same # Victories&quot;) [1] &quot;B&quot; sum(bet$winner == &quot;tie&quot;)/length(bet$winner) [1] 0.11 You can think of case_when() as a generalized ifelse(). The syntax is a little more complicated. Each expression is followed by ~ and what should be returned if that expression is TRUE. The final expression, TRUE, is always true, and thus is the residual category if none of the above expression are TRUE. Thus, the second case_when() in our above code will print “A” if A is the winner in more replications than B, “B” if B is the winner more than A, and “Same # Victories” otherwise. Side B is more likely to win. The chance of a tie is approximately 11%. 1.5 Resources Hadley Wickham’s book [Advanced R][adv-r] (???) Section on [function arguments][adv-r-fxn-args] Unit testing with testthat On [CRAN][testthat-cran], development on [GitHub][testthat-github], main [webpage][testthat-web] Wickham and Bryan’s [R Packages][r-pkgs2] book (???) Testing chapter Wickham’s [testthat: Get Started with Testing][testthat-article] article in The R Journal (???). Maybe this is completely superseded by the newer chapter above? Be aware that parts could be out of date, but I recall it was a helpful read. If I were going to give a lecture on these topics, it would look like this one.↩ You may wonder why we aren’t using map_int() instead. We could, but we’d have to write the code a little differently. R uses L to mark integers, so we’d have to say map_int(~ . + 1L).↩ "]
]
