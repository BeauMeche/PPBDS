<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Multiple Regression | Preceptor’s Primer for Bayesian Data Science</title>
  <meta name="description" content="Chapter 12 Multiple Regression | Preceptor’s Primer for Bayesian Data Science" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Multiple Regression | Preceptor’s Primer for Bayesian Data Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="davidkane9/PPBDS" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Multiple Regression | Preceptor’s Primer for Bayesian Data Science" />
  
  
  

<meta name="author" content="David Kane" />


<meta name="date" content="2020-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="11-regression.html"/>
<link rel="next" href="13-classification.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="forward.html"><a href="forward.html"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="warning.html"><a href="warning.html"><i class="fa fa-check"></i>Warning</a></li>
<li class="chapter" data-level="" data-path="license.html"><a href="license.html"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="1" data-path="1-getting-started.html"><a href="1-getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting Started</a><ul>
<li class="chapter" data-level="1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>1.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#installing"><i class="fa fa-check"></i><b>1.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#code"><i class="fa fa-check"></i><b>1.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-getting-started.html"><a href="1-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>1.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-getting-started.html"><a href="1-getting-started.html#messages"><i class="fa fa-check"></i><b>1.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-getting-started.html"><a href="1-getting-started.html#tips-code"><i class="fa fa-check"></i><b>1.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-getting-started.html"><a href="1-getting-started.html#packages"><i class="fa fa-check"></i><b>1.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-getting-started.html"><a href="1-getting-started.html#package-installation"><i class="fa fa-check"></i><b>1.3.1</b> Package installation</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-getting-started.html"><a href="1-getting-started.html#package-loading"><i class="fa fa-check"></i><b>1.3.2</b> Package loading</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-getting-started.html"><a href="1-getting-started.html#package-use"><i class="fa fa-check"></i><b>1.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>1.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>1.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-getting-started.html"><a href="1-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>1.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-getting-started.html"><a href="1-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>1.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-getting-started.html"><a href="1-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>1.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="1-getting-started.html"><a href="1-getting-started.html#help-files"><i class="fa fa-check"></i><b>1.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-getting-started.html"><a href="1-getting-started.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a><ul>
<li class="chapter" data-level="1.5.1" data-path="1-getting-started.html"><a href="1-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>1.5.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-viz.html"><a href="2-viz.html"><i class="fa fa-check"></i><b>2</b> Visualization</a><ul>
<li class="chapter" data-level="" data-path="2-viz.html"><a href="2-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="2.1" data-path="2-viz.html"><a href="2-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>2.1</b> The grammar of graphics</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-viz.html"><a href="2-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>2.1.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-viz.html"><a href="2-viz.html#gapminder"><i class="fa fa-check"></i><b>2.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-viz.html"><a href="2-viz.html#other-components"><i class="fa fa-check"></i><b>2.1.3</b> Other components</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-viz.html"><a href="2-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>2.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-viz.html"><a href="2-viz.html#scatterplots"><i class="fa fa-check"></i><b>2.2</b> Scatterplots</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-viz.html"><a href="2-viz.html#geompoint"><i class="fa fa-check"></i><b>2.2.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="2.2.2" data-path="2-viz.html"><a href="2-viz.html#overplotting"><i class="fa fa-check"></i><b>2.2.2</b> Overplotting</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-viz.html"><a href="2-viz.html#summary"><i class="fa fa-check"></i><b>2.2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-viz.html"><a href="2-viz.html#linegraphs"><i class="fa fa-check"></i><b>2.3</b> Linegraphs</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-viz.html"><a href="2-viz.html#geomline"><i class="fa fa-check"></i><b>2.3.1</b> Linegraphs via <code>geom_line</code></a></li>
<li class="chapter" data-level="2.3.2" data-path="2-viz.html"><a href="2-viz.html#summary-1"><i class="fa fa-check"></i><b>2.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-viz.html"><a href="2-viz.html#histograms"><i class="fa fa-check"></i><b>2.4</b> Histograms</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-viz.html"><a href="2-viz.html#geomhistogram"><i class="fa fa-check"></i><b>2.4.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="2.4.2" data-path="2-viz.html"><a href="2-viz.html#adjustbins"><i class="fa fa-check"></i><b>2.4.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-viz.html"><a href="2-viz.html#summary-2"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-viz.html"><a href="2-viz.html#facets"><i class="fa fa-check"></i><b>2.5</b> Facets</a></li>
<li class="chapter" data-level="2.6" data-path="2-viz.html"><a href="2-viz.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a><ul>
<li class="chapter" data-level="2.6.1" data-path="2-viz.html"><a href="2-viz.html#geomboxplot"><i class="fa fa-check"></i><b>2.6.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="2-viz.html"><a href="2-viz.html#summary-3"><i class="fa fa-check"></i><b>2.6.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2-viz.html"><a href="2-viz.html#geombar"><i class="fa fa-check"></i><b>2.7</b> Barplots</a><ul>
<li class="chapter" data-level="2.7.1" data-path="2-viz.html"><a href="2-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>2.7.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="2.7.2" data-path="2-viz.html"><a href="2-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>2.7.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="2.7.3" data-path="2-viz.html"><a href="2-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>2.7.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="2.7.4" data-path="2-viz.html"><a href="2-viz.html#summary-4"><i class="fa fa-check"></i><b>2.7.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="2-viz.html"><a href="2-viz.html#conclusion-1"><i class="fa fa-check"></i><b>2.8</b> Conclusion</a><ul>
<li class="chapter" data-level="2.8.1" data-path="2-viz.html"><a href="2-viz.html#summary-table"><i class="fa fa-check"></i><b>2.8.1</b> Summary table</a></li>
<li class="chapter" data-level="2.8.2" data-path="2-viz.html"><a href="2-viz.html#function-argument-specification"><i class="fa fa-check"></i><b>2.8.2</b> Function argument specification</a></li>
<li class="chapter" data-level="2.8.3" data-path="2-viz.html"><a href="2-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>2.8.3</b> Additional resources</a></li>
<li class="chapter" data-level="2.8.4" data-path="2-viz.html"><a href="2-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>2.8.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-productivity.html"><a href="3-productivity.html"><i class="fa fa-check"></i><b>3</b> Productivity</a><ul>
<li class="chapter" data-level="3.1" data-path="3-productivity.html"><a href="3-productivity.html#set-up"><i class="fa fa-check"></i><b>3.1</b> Set Up</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-mac"><i class="fa fa-check"></i><b>3.1.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>3.1.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>3.1.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-windows"><i class="fa fa-check"></i><b>3.1.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-productivity.html"><a href="3-productivity.html#unix"><i class="fa fa-check"></i><b>3.2</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-productivity.html"><a href="3-productivity.html#naming-convention"><i class="fa fa-check"></i><b>3.2.1</b> Naming convention</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-productivity.html"><a href="3-productivity.html#the-terminal"><i class="fa fa-check"></i><b>3.2.2</b> The terminal</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-productivity.html"><a href="3-productivity.html#filesystem"><i class="fa fa-check"></i><b>3.2.3</b> The filesystem</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-productivity.html"><a href="3-productivity.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>3.2.4</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-productivity.html"><a href="3-productivity.html#the-home-directory"><i class="fa fa-check"></i><b>3.2.5</b> The home directory</a></li>
<li class="chapter" data-level="3.2.6" data-path="3-productivity.html"><a href="3-productivity.html#working-directory"><i class="fa fa-check"></i><b>3.2.6</b> Working directory</a></li>
<li class="chapter" data-level="3.2.7" data-path="3-productivity.html"><a href="3-productivity.html#paths"><i class="fa fa-check"></i><b>3.2.7</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-productivity.html"><a href="3-productivity.html#unix-commands"><i class="fa fa-check"></i><b>3.3</b> Unix commands</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-productivity.html"><a href="3-productivity.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>3.3.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-productivity.html"><a href="3-productivity.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>3.3.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-productivity.html"><a href="3-productivity.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>3.3.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-productivity.html"><a href="3-productivity.html#some-examples"><i class="fa fa-check"></i><b>3.3.4</b> Some examples</a></li>
<li class="chapter" data-level="3.3.5" data-path="3-productivity.html"><a href="3-productivity.html#more-unix-commands"><i class="fa fa-check"></i><b>3.3.5</b> More Unix commands</a></li>
<li class="chapter" data-level="3.3.6" data-path="3-productivity.html"><a href="3-productivity.html#advanced-unix"><i class="fa fa-check"></i><b>3.3.6</b> Advanced Unix</a></li>
<li class="chapter" data-level="3.3.7" data-path="3-productivity.html"><a href="3-productivity.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>3.3.7</b> File manipulation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-productivity.html"><a href="3-productivity.html#git"><i class="fa fa-check"></i><b>3.4</b> Git and GitHub</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-productivity.html"><a href="3-productivity.html#github-accounts"><i class="fa fa-check"></i><b>3.4.1</b> GitHub accounts</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-productivity.html"><a href="3-productivity.html#github-repos"><i class="fa fa-check"></i><b>3.4.2</b> GitHub repositories</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-productivity.html"><a href="3-productivity.html#git-overview"><i class="fa fa-check"></i><b>3.4.3</b> Overview of Git</a></li>
<li class="chapter" data-level="3.4.4" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-git"><i class="fa fa-check"></i><b>3.4.4</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-productivity.html"><a href="3-productivity.html#r"><i class="fa fa-check"></i><b>3.5</b> R</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-projects"><i class="fa fa-check"></i><b>3.5.1</b> RStudio projects</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-productivity.html"><a href="3-productivity.html#r-markdown"><i class="fa fa-check"></i><b>3.5.2</b> R markdown</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-productivity.html"><a href="3-productivity.html#help-for-r"><i class="fa fa-check"></i><b>3.5.3</b> Help for R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#factors"><i class="fa fa-check"></i><b>4.7</b> Factors</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#the-forcats-package"><i class="fa fa-check"></i><b>4.7.1</b> The <strong>forcats</strong> package</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#dropping-unused-levels"><i class="fa fa-check"></i><b>4.7.2</b> Dropping unused levels</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#reorder-factors"><i class="fa fa-check"></i><b>4.7.3</b> Change order of the levels, principled</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#change-order-of-the-levels-because-i-said-so"><i class="fa fa-check"></i><b>4.7.4</b> Change order of the levels, “because I said so”</a></li>
<li class="chapter" data-level="4.7.5" data-path="4-wrangling.html"><a href="4-wrangling.html#recode-the-levels"><i class="fa fa-check"></i><b>4.7.5</b> Recode the levels</a></li>
<li class="chapter" data-level="4.7.6" data-path="4-wrangling.html"><a href="4-wrangling.html#grow-a-factor"><i class="fa fa-check"></i><b>4.7.6</b> Grow a factor</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors"><i class="fa fa-check"></i><b>4.8</b> Character Vectors</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#manipulating-character-vectors"><i class="fa fa-check"></i><b>4.8.1</b> Manipulating character vectors</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-resources"><i class="fa fa-check"></i><b>4.8.2</b> Regular expressions resources</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#character-encoding-resources"><i class="fa fa-check"></i><b>4.8.3</b> Character encoding resources</a></li>
<li class="chapter" data-level="4.8.4" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors-that-live-in-a-data-frame"><i class="fa fa-check"></i><b>4.8.4</b> Character vectors that live in a data frame</a></li>
<li class="chapter" data-level="4.8.5" data-path="4-wrangling.html"><a href="4-wrangling.html#regex-free-string-manipulation-with-stringr-and-tidyr"><i class="fa fa-check"></i><b>4.8.5</b> Regex-free string manipulation with stringr and tidyr</a></li>
<li class="chapter" data-level="4.8.6" data-path="4-wrangling.html"><a href="4-wrangling.html#detect-or-filter-on-a-target-string"><i class="fa fa-check"></i><b>4.8.6</b> Detect or filter on a target string</a></li>
<li class="chapter" data-level="4.8.7" data-path="4-wrangling.html"><a href="4-wrangling.html#string-splitting-by-delimiter"><i class="fa fa-check"></i><b>4.8.7</b> String splitting by delimiter</a></li>
<li class="chapter" data-level="4.8.8" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-extraction-and-replacement-by-position"><i class="fa fa-check"></i><b>4.8.8</b> Substring extraction (and replacement) by position</a></li>
<li class="chapter" data-level="4.8.9" data-path="4-wrangling.html"><a href="4-wrangling.html#collapse-a-vector"><i class="fa fa-check"></i><b>4.8.9</b> Collapse a vector</a></li>
<li class="chapter" data-level="4.8.10" data-path="4-wrangling.html"><a href="4-wrangling.html#catenate-vectors"><i class="fa fa-check"></i><b>4.8.10</b> Create a character vector by catenating multiple vectors</a></li>
<li class="chapter" data-level="4.8.11" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-replacement"><i class="fa fa-check"></i><b>4.8.11</b> Substring replacement</a></li>
<li class="chapter" data-level="4.8.12" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-with-stringr"><i class="fa fa-check"></i><b>4.8.12</b> Regular expressions with stringr</a></li>
<li class="chapter" data-level="4.8.13" data-path="4-wrangling.html"><a href="4-wrangling.html#characters-with-special-meaning"><i class="fa fa-check"></i><b>4.8.13</b> Characters with special meaning</a></li>
<li class="chapter" data-level="4.8.14" data-path="4-wrangling.html"><a href="4-wrangling.html#character-classes"><i class="fa fa-check"></i><b>4.8.14</b> Character classes</a></li>
<li class="chapter" data-level="4.8.15" data-path="4-wrangling.html"><a href="4-wrangling.html#quantifiers"><i class="fa fa-check"></i><b>4.8.15</b> Quantifiers</a></li>
<li class="chapter" data-level="4.8.16" data-path="4-wrangling.html"><a href="4-wrangling.html#escaping"><i class="fa fa-check"></i><b>4.8.16</b> Escaping</a></li>
<li class="chapter" data-level="4.8.17" data-path="4-wrangling.html"><a href="4-wrangling.html#groups-and-backreferences"><i class="fa fa-check"></i><b>4.8.17</b> Groups and backreferences</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#combining-data"><i class="fa fa-check"></i><b>4.9</b> Combining Data</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#bind"><i class="fa fa-check"></i><b>4.9.1</b> Bind</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#joins-in-dplyr"><i class="fa fa-check"></i><b>4.9.2</b> Joins in dplyr</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#joining"><i class="fa fa-check"></i><b>4.9.3</b> Joining</a></li>
<li class="chapter" data-level="4.9.4" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.9.4</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.9.5" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.9.5</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.9.6" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.9.6</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.9.7" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.9.7</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.10</b> Other Verbs</a><ul>
<li class="chapter" data-level="4.10.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.10.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.10.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.10.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.10.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.10.3</b> <code>top_n</code> values of a variable</a></li>
<li class="chapter" data-level="4.10.4" data-path="4-wrangling.html"><a href="4-wrangling.html#slice-and-pull-and"><i class="fa fa-check"></i><b>4.10.4</b> <code>slice</code> and <code>pull</code> and <code>[]</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.11</b> Conclusion</a><ul>
<li class="chapter" data-level="4.11.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.11.1</b> Summary table</a></li>
<li class="chapter" data-level="4.11.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.11.2</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Tidy</a><ul>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#web-scraping"><i class="fa fa-check"></i><b>5.2</b> Web scraping</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#html"><i class="fa fa-check"></i><b>5.2.1</b> HTML</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#the-rvest-package"><i class="fa fa-check"></i><b>5.2.2</b> The rvest package</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#css-selectors"><i class="fa fa-check"></i><b>5.2.3</b> CSS selectors</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-tidy.html"><a href="5-tidy.html#json"><i class="fa fa-check"></i><b>5.2.4</b> JSON</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.3</b> “Tidy” data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-tidy.html"><a href="5-tidy.html#tidy-definition"><i class="fa fa-check"></i><b>5.3.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.3.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.3.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.3.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.3.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.4</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.5" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.5</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.6" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.6</b> Conclusion</a><ul>
<li class="chapter" data-level="5.6.1" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.6.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-functions.html"><a href="6-functions.html"><i class="fa fa-check"></i><b>6</b> Functions</a><ul>
<li class="chapter" data-level="6.1" data-path="6-functions.html"><a href="6-functions.html#part-1"><i class="fa fa-check"></i><b>6.1</b> Part 1</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works"><i class="fa fa-check"></i><b>6.1.1</b> Get something that works</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-functions.html"><a href="6-functions.html#skateboard-perfectly-formed-rear-view-mirror"><i class="fa fa-check"></i><b>6.1.2</b> Skateboard &gt;&gt; perfectly formed rear-view mirror</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function"><i class="fa fa-check"></i><b>6.1.3</b> Turn the working interactive code into a function</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-functions.html"><a href="6-functions.html#test-your-function"><i class="fa fa-check"></i><b>6.1.4</b> Test your function</a></li>
<li class="chapter" data-level="6.1.5" data-path="6-functions.html"><a href="6-functions.html#check-the-validity-of-arguments"><i class="fa fa-check"></i><b>6.1.5</b> Check the validity of arguments</a></li>
<li class="chapter" data-level="6.1.6" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next"><i class="fa fa-check"></i><b>6.1.6</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-functions.html"><a href="6-functions.html#part-2"><i class="fa fa-check"></i><b>6.2</b> Part 2</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-functions.html"><a href="6-functions.html#resources"><i class="fa fa-check"></i><b>6.2.1</b> Resources</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-functions.html"><a href="6-functions.html#where-were-we-where-are-we-going"><i class="fa fa-check"></i><b>6.2.2</b> Where were we? Where are we going?</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function"><i class="fa fa-check"></i><b>6.2.3</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.2.4" data-path="6-functions.html"><a href="6-functions.html#generalize-our-function-to-other-quantiles"><i class="fa fa-check"></i><b>6.2.4</b> Generalize our function to other quantiles</a></li>
<li class="chapter" data-level="6.2.5" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works-again"><i class="fa fa-check"></i><b>6.2.5</b> Get something that works, again</a></li>
<li class="chapter" data-level="6.2.6" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function-again"><i class="fa fa-check"></i><b>6.2.6</b> Turn the working interactive code into a function, again</a></li>
<li class="chapter" data-level="6.2.7" data-path="6-functions.html"><a href="6-functions.html#argument-names-freedom-and-conventions"><i class="fa fa-check"></i><b>6.2.7</b> Argument names: freedom and conventions</a></li>
<li class="chapter" data-level="6.2.8" data-path="6-functions.html"><a href="6-functions.html#what-a-function-returns"><i class="fa fa-check"></i><b>6.2.8</b> What a function returns</a></li>
<li class="chapter" data-level="6.2.9" data-path="6-functions.html"><a href="6-functions.html#default-values-freedom-to-not-specify-the-arguments"><i class="fa fa-check"></i><b>6.2.9</b> Default values: freedom to NOT specify the arguments</a></li>
<li class="chapter" data-level="6.2.10" data-path="6-functions.html"><a href="6-functions.html#check-the-validity-of-arguments-again"><i class="fa fa-check"></i><b>6.2.10</b> Check the validity of arguments, again</a></li>
<li class="chapter" data-level="6.2.11" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next-1"><i class="fa fa-check"></i><b>6.2.11</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-functions.html"><a href="6-functions.html#part-3"><i class="fa fa-check"></i><b>6.3</b> Part 3</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-functions.html"><a href="6-functions.html#resources-1"><i class="fa fa-check"></i><b>6.3.1</b> Resources</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-functions.html"><a href="6-functions.html#where-were-we-where-are-we-going-1"><i class="fa fa-check"></i><b>6.3.2</b> Where were we? Where are we going?</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-functions.html"><a href="6-functions.html#load-the-gapminder-data"><i class="fa fa-check"></i><b>6.3.3</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="6.3.4" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function-1"><i class="fa fa-check"></i><b>6.3.4</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.3.5" data-path="6-functions.html"><a href="6-functions.html#be-proactive-about-nas"><i class="fa fa-check"></i><b>6.3.5</b> Be proactive about <code>NA</code>s</a></li>
<li class="chapter" data-level="6.3.6" data-path="6-functions.html"><a href="6-functions.html#the-useful-but-mysterious-...-argument"><i class="fa fa-check"></i><b>6.3.6</b> The useful but mysterious <code>...</code> argument</a></li>
<li class="chapter" data-level="6.3.7" data-path="6-functions.html"><a href="6-functions.html#use-testthat-for-formal-unit-tests"><i class="fa fa-check"></i><b>6.3.7</b> Use testthat for formal unit tests</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-functions.html"><a href="6-functions.html#list-columns-and-map_-functions"><i class="fa fa-check"></i><b>6.4</b> List columns and <code>map_*</code> functions</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-functions.html"><a href="6-functions.html#what-are-list-columns"><i class="fa fa-check"></i><b>6.4.1</b> What are list columns?</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-functions.html"><a href="6-functions.html#creating-list-columns-with-mutate"><i class="fa fa-check"></i><b>6.4.2</b> Creating list columns with <code>mutate()</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="6-functions.html"><a href="6-functions.html#map_-functions"><i class="fa fa-check"></i><b>6.4.3</b> <code>map_*</code> functions</a></li>
<li class="chapter" data-level="6.4.4" data-path="6-functions.html"><a href="6-functions.html#using-map_-functions-to-create-list-columns"><i class="fa fa-check"></i><b>6.4.4</b> Using <code>map_*</code> functions to create list columns</a></li>
<li class="chapter" data-level="6.4.5" data-path="6-functions.html"><a href="6-functions.html#practice-with-map_-functions-and-list-columns"><i class="fa fa-check"></i><b>6.4.5</b> Practice with <code>map_*</code> functions and list columns</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6-functions.html"><a href="6-functions.html#resources-2"><i class="fa fa-check"></i><b>6.5</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-probability.html"><a href="7-probability.html"><i class="fa fa-check"></i><b>7</b> Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="7-probability.html"><a href="7-probability.html#basicsOfProbability"><i class="fa fa-check"></i><b>7.1</b> Defining probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-probability.html"><a href="7-probability.html#intro-questions"><i class="fa fa-check"></i><b>7.1.1</b> Intro Questions</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-probability.html"><a href="7-probability.html#probability-1"><i class="fa fa-check"></i><b>7.1.2</b> Probability</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-probability.html"><a href="7-probability.html#disjoint-or-mutually-exclusive-outcomes"><i class="fa fa-check"></i><b>7.1.3</b> Disjoint or mutually exclusive outcomes</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-probability.html"><a href="7-probability.html#probabilities-when-events-are-not-disjoint"><i class="fa fa-check"></i><b>7.1.4</b> Probabilities when events are not disjoint</a></li>
<li class="chapter" data-level="7.1.5" data-path="7-probability.html"><a href="7-probability.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.5</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.6" data-path="7-probability.html"><a href="7-probability.html#complement-of-an-event"><i class="fa fa-check"></i><b>7.1.6</b> Complement of an event</a></li>
<li class="chapter" data-level="7.1.7" data-path="7-probability.html"><a href="7-probability.html#probabilityIndependence"><i class="fa fa-check"></i><b>7.1.7</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-probability.html"><a href="7-probability.html#conditionalProbabilitySection"><i class="fa fa-check"></i><b>7.2</b> Conditional probability</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-probability.html"><a href="7-probability.html#marginalAndJointProbabilities"><i class="fa fa-check"></i><b>7.2.1</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-probability.html"><a href="7-probability.html#defining-conditional-probability"><i class="fa fa-check"></i><b>7.2.2</b> Defining conditional probability</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-probability.html"><a href="7-probability.html#smallpox-in-boston-1721"><i class="fa fa-check"></i><b>7.2.3</b> Smallpox in Boston, 1721</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-probability.html"><a href="7-probability.html#general-multiplication-rule"><i class="fa fa-check"></i><b>7.2.4</b> General multiplication rule</a></li>
<li class="chapter" data-level="7.2.5" data-path="7-probability.html"><a href="7-probability.html#independence-considerations-in-conditional-probability"><i class="fa fa-check"></i><b>7.2.5</b> Independence considerations in conditional probability</a></li>
<li class="chapter" data-level="7.2.6" data-path="7-probability.html"><a href="7-probability.html#tree-diagrams"><i class="fa fa-check"></i><b>7.2.6</b> Tree diagrams</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-probability.html"><a href="7-probability.html#randomVariablesSection"><i class="fa fa-check"></i><b>7.3</b> Random variables</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-probability.html"><a href="7-probability.html#expectation"><i class="fa fa-check"></i><b>7.3.1</b> Expectation</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-probability.html"><a href="7-probability.html#variability-in-random-variables"><i class="fa fa-check"></i><b>7.3.2</b> Variability in random variables</a></li>
<li class="chapter" data-level="7.3.3" data-path="7-probability.html"><a href="7-probability.html#linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.3.3</b> Linear combinations of random variables</a></li>
<li class="chapter" data-level="7.3.4" data-path="7-probability.html"><a href="7-probability.html#variability-in-linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.3.4</b> Variability in linear combinations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7-probability.html"><a href="7-probability.html#appendixA"><i class="fa fa-check"></i><b>7.4</b> Statistical Background</a></li>
<li class="chapter" data-level="7.5" data-path="7-probability.html"><a href="7-probability.html#appendix-stat-terms"><i class="fa fa-check"></i><b>7.5</b> Basic statistical terms</a><ul>
<li class="chapter" data-level="7.5.1" data-path="7-probability.html"><a href="7-probability.html#mean"><i class="fa fa-check"></i><b>7.5.1</b> Mean</a></li>
<li class="chapter" data-level="7.5.2" data-path="7-probability.html"><a href="7-probability.html#median"><i class="fa fa-check"></i><b>7.5.2</b> Median</a></li>
<li class="chapter" data-level="7.5.3" data-path="7-probability.html"><a href="7-probability.html#standard-deviation"><i class="fa fa-check"></i><b>7.5.3</b> Standard deviation</a></li>
<li class="chapter" data-level="7.5.4" data-path="7-probability.html"><a href="7-probability.html#five-number-summary"><i class="fa fa-check"></i><b>7.5.4</b> Five-number summary</a></li>
<li class="chapter" data-level="7.5.5" data-path="7-probability.html"><a href="7-probability.html#distribution"><i class="fa fa-check"></i><b>7.5.5</b> Distribution</a></li>
<li class="chapter" data-level="7.5.6" data-path="7-probability.html"><a href="7-probability.html#outliers"><i class="fa fa-check"></i><b>7.5.6</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="7-probability.html"><a href="7-probability.html#appendix-normal-curve"><i class="fa fa-check"></i><b>7.6</b> Normal distribution</a></li>
<li class="chapter" data-level="7.7" data-path="7-probability.html"><a href="7-probability.html#appendix-log10-transformations"><i class="fa fa-check"></i><b>7.7</b> log10 transformations</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html"><i class="fa fa-check"></i><b>8</b> Bayes’s Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conditional-probability"><i class="fa fa-check"></i><b>8.1</b> Conditional probability</a></li>
<li class="chapter" data-level="8.2" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conjoint-probability"><i class="fa fa-check"></i><b>8.2</b> Conjoint probability</a></li>
<li class="chapter" data-level="8.3" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-cookie-problem"><i class="fa fa-check"></i><b>8.3</b> The cookie problem</a></li>
<li class="chapter" data-level="8.4" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#bayess-theorem-1"><i class="fa fa-check"></i><b>8.4</b> Bayes’s Theorem</a></li>
<li class="chapter" data-level="8.5" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-diachronic-interpretation"><i class="fa fa-check"></i><b>8.5</b> The diachronic interpretation</a></li>
<li class="chapter" data-level="8.6" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-mm-problem"><i class="fa fa-check"></i><b>8.6</b> The M&amp;M problem</a></li>
<li class="chapter" data-level="8.7" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-monty-hall-problem"><i class="fa fa-check"></i><b>8.7</b> The Monty Hall problem</a></li>
<li class="chapter" data-level="8.8" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#discussion"><i class="fa fa-check"></i><b>8.8</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-sampling.html"><a href="9-sampling.html"><i class="fa fa-check"></i><b>9</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="9-sampling.html"><a href="9-sampling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>9.1</b> Sampling bowl activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-sampling.html"><a href="9-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>9.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>9.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-sampling.html"><a href="9-sampling.html#student-shovels"><i class="fa fa-check"></i><b>9.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-sampling.html"><a href="9-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>9.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Virtual sampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>9.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>9.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-sampling.html"><a href="9-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>9.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="9.2.4" data-path="9-sampling.html"><a href="9-sampling.html#different-shovels"><i class="fa fa-check"></i><b>9.2.4</b> Using different shovels</a></li>
<li class="chapter" data-level="9.2.5" data-path="9-sampling.html"><a href="9-sampling.html#using-many-shovels-at-once"><i class="fa fa-check"></i><b>9.2.5</b> Using many shovels at once</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-sampling.html"><a href="9-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>9.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-sampling.html"><a href="9-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>9.3.1</b> Terminology and notation</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>9.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="9.3.3" data-path="9-sampling.html"><a href="9-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>9.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-sampling.html"><a href="9-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>9.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="9.5" data-path="9-sampling.html"><a href="9-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>9.5.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-sampling.html"><a href="9-sampling.html#whats-to-come"><i class="fa fa-check"></i><b>9.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>10.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>10.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>10.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>10.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>10.1.4</b> What did we just do?</a></li>
<li class="chapter" data-level="10.1.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>10.1.5</b> Virtually resampling once</a></li>
<li class="chapter" data-level="10.1.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-35-replicates"><i class="fa fa-check"></i><b>10.1.6</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="10.1.7" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>10.1.7</b> Virtually resampling 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>10.2</b> Measuring uncertainty with confidence intervals</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>10.2.1</b> Percentile method</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>10.2.2</b> Standard error method</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>10.2.3</b> Interpreting confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>10.3</b> Width of confidence intervals</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-confidence-level"><i class="fa fa-check"></i><b>10.3.1</b> Impact of confidence level</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#fitting-multiple-models-using-map"><i class="fa fa-check"></i><b>10.3.2</b> Fitting multiple models using <code>map()</code></a></li>
<li class="chapter" data-level="10.3.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-sample-size"><i class="fa fa-check"></i><b>10.3.3</b> Impact of sample size</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut"><i class="fa fa-check"></i><b>10.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="10.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>10.5</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>10.5.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>10.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>10.5.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="10.5.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut-1"><i class="fa fa-check"></i><b>10.5.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>10.6.1</b> Comparing bootstrap and sampling distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-regression.html"><a href="11-regression.html"><i class="fa fa-check"></i><b>11</b> Regression</a><ul>
<li class="chapter" data-level="" data-path="11-regression.html"><a href="11-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-regression.html"><a href="11-regression.html#model1"><i class="fa fa-check"></i><b>11.1</b> Teaching evaluations: one numerical explanatory variable</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-regression.html"><a href="11-regression.html#model1EDA"><i class="fa fa-check"></i><b>11.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-regression.html"><a href="11-regression.html#model1table"><i class="fa fa-check"></i><b>11.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="11.1.3" data-path="11-regression.html"><a href="11-regression.html#interpreting-regression-coefficients"><i class="fa fa-check"></i><b>11.1.3</b> Interpreting regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-regression.html"><a href="11-regression.html#uncertainty-in-simple-linear-regressions"><i class="fa fa-check"></i><b>11.2</b> Uncertainty in simple linear regressions</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-regression.html"><a href="11-regression.html#interpreting-confidence-intervals"><i class="fa fa-check"></i><b>11.2.1</b> Interpreting confidence intervals</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-regression.html"><a href="11-regression.html#using-lm-and-tidy-as-a-shortcut-2"><i class="fa fa-check"></i><b>11.2.2</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="11.2.3" data-path="11-regression.html"><a href="11-regression.html#model1points"><i class="fa fa-check"></i><b>11.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-regression.html"><a href="11-regression.html#model2"><i class="fa fa-check"></i><b>11.3</b> Life expectancy: one categorical explanatory variable</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-regression.html"><a href="11-regression.html#model2EDA"><i class="fa fa-check"></i><b>11.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-regression.html"><a href="11-regression.html#model2table"><i class="fa fa-check"></i><b>11.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-regression.html"><a href="11-regression.html#model2points"><i class="fa fa-check"></i><b>11.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-regression.html"><a href="11-regression.html#fitting-multiple-models-using-map-1"><i class="fa fa-check"></i><b>11.4</b> Fitting multiple models using <code>map()</code></a></li>
<li class="chapter" data-level="11.5" data-path="11-regression.html"><a href="11-regression.html#leastsquares"><i class="fa fa-check"></i><b>11.5</b> Best-fitting line</a></li>
<li class="chapter" data-level="11.6" data-path="11-regression.html"><a href="11-regression.html#conclusion-4"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a><ul>
<li class="chapter" data-level="11.6.1" data-path="11-regression.html"><a href="11-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>11.6.1</b> Additional resources</a></li>
<li class="chapter" data-level="11.6.2" data-path="11-regression.html"><a href="11-regression.html#whats-to-come-1"><i class="fa fa-check"></i><b>11.6.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html"><i class="fa fa-check"></i><b>12</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4"><i class="fa fa-check"></i><b>12.1</b> One numerical and one categorical explanatory variable</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>12.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>12.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>12.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3"><i class="fa fa-check"></i><b>12.2</b> Two numerical explanatory variables</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>12.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>12.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>12.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#related-topics"><i class="fa fa-check"></i><b>12.3</b> Related topics</a><ul>
<li class="chapter" data-level="12.3.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>12.3.1</b> Model selection</a></li>
<li class="chapter" data-level="12.3.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>12.3.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="12.3.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>12.3.3</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.4</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.4.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.4.1</b> Exploratory data analysis: Part I</a></li>
<li class="chapter" data-level="12.4.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-II"><i class="fa fa-check"></i><b>12.4.2</b> Exploratory data analysis: Part II</a></li>
<li class="chapter" data-level="12.4.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-regression"><i class="fa fa-check"></i><b>12.4.3</b> Regression modeling</a></li>
<li class="chapter" data-level="12.4.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.4.4</b> Making predictions</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#data-journalism"><i class="fa fa-check"></i><b>12.5</b> Case study: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.5.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.5.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.5.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.5.2</b> US Births in 1999</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-classification.html"><a href="13-classification.html"><i class="fa fa-check"></i><b>13</b> Classification</a><ul>
<li class="chapter" data-level="13.1" data-path="13-classification.html"><a href="13-classification.html#learning-objectives"><i class="fa fa-check"></i><b>13.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="13.2" data-path="13-classification.html"><a href="13-classification.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>13.2</b> Introduction to Logistic Regression</a><ul>
<li class="chapter" data-level="13.2.1" data-path="13-classification.html"><a href="13-classification.html#logistic-regression-assumptions"><i class="fa fa-check"></i><b>13.2.1</b> Logistic Regression Assumptions</a></li>
<li class="chapter" data-level="13.2.2" data-path="13-classification.html"><a href="13-classification.html#a-graphical-look-at-logistic-regression"><i class="fa fa-check"></i><b>13.2.2</b> A Graphical Look at Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13-classification.html"><a href="13-classification.html#case-studies-overview"><i class="fa fa-check"></i><b>13.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="13.4" data-path="13-classification.html"><a href="13-classification.html#case-study-soccer-goalkeepers"><i class="fa fa-check"></i><b>13.4</b> Case Study: Soccer Goalkeepers</a><ul>
<li class="chapter" data-level="13.4.1" data-path="13-classification.html"><a href="13-classification.html#modeling-odds"><i class="fa fa-check"></i><b>13.4.1</b> Modeling Odds</a></li>
<li class="chapter" data-level="13.4.2" data-path="13-classification.html"><a href="13-classification.html#logistic-regression-models-for-binomial-responses"><i class="fa fa-check"></i><b>13.4.2</b> Logistic Regression Models for Binomial Responses</a></li>
<li class="chapter" data-level="13.4.3" data-path="13-classification.html"><a href="13-classification.html#theoretical-rationale-for-logistic-regression-models-optional"><i class="fa fa-check"></i><b>13.4.3</b> Theoretical rationale for logistic regression models (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13-classification.html"><a href="13-classification.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>13.5</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="13.5.1" data-path="13-classification.html"><a href="13-classification.html#data-organization"><i class="fa fa-check"></i><b>13.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="13.5.2" data-path="13-classification.html"><a href="13-classification.html#exploratory-analyses"><i class="fa fa-check"></i><b>13.5.2</b> Exploratory Analyses</a></li>
<li class="chapter" data-level="13.5.3" data-path="13-classification.html"><a href="13-classification.html#initial-models"><i class="fa fa-check"></i><b>13.5.3</b> Initial Models</a></li>
<li class="chapter" data-level="13.5.4" data-path="13-classification.html"><a href="13-classification.html#sec-logisticInf"><i class="fa fa-check"></i><b>13.5.4</b> Tests for significance of model coefficients</a></li>
<li class="chapter" data-level="13.5.5" data-path="13-classification.html"><a href="13-classification.html#confidence-intervals-for-model-coefficients"><i class="fa fa-check"></i><b>13.5.5</b> Confidence intervals for model coefficients</a></li>
<li class="chapter" data-level="13.5.6" data-path="13-classification.html"><a href="13-classification.html#testing-for-goodness-of-fit"><i class="fa fa-check"></i><b>13.5.6</b> Testing for goodness of fit</a></li>
<li class="chapter" data-level="13.5.7" data-path="13-classification.html"><a href="13-classification.html#residuals-for-binomial-regression"><i class="fa fa-check"></i><b>13.5.7</b> Residuals for Binomial Regression</a></li>
<li class="chapter" data-level="13.5.8" data-path="13-classification.html"><a href="13-classification.html#sec-logOverdispersion"><i class="fa fa-check"></i><b>13.5.8</b> Overdispersion</a></li>
<li class="chapter" data-level="13.5.9" data-path="13-classification.html"><a href="13-classification.html#summary-5"><i class="fa fa-check"></i><b>13.5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13-classification.html"><a href="13-classification.html#least-squares-regression-vs.-logistic-regression"><i class="fa fa-check"></i><b>13.6</b> Least Squares Regression vs. Logistic Regression</a></li>
<li class="chapter" data-level="13.7" data-path="13-classification.html"><a href="13-classification.html#case-study-trying-to-lose-weight"><i class="fa fa-check"></i><b>13.7</b> Case Study: Trying to Lose Weight</a><ul>
<li class="chapter" data-level="13.7.1" data-path="13-classification.html"><a href="13-classification.html#data-organization-1"><i class="fa fa-check"></i><b>13.7.1</b> Data Organization</a></li>
<li class="chapter" data-level="13.7.2" data-path="13-classification.html"><a href="13-classification.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>13.7.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="13.7.3" data-path="13-classification.html"><a href="13-classification.html#initial-models-1"><i class="fa fa-check"></i><b>13.7.3</b> Initial Models</a></li>
<li class="chapter" data-level="13.7.4" data-path="13-classification.html"><a href="13-classification.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>13.7.4</b> Drop-in-deviance Tests</a></li>
<li class="chapter" data-level="13.7.5" data-path="13-classification.html"><a href="13-classification.html#model-discussion-and-summary"><i class="fa fa-check"></i><b>13.7.5</b> Model Discussion and Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="13-classification.html"><a href="13-classification.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>13.8</b> Classification and regression trees (CART)</a><ul>
<li class="chapter" data-level="13.8.1" data-path="13-classification.html"><a href="13-classification.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>13.8.1</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="13.8.2" data-path="13-classification.html"><a href="13-classification.html#cart-motivation"><i class="fa fa-check"></i><b>13.8.2</b> CART motivation</a></li>
<li class="chapter" data-level="13.8.3" data-path="13-classification.html"><a href="13-classification.html#regression-trees"><i class="fa fa-check"></i><b>13.8.3</b> Regression trees</a></li>
<li class="chapter" data-level="13.8.4" data-path="13-classification.html"><a href="13-classification.html#classification-decision-trees"><i class="fa fa-check"></i><b>13.8.4</b> Classification (decision) trees</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="13-classification.html"><a href="13-classification.html#random-forests"><i class="fa fa-check"></i><b>13.9</b> Random forests</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-machine.html"><a href="14-machine.html"><i class="fa fa-check"></i><b>14</b> Machine Learning</a><ul>
<li class="chapter" data-level="14.1" data-path="14-machine.html"><a href="14-machine.html#notation"><i class="fa fa-check"></i><b>14.1</b> Notation</a></li>
<li class="chapter" data-level="14.2" data-path="14-machine.html"><a href="14-machine.html#an-example"><i class="fa fa-check"></i><b>14.2</b> An example</a></li>
<li class="chapter" data-level="14.3" data-path="14-machine.html"><a href="14-machine.html#evaluation-metrics"><i class="fa fa-check"></i><b>14.3</b> Evaluation metrics</a><ul>
<li class="chapter" data-level="14.3.1" data-path="14-machine.html"><a href="14-machine.html#training-and-test-sets"><i class="fa fa-check"></i><b>14.3.1</b> Training and test sets</a></li>
<li class="chapter" data-level="14.3.2" data-path="14-machine.html"><a href="14-machine.html#overall-accuracy"><i class="fa fa-check"></i><b>14.3.2</b> Overall accuracy</a></li>
<li class="chapter" data-level="14.3.3" data-path="14-machine.html"><a href="14-machine.html#the-confusion-matrix"><i class="fa fa-check"></i><b>14.3.3</b> The confusion matrix</a></li>
<li class="chapter" data-level="14.3.4" data-path="14-machine.html"><a href="14-machine.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.3.4</b> Sensitivity and specificity</a></li>
<li class="chapter" data-level="14.3.5" data-path="14-machine.html"><a href="14-machine.html#balanced-accuracy-and-f_1-score"><i class="fa fa-check"></i><b>14.3.5</b> Balanced accuracy and <span class="math inline">\(F_1\)</span> score</a></li>
<li class="chapter" data-level="14.3.6" data-path="14-machine.html"><a href="14-machine.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>14.3.6</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="14.3.7" data-path="14-machine.html"><a href="14-machine.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>14.3.7</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="14.3.8" data-path="14-machine.html"><a href="14-machine.html#loss-function"><i class="fa fa-check"></i><b>14.3.8</b> The loss function</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14-machine.html"><a href="14-machine.html#conditional-probabilities-and-expectations"><i class="fa fa-check"></i><b>14.4</b> Conditional probabilities and expectations</a><ul>
<li class="chapter" data-level="14.4.1" data-path="14-machine.html"><a href="14-machine.html#conditional-probabilities"><i class="fa fa-check"></i><b>14.4.1</b> Conditional probabilities</a></li>
<li class="chapter" data-level="14.4.2" data-path="14-machine.html"><a href="14-machine.html#conditional-expectations"><i class="fa fa-check"></i><b>14.4.2</b> Conditional expectations</a></li>
<li class="chapter" data-level="14.4.3" data-path="14-machine.html"><a href="14-machine.html#conditional-expectation-minimizes-squared-loss-function"><i class="fa fa-check"></i><b>14.4.3</b> Conditional expectation minimizes squared loss function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="14-machine.html"><a href="14-machine.html#two-or-seven"><i class="fa fa-check"></i><b>14.5</b> Case study: is it a 2 or a 7?</a></li>
<li class="chapter" data-level="14.6" data-path="14-machine.html"><a href="14-machine.html#cross-validation"><i class="fa fa-check"></i><b>14.6</b> Cross validation</a></li>
<li class="chapter" data-level="14.7" data-path="14-machine.html"><a href="14-machine.html#knn-cv-intro"><i class="fa fa-check"></i><b>14.7</b> Motivation with k-nearest neighbors</a><ul>
<li class="chapter" data-level="14.7.1" data-path="14-machine.html"><a href="14-machine.html#over-training"><i class="fa fa-check"></i><b>14.7.1</b> Over-training</a></li>
<li class="chapter" data-level="14.7.2" data-path="14-machine.html"><a href="14-machine.html#over-smoothing"><i class="fa fa-check"></i><b>14.7.2</b> Over-smoothing</a></li>
<li class="chapter" data-level="14.7.3" data-path="14-machine.html"><a href="14-machine.html#picking-the-k-in-knn"><i class="fa fa-check"></i><b>14.7.3</b> Picking the <span class="math inline">\(k\)</span> in kNN</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="14-machine.html"><a href="14-machine.html#mathematical-description-of-cross-validation"><i class="fa fa-check"></i><b>14.8</b> Mathematical description of cross validation</a></li>
<li class="chapter" data-level="14.9" data-path="14-machine.html"><a href="14-machine.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>14.9</b> K-fold cross validation</a></li>
<li class="chapter" data-level="14.10" data-path="14-machine.html"><a href="14-machine.html#bootstrap"><i class="fa fa-check"></i><b>14.10</b> Bootstrap</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html"><i class="fa fa-check"></i><b>A</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="A.1" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#causal-effects"><i class="fa fa-check"></i><b>A.1</b> Causal effects</a></li>
<li class="chapter" data-level="A.2" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#potential-outcomes"><i class="fa fa-check"></i><b>A.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="A.3" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#no-causation-without-manipulation"><i class="fa fa-check"></i><b>A.3</b> No causation without manipulation</a></li>
<li class="chapter" data-level="A.4" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#average-treatment-effect"><i class="fa fa-check"></i><b>A.4</b> Average treatment effect</a></li>
<li class="chapter" data-level="A.5" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>A.5</b> Stable unit treatment value assumption (SUTVA)</a></li>
<li class="chapter" data-level="A.6" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>A.6</b> The fundamental problem of causal inference</a></li>
<li class="chapter" data-level="A.7" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-assignment-mechanism"><i class="fa fa-check"></i><b>A.7</b> The assignment mechanism</a></li>
<li class="chapter" data-level="A.8" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#permutation-tests"><i class="fa fa-check"></i><b>A.8</b> Permutation tests</a></li>
<li class="chapter" data-level="A.9" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#confounding-and-selection-bias"><i class="fa fa-check"></i><b>A.9</b> Confounding and selection bias</a></li>
<li class="chapter" data-level="A.10" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#internal-and-external-validity"><i class="fa fa-check"></i><b>A.10</b> Internal and external validity</a></li>
<li class="chapter" data-level="A.11" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#survey-research-and-external-validity"><i class="fa fa-check"></i><b>A.11</b> Survey research and external validity</a></li>
<li class="chapter" data-level="A.12" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#conclusion-5"><i class="fa fa-check"></i><b>A.12</b> Conclusion</a></li>
<li class="chapter" data-level="A.13" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#references"><i class="fa fa-check"></i><b>A.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-maps.html"><a href="B-maps.html"><i class="fa fa-check"></i><b>B</b> Maps</a><ul>
<li class="chapter" data-level="B.1" data-path="B-maps.html"><a href="B-maps.html#tidycensus"><i class="fa fa-check"></i><b>B.1</b> Tidycensus</a></li>
<li class="chapter" data-level="B.2" data-path="B-maps.html"><a href="B-maps.html#conceptual-introduction-to-mapping"><i class="fa fa-check"></i><b>B.2</b> Conceptual introduction to mapping</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-maps.html"><a href="B-maps.html#vector-versus-spatial-data"><i class="fa fa-check"></i><b>B.2.1</b> Vector versus spatial data</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-maps.html"><a href="B-maps.html#sf-vs-sp"><i class="fa fa-check"></i><b>B.2.2</b> <strong>sf</strong> vs <strong>sp</strong></a></li>
<li class="chapter" data-level="B.2.3" data-path="B-maps.html"><a href="B-maps.html#shapefiles"><i class="fa fa-check"></i><b>B.2.3</b> Shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-maps.html"><a href="B-maps.html#mapping-with-tidycensus-and-geom_sf"><i class="fa fa-check"></i><b>B.3</b> Mapping with <strong>tidycensus</strong> and <code>geom_sf()</code></a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-maps.html"><a href="B-maps.html#making-maps-pretty"><i class="fa fa-check"></i><b>B.3.1</b> Making maps pretty</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-maps.html"><a href="B-maps.html#adding-back-alaska-and-hawaii"><i class="fa fa-check"></i><b>B.3.2</b> Adding back Alaska and Hawaii</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-maps.html"><a href="B-maps.html#faceting-maps"><i class="fa fa-check"></i><b>B.4</b> Faceting maps</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-maps.html"><a href="B-maps.html#transforming-and-mapping-the-data"><i class="fa fa-check"></i><b>B.4.1</b> Transforming and mapping the data</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-maps.html"><a href="B-maps.html#want-to-explore-further"><i class="fa fa-check"></i><b>B.5</b> Want to explore further?</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-animation.html"><a href="C-animation.html"><i class="fa fa-check"></i><b>C</b> Animation</a><ul>
<li class="chapter" data-level="C.1" data-path="C-animation.html"><a href="C-animation.html#gganimate-how-to-create-plots-with-beautiful-animation-in-r"><i class="fa fa-check"></i><b>C.1</b> gganimate: How to Create Plots with Beautiful Animation in R</a><ul>
<li class="chapter" data-level="C.1.1" data-path="C-animation.html"><a href="C-animation.html#prerequisites"><i class="fa fa-check"></i><b>C.1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="C.1.2" data-path="C-animation.html"><a href="C-animation.html#demo-dataset"><i class="fa fa-check"></i><b>C.1.2</b> Demo dataset</a></li>
<li class="chapter" data-level="C.1.3" data-path="C-animation.html"><a href="C-animation.html#static-plot"><i class="fa fa-check"></i><b>C.1.3</b> Static plot</a></li>
<li class="chapter" data-level="C.1.4" data-path="C-animation.html"><a href="C-animation.html#transition-through-distinct-states-in-time"><i class="fa fa-check"></i><b>C.1.4</b> Transition through distinct states in time</a></li>
<li class="chapter" data-level="C.1.5" data-path="C-animation.html"><a href="C-animation.html#reveal-data-along-a-given-dimension"><i class="fa fa-check"></i><b>C.1.5</b> Reveal data along a given dimension</a></li>
<li class="chapter" data-level="C.1.6" data-path="C-animation.html"><a href="C-animation.html#transition-between-several-distinct-stages-of-the-data"><i class="fa fa-check"></i><b>C.1.6</b> Transition between several distinct stages of the data</a></li>
<li class="chapter" data-level="C.1.7" data-path="C-animation.html"><a href="C-animation.html#read-more"><i class="fa fa-check"></i><b>C.1.7</b> Read more</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="C-animation.html"><a href="C-animation.html#how-to-save-your-animation"><i class="fa fa-check"></i><b>C.2</b> How to save your animation</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-shiny.html"><a href="D-shiny.html"><i class="fa fa-check"></i><b>D</b> Shiny</a><ul>
<li class="chapter" data-level="D.1" data-path="D-shiny.html"><a href="D-shiny.html#helpful-resources"><i class="fa fa-check"></i><b>D.1</b> Helpful Resources</a></li>
<li class="chapter" data-level="D.2" data-path="D-shiny.html"><a href="D-shiny.html#set-up-and-getting-started"><i class="fa fa-check"></i><b>D.2</b> Set Up and Getting Started</a></li>
<li class="chapter" data-level="D.3" data-path="D-shiny.html"><a href="D-shiny.html#building-your-basic-app"><i class="fa fa-check"></i><b>D.3</b> Building Your Basic App</a><ul>
<li class="chapter" data-level="D.3.1" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-basic-ui"><i class="fa fa-check"></i><b>D.3.1</b> Setting Up the Basic UI</a></li>
<li class="chapter" data-level="D.3.2" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-server"><i class="fa fa-check"></i><b>D.3.2</b> Setting up the Server</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="D-shiny.html"><a href="D-shiny.html#organization"><i class="fa fa-check"></i><b>D.4</b> Organization</a></li>
<li class="chapter" data-level="D.5" data-path="D-shiny.html"><a href="D-shiny.html#customizations"><i class="fa fa-check"></i><b>D.5</b> Customizations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preceptor’s Primer for Bayesian Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> Multiple Regression</h1>
<p>In Chapter <a href="11-regression.html#regression">11</a> we introduced ideas related to modeling for explanation, in particular that the goal of modeling is to make explicit the relationship between some outcome variable <span class="math inline">\(y\)</span> and some explanatory variable <span class="math inline">\(x\)</span>. While there are many approaches to modeling, we focused on one particular technique: <em>linear regression</em>, one of the most commonly used and easy-to-understand approaches to modeling. Furthermore to keep things simple, we only considered models with one explanatory <span class="math inline">\(x\)</span> variable that was either numerical in Section <a href="11-regression.html#model1">11.1</a> or categorical in Section <a href="11-regression.html#model2">11.3</a>.</p>
<p>In this chapter on multiple regression, we’ll start considering models that include more than one explanatory variable <span class="math inline">\(x\)</span>. You can imagine when trying to model a particular outcome variable, like teaching evaluation scores as in Section <a href="11-regression.html#model1">11.1</a> or life expectancy as in Section <a href="11-regression.html#model2">11.3</a>, that it would be useful to include more than just one explanatory variable’s worth of information.</p>
<p>Since our regression models will now consider more than one explanatory variable, the interpretation of the associated effect of any one explanatory variable must be made in conjunction with the other explanatory variables included in your model. Let’s begin!</p>
<div id="needed-packages-4" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s load all the packages needed for this chapter (this assumes you’ve already installed them). Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.5</a> that loading the <strong>tidyverse</strong> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><strong>ggplot2</strong> for data visualization</li>
<li><strong>dplyr</strong> for data wrangling</li>
<li><strong>tidyr</strong> for converting data to “tidy” format</li>
<li><strong>readr</strong> for importing spreadsheet data into R</li>
<li>As well as the more advanced <strong>purrr</strong>, <strong>tibble</strong>, <strong>stringr</strong>, and <strong>forcats</strong> packages</li>
</ul>
<p>If needed, read Section <a href="1-getting-started.html#packages">1.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb787-1"><a href="12-multiple-regression.html#cb787-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb787-2"><a href="12-multiple-regression.html#cb787-2"></a><span class="kw">library</span>(broom)</span>
<span id="cb787-3"><a href="12-multiple-regression.html#cb787-3"></a><span class="kw">library</span>(skimr)</span>
<span id="cb787-4"><a href="12-multiple-regression.html#cb787-4"></a><span class="kw">library</span>(ISLR)</span>
<span id="cb787-5"><a href="12-multiple-regression.html#cb787-5"></a><span class="kw">library</span>(fivethirtyeight)</span></code></pre></div>
</div>
<div id="model4" class="section level2">
<h2><span class="header-section-number">12.1</span> One numerical and one categorical explanatory variable</h2>
<p>Let’s revisit the instructor evaluation data from UT Austin we introduced in Section <a href="11-regression.html#model1">11.1</a>. We studied the relationship between teaching evaluation scores as given by students and “beauty” scores. The variable teaching <code>score</code> was the numerical outcome variable <span class="math inline">\(y\)</span>, and the variable “beauty” score (<code>bty_avg</code>) was the numerical explanatory <span class="math inline">\(x\)</span> variable.</p>
<p>In this section, we are going to consider a different model. Our outcome variable will still be teaching score, but we’ll now include two different explanatory variables: age and (binary) gender. Could it be that instructors who are older receive better teaching evaluations from students? Or could it instead be that younger instructors receive better evaluations? Are there differences in evaluations given by students for instructors of different genders? We’ll answer these questions by modeling the relationship between these variables using <em>multiple regression</em>, where we have:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, the instructor’s teaching score, and</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>, the instructor’s age.</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>, the instructor’s (binary) gender.</li>
</ol></li>
</ol>
<p>It is important to note that at the time of this study due to then commonly held beliefs about gender, this variable was often recorded as a binary variable. While the results of a model that oversimplifies gender this way may be imperfect, we still found the results to be pertinent and relevant today.</p>
<div id="model4EDA" class="section level3">
<h3><span class="header-section-number">12.1.1</span> Exploratory data analysis</h3>
<p>Recall that data on the 463 courses at UT Austin can be found in the <code>evals</code> data frame included in the <strong>moderndive</strong> package. However, to keep things simple, let’s <code>select()</code> only the subset of the variables we’ll consider in this chapter, and save this data in a new data frame called <code>evals_ch12</code>. Note that these are different from the variables chosen in Chapter <a href="11-regression.html#regression">11</a>.</p>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="12-multiple-regression.html#cb788-1"></a><span class="kw">library</span>(moderndive)</span>
<span id="cb788-2"><a href="12-multiple-regression.html#cb788-2"></a></span>
<span id="cb788-3"><a href="12-multiple-regression.html#cb788-3"></a>evals_ch12 &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span></span>
<span id="cb788-4"><a href="12-multiple-regression.html#cb788-4"></a><span class="st">  </span><span class="kw">select</span>(ID, score, age, gender)</span></code></pre></div>
<p>Recall the three common steps in an exploratory data analysis we saw in Subsection <a href="11-regression.html#model1EDA">11.1.1</a>:</p>
<ol style="list-style-type: decimal">
<li>Looking at the raw data values.</li>
<li>Computing summary statistics.</li>
<li>Creating data visualizations.</li>
</ol>
<p>Let’s first look at the raw data values by either looking at <code>evals_ch12</code> using RStudio’s spreadsheet viewer or by using the <code>glimpse()</code> function from the <strong>dplyr</strong> package:</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb789-1"><a href="12-multiple-regression.html#cb789-1"></a><span class="kw">glimpse</span>(evals_ch12)</span></code></pre></div>
<pre><code>Observations: 463
Variables: 4
$ ID     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…
$ score  &lt;dbl&gt; 4.7, 4.1, 3.9, 4.8, 4.6, 4.3, 2.8, 4.1, 3.4, 4.5, 3.8, 4.5, 4.…
$ age    &lt;int&gt; 36, 36, 36, 36, 59, 59, 59, 51, 51, 40, 40, 40, 40, 40, 40, 40…
$ gender &lt;fct&gt; female, female, female, female, male, male, male, male, male, …</code></pre>
<p>Let’s also display a random sample of 5 rows of the 463 rows corresponding to different courses in Table <a href="12-multiple-regression.html#tab:model4-data-preview">12.1</a>. Remember due to the random nature of the sampling, you will likely end up with a different subset of 5 rows.</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="12-multiple-regression.html#cb791-1"></a>evals_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb791-2"><a href="12-multiple-regression.html#cb791-2"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model4-data-preview">TABLE 12.1: </span>A random sample of 5 out of the 463 courses at UT Austin
</caption>
<thead>
<tr>
<th style="text-align:right;">
ID
</th>
<th style="text-align:right;">
score
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
gender
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
129
</td>
<td style="text-align:right;">
3.7
</td>
<td style="text-align:right;">
62
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
109
</td>
<td style="text-align:right;">
4.7
</td>
<td style="text-align:right;">
46
</td>
<td style="text-align:left;">
female
</td>
</tr>
<tr>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
4.8
</td>
<td style="text-align:right;">
62
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
434
</td>
<td style="text-align:right;">
2.8
</td>
<td style="text-align:right;">
62
</td>
<td style="text-align:left;">
male
</td>
</tr>
<tr>
<td style="text-align:right;">
330
</td>
<td style="text-align:right;">
4.0
</td>
<td style="text-align:right;">
64
</td>
<td style="text-align:left;">
male
</td>
</tr>
</tbody>
</table>
<p>Now that we’ve looked at the raw values in our <code>evals_ch12</code> data frame and got a sense of the data, let’s compute summary statistics. As we did in our exploratory data analyses in Sections <a href="11-regression.html#model1EDA">11.1.1</a> and <a href="11-regression.html#model2EDA">11.3.1</a> from the previous chapter, let’s use the <code>skim()</code> function from the <strong>skimr</strong> package, being sure to only <code>select()</code> the variables of interest in our model:</p>
<div class="sourceCode" id="cb792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb792-1"><a href="12-multiple-regression.html#cb792-1"></a>evals_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb792-2"><a href="12-multiple-regression.html#cb792-2"></a><span class="st">  </span><span class="kw">select</span>(score, age, gender) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb792-3"><a href="12-multiple-regression.html#cb792-3"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
<span id="tab:unnamed-chunk-529">TABLE 12.2: </span>Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
Piped data
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
463
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
factor
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:left;">
ordered
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:left;">
top_counts
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
gender
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
mal: 268, fem: 195
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
score
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.17
</td>
<td style="text-align:right;">
0.54
</td>
<td style="text-align:right;">
2.3
</td>
<td style="text-align:right;">
3.8
</td>
<td style="text-align:right;">
4.3
</td>
<td style="text-align:right;">
4.6
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
▁▁▅▇▇
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
48.37
</td>
<td style="text-align:right;">
9.80
</td>
<td style="text-align:right;">
29.0
</td>
<td style="text-align:right;">
42.0
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
57.0
</td>
<td style="text-align:right;">
73
</td>
<td style="text-align:left;">
▅▆▇▆▁
</td>
</tr>
</tbody>
</table>
<p>Observe that we have no missing data, that there are 268 courses taught by male instructors and 195 courses taught by female instructors, and that the average instructor age is 48.37. Recall that each row represents a particular course and that the same instructor often teaches more than one course. Therefore, the average age of the unique instructors may differ.</p>
<p>Furthermore, let’s compute the correlation coefficient between our two numerical variables: <code>score</code> and <code>age</code>. Recall from Subsection <a href="11-regression.html#model1EDA">11.1.1</a> that correlation coefficients only exist between numerical variables. We observe that they are “weakly negatively” correlated.</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb793-1"><a href="12-multiple-regression.html#cb793-1"></a>evals_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-2"><a href="12-multiple-regression.html#cb793-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">correlation =</span> <span class="kw">cor</span>(score, age)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-3"><a href="12-multiple-regression.html#cb793-3"></a><span class="st">  </span><span class="kw">round</span>(<span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-4"><a href="12-multiple-regression.html#cb793-4"></a><span class="st">  </span><span class="kw">pull</span>()</span></code></pre></div>
<pre><code>[1] -0.107</code></pre>
<p>Let’s now perform the last of the three common steps in an exploratory data analysis: creating data visualizations. Given that the outcome variable <code>score</code> and explanatory variable <code>age</code> are both numerical, we’ll use a scatterplot to display their relationship. How can we incorporate the categorical variable <code>gender</code>, however? By mapping the variable <code>gender</code> to the <code>color</code> aesthetic, thereby creating a <em>colored</em> scatterplot. The following code is similar to the code that created the scatterplot of teaching score over “beauty” score in Figure <a href="#fig:numxplot1"><strong>??</strong></a>, but with <code>color = gender</code> added to the <code>aes()</code>thetic mapping.</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="12-multiple-regression.html#cb795-1"></a>evals_ch12 <span class="op">%&gt;%</span></span>
<span id="cb795-2"><a href="12-multiple-regression.html#cb795-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">color =</span> gender)) <span class="op">+</span></span>
<span id="cb795-3"><a href="12-multiple-regression.html#cb795-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb795-4"><a href="12-multiple-regression.html#cb795-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span></span>
<span id="cb795-5"><a href="12-multiple-regression.html#cb795-5"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxcatxplot1"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/numxcatxplot1-1.png" alt="Colored scatterplot of relationship of teaching and beauty scores." width="\textwidth" />
<p class="caption">
FIGURE 12.1: Colored scatterplot of relationship of teaching and beauty scores.
</p>
</div>
<p>In the resulting Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>, observe that <code>ggplot()</code> assigns a default in red/blue color scheme to the points and to the lines associated with the two levels of <code>gender</code>: <code>female</code> and <code>male</code>. Furthermore, the <code>geom_smooth(method = "lm", se = FALSE)</code> layer automatically fits a different regression line for each group.</p>
<p>We notice some interesting trends. First, there are almost no women faculty over the age of 60 as evidenced by lack of red dots above <span class="math inline">\(x\)</span> = 60. Second, while both regression lines are negatively sloped with age (i.e., older instructors tend to have lower scores), the slope for age for the female instructors is <em>more</em> negative. In other words, female instructors are paying a harsher penalty for advanced age than the male instructors.</p>
</div>
<div id="model4interactiontable" class="section level3">
<h3><span class="header-section-number">12.1.2</span> Interaction model</h3>
<p>Let’s now quantify the relationship of our outcome variable <span class="math inline">\(y\)</span> and the two explanatory variables using one type of multiple regression model known as an <em>interaction model</em>.  We’ll explain where the term “interaction” comes from at the end of this section.</p>
<p>In particular, we’ll write out the equation of the two regression lines in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a> using the values from a regression table. Before we do this, however, let’s go over a brief refresher of regression when you have a categorical explanatory variable <span class="math inline">\(x\)</span>.</p>
<p>Recall in Subsection <a href="11-regression.html#model2table">11.3.2</a> we fit a regression model for countries’ life expectancies as a function of which continent the country was in. In other words, we had a numerical outcome variable <span class="math inline">\(y\)</span> = <code>lifeExp</code> and a categorical explanatory variable <span class="math inline">\(x\)</span> = <code>continent</code> which had 5 levels: <code>Africa</code>, <code>Americas</code>, <code>Asia</code>, <code>Europe</code>, and <code>Oceania</code>. Let’s re-display the regression table you saw in Table <a href="#tab:catxplot4b"><strong>??</strong></a>:</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-532">TABLE 12.3: </span>Regression table for life expectancy as a function of continent
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
56.8
</td>
</tr>
<tr>
<td style="text-align:left;">
continentAmericas
</td>
<td style="text-align:right;">
18.8
</td>
<td style="text-align:right;">
15.2
</td>
<td style="text-align:right;">
22.4
</td>
</tr>
<tr>
<td style="text-align:left;">
continentAsia
</td>
<td style="text-align:right;">
15.9
</td>
<td style="text-align:right;">
12.7
</td>
<td style="text-align:right;">
19.2
</td>
</tr>
<tr>
<td style="text-align:left;">
continentEurope
</td>
<td style="text-align:right;">
22.8
</td>
<td style="text-align:right;">
19.5
</td>
<td style="text-align:right;">
26.2
</td>
</tr>
<tr>
<td style="text-align:left;">
continentOceania
</td>
<td style="text-align:right;">
25.9
</td>
<td style="text-align:right;">
15.4
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
</tbody>
</table>
<p>Recall our interpretation of the <code>estimate</code> column. Since <code>Africa</code> was the “baseline for comparison” group, the <code>intercept</code> term corresponds to the mean life expectancy for all countries in Africa of 54.8 years. The other four values of <code>estimate</code> correspond to “offsets” relative to the baseline group. So, for example, the “offset” corresponding to the Americas is +18.8 as compared to the baseline for comparison group Africa. In other words, the average life expectancy for countries in the Americas is 18.8 years <em>higher</em>. Thus the mean life expectancy for all countries in the Americas is 54.8 + 18.8 = 73.6. The same interpretation holds for Asia, Europe, and Oceania.</p>
<p>Going back to our multiple regression model for teaching <code>score</code> using <code>age</code> and <code>gender</code> in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>, we generate the regression table using the same two-step approach from Chapter <a href="11-regression.html#regression">11</a>: we first “fit” the model using the <code>lm()</code> “linear model” function and then we apply the <code>tidy()</code> function. This time, however, our model formula won’t be of the form <code>y ~ x</code>, but rather of the form <code>y ~ x1 * x2</code>. In other words, our two explanatory variables <code>x1</code> and <code>x2</code> are separated by a <code>*</code> sign:</p>
<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb796-1"><a href="12-multiple-regression.html#cb796-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb796-2"><a href="12-multiple-regression.html#cb796-2"></a></span>
<span id="cb796-3"><a href="12-multiple-regression.html#cb796-3"></a>score_model_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">*</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch12)</span>
<span id="cb796-4"><a href="12-multiple-regression.html#cb796-4"></a></span>
<span id="cb796-5"><a href="12-multiple-regression.html#cb796-5"></a><span class="co"># Get regression table:</span></span>
<span id="cb796-6"><a href="12-multiple-regression.html#cb796-6"></a></span>
<span id="cb796-7"><a href="12-multiple-regression.html#cb796-7"></a>score_model_interaction <span class="op">%&gt;%</span></span>
<span id="cb796-8"><a href="12-multiple-regression.html#cb796-8"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb796-9"><a href="12-multiple-regression.html#cb796-9"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:regtable-interaction">TABLE 12.4: </span>Regression table for interaction model
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
4.883
</td>
<td style="text-align:right;">
4.480
</td>
<td style="text-align:right;">
5.286
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
-0.018
</td>
<td style="text-align:right;">
-0.026
</td>
<td style="text-align:right;">
-0.009
</td>
</tr>
<tr>
<td style="text-align:left;">
gendermale
</td>
<td style="text-align:right;">
-0.446
</td>
<td style="text-align:right;">
-0.968
</td>
<td style="text-align:right;">
0.076
</td>
</tr>
<tr>
<td style="text-align:left;">
age:gendermale
</td>
<td style="text-align:right;">
0.014
</td>
<td style="text-align:right;">
0.003
</td>
<td style="text-align:right;">
0.024
</td>
</tr>
</tbody>
</table>
<p>Looking at the regression table output in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>, there are four rows of values in the <code>estimate</code> column. While it is not immediately apparent, using these four values we can write out the equations of both lines in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>. First, since the word <code>female</code> comes alphabetically before <code>male</code>, female instructors are the “baseline for comparison” group. Thus, <code>intercept</code> is the intercept <em>for only the female instructors</em>.</p>
<p>This holds similarly for <code>age</code>. It is the slope for age <em>for only the female instructors</em>. Thus, the red regression line in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a> has an intercept of 4.883 and slope for age of -0.018. Remember that for this data, while the intercept has a mathematical interpretation, it has no <em>practical</em> interpretation since instructors can’t have zero age.</p>
<p>What about the intercept and slope for age of the male instructors in the blue line in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>? This is where our notion of “offsets” comes into play once again.</p>
<p>The value for <code>gendermale</code> of -0.446 is not the intercept for the male instructors, but rather the <em>offset</em> in intercept for male instructors relative to female instructors. The intercept for the male instructors is <code>intercept + gendermale</code> = 4.883 + (-0.446) = 4.883 - 0.446 = 4.437.</p>
<p>Similarly, <code>age:gendermale</code> = 0.014 is not the slope for age for the male instructors, but rather the <em>offset</em> in slope for the male instructors. Therefore, the slope for age for the male instructors is <code>age + age:gendermale</code> <span class="math inline">\(= -0.018 + 0.014 = -0.004\)</span>. Thus, the blue regression line in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a> has intercept 4.437 and slope for age of -0.004. Let’s summarize these values in Table <a href="12-multiple-regression.html#tab:interaction-summary">12.5</a> and focus on the two slopes for age:</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:interaction-summary">TABLE 12.5: </span>Comparison of intercepts and slopes for interaction model
</caption>
<thead>
<tr>
<th style="text-align:left;">
Gender
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Slope for age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Female instructors
</td>
<td style="text-align:right;">
4.883
</td>
<td style="text-align:right;">
-0.018
</td>
</tr>
<tr>
<td style="text-align:left;">
Male instructors
</td>
<td style="text-align:right;">
4.437
</td>
<td style="text-align:right;">
-0.004
</td>
</tr>
</tbody>
</table>
<p>Since the slope for age for the female instructors was -0.018, it means that on average, a female instructor who is a year older would have a teaching score that is 0.018 units <strong>lower</strong>. For the male instructors, however, the corresponding associated decrease was on average only 0.004 units. While both slopes for age were negative, the slope for age for the female instructors is <em>more negative</em>. This is consistent with our observation from Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>, that this model is suggesting that age impacts teaching scores for female instructors more than for male instructors.</p>
<p>Let’s now write the equation for our regression lines, which we can use to compute our fitted values <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\text{age}} \cdot \text{age} + b_{\text{male}} \cdot \mathbb{1}_{\text{is male}}(x) + b_{\text{age,male}} \cdot \text{age} \cdot \mathbb{1}_{\text{is male}}\\
&amp;= 4.883 -0.018 \cdot \text{age} - 0.446 \cdot \mathbb{1}_{\text{is male}}(x) + 0.014 \cdot \text{age} \cdot \mathbb{1}_{\text{is male}}
\end{aligned}
\]</span></p>
<p>Whoa! That’s even more daunting than the equation you saw for the life expectancy as a function of continent in Subsection <a href="11-regression.html#model2table">11.3.2</a>! However, if you recall what an “indicator function” does, the equation simplifies greatly. In the previous equation, we have one indicator function of interest:</p>
<p><span class="math display">\[
\mathbb{1}_{\text{is male}}(x) = \left\{
\begin{array}{ll}
1 &amp; \text{if } \text{instructor } x \text{ is male} \\
0 &amp; \text{otherwise}\end{array}
\right.
\]</span></p>
<p>Second, let’s match coefficients in the previous equation with values in the <code>estimate</code> column in our regression table in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(b_0\)</span> is the <code>intercept</code> = 4.883 for the female instructors</li>
<li><span class="math inline">\(b_{\text{age}}\)</span> is the slope for <code>age</code> = -0.018 for the female instructors</li>
<li><span class="math inline">\(b_{\text{male}}\)</span> is the offset in intercept = -0.446 for the male instructors</li>
<li><span class="math inline">\(b_{\text{age,male}}\)</span> is the offset in slope for age = 0.014 for the male instructors</li>
</ol>
<p>Let’s put this all together and compute the fitted value <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span> for female instructors. Since for female instructors <span class="math inline">\(\mathbb{1}_{\text{is male}}(x)\)</span> = 0, the previous equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= 4.883 - 0.018   \cdot \text{age} - 0.446 \cdot 0 + 0.014 \cdot \text{age} \cdot 0\\
&amp;= 4.883 - 0.018    \cdot \text{age} - 0 + 0\\
&amp;= 4.883 - 0.018    \cdot \text{age}\\
\end{aligned}
\]</span></p>
<p>which is the equation of the red regression line in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a> corresponding to the female instructors in Table <a href="12-multiple-regression.html#tab:interaction-summary">12.5</a>. Correspondingly, since for male instructors <span class="math inline">\(\mathbb{1}_{\text{is male}}(x)\)</span> = 1, the previous equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= 4.883 - 0.018   \cdot \text{age} - 0.446 + 0.014 \cdot \text{age}\\
&amp;= (4.883 - 0.446) + (- 0.018 + 0.014) * \text{age}\\
&amp;= 4.437 - 0.004    \cdot \text{age}\\
\end{aligned}
\]</span></p>
<p>which is the equation of the blue regression line in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a> corresponding to the male instructors in Table <a href="12-multiple-regression.html#tab:interaction-summary">12.5</a>.</p>
<p>Phew! That was a lot of arithmetic! Don’t fret, however, this is as hard as modeling will get in this book. If you’re still a little unsure about using indicator functions and using categorical explanatory variables in a regression model, we <em>highly</em> suggest you re-read Subsection <a href="11-regression.html#model2table">11.3.2</a>. This involves only a single categorical explanatory variable and thus is much simpler.</p>
<p>Before we end this section, we explain why we refer to this type of model as an “interaction model.” The <span class="math inline">\(b_{\text{age,male}}\)</span> term in the equation for the fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> is what’s known in statistical modeling as an “interaction effect.” The interaction term corresponds to the <code>age:gendermale</code> = 0.014 in the final row of the regression table in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>.</p>
<p>We say there is an interaction effect if the associated effect of one variable <em>depends on the value of another variable</em>. That is to say, the two variables are “interacting” with each other. Here, the associated effect of the variable age <em>depends</em> on the value of the other variable gender. The difference in slopes for age of +0.014 of male instructors relative to female instructors shows this. </p>
<p>Another way of thinking about interaction effects on teaching scores is as follows. For a given instructor at UT Austin, there might be an associated effect of their age <em>by itself</em>, there might be an associated effect of their gender <em>by itself</em>, but when age and gender are considered <em>together</em> there might be an <em>additional effect</em> above and beyond the two individual effects.</p>
</div>
<div id="model4table" class="section level3">
<h3><span class="header-section-number">12.1.3</span> Parallel slopes model</h3>
<p>When creating regression models with one numerical and one categorical explanatory variable, we are not just limited to interaction models as we just saw. Another type of model we can use is known as a <em>parallel slopes</em> model. Unlike interaction models where the regression lines can have different intercepts and different slopes, parallel slopes models still allow for different intercepts but <em>force</em> all lines to have the same slope. The resulting regression lines are thus parallel. Let’s visualize the best-fitting parallel slopes model to <code>evals_ch12</code>.</p>
<p>Unfortunately, the <code>geom_smooth()</code> function in the <code>ggplot2</code> package does not have a convenient way to plot parallel slopes models. Evgeni Chasnovski thus created a special purpose function called <code>geom_parallel_slopes()</code> that is included in the <strong>moderndive</strong> package. You won’t find <code>geom_parallel_slopes()</code> in the <strong>ggplot2</strong> package, but rather the <strong>moderndive</strong> package. Thus, if you want to be able to use it, you will need to load both the <strong>ggplot2</strong> and <strong>moderndive</strong> packages. Using this function, let’s now plot the parallel slopes model for teaching score. Notice how the code is identical to the code that produced the visualization of the interaction model in Figure <a href="12-multiple-regression.html#fig:numxcatxplot1">12.1</a>, but now the <code>geom_smooth(method = "lm", se = FALSE)</code> layer is replaced with <code>geom_parallel_slopes(se = FALSE)</code>.</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="12-multiple-regression.html#cb797-1"></a><span class="kw">ggplot</span>(evals_ch12, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> score, <span class="dt">color =</span> gender)) <span class="op">+</span></span>
<span id="cb797-2"><a href="12-multiple-regression.html#cb797-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb797-3"><a href="12-multiple-regression.html#cb797-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Age&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;Gender&quot;</span>) <span class="op">+</span></span>
<span id="cb797-4"><a href="12-multiple-regression.html#cb797-4"></a><span class="st">  </span><span class="kw">geom_parallel_slopes</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-parallel"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/numxcatx-parallel-1.png" alt="Parallel slopes model of score with age and gender." width="\textwidth" />
<p class="caption">
FIGURE 12.2: Parallel slopes model of score with age and gender.
</p>
</div>
<p>Observe in Figure <a href="12-multiple-regression.html#fig:numxcatx-parallel">12.2</a> that we now have parallel lines corresponding to the female and male instructors, respectively: here they have the same negative slope. This is telling us that instructors who are older will tend to receive lower teaching scores than instructors who are younger. Furthermore, since the lines are parallel, the associated penalty for being older is assumed to be the same for both female and male instructors.</p>
<p>However, observe also in Figure <a href="12-multiple-regression.html#fig:numxcatx-parallel">12.2</a> that these two lines have different intercepts as evidenced by the fact that the blue line corresponding to the male instructors is higher than the red line corresponding to the female instructors. This is telling us that irrespective of age, female instructors tended to receive lower teaching scores than male instructors.</p>
<p>In order to obtain the precise numerical values of the two intercepts and the single common slope, we once again “fit” the model using the <code>lm()</code> “linear model” function and then apply the <code>tidy()</code> function. However, unlike the interaction model which had a model formula of the form <code>y ~ x1 * x2</code>, our model formula is now of the form <code>y ~ x1 + x2</code>. In other words, our two explanatory variables <code>x1</code> and <code>x2</code> are separated by a <code>+</code> sign:</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="12-multiple-regression.html#cb798-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb798-2"><a href="12-multiple-regression.html#cb798-2"></a></span>
<span id="cb798-3"><a href="12-multiple-regression.html#cb798-3"></a>score_model_parallel_slopes &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> evals_ch12)</span>
<span id="cb798-4"><a href="12-multiple-regression.html#cb798-4"></a></span>
<span id="cb798-5"><a href="12-multiple-regression.html#cb798-5"></a><span class="co"># Get regression table:</span></span>
<span id="cb798-6"><a href="12-multiple-regression.html#cb798-6"></a></span>
<span id="cb798-7"><a href="12-multiple-regression.html#cb798-7"></a>score_model_parallel_slopes <span class="op">%&gt;%</span></span>
<span id="cb798-8"><a href="12-multiple-regression.html#cb798-8"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb798-9"><a href="12-multiple-regression.html#cb798-9"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:regtable-parallel-slopes">TABLE 12.6: </span>Regression table for parallel slopes model
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
4.484
</td>
<td style="text-align:right;">
4.238
</td>
<td style="text-align:right;">
4.730
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
-0.009
</td>
<td style="text-align:right;">
-0.014
</td>
<td style="text-align:right;">
-0.003
</td>
</tr>
<tr>
<td style="text-align:left;">
gendermale
</td>
<td style="text-align:right;">
0.191
</td>
<td style="text-align:right;">
0.087
</td>
<td style="text-align:right;">
0.294
</td>
</tr>
</tbody>
</table>
<p>Similarly to the regression table for the interaction model from Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>, we have an <code>intercept</code> term corresponding to the intercept for the “baseline for comparison” female instructor group and a <code>gendermale</code> term corresponding to the <em>offset</em> in intercept for the male instructors relative to female instructors. In other words, in Figure <a href="12-multiple-regression.html#fig:numxcatx-parallel">12.2</a> the red regression line corresponding to the female instructors has an intercept of 4.484 while the blue regression line corresponding to the male instructors has an intercept of 4.484 + 0.191 = 4.675. Once again, since there aren’t any instructors of age 0, the intercepts only have a mathematical interpretation but no practical one.</p>
<p>Unlike in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>, however, we now only have a single slope for age of -0.009. This is because the model dictates that both the female and male instructors have a common slope for age.  This is telling us that an instructor who is a year older than another instructor received a teaching score that is on average 0.009 units <em>lower</em>. This penalty for being of advanced age applies equally to both female and male instructors.</p>
<p>Let’s summarize these values in Table <a href="12-multiple-regression.html#tab:parallel-slopes-summary">12.7</a>, noting the different intercepts but common slopes:</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:parallel-slopes-summary">TABLE 12.7: </span>Comparison of intercepts and slope for parallel slopes model
</caption>
<thead>
<tr>
<th style="text-align:left;">
Gender
</th>
<th style="text-align:right;">
Intercept
</th>
<th style="text-align:right;">
Slope for age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Female instructors
</td>
<td style="text-align:right;">
4.484
</td>
<td style="text-align:right;">
-0.009
</td>
</tr>
<tr>
<td style="text-align:left;">
Male instructors
</td>
<td style="text-align:right;">
4.675
</td>
<td style="text-align:right;">
-0.009
</td>
</tr>
</tbody>
</table>
<p>Let’s now write the equation for our regression lines, which we can use to compute our fitted values <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= b_0 + b_{\text{age}} \cdot \text{age} + b_{\text{male}} \cdot \mathbb{1}_{\text{is male}}(x)\\
&amp;= 4.484 -0.009 \cdot \text{age} + 0.191 \cdot \mathbb{1}_{\text{is male}}(x) 
\end{aligned}
\]</span></p>
<p>Let’s put this all together and compute the fitted value <span class="math inline">\(\widehat{y} = \widehat{\text{score}}\)</span> for female instructors. Since for female instructors the indicator function <span class="math inline">\(\mathbb{1}_{\text{is male}}(x)\)</span> = 0, the previous equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= 4.484 -0.009    \cdot \text{age} + 0.191 \cdot 0\\
&amp;= 4.484 -0.009 \cdot \text{age}
\end{aligned}
\]</span></p>
<p>which is the equation of the red regression line in Figure <a href="12-multiple-regression.html#fig:numxcatx-parallel">12.2</a> corresponding to the female instructors. Correspondingly, since for male instructors the indicator function <span class="math inline">\(\mathbb{1}_{\text{is male}}(x)\)</span> = 1, the previous equation becomes</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{score}} &amp;= 4.484 -0.009    \cdot \text{age} + 0.191 \cdot 1\\
&amp;= (4.484 + 0.191) - 0.009 \cdot \text{age}\\
&amp;= 4.675 -0.009 \cdot \text{age}
\end{aligned}
\]</span></p>
<p>which is the equation of the blue regression line in Figure <a href="12-multiple-regression.html#fig:numxcatx-parallel">12.2</a> corresponding to the male instructors.</p>
<p>Great! We’ve considered both an interaction model and a parallel slopes model for our data. Let’s compare the visualizations for both models side-by-side in Figure <a href="12-multiple-regression.html#fig:numxcatx-comparison">12.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-comparison"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/numxcatx-comparison-1.png" alt="Comparison of interaction and parallel slopes models." width="\textwidth" />
<p class="caption">
FIGURE 12.3: Comparison of interaction and parallel slopes models.
</p>
</div>
<p>At this point, you might be asking yourself: “Why would we ever use a parallel slopes model?”. Looking at the left-hand plot in Figure <a href="12-multiple-regression.html#fig:numxcatx-comparison">12.3</a>, the two lines definitely do not appear to be parallel, so why would we <em>force</em> them to be parallel? For this data, we agree! It can easily be argued that the interaction model on the left is more appropriate. However, in the upcoming Subsection <a href="12-multiple-regression.html#model-selection">12.3.1</a> on model selection, we’ll present an example where it can be argued that the case for a parallel slopes model might be stronger.</p>
</div>
<div id="model4points" class="section level3">
<h3><span class="header-section-number">12.1.4</span> Observed/fitted values and residuals</h3>
<p>For brevity’s sake, in this section we’ll only compute the observed values, fitted values, and residuals for the interaction model which we saved in <code>score_model_interaction</code>.</p>
<p>Say, you have an instructor who identifies as female and is 36 years old. What fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> would our model yield? Say, you have another instructor who identifies as male and is 59 years old. What would their fitted value <span class="math inline">\(\widehat{y}\)</span> be?</p>
<p>We answer this question visually first for the female instructor by finding the intersection of the red regression line and the vertical line at <span class="math inline">\(x\)</span> = age = 36. We mark this value with a large red dot in Figure <a href="12-multiple-regression.html#fig:fitted-values">12.4</a>. Similarly, we can identify the fitted value <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> for the male instructor by finding the intersection of the blue regression line and the vertical line at <span class="math inline">\(x\)</span> = age = 59. We mark this value with a large blue dot in Figure <a href="12-multiple-regression.html#fig:fitted-values">12.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:fitted-values"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/fitted-values-1.png" alt="Fitted values for two new professors." width="\textwidth" />
<p class="caption">
FIGURE 12.4: Fitted values for two new professors.
</p>
</div>
<p>What are these two values of <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> precisely? We can use the equations of the two regression lines we computed in Subsection <a href="12-multiple-regression.html#model4interactiontable">12.1.2</a>, which in turn were based on values from the regression table in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a>:</p>
<ul>
<li>For all female instructors: <span class="math inline">\(\widehat{y} = \widehat{\text{score}} = 4.883 - 0.018 \cdot \text{age}\)</span></li>
<li>For all male instructors: <span class="math inline">\(\widehat{y} = \widehat{\text{score}} = 4.437 - 0.004 \cdot \text{age}\)</span></li>
</ul>
<p>So our fitted values would be: <span class="math inline">\(4.883 - 0.018 \cdot 36 = 4.25\)</span> and <span class="math inline">\(4.437 - 0.004 \cdot 59 = 4.20\)</span>, respectively.</p>
<p>Now what if we want the fitted values not just for these two instructors, but for the instructors of all 463 courses included in the <code>evals_ch12</code> data frame? Doing this by hand would be long and tedious! This is where the <code>augment()</code> function from the <strong>broom</strong> package can help: it will quickly automate the above calculations for all 463 courses. We present a preview of just the first 10 rows out of 463 in Table <a href="12-multiple-regression.html#tab:model4-points-table">12.8</a>.</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="12-multiple-regression.html#cb799-1"></a>regression_points &lt;-<span class="st"> </span><span class="kw">augment</span>(score_model_interaction)</span>
<span id="cb799-2"><a href="12-multiple-regression.html#cb799-2"></a>regression_points</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model4-points-table">TABLE 12.8: </span>Regression points (First 10 out of 463 courses)
</caption>
<thead>
<tr>
<th style="text-align:right;">
score
</th>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
gender
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.se.fit
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
4.7
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
4.25
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
0.448
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.847
</td>
</tr>
<tr>
<td style="text-align:right;">
4.1
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
4.25
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
-0.152
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.288
</td>
</tr>
<tr>
<td style="text-align:right;">
3.9
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
4.25
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
-0.352
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
-0.666
</td>
</tr>
<tr>
<td style="text-align:right;">
4.8
</td>
<td style="text-align:right;">
36
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
4.25
</td>
<td style="text-align:right;">
0.056
</td>
<td style="text-align:right;">
0.548
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.531
</td>
<td style="text-align:right;">
0.003
</td>
<td style="text-align:right;">
1.037
</td>
</tr>
<tr>
<td style="text-align:right;">
4.6
</td>
<td style="text-align:right;">
59
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
4.20
</td>
<td style="text-align:right;">
0.042
</td>
<td style="text-align:right;">
0.399
</td>
<td style="text-align:right;">
0.006
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.752
</td>
</tr>
<tr>
<td style="text-align:right;">
4.3
</td>
<td style="text-align:right;">
59
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
4.20
</td>
<td style="text-align:right;">
0.042
</td>
<td style="text-align:right;">
0.099
</td>
<td style="text-align:right;">
0.006
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.186
</td>
</tr>
<tr>
<td style="text-align:right;">
2.8
</td>
<td style="text-align:right;">
59
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
4.20
</td>
<td style="text-align:right;">
0.042
</td>
<td style="text-align:right;">
-1.401
</td>
<td style="text-align:right;">
0.006
</td>
<td style="text-align:right;">
0.528
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-2.645
</td>
</tr>
<tr>
<td style="text-align:right;">
4.1
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
4.23
</td>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
-0.133
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.251
</td>
</tr>
<tr>
<td style="text-align:right;">
3.4
</td>
<td style="text-align:right;">
51
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
4.23
</td>
<td style="text-align:right;">
0.032
</td>
<td style="text-align:right;">
-0.833
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.531
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
-1.571
</td>
</tr>
<tr>
<td style="text-align:right;">
4.5
</td>
<td style="text-align:right;">
40
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
4.18
</td>
<td style="text-align:right;">
0.044
</td>
<td style="text-align:right;">
0.318
</td>
<td style="text-align:right;">
0.007
</td>
<td style="text-align:right;">
0.532
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.600
</td>
</tr>
</tbody>
</table>
<p>It turns out that the female instructor of age 36 taught the first four courses, while the male instructor taught the next 3. The resulting <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> fitted values are in the <code>.fitted</code> column. Furthermore, the <code>augment()</code> function also returns the residuals <span class="math inline">\(y-\widehat{y}\)</span>. Notice, for example, the first and fourth courses the female instructor of age 36 taught had positive residuals, indicating that the actual teaching scores they received from students were greater than their fitted score of 4.25. On the other hand, the second and third courses this instructor taught had negative residuals, indicating that the actual teaching scores they received from students were less than 4.25.</p>
</div>
</div>
<div id="model3" class="section level2">
<h2><span class="header-section-number">12.2</span> Two numerical explanatory variables</h2>
<p>Let’s now switch gears and consider multiple regression models where instead of one numerical and one categorical explanatory variable, we now have two numerical explanatory variables. The dataset we’ll use is from <a href="http://www-bcf.usc.edu/~gareth/ISL/"><em>An Introduction to Statistical Learning with Applications in R (ISLR)</em></a>, an intermediate-level textbook on statistical and machine learning <span class="citation">(James et al. <a href="#ref-islr2017" role="doc-biblioref">2017</a>)</span>. Its accompanying <strong>ISLR</strong> R package contains the datasets to which the authors apply various machine learning methods.</p>
<p>One frequently used dataset in this book is the <code>Credit</code> dataset, where the outcome variable of interest is the credit card debt of 400 individuals. Other variables like income, credit limit, credit rating, and age are included as well. Note that the <code>Credit</code> data is not based on real individuals’ financial information, but rather is a simulated dataset used for educational purposes.</p>
<p>In this section, we’ll fit a regression model where we have</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span>, the cardholder’s credit card debt</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>One numerical explanatory variable <span class="math inline">\(x_1\)</span>, the cardholder’s credit limit</li>
<li>Another numerical explanatory variable <span class="math inline">\(x_2\)</span>, the cardholder’s income (in thousands of dollars).</li>
</ol></li>
</ol>
<div id="model3EDA" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Exploratory data analysis</h3>
<p>Let’s load the <code>Credit</code> dataset. To keep things simple let’s <code>select()</code> the subset of the variables we’ll consider in this chapter, and save this data in the new data frame <code>credit_ch12</code>. Notice our slightly different use of the <code>select()</code> verb here than we introduced in Subsection <a href="4-wrangling.html#select">4.10.1</a>. For example, we’ll select the <code>Balance</code> variable from <code>Credit</code> but then save it with a new variable name <code>debt</code>. We do this because here the term “debt” is easier to interpret than “balance.”</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="12-multiple-regression.html#cb800-1"></a><span class="kw">library</span>(ISLR)</span>
<span id="cb800-2"><a href="12-multiple-regression.html#cb800-2"></a>credit_ch12 &lt;-<span class="st"> </span>Credit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-3"><a href="12-multiple-regression.html#cb800-3"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-4"><a href="12-multiple-regression.html#cb800-4"></a><span class="st">  </span><span class="kw">select</span>(ID, <span class="dt">debt =</span> Balance, <span class="dt">credit_limit =</span> Limit, </span>
<span id="cb800-5"><a href="12-multiple-regression.html#cb800-5"></a>         <span class="dt">income =</span> Income, <span class="dt">credit_rating =</span> Rating, <span class="dt">age =</span> Age)</span></code></pre></div>
<p>You can observe the effect of our use of <code>select()</code> in the first common step of an exploratory data analysis: looking at the raw values either in RStudio’s spreadsheet viewer or by using <code>glimpse()</code>.</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="12-multiple-regression.html#cb801-1"></a><span class="kw">glimpse</span>(credit_ch12)</span></code></pre></div>
<pre><code>Observations: 400
Variables: 6
$ ID            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …
$ debt          &lt;int&gt; 333, 903, 580, 964, 331, 1151, 203, 872, 279, 1350, 140…
$ credit_limit  &lt;int&gt; 3606, 6645, 7075, 9504, 4897, 8047, 3388, 7114, 3300, 6…
$ income        &lt;dbl&gt; 14.9, 106.0, 104.6, 148.9, 55.9, 80.2, 21.0, 71.4, 15.1…
$ credit_rating &lt;int&gt; 283, 483, 514, 681, 357, 569, 259, 512, 266, 491, 589, …
$ age           &lt;int&gt; 34, 82, 71, 36, 68, 77, 37, 87, 66, 41, 30, 64, 57, 49,…</code></pre>
<p>Furthermore, let’s look at a random sample of five out of the 400 credit card holders in Table <a href="12-multiple-regression.html#tab:model3-data-preview">12.9</a>. Once again, note that due to the random nature of the sampling, you will likely end up with a different subset of five rows.</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="12-multiple-regression.html#cb803-1"></a>credit_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb803-2"><a href="12-multiple-regression.html#cb803-2"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model3-data-preview">TABLE 12.9: </span>Random sample of 5 credit card holders
</caption>
<thead>
<tr>
<th style="text-align:right;">
ID
</th>
<th style="text-align:right;">
debt
</th>
<th style="text-align:right;">
credit_limit
</th>
<th style="text-align:right;">
income
</th>
<th style="text-align:right;">
credit_rating
</th>
<th style="text-align:right;">
age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
272
</td>
<td style="text-align:right;">
436
</td>
<td style="text-align:right;">
4866
</td>
<td style="text-align:right;">
45.0
</td>
<td style="text-align:right;">
347
</td>
<td style="text-align:right;">
30
</td>
</tr>
<tr>
<td style="text-align:right;">
239
</td>
<td style="text-align:right;">
52
</td>
<td style="text-align:right;">
2910
</td>
<td style="text-align:right;">
26.5
</td>
<td style="text-align:right;">
236
</td>
<td style="text-align:right;">
58
</td>
</tr>
<tr>
<td style="text-align:right;">
87
</td>
<td style="text-align:right;">
815
</td>
<td style="text-align:right;">
6340
</td>
<td style="text-align:right;">
55.4
</td>
<td style="text-align:right;">
448
</td>
<td style="text-align:right;">
33
</td>
</tr>
<tr>
<td style="text-align:right;">
108
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3189
</td>
<td style="text-align:right;">
39.1
</td>
<td style="text-align:right;">
263
</td>
<td style="text-align:right;">
72
</td>
</tr>
<tr>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2420
</td>
<td style="text-align:right;">
15.2
</td>
<td style="text-align:right;">
192
</td>
<td style="text-align:right;">
69
</td>
</tr>
</tbody>
</table>
<p>Now that we’ve looked at the raw values in our <code>credit_ch12</code> data frame and got a sense of the data, let’s move on to the next common step in an exploratory data analysis: computing summary statistics. Let’s use the <code>skim()</code> function from the <strong>skimr</strong> package, being sure to only <code>select()</code> the columns of interest for our model:</p>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="12-multiple-regression.html#cb804-1"></a>credit_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb804-2"><a href="12-multiple-regression.html#cb804-2"></a><span class="st">  </span><span class="kw">select</span>(debt, credit_limit, income) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb804-3"><a href="12-multiple-regression.html#cb804-3"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
<span id="tab:unnamed-chunk-541">TABLE 12.10: </span>Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
Piped data
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
400
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
debt
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
520.0
</td>
<td style="text-align:right;">
459.8
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
68.8
</td>
<td style="text-align:right;">
459.5
</td>
<td style="text-align:right;">
863.0
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
▇▅▃▂▁
</td>
</tr>
<tr>
<td style="text-align:left;">
credit_limit
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4735.6
</td>
<td style="text-align:right;">
2308.2
</td>
<td style="text-align:right;">
855.0
</td>
<td style="text-align:right;">
3088.0
</td>
<td style="text-align:right;">
4622.5
</td>
<td style="text-align:right;">
5872.8
</td>
<td style="text-align:right;">
13913
</td>
<td style="text-align:left;">
▆▇▃▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
45.2
</td>
<td style="text-align:right;">
35.2
</td>
<td style="text-align:right;">
10.3
</td>
<td style="text-align:right;">
21.0
</td>
<td style="text-align:right;">
33.1
</td>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
187
</td>
<td style="text-align:left;">
▇▂▁▁▁
</td>
</tr>
</tbody>
</table>
<p>Observe the summary statistics for the outcome variable <code>debt</code>: the mean and median credit card debt are $520.01 and $459.50, respectively, and that 25% of card holders had debts of $68.75 or less. Let’s now look at one of the explanatory variables <code>credit_limit</code>: the mean and median credit card limit are $4735.6 and $4622.50, respectively, while 75% of card holders had incomes of $57,470 or less.</p>
<p>Since our outcome variable <code>debt</code> and the explanatory variables <code>credit_limit</code> and <code>income</code> are numerical, we can compute the correlation coefficient between the different possible pairs of these variables. First, we can run the <code>cor()</code> command as seen in Subsection <a href="11-regression.html#model1EDA">11.1.1</a> twice, once for each explanatory variable:</p>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="12-multiple-regression.html#cb805-1"></a>credit_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb805-2"><a href="12-multiple-regression.html#cb805-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">correlation =</span> <span class="kw">cor</span>(debt, credit_limit)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb805-3"><a href="12-multiple-regression.html#cb805-3"></a><span class="st">  </span><span class="kw">pull</span>(correlation)</span>
<span id="cb805-4"><a href="12-multiple-regression.html#cb805-4"></a>credit_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb805-5"><a href="12-multiple-regression.html#cb805-5"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">correlation =</span> <span class="kw">cor</span>(debt, income)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb805-6"><a href="12-multiple-regression.html#cb805-6"></a><span class="st">  </span><span class="kw">pull</span>(correlation)</span></code></pre></div>
<p>Or we can simultaneously compute them by returning a <em>correlation matrix</em> which we display in Table <a href="12-multiple-regression.html#tab:model3-correlation">12.11</a>.  We can see the correlation coefficient for any pair of variables by looking them up in the appropriate row/column combination.</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="12-multiple-regression.html#cb806-1"></a>credit_ch12 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb806-2"><a href="12-multiple-regression.html#cb806-2"></a><span class="st">  </span><span class="kw">select</span>(debt, credit_limit, income) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb806-3"><a href="12-multiple-regression.html#cb806-3"></a><span class="st">  </span><span class="kw">cor</span>()</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model3-correlation">TABLE 12.11: </span>Correlation coefficients between credit card debt, credit limit, and income
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
debt
</th>
<th style="text-align:right;">
credit_limit
</th>
<th style="text-align:right;">
income
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
debt
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.862
</td>
<td style="text-align:right;">
0.464
</td>
</tr>
<tr>
<td style="text-align:left;">
credit_limit
</td>
<td style="text-align:right;">
0.862
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.792
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
0.464
</td>
<td style="text-align:right;">
0.792
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
<p>For example, the correlation coefficient of:</p>
<ol style="list-style-type: decimal">
<li><code>debt</code> with itself is 1 as we would expect based on the definition of the correlation coefficient.</li>
<li><code>debt</code> with <code>credit_limit</code> is 0.862. This indicates a strong positive linear relationship, which makes sense as only individuals with large credit limits can accrue large credit card debts.</li>
<li><code>debt</code> with <code>income</code> is 0.464. This is suggestive of another positive linear relationship, although not as strong as the relationship between <code>debt</code> and <code>credit_limit</code>.</li>
<li>As an added bonus, we can read off the correlation coefficient between the two explanatory variables of <code>credit_limit</code> and <code>income</code> as 0.792.</li>
</ol>
<p>We say there is a high degree of <em>collinearity</em> between the <code>credit_limit</code> and <code>income</code> explanatory variables. Collinearity (or multicollinearity) is a phenomenon where one explanatory variable in a multiple regression model is highly correlated with another.</p>
<p>So in our case since <code>credit_limit</code> and <code>income</code> are highly correlated, if we knew someone’s <code>credit_limit</code>, we could make pretty good guesses about their <code>income</code> as well. Thus, these two variables provide somewhat redundant information. However, we’ll leave discussion on how to work with collinear explanatory variables to a more intermediate-level book on regression modeling.</p>
<p>Let’s visualize the relationship of the outcome variable with each of the two explanatory variables in two separate plots in Figure <a href="12-multiple-regression.html#fig:2numxplot1">12.5</a>.</p>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb807-1"><a href="12-multiple-regression.html#cb807-1"></a>credit_ch12 <span class="op">%&gt;%</span></span>
<span id="cb807-2"><a href="12-multiple-regression.html#cb807-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> credit_limit, <span class="dt">y =</span> debt)) <span class="op">+</span></span>
<span id="cb807-3"><a href="12-multiple-regression.html#cb807-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb807-4"><a href="12-multiple-regression.html#cb807-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Credit limit (in $)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card debt (in $)&quot;</span>, </span>
<span id="cb807-5"><a href="12-multiple-regression.html#cb807-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Debt and credit limit&quot;</span>) <span class="op">+</span></span>
<span id="cb807-6"><a href="12-multiple-regression.html#cb807-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</span>
<span id="cb807-7"><a href="12-multiple-regression.html#cb807-7"></a></span>
<span id="cb807-8"><a href="12-multiple-regression.html#cb807-8"></a>credit_ch12 <span class="op">%&gt;%</span></span>
<span id="cb807-9"><a href="12-multiple-regression.html#cb807-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> income, <span class="dt">y =</span> debt)) <span class="op">+</span></span>
<span id="cb807-10"><a href="12-multiple-regression.html#cb807-10"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb807-11"><a href="12-multiple-regression.html#cb807-11"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Income (in $1000)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Credit card debt (in $)&quot;</span>, </span>
<span id="cb807-12"><a href="12-multiple-regression.html#cb807-12"></a>       <span class="dt">title =</span> <span class="st">&quot;Debt and income&quot;</span>) <span class="op">+</span></span>
<span id="cb807-13"><a href="12-multiple-regression.html#cb807-13"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:2numxplot1"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/2numxplot1-1.png" alt="Relationship between credit card debt and credit limit/income." width="\textwidth" />
<p class="caption">
FIGURE 12.5: Relationship between credit card debt and credit limit/income.
</p>
</div>
<p>Observe there is a positive relationship between credit limit and credit card debt: as credit limit increases so also does credit card debt. This is consistent with the strongly positive correlation coefficient of 0.862 we computed earlier. In the case of income, the positive relationship doesn’t appear as strong, given the weakly positive correlation coefficient of 0.464.</p>
<p>However, the two plots in Figure <a href="12-multiple-regression.html#fig:2numxplot1">12.5</a> only focus on the relationship of the outcome variable with each of the two explanatory variables <em>separately</em>. To visualize the <em>joint</em> relationship of all three variables simultaneously, we need a 3-dimensional (3D) scatterplot as seen in Figure <a href="12-multiple-regression.html#fig:3D-scatterplot">12.6</a>. Each of the 400 observations in the <code>credit_ch12</code> data frame are marked with a blue point where</p>
<ol style="list-style-type: decimal">
<li>The numerical outcome variable <span class="math inline">\(y\)</span> <code>debt</code> is on the vertical axis.</li>
<li>The two numerical explanatory variables, <span class="math inline">\(x_1\)</span> <code>income</code> and <span class="math inline">\(x_2\)</span> <code>credit_limit</code>, are on the two axes that form the bottom plane.</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:3D-scatterplot"></span>
<img src="images/credit_card_balance_regression_plane.png" alt="3D scatterplot and regression plane." width="75%" />
<p class="caption">
FIGURE 12.6: 3D scatterplot and regression plane.
</p>
</div>
<p>Furthermore, we also include the <em>regression plane</em>. Recall from Subsection <a href="11-regression.html#leastsquares">11.5</a> that regression lines are “best-fitting” in that of all possible lines we can draw through a cloud of points, the regression line minimizes the <em>sum of squared residuals</em>. This concept also extends to models with two numerical explanatory variables. The difference is instead of a “best-fitting” line, we now have a “best-fitting” plane that similarly minimizes the sum of squared residuals. Head to <a href="https://moderndive.com/regression-plane">this website</a> to open an interactive version of this plot in your browser.</p>
</div>
<div id="model3table" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Regression plane</h3>
<p>Let’s now fit a regression model and get the regression table corresponding to the regression plane in Figure <a href="12-multiple-regression.html#fig:3D-scatterplot">12.6</a>. To keep things brief in this subsection, we won’t consider an interaction model for the two numerical explanatory variables <code>income</code> and <code>credit_limit</code> like we did in Subsection <a href="12-multiple-regression.html#model4interactiontable">12.1.2</a> using the model formula <code>score ~ age * gender</code>. Rather we’ll only consider a model fit with a formula of the form <code>y ~ x1 + x2</code>. Confusingly, however, since we now have a regression plane instead of multiple lines, the label “parallel slopes” doesn’t apply when you have two numerical explanatory variables. Just as we have done multiple times throughout Chapters <a href="11-regression.html#regression">11</a> and this chapter, the regression table for this model using our two-step process is in Table <a href="12-multiple-regression.html#tab:model3-table-output">12.12</a>.</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="12-multiple-regression.html#cb808-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb808-2"><a href="12-multiple-regression.html#cb808-2"></a></span>
<span id="cb808-3"><a href="12-multiple-regression.html#cb808-3"></a>debt_model &lt;-<span class="st"> </span><span class="kw">lm</span>(debt <span class="op">~</span><span class="st"> </span>credit_limit <span class="op">+</span><span class="st"> </span>income, <span class="dt">data =</span> credit_ch12)</span>
<span id="cb808-4"><a href="12-multiple-regression.html#cb808-4"></a></span>
<span id="cb808-5"><a href="12-multiple-regression.html#cb808-5"></a><span class="co"># Get regression table:</span></span>
<span id="cb808-6"><a href="12-multiple-regression.html#cb808-6"></a></span>
<span id="cb808-7"><a href="12-multiple-regression.html#cb808-7"></a>debt_model <span class="op">%&gt;%</span></span>
<span id="cb808-8"><a href="12-multiple-regression.html#cb808-8"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb808-9"><a href="12-multiple-regression.html#cb808-9"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model3-table-output">TABLE 12.12: </span>Multiple regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-385.179
</td>
<td style="text-align:right;">
-423.446
</td>
<td style="text-align:right;">
-346.912
</td>
</tr>
<tr>
<td style="text-align:left;">
credit_limit
</td>
<td style="text-align:right;">
0.264
</td>
<td style="text-align:right;">
0.253
</td>
<td style="text-align:right;">
0.276
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
-7.663
</td>
<td style="text-align:right;">
-8.420
</td>
<td style="text-align:right;">
-6.906
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>We first “fit” the linear regression model using the <code>lm(y ~ x1 + x2, data)</code> function and save it in <code>debt_model</code>.</li>
<li>We get the regression table by applying the <code>tidy()</code> function from the <strong>broom</strong> package to <code>debt_model</code>.</li>
</ol>
<p>Let’s interpret the three values in the <code>estimate</code> column. First, the <code>intercept</code> value is -$385.179. This intercept represents the credit card debt for an individual who has <code>credit_limit</code> of $0 and <code>income</code> of $0. In our data, however, the intercept has no practical interpretation since no individuals had <code>credit_limit</code> or <code>income</code> values of $0. Rather, the intercept is used to situate the regression plane in 3D space.</p>
<p>Second, the <code>credit_limit</code> value is $0.264. Taking into account all the other explanatory variables in our model, for every increase of one dollar in <code>credit_limit</code>, there is an associated increase of on average $0.26 in credit card debt. Just as we did in Subsection <a href="11-regression.html#model1table">11.1.2</a>, we are cautious <em>not</em> to imply causality as we have seen that “correlation is not necessarily causation.” We do this merely stating there was an <em>associated</em> increase.</p>
<p>Furthermore, we preface our interpretation with the statement, “taking into account all the other explanatory variables in our model.” Here, by all other explanatory variables we mean <code>income</code>. We do this to emphasize that we are now jointly interpreting the associated effect of multiple explanatory variables in the same model at the same time.</p>
<p>Third, <code>income</code> = -$7.66. Taking into account all other explanatory variables in our model, for every increase of one unit of <code>income</code> ($1000 in actual income), there is an associated decrease of, on average, $7.66 in credit card debt.</p>
<p>Putting these results together, the equation of the regression plane that gives us fitted values <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{debt}}\)</span> is:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} &amp;= b_0 + b_1 \cdot x_1 +  b_2 \cdot x_2\\
\widehat{\text{debt}} &amp;= b_0 + b_{\text{limit}} \cdot \text{limit} + b_{\text{income}} \cdot \text{income}\\
&amp;= -385.179 + 0.263 \cdot\text{limit} - 7.663 \cdot\text{income}
\end{aligned}
\]</span></p>
<p>Recall however in the right-hand plot of Figure <a href="12-multiple-regression.html#fig:2numxplot1">12.5</a> that when plotting the relationship between <code>debt</code> and <code>income</code> in isolation, there appeared to be a <em>positive</em> relationship. In the last discussed multiple regression, however, when <em>jointly</em> modeling the relationship between <code>debt</code>, <code>credit_limit</code>, and <code>income</code>, there appears to be a <em>negative</em> relationship of <code>debt</code> and <code>income</code> as evidenced by the negative slope for <code>income</code> of -$7.663. What explains these contradictory results? A phenomenon known as <em>Simpson’s Paradox</em>, whereby overall trends that exist in aggregate either disappear or reverse when the data are broken down into groups. In Subsection <a href="12-multiple-regression.html#simpsonsparadox">12.3.3</a> we elaborate on this idea by looking at the relationship between <code>credit_limit</code> and credit card <code>debt</code>, but split along different <code>income</code> brackets.</p>
</div>
<div id="model3points" class="section level3">
<h3><span class="header-section-number">12.2.3</span> Observed/fitted values and residuals</h3>
<p>Let’s also compute all fitted values and residuals for our regression model using the <code>augment()</code> function and present only the first 10 rows of output in Table <a href="12-multiple-regression.html#tab:model3-points-table">12.13</a>. Remember that the coordinates of each of the blue points in our 3D scatterplot in Figure <a href="12-multiple-regression.html#fig:3D-scatterplot">12.6</a> can be found in the <code>income</code>, <code>credit_limit</code>, and <code>debt</code> columns. The fitted values on the regression plane are found in the <code>.fitted</code> column and are computed using our equation for the regression plane in the previous section:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{debt}} &amp;= -385.179 + 0.263 \cdot \text{limit} - 7.663 \cdot \text{income}
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="12-multiple-regression.html#cb809-1"></a><span class="kw">augment</span>(debt_model)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model3-points-table">TABLE 12.13: </span>Regression points (First 10 credit card holders out of 400)
</caption>
<thead>
<tr>
<th style="text-align:right;">
debt
</th>
<th style="text-align:right;">
credit_limit
</th>
<th style="text-align:right;">
income
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.se.fit
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
333
</td>
<td style="text-align:right;">
3606
</td>
<td style="text-align:right;">
14.9
</td>
<td style="text-align:right;">
454
</td>
<td style="text-align:right;">
11.23
</td>
<td style="text-align:right;">
-120.8
</td>
<td style="text-align:right;">
0.005
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
-0.732
</td>
</tr>
<tr>
<td style="text-align:right;">
903
</td>
<td style="text-align:right;">
6645
</td>
<td style="text-align:right;">
106.0
</td>
<td style="text-align:right;">
559
</td>
<td style="text-align:right;">
18.06
</td>
<td style="text-align:right;">
344.3
</td>
<td style="text-align:right;">
0.012
</td>
<td style="text-align:right;">
165
</td>
<td style="text-align:right;">
0.018
</td>
<td style="text-align:right;">
2.093
</td>
</tr>
<tr>
<td style="text-align:right;">
580
</td>
<td style="text-align:right;">
7075
</td>
<td style="text-align:right;">
104.6
</td>
<td style="text-align:right;">
683
</td>
<td style="text-align:right;">
16.80
</td>
<td style="text-align:right;">
-103.4
</td>
<td style="text-align:right;">
0.010
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
-0.628
</td>
</tr>
<tr>
<td style="text-align:right;">
964
</td>
<td style="text-align:right;">
9504
</td>
<td style="text-align:right;">
148.9
</td>
<td style="text-align:right;">
986
</td>
<td style="text-align:right;">
25.99
</td>
<td style="text-align:right;">
-21.7
</td>
<td style="text-align:right;">
0.025
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.133
</td>
</tr>
<tr>
<td style="text-align:right;">
331
</td>
<td style="text-align:right;">
4897
</td>
<td style="text-align:right;">
55.9
</td>
<td style="text-align:right;">
481
</td>
<td style="text-align:right;">
8.95
</td>
<td style="text-align:right;">
-150.0
</td>
<td style="text-align:right;">
0.003
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
-0.908
</td>
</tr>
<tr>
<td style="text-align:right;">
1151
</td>
<td style="text-align:right;">
8047
</td>
<td style="text-align:right;">
80.2
</td>
<td style="text-align:right;">
1127
</td>
<td style="text-align:right;">
14.61
</td>
<td style="text-align:right;">
23.6
</td>
<td style="text-align:right;">
0.008
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.143
</td>
</tr>
<tr>
<td style="text-align:right;">
203
</td>
<td style="text-align:right;">
3388
</td>
<td style="text-align:right;">
21.0
</td>
<td style="text-align:right;">
349
</td>
<td style="text-align:right;">
10.06
</td>
<td style="text-align:right;">
-146.4
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
-0.887
</td>
</tr>
<tr>
<td style="text-align:right;">
872
</td>
<td style="text-align:right;">
7114
</td>
<td style="text-align:right;">
71.4
</td>
<td style="text-align:right;">
948
</td>
<td style="text-align:right;">
11.93
</td>
<td style="text-align:right;">
-76.0
</td>
<td style="text-align:right;">
0.005
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.460
</td>
</tr>
<tr>
<td style="text-align:right;">
279
</td>
<td style="text-align:right;">
3300
</td>
<td style="text-align:right;">
15.1
</td>
<td style="text-align:right;">
371
</td>
<td style="text-align:right;">
10.91
</td>
<td style="text-align:right;">
-92.2
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
166
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.558
</td>
</tr>
<tr>
<td style="text-align:right;">
1350
</td>
<td style="text-align:right;">
6819
</td>
<td style="text-align:right;">
71.1
</td>
<td style="text-align:right;">
873
</td>
<td style="text-align:right;">
11.15
</td>
<td style="text-align:right;">
477.3
</td>
<td style="text-align:right;">
0.005
</td>
<td style="text-align:right;">
164
</td>
<td style="text-align:right;">
0.013
</td>
<td style="text-align:right;">
2.891
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="related-topics" class="section level2">
<h2><span class="header-section-number">12.3</span> Related topics</h2>
<div id="model-selection" class="section level3">
<h3><span class="header-section-number">12.3.1</span> Model selection</h3>
<p>When should we use an interaction model versus a parallel slopes model? Recall in Sections <a href="12-multiple-regression.html#model4interactiontable">12.1.2</a> and <a href="12-multiple-regression.html#model4table">12.1.3</a> we fit both interaction and parallel slopes models for the outcome variable <span class="math inline">\(y\)</span> (teaching score) using a numerical explanatory variable <span class="math inline">\(x_1\)</span> (age) and a categorical explanatory variable <span class="math inline">\(x_2\)</span> (gender recorded as a binary variable). We compared these models in Figure <a href="12-multiple-regression.html#fig:numxcatx-comparison">12.3</a>, which we display again now.</p>
<div class="figure" style="text-align: center"><span id="fig:recall-parallel-vs-interaction"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/recall-parallel-vs-interaction-1.png" alt="Previously seen comparison of interaction and parallel slopes models." width="\textwidth" />
<p class="caption">
FIGURE 12.7: Previously seen comparison of interaction and parallel slopes models.
</p>
</div>
<p>A lot of you might have asked yourselves: “Why would I force the lines to have parallel slopes (as seen in the right-hand plot) when they clearly have different slopes (as seen in the left-hand plot)?”.</p>
<p>The answer lies in a philosophical principle known as “Occam’s Razor.” It states that, “all other things being equal, simpler solutions are more likely to be correct than complex ones.” When viewed in a modeling framework, Occam’s Razor  can be restated as, “all other things being equal, simpler models are to be preferred over complex ones.” In other words, we should only favor the more complex model if the additional complexity is <em>warranted</em>.</p>
<p>Let’s revisit the equations for the regression line for both the interaction and parallel slopes model:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Interaction} &amp;: \widehat{y} = \widehat{\text{score}} = b_0 + b_{\text{age}} \cdot \text{age} + b_{\text{male}} \cdot \mathbb{1}_{\text{is male}}(x) + \\
&amp; \qquad b_{\text{age,male}} \cdot \text{age} \cdot \mathbb{1}_{\text{is male}}\\
\text{Parallel slopes} &amp;: \widehat{y} = \widehat{\text{score}} = b_0 + b_{\text{age}} \cdot \text{age} + b_{\text{male}} \cdot \mathbb{1}_{\text{is male}}(x)
\end{aligned}
\]</span></p>
<p>The interaction model is “more complex” in that there is an additional <span class="math inline">\(b_{\text{age,male}} \cdot \text{age} \cdot \mathbb{1}_{\text{is male}}\)</span> interaction term in the equation not present for the parallel slopes model. Or viewed alternatively, the regression table for the interaction model in Table <a href="12-multiple-regression.html#tab:regtable-interaction">12.4</a> has <em>four</em> rows, whereas the regression table for the parallel slopes model in Table <a href="12-multiple-regression.html#tab:regtable-parallel-slopes">12.6</a> has <em>three</em> rows. The question becomes: “Is this additional complexity warranted?”. In this case, it can be argued that this additional complexity is warranted, as evidenced by the clear x-shaped pattern of the two regression lines in the left-hand plot of Figure <a href="12-multiple-regression.html#fig:recall-parallel-vs-interaction">12.7</a>.</p>
<p>However, let’s consider an example where the additional complexity might <em>not</em> be warranted. Let’s consider the <code>MA_schools</code> data included in the <strong>moderndive</strong> package which contains 2017 data on Massachusetts public high schools provided by the Massachusetts Department of Education. For more details, read the help file for this data by running <code>?MA_schools</code> in the console.</p>
<p>Let’s model the numerical outcome variable <span class="math inline">\(y\)</span>, average SAT math score for a given high school, as a function of two explanatory variables:</p>
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>, the percentage of that high school’s student body that are economically disadvantaged and</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>, the school size as measured by enrollment: small (13-341 students), medium (342-541 students), and large (542-4264 students).</li>
</ol>
<p>Let’s create visualizations of both the interaction and parallel slopes model once again and display the output in Figure <a href="12-multiple-regression.html#fig:numxcatx-comparison-2">12.8</a>. Recall from Subsection <a href="12-multiple-regression.html#model4table">12.1.3</a> that the <code>geom_parallel_slopes()</code> function is a special purpose function included in the <strong>moderndive</strong> package, since the <code>geom_smooth()</code> method in the <code>ggplot2</code> package does not have a convenient way to plot parallel slopes models.</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="12-multiple-regression.html#cb810-1"></a><span class="co"># Interaction model</span></span>
<span id="cb810-2"><a href="12-multiple-regression.html#cb810-2"></a></span>
<span id="cb810-3"><a href="12-multiple-regression.html#cb810-3"></a>MA_schools <span class="op">%&gt;%</span></span>
<span id="cb810-4"><a href="12-multiple-regression.html#cb810-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> perc_disadvan, <span class="dt">y =</span> average_sat_math, <span class="dt">color =</span> size)) <span class="op">+</span></span>
<span id="cb810-5"><a href="12-multiple-regression.html#cb810-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.25</span>) <span class="op">+</span></span>
<span id="cb810-6"><a href="12-multiple-regression.html#cb810-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb810-7"><a href="12-multiple-regression.html#cb810-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Percent economically disadvantaged&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math SAT Score&quot;</span>, </span>
<span id="cb810-8"><a href="12-multiple-regression.html#cb810-8"></a>       <span class="dt">color =</span> <span class="st">&quot;School size&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Interaction model&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="12-multiple-regression.html#cb811-1"></a><span class="co"># Parallel slopes model</span></span>
<span id="cb811-2"><a href="12-multiple-regression.html#cb811-2"></a></span>
<span id="cb811-3"><a href="12-multiple-regression.html#cb811-3"></a><span class="kw">ggplot</span>(MA_schools, </span>
<span id="cb811-4"><a href="12-multiple-regression.html#cb811-4"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> perc_disadvan, <span class="dt">y =</span> average_sat_math, <span class="dt">color =</span> size)) <span class="op">+</span></span>
<span id="cb811-5"><a href="12-multiple-regression.html#cb811-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.25</span>) <span class="op">+</span></span>
<span id="cb811-6"><a href="12-multiple-regression.html#cb811-6"></a><span class="st">  </span><span class="kw">geom_parallel_slopes</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb811-7"><a href="12-multiple-regression.html#cb811-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Percent economically disadvantaged&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Math SAT Score&quot;</span>, </span>
<span id="cb811-8"><a href="12-multiple-regression.html#cb811-8"></a>       <span class="dt">color =</span> <span class="st">&quot;School size&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;Parallel slopes model&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:numxcatx-comparison-2"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/numxcatx-comparison-2-1.png" alt="Comparison of interaction and parallel slopes models for Massachusetts schools." width="\textwidth" />
<p class="caption">
FIGURE 12.8: Comparison of interaction and parallel slopes models for Massachusetts schools.
</p>
</div>
<p>Look closely at the left-hand plot of Figure <a href="12-multiple-regression.html#fig:numxcatx-comparison-2">12.8</a> corresponding to an interaction model. While the slopes are indeed different, they do not differ <em>by much</em> and are nearly identical. Now compare the left-hand plot with the right-hand plot corresponding to a parallel slopes model. The two models don’t appear all that different. So in this case, it can be argued that the additional complexity of the interaction model is <em>not warranted</em>. Thus following Occam’s Razor, we should prefer the “simpler” parallel slopes model. Let’s explicitly define what “simpler” means in this case. Let’s compare the regression tables for the interaction and parallel slopes models in Tables <a href="12-multiple-regression.html#tab:model2-interaction">12.14</a> and <a href="12-multiple-regression.html#tab:model2-parallel-slopes">12.15</a>.</p>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="12-multiple-regression.html#cb812-1"></a>model_<span class="dv">2</span>_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(average_sat_math <span class="op">~</span><span class="st"> </span>perc_disadvan <span class="op">*</span><span class="st"> </span>size, </span>
<span id="cb812-2"><a href="12-multiple-regression.html#cb812-2"></a>                          <span class="dt">data =</span> MA_schools)</span>
<span id="cb812-3"><a href="12-multiple-regression.html#cb812-3"></a>model_<span class="dv">2</span>_interaction <span class="op">%&gt;%</span></span>
<span id="cb812-4"><a href="12-multiple-regression.html#cb812-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb812-5"><a href="12-multiple-regression.html#cb812-5"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model2-interaction">TABLE 12.14: </span>Interaction model regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
594.327
</td>
<td style="text-align:right;">
568.186
</td>
<td style="text-align:right;">
620.469
</td>
</tr>
<tr>
<td style="text-align:left;">
perc_disadvan
</td>
<td style="text-align:right;">
-2.932
</td>
<td style="text-align:right;">
-3.511
</td>
<td style="text-align:right;">
-2.353
</td>
</tr>
<tr>
<td style="text-align:left;">
sizemedium
</td>
<td style="text-align:right;">
-17.764
</td>
<td style="text-align:right;">
-48.899
</td>
<td style="text-align:right;">
13.371
</td>
</tr>
<tr>
<td style="text-align:left;">
sizelarge
</td>
<td style="text-align:right;">
-13.293
</td>
<td style="text-align:right;">
-40.466
</td>
<td style="text-align:right;">
13.880
</td>
</tr>
<tr>
<td style="text-align:left;">
perc_disadvan:sizemedium
</td>
<td style="text-align:right;">
0.146
</td>
<td style="text-align:right;">
-0.585
</td>
<td style="text-align:right;">
0.877
</td>
</tr>
<tr>
<td style="text-align:left;">
perc_disadvan:sizelarge
</td>
<td style="text-align:right;">
0.189
</td>
<td style="text-align:right;">
-0.446
</td>
<td style="text-align:right;">
0.824
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="12-multiple-regression.html#cb813-1"></a>model_<span class="dv">2</span>_parallel_slopes &lt;-<span class="st"> </span><span class="kw">lm</span>(average_sat_math <span class="op">~</span><span class="st"> </span>perc_disadvan <span class="op">+</span><span class="st"> </span>size, </span>
<span id="cb813-2"><a href="12-multiple-regression.html#cb813-2"></a>                              <span class="dt">data =</span> MA_schools)</span>
<span id="cb813-3"><a href="12-multiple-regression.html#cb813-3"></a>model_<span class="dv">2</span>_parallel_slopes <span class="op">%&gt;%</span></span>
<span id="cb813-4"><a href="12-multiple-regression.html#cb813-4"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb813-5"><a href="12-multiple-regression.html#cb813-5"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model2-parallel-slopes">TABLE 12.15: </span>Parallel slopes regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
588.19
</td>
<td style="text-align:right;">
573.23
</td>
<td style="text-align:right;">
603.15
</td>
</tr>
<tr>
<td style="text-align:left;">
perc_disadvan
</td>
<td style="text-align:right;">
-2.78
</td>
<td style="text-align:right;">
-2.99
</td>
<td style="text-align:right;">
-2.57
</td>
</tr>
<tr>
<td style="text-align:left;">
sizemedium
</td>
<td style="text-align:right;">
-11.91
</td>
<td style="text-align:right;">
-26.74
</td>
<td style="text-align:right;">
2.91
</td>
</tr>
<tr>
<td style="text-align:left;">
sizelarge
</td>
<td style="text-align:right;">
-6.36
</td>
<td style="text-align:right;">
-19.98
</td>
<td style="text-align:right;">
7.26
</td>
</tr>
</tbody>
</table>
<p>Observe how the regression table for the interaction model has 2 more rows (6 versus 4). This reflects the additional “complexity” of the interaction model over the parallel slopes model.</p>
<p>Furthermore, note in Table <a href="12-multiple-regression.html#tab:model2-interaction">12.14</a> how the <em>offsets for the slopes</em> <code>perc_disadvan:sizemedium</code> being 0.146 and <code>perc_disadvan:sizelarge</code> being 0.189 are small relative to the <em>slope for the baseline group</em> of small schools of <span class="math inline">\(-2.932\)</span>. In other words, all three slopes are similarly negative: <span class="math inline">\(-2.932\)</span> for small schools, <span class="math inline">\(-2.786\)</span> <span class="math inline">\((=-2.932 + 0.146)\)</span> for medium schools, and <span class="math inline">\(-2.743\)</span> <span class="math inline">\((=-2.932 + 0.189)\)</span> for large schools. These results are suggesting that irrespective of school size, the relationship between average math SAT scores and the percent of the student body that is economically disadvantaged is similar and, alas, quite negative.</p>
<p>What you have just performed is a rudimentary <em>model selection</em>: choosing which model fits data best among a set of candidate models. While the model selection approach we just took was visual in nature and hence somewhat qualitative, more statistically rigorous methods for model selection exist in the fields of multiple regression and statistical/machine learning.</p>
<!--
TODO:
Given that intercepts in the parallel slopes model in the right-hand plot of Figure \@ref(fig:numxcatx-comparison-2) are also similar as well, it can be argued that an even better model is one without the categorical variable school size. 
-->
</div>
<div id="correlationcoefficient2" class="section level3">
<h3><span class="header-section-number">12.3.2</span> Correlation coefficient</h3>
<p>Recall from Table <a href="12-multiple-regression.html#tab:model3-correlation">12.11</a> that the correlation coefficient between <code>income</code> in thousands of dollars and credit card <code>debt</code> was 0.464. What if instead we looked at the correlation coefficient between <code>income</code> and credit card <code>debt</code>, but where <code>income</code> was in dollars and not thousands of dollars? This can be done by multiplying <code>income</code> by 1000.</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="12-multiple-regression.html#cb814-1"></a>credit_ch12 <span class="op">%&gt;%</span></span>
<span id="cb814-2"><a href="12-multiple-regression.html#cb814-2"></a><span class="st">  </span><span class="kw">select</span>(debt, income) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb814-3"><a href="12-multiple-regression.html#cb814-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">income =</span> income <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb814-4"><a href="12-multiple-regression.html#cb814-4"></a><span class="st">  </span><span class="kw">cor</span>()</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:cor-credit-2">TABLE 12.16: </span>Correlation between income (in dollars) and credit card debt
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
debt
</th>
<th style="text-align:right;">
income
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
debt
</td>
<td style="text-align:right;">
1.000
</td>
<td style="text-align:right;">
0.464
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
0.464
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
<p>We see it is the same! We say that the correlation coefficient is <em>invariant to linear transformations</em>. The correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be the same as the correlation between <span class="math inline">\(a\cdot x + b\)</span> and <span class="math inline">\(y\)</span> for any numerical values <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
</div>
<div id="simpsonsparadox" class="section level3">
<h3><span class="header-section-number">12.3.3</span> Simpson’s Paradox</h3>
<p>Recall in Section <a href="12-multiple-regression.html#model3">12.2</a>, we saw the two seemingly contradictory results when studying the relationship between credit card <code>debt</code> and <code>income</code>. On the one hand, the right hand plot of Figure <a href="12-multiple-regression.html#fig:2numxplot1">12.5</a> suggested that the relationship between credit card <code>debt</code> and <code>income</code> was <em>positive</em>. We re-display this in Figure <a href="12-multiple-regression.html#fig:2numxplot1-repeat">12.9</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:2numxplot1-repeat"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/2numxplot1-repeat-1.png" alt="Relationship between credit card debt and income." width="\textwidth" />
<p class="caption">
FIGURE 12.9: Relationship between credit card debt and income.
</p>
</div>
<p>On the other hand, the multiple regression results in Table <a href="12-multiple-regression.html#tab:model3-table-output">12.12</a> suggested that the relationship between <code>debt</code> and <code>income</code> was <em>negative</em>. We re-display this information in Table <a href="12-multiple-regression.html#tab:model3-table-output-repeat">12.17</a>.</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model3-table-output-repeat">TABLE 12.17: </span>Multiple regression results
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-385.179
</td>
<td style="text-align:right;">
-423.446
</td>
<td style="text-align:right;">
-346.912
</td>
</tr>
<tr>
<td style="text-align:left;">
credit_limit
</td>
<td style="text-align:right;">
0.264
</td>
<td style="text-align:right;">
0.253
</td>
<td style="text-align:right;">
0.276
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
-7.663
</td>
<td style="text-align:right;">
-8.420
</td>
<td style="text-align:right;">
-6.906
</td>
</tr>
</tbody>
</table>
<p>Observe how the slope for <code>income</code> is <span class="math inline">\(-7.663\)</span> and, most importantly for now, it is negative. This contradicts our observation in Figure <a href="12-multiple-regression.html#fig:2numxplot1-repeat">12.9</a> that the relationship is positive. How can this be? Recall the interpretation of the slope for <code>income</code> in the context of a multiple regression model: <em>taking into account all the other explanatory variables in our model</em>, for every increase of one unit in <code>income</code> (i.e., $1000), there is an associated decrease of on average $7.663 in <code>debt</code>.</p>
<p>In other words, while in <em>isolation</em>, the relationship between <code>debt</code> and <code>income</code> may be positive, when taking into account <code>credit_limit</code> as well, this relationship becomes negative. These seemingly paradoxical results are due to a phenomenon aptly named <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox"><em>Simpson’s Paradox</em></a>. Simpson’s Paradox occurs when trends that exist for the data in aggregate either disappear or reverse when the data are broken down into groups.</p>
<p>Let’s show how Simpson’s Paradox manifests itself in the <code>credit_ch12</code> data. Let’s first visualize the distribution of the numerical explanatory variable <code>credit_limit</code> with a histogram in Figure <a href="12-multiple-regression.html#fig:credit-limit-quartiles">12.10</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:credit-limit-quartiles"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/credit-limit-quartiles-1.png" alt="Histogram of credit limits and brackets." width="\textwidth" />
<p class="caption">
FIGURE 12.10: Histogram of credit limits and brackets.
</p>
</div>
<p>The vertical dashed lines are the <em>quartiles</em> that cut up the variable <code>credit_limit</code> into four equally sized groups. Let’s think of these quartiles as converting our numerical variable <code>credit_limit</code> into a categorical variable “<code>credit_limit</code> bracket” with four levels. This means that</p>
<ol style="list-style-type: decimal">
<li>25% of credit limits were between $0 and $3088. Let’s assign these 100 people to the “low” <code>credit_limit</code> bracket.</li>
<li>25% of credit limits were between $3088 and $4622. Let’s assign these 100 people to the “medium-low” <code>credit_limit</code> bracket.</li>
<li>25% of credit limits were between $4622 and $5873. Let’s assign these 100 people to the “medium-high” <code>credit_limit</code> bracket.</li>
<li>25% of credit limits were over $5873. Let’s assign these 100 people to the “high” <code>credit_limit</code> bracket.</li>
</ol>
<p>Now in Figure <a href="12-multiple-regression.html#fig:2numxplot4">12.11</a> let’s re-display two versions of the scatterplot of <code>debt</code> and <code>income</code> from Figure <a href="12-multiple-regression.html#fig:2numxplot1-repeat">12.9</a>, but with a slight twist:</p>
<ol style="list-style-type: decimal">
<li>The left-hand plot shows the regular scatterplot and the single regression line, just as you saw in Figure <a href="12-multiple-regression.html#fig:2numxplot1-repeat">12.9</a>.</li>
<li>The right-hand plot shows the <em>colored scatterplot</em>, where the color aesthetic is mapped to “<code>credit_limit</code> bracket.” Furthermore, there are now four separate regression lines.</li>
</ol>
<p>In other words, the location of the 400 points are the same in both scatterplots, but the right-hand plot shows an additional variable of information: <code>credit_limit</code> bracket.</p>
<div class="figure" style="text-align: center"><span id="fig:2numxplot4"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/2numxplot4-1.png" alt="Relationship between credit card debt and income by credit limit bracket." width="\textwidth" />
<p class="caption">
FIGURE 12.11: Relationship between credit card debt and income by credit limit bracket.
</p>
</div>
<p>The left-hand plot of Figure <a href="12-multiple-regression.html#fig:2numxplot4">12.11</a> focuses on the relationship between <code>debt</code> and <code>income</code> in <em>aggregate</em>. It is suggesting that overall there exists a positive relationship between <code>debt</code> and <code>income</code>. However, the right-hand plot of Figure <a href="12-multiple-regression.html#fig:2numxplot4">12.11</a> focuses on the relationship between <code>debt</code> and <code>income</code> <em>broken down by <code>credit_limit</code> bracket</em>. In other words, we focus on four <em>separate</em> relationships between <code>debt</code> and <code>income</code>: one for the “low” <code>credit_limit</code> bracket, one for the “medium-low” <code>credit_limit</code> bracket, and so on.</p>
<p>Observe in the right-hand plot that the relationship between <code>debt</code> and <code>income</code> is clearly negative for the “medium-low” and “medium-high” <code>credit_limit</code> brackets, while the relationship is somewhat flat for the “low” <code>credit_limit</code> bracket. The only <code>credit_limit</code> bracket where the relationship remains positive is for the “high” <code>credit_limit</code> bracket. However, this relationship is less positive than in the relationship in aggregate, since the slope is shallower than the slope of the regression line in the left-hand plot.</p>
<p>In this example of Simpson’s Paradox, the <code>credit_limit</code> is a <em>confounding variable</em> of the relationship between credit card <code>debt</code> and <code>income</code>. Thus, <code>credit_limit</code> needs to be accounted for in any appropriate model for the relationship between <code>debt</code> and <code>income</code>.</p>
</div>
</div>
<div id="seattle-house-prices" class="section level2">
<h2><span class="header-section-number">12.4</span> Case study: Seattle house prices</h2>
<p><a href="https://www.kaggle.com/">Kaggle.com</a> is a machine learning and predictive modeling competition website that hosts datasets uploaded by companies, governmental organizations, and other individuals. One of their datasets is the <a href="https://www.kaggle.com/harlfoxem/housesalesprediction">“House Sales in King County, USA”</a>. It consists of sale prices of homes sold between May 2014 and May 2015 in King County, Washington, USA, which includes the greater Seattle metropolitan area. This dataset is in the <code>house_prices</code> data frame included in the <strong>moderndive</strong> package.</p>
<p>The dataset consists of 21,613 houses and 21 variables describing these houses (for a full list and description of these variables, see the help file by running <code>?house_prices</code> in the console). In this case study, we’ll create a multiple regression model where:</p>
<ul>
<li>The outcome variable <span class="math inline">\(y\)</span> is the sale <code>price</code> of houses.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>: house size <code>sqft_living</code> as measured in square feet of living space. Note that 1 square foot is about 0.09 square meters.</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>: house <code>condition</code>, a categorical variable with five levels where <code>1</code> indicates “poor” and <code>5</code> indicates “excellent.”</li>
</ol></li>
</ul>
<div id="house-prices-EDA-I" class="section level3">
<h3><span class="header-section-number">12.4.1</span> Exploratory data analysis: Part I</h3>
<p>As we’ve said numerous times throughout this book, a crucial first step when presented with data is to perform an exploratory data analysis (EDA). Exploratory data analysis can give you a sense of your data, help identify issues with your data, bring to light any outliers, and help inform model construction.</p>
<p>Recall the three common steps in an exploratory data analysis we introduced in Subsection <a href="11-regression.html#model1EDA">11.1.1</a>:</p>
<ol style="list-style-type: decimal">
<li>Looking at the raw data values.</li>
<li>Computing summary statistics.</li>
<li>Creating data visualizations.</li>
</ol>
<p>First, let’s look at the raw data using <code>View()</code> to bring up RStudio’s spreadsheet viewer and the <code>glimpse()</code> function from the <strong>dplyr</strong> package:</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="12-multiple-regression.html#cb815-1"></a><span class="kw">View</span>(house_prices)</span>
<span id="cb815-2"><a href="12-multiple-regression.html#cb815-2"></a><span class="kw">glimpse</span>(house_prices)</span></code></pre></div>
<pre><code>Observations: 21,613
Variables: 21
$ id            &lt;chr&gt; &quot;7129300520&quot;, &quot;6414100192&quot;, &quot;5631500400&quot;, &quot;2487200875&quot;,…
$ date          &lt;date&gt; 2014-10-13, 2014-12-09, 2015-02-25, 2014-12-09, 2015-0…
$ price         &lt;dbl&gt; 221900, 538000, 180000, 604000, 510000, 1225000, 257500…
$ bedrooms      &lt;int&gt; 3, 3, 2, 4, 3, 4, 3, 3, 3, 3, 3, 2, 3, 3, 5, 4, 3, 4, 2…
$ bathrooms     &lt;dbl&gt; 1.00, 2.25, 1.00, 3.00, 2.00, 4.50, 2.25, 1.50, 1.00, 2…
$ sqft_living   &lt;int&gt; 1180, 2570, 770, 1960, 1680, 5420, 1715, 1060, 1780, 18…
$ sqft_lot      &lt;int&gt; 5650, 7242, 10000, 5000, 8080, 101930, 6819, 9711, 7470…
$ floors        &lt;dbl&gt; 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, …
$ waterfront    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
$ view          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0…
$ condition     &lt;fct&gt; 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4…
$ grade         &lt;fct&gt; 7, 7, 6, 7, 8, 11, 7, 7, 7, 7, 8, 7, 7, 7, 7, 9, 7, 7, …
$ sqft_above    &lt;int&gt; 1180, 2170, 770, 1050, 1680, 3890, 1715, 1060, 1050, 18…
$ sqft_basement &lt;int&gt; 0, 400, 0, 910, 0, 1530, 0, 0, 730, 0, 1700, 300, 0, 0,…
$ yr_built      &lt;int&gt; 1955, 1951, 1933, 1965, 1987, 2001, 1995, 1963, 1960, 2…
$ yr_renovated  &lt;int&gt; 0, 1991, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ zipcode       &lt;fct&gt; 98178, 98125, 98028, 98136, 98074, 98053, 98003, 98198,…
$ lat           &lt;dbl&gt; 47.5, 47.7, 47.7, 47.5, 47.6, 47.7, 47.3, 47.4, 47.5, 4…
$ long          &lt;dbl&gt; -122, -122, -122, -122, -122, -122, -122, -122, -122, -…
$ sqft_living15 &lt;int&gt; 1340, 1690, 2720, 1360, 1800, 4760, 2238, 1650, 1780, 2…
$ sqft_lot15    &lt;int&gt; 5650, 7639, 8062, 5000, 7503, 101930, 6819, 9711, 8113,…</code></pre>
<p>Here are some questions you can ask yourself at this stage of an EDA: Which variables are numerical? Which are categorical? For the categorical variables, what are their levels? Besides the variables we’ll be using in our regression model, what other variables do you think would be useful to use in a model for house price?</p>
<p>Observe, for example, that while the <code>condition</code> variable has values <code>1</code> through <code>5</code>, these are saved in R as <code>fct</code> standing for “factors.” This is one of R’s ways of saving categorical variables. So you should think of these as the “labels” <code>1</code> through <code>5</code> and not the numerical values <code>1</code> through <code>5</code>.</p>
<p>Let’s now perform the second step in an EDA: computing summary statistics. Recall from Section <a href="4-wrangling.html#summarize">4.3</a> that <em>summary statistics</em> are single numerical values that summarize a large number of values. Examples of summary statistics include the mean, the median, the standard deviation, and various percentiles.</p>
<p>We could do this using the <code>summarize()</code> function in the <strong>dplyr</strong> package along with R’s built-in <em>summary functions</em>, like <code>mean()</code> and <code>median()</code>. However, recall in Section <a href="4-wrangling.html#mutate">4.5</a>, we saw the following code that computes a variety of summary statistics of the variable <code>gain</code>, which is the amount of time that a flight makes up mid-air:</p>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="12-multiple-regression.html#cb817-1"></a>gain_summary &lt;-<span class="st"> </span>flights <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb817-2"><a href="12-multiple-regression.html#cb817-2"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb817-3"><a href="12-multiple-regression.html#cb817-3"></a>    <span class="dt">min =</span> <span class="kw">min</span>(gain, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-4"><a href="12-multiple-regression.html#cb817-4"></a>    <span class="dt">q1 =</span> <span class="kw">quantile</span>(gain, <span class="fl">0.25</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-5"><a href="12-multiple-regression.html#cb817-5"></a>    <span class="dt">median =</span> <span class="kw">quantile</span>(gain, <span class="fl">0.5</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-6"><a href="12-multiple-regression.html#cb817-6"></a>    <span class="dt">q3 =</span> <span class="kw">quantile</span>(gain, <span class="fl">0.75</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-7"><a href="12-multiple-regression.html#cb817-7"></a>    <span class="dt">max =</span> <span class="kw">max</span>(gain, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-8"><a href="12-multiple-regression.html#cb817-8"></a>    <span class="dt">mean =</span> <span class="kw">mean</span>(gain, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-9"><a href="12-multiple-regression.html#cb817-9"></a>    <span class="dt">sd =</span> <span class="kw">sd</span>(gain, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>),</span>
<span id="cb817-10"><a href="12-multiple-regression.html#cb817-10"></a>    <span class="dt">missing =</span> <span class="kw">sum</span>(<span class="kw">is.na</span>(gain))</span>
<span id="cb817-11"><a href="12-multiple-regression.html#cb817-11"></a>  )</span></code></pre></div>
<p>To repeat this for all three <code>price</code>, <code>sqft_living</code>, and <code>condition</code> variables would be tedious to code up. So instead, let’s use the convenient <code>skim()</code> function from the <strong>skimr</strong> package we first used in Subsection <a href="12-multiple-regression.html#model4EDA">12.1.1</a>, being sure to only <code>select()</code> the variables of interest for our model:</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="12-multiple-regression.html#cb818-1"></a><span class="co">## DDK: The current output does not include the p75 and p100 columns. Fixable?</span></span>
<span id="cb818-2"><a href="12-multiple-regression.html#cb818-2"></a></span>
<span id="cb818-3"><a href="12-multiple-regression.html#cb818-3"></a>house_prices <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb818-4"><a href="12-multiple-regression.html#cb818-4"></a><span class="st">  </span><span class="kw">select</span>(price, sqft_living, condition) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb818-5"><a href="12-multiple-regression.html#cb818-5"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
<span id="tab:unnamed-chunk-556">TABLE 12.18: </span>Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
Piped data
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
21613
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
factor
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:left;">
ordered
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:left;">
top_counts
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
condition
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
3: 14031, 4: 5679, 5: 1701, 2: 172
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
price
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
540088
</td>
<td style="text-align:right;">
367127
</td>
<td style="text-align:right;">
75000
</td>
<td style="text-align:right;">
321950
</td>
<td style="text-align:right;">
450000
</td>
<td style="text-align:right;">
645000
</td>
<td style="text-align:right;">
7700000
</td>
<td style="text-align:left;">
▇▁▁▁▁
</td>
</tr>
<tr>
<td style="text-align:left;">
sqft_living
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2080
</td>
<td style="text-align:right;">
918
</td>
<td style="text-align:right;">
290
</td>
<td style="text-align:right;">
1427
</td>
<td style="text-align:right;">
1910
</td>
<td style="text-align:right;">
2550
</td>
<td style="text-align:right;">
13540
</td>
<td style="text-align:left;">
▇▂▁▁▁
</td>
</tr>
</tbody>
</table>
<p>Observe that the mean <code>price</code> of $540,088 is larger than the median of $450,000. This is because a small number of very expensive houses are inflating the average. In other words, there are “outlier” house prices in our dataset. (This fact will become even more apparent when we create our visualizations next.)</p>
<p>However, the median is not as sensitive to such outlier house prices. This is why news about the real estate market generally report median house prices and not mean/average house prices. We say here that the median is more <em>robust to outliers</em> than the mean. Similarly, while both the standard deviation and interquartile-range (IQR) are both measures of spread and variability, the IQR is more <em>robust to outliers</em>.</p>
<p>Let’s now perform the last of the three common steps in an exploratory data analysis: creating data visualizations. Let’s first create <em>univariate</em> visualizations. These are plots focusing on a single variable at a time. Since <code>price</code> and <code>sqft_living</code> are numerical variables, we can visualize their distributions using a <code>geom_histogram()</code> as seen in Section <a href="2-viz.html#histograms">2.4</a> on histograms. On the other hand, since <code>condition</code> is categorical, we can visualize its distribution using a <code>geom_bar()</code>. Recall from Section <a href="2-viz.html#geombar">2.7</a> on barplots that since <code>condition</code> is not “pre-counted”, we use a <code>geom_bar()</code> and not a <code>geom_col()</code>.</p>
<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb819-1"><a href="12-multiple-regression.html#cb819-1"></a><span class="co"># Histogram of house price:</span></span>
<span id="cb819-2"><a href="12-multiple-regression.html#cb819-2"></a></span>
<span id="cb819-3"><a href="12-multiple-regression.html#cb819-3"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb819-4"><a href="12-multiple-regression.html#cb819-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> price)) <span class="op">+</span></span>
<span id="cb819-5"><a href="12-multiple-regression.html#cb819-5"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb819-6"><a href="12-multiple-regression.html#cb819-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;price (USD)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House price&quot;</span>)</span>
<span id="cb819-7"><a href="12-multiple-regression.html#cb819-7"></a></span>
<span id="cb819-8"><a href="12-multiple-regression.html#cb819-8"></a><span class="co"># Histogram of sqft_living</span></span>
<span id="cb819-9"><a href="12-multiple-regression.html#cb819-9"></a></span>
<span id="cb819-10"><a href="12-multiple-regression.html#cb819-10"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb819-11"><a href="12-multiple-regression.html#cb819-11"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sqft_living)) <span class="op">+</span></span>
<span id="cb819-12"><a href="12-multiple-regression.html#cb819-12"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb819-13"><a href="12-multiple-regression.html#cb819-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;living space (square feet)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House size&quot;</span>)</span>
<span id="cb819-14"><a href="12-multiple-regression.html#cb819-14"></a></span>
<span id="cb819-15"><a href="12-multiple-regression.html#cb819-15"></a><span class="co"># Barplot of condition:</span></span>
<span id="cb819-16"><a href="12-multiple-regression.html#cb819-16"></a></span>
<span id="cb819-17"><a href="12-multiple-regression.html#cb819-17"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb819-18"><a href="12-multiple-regression.html#cb819-18"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition)) <span class="op">+</span></span>
<span id="cb819-19"><a href="12-multiple-regression.html#cb819-19"></a><span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span></span>
<span id="cb819-20"><a href="12-multiple-regression.html#cb819-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;condition&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House condition&quot;</span>)</span></code></pre></div>
<p>In Figure <a href="12-multiple-regression.html#fig:house-prices-viz">12.12</a>, we display all three of these visualizations at once.</p>
<div class="figure" style="text-align: center"><span id="fig:house-prices-viz"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/house-prices-viz-1.png" alt="Exploratory visualizations of Seattle house prices data." width="\textwidth" />
<p class="caption">
FIGURE 12.12: Exploratory visualizations of Seattle house prices data.
</p>
</div>
<p>First, observe in the bottom plot that most houses are of condition “3”, with a few more of conditions “4” and “5”, and almost none that are “1” or “2”.</p>
<p>Next, observe in the histogram for <code>price</code> in the top-left plot that a majority of houses are less than two million dollars. Observe also that the x-axis stretches out to 8 million dollars, even though there does not appear to be any houses close to that price. This is because there are a <em>very small number</em> of houses with prices closer to 8 million. These are the outlier house prices we mentioned earlier. We say that the variable <code>price</code> is <em>right-skewed</em> as exhibited by the long right tail.</p>
<p>Further, observe in the histogram of <code>sqft_living</code> in the middle plot as well that most houses appear to have less than 5000 square feet of living space. For comparison, a football field in the US is about 57,600 square feet, whereas a standard soccer/association football field is about 64,000 square feet. Observe also that this variable is also right-skewed, although not as drastically as the <code>price</code> variable.</p>
<p>For both the <code>price</code> and <code>sqft_living</code> variables, the right-skew makes distinguishing houses at the lower end of the x-axis hard. This is because the scale of the x-axis is compressed by the small number of quite expensive and immensely-sized houses.</p>
<p>So what can we do about this skew? Let’s apply a <em>log10 transformation</em> to these variables. If you are unfamiliar with such transformations, we highly recommend you read Appendix <a href="7-probability.html#appendix-log10-transformations">7.7</a> on logarithmic (log) transformations. In summary, log transformations allow us to alter the scale of a variable to focus on <em>multiplicative</em> changes instead of <em>additive</em> changes. In other words, they shift the view to be on <em>relative</em> changes instead of <em>absolute</em> changes. Such multiplicative/relative changes are also called changes in <em>orders of magnitude</em>.</p>
<p>Let’s create new log10 transformed versions of the right-skewed variable <code>price</code> and <code>sqft_living</code> using the <code>mutate()</code> function from Section <a href="4-wrangling.html#mutate">4.5</a>, but we’ll give the latter the name <code>log10_size</code>, which is shorter and easier to understand than the name <code>log10_sqft_living</code>.</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="12-multiple-regression.html#cb820-1"></a>house_prices &lt;-<span class="st"> </span>house_prices <span class="op">%&gt;%</span></span>
<span id="cb820-2"><a href="12-multiple-regression.html#cb820-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb820-3"><a href="12-multiple-regression.html#cb820-3"></a>    <span class="dt">log10_price =</span> <span class="kw">log10</span>(price),</span>
<span id="cb820-4"><a href="12-multiple-regression.html#cb820-4"></a>    <span class="dt">log10_size =</span> <span class="kw">log10</span>(sqft_living)</span>
<span id="cb820-5"><a href="12-multiple-regression.html#cb820-5"></a>    )</span></code></pre></div>
<p>Let’s display the before and after effects of this transformation on these variables for only the first 10 rows of <code>house_prices</code>:</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb821-1"><a href="12-multiple-regression.html#cb821-1"></a>house_prices <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb821-2"><a href="12-multiple-regression.html#cb821-2"></a><span class="st">  </span><span class="kw">select</span>(price, log10_price, sqft_living, log10_size)</span></code></pre></div>
<pre><code># A tibble: 21,613 x 4
     price log10_price sqft_living log10_size
     &lt;dbl&gt;       &lt;dbl&gt;       &lt;int&gt;      &lt;dbl&gt;
 1  221900     5.34616        1180    3.07188
 2  538000     5.73078        2570    3.40993
 3  180000     5.25527         770    2.88649
 4  604000     5.78104        1960    3.29226
 5  510000     5.70757        1680    3.22531
 6 1225000     6.08814        5420    3.73400
 7  257500     5.41078        1715    3.23426
 8  291850     5.46516        1060    3.02531
 9  229500     5.36078        1780    3.25042
10  323000     5.50920        1890    3.27646
# … with 21,603 more rows</code></pre>
<p>Observe in particular the houses in the sixth and third rows. The house in the sixth row has <code>price</code> $1,225,000, which is just above one million dollars. Since <span class="math inline">\(10^6\)</span> is one million, its <code>log10_price</code> is around 6.09.</p>
<p>Contrast this with all other houses with <code>log10_price</code> less than six, since they all have <code>price</code> less than $1,000,000. The house in the third row is the only house with <code>sqft_living</code> less than 1000. Since <span class="math inline">\(1000 = 10^3\)</span>, it’s the lone house with <code>log10_size</code> less than 3.</p>
<p>Let’s now visualize the before and after effects of this transformation for <code>price</code> in Figure <a href="12-multiple-regression.html#fig:log10-price-viz">12.13</a>.</p>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="12-multiple-regression.html#cb823-1"></a><span class="co"># Before log10 transformation:</span></span>
<span id="cb823-2"><a href="12-multiple-regression.html#cb823-2"></a></span>
<span id="cb823-3"><a href="12-multiple-regression.html#cb823-3"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb823-4"><a href="12-multiple-regression.html#cb823-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> price)) <span class="op">+</span></span>
<span id="cb823-5"><a href="12-multiple-regression.html#cb823-5"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb823-6"><a href="12-multiple-regression.html#cb823-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;price (USD)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House price: Before&quot;</span>)</span>
<span id="cb823-7"><a href="12-multiple-regression.html#cb823-7"></a></span>
<span id="cb823-8"><a href="12-multiple-regression.html#cb823-8"></a><span class="co"># After log10 transformation:</span></span>
<span id="cb823-9"><a href="12-multiple-regression.html#cb823-9"></a></span>
<span id="cb823-10"><a href="12-multiple-regression.html#cb823-10"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb823-11"><a href="12-multiple-regression.html#cb823-11"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log10_price)) <span class="op">+</span></span>
<span id="cb823-12"><a href="12-multiple-regression.html#cb823-12"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb823-13"><a href="12-multiple-regression.html#cb823-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log10 price (USD)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House price: After&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:log10-price-viz"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/log10-price-viz-1.png" alt="House price before and after log10 transformation." width="\textwidth" />
<p class="caption">
FIGURE 12.13: House price before and after log10 transformation.
</p>
</div>
<p>Observe that after the transformation, the distribution is much less skewed, and in this case, more symmetric and more bell-shaped. Now you can more easily distinguish the lower priced houses.</p>
<p>Let’s do the same for house size, where the variable <code>sqft_living</code> was log10 transformed to <code>log10_size</code>.</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="12-multiple-regression.html#cb824-1"></a><span class="co"># Before log10 transformation:</span></span>
<span id="cb824-2"><a href="12-multiple-regression.html#cb824-2"></a></span>
<span id="cb824-3"><a href="12-multiple-regression.html#cb824-3"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb824-4"><a href="12-multiple-regression.html#cb824-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sqft_living)) <span class="op">+</span></span>
<span id="cb824-5"><a href="12-multiple-regression.html#cb824-5"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb824-6"><a href="12-multiple-regression.html#cb824-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;living space (square feet)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House size: Before&quot;</span>)</span>
<span id="cb824-7"><a href="12-multiple-regression.html#cb824-7"></a></span>
<span id="cb824-8"><a href="12-multiple-regression.html#cb824-8"></a><span class="co"># After log10 transformation:</span></span>
<span id="cb824-9"><a href="12-multiple-regression.html#cb824-9"></a></span>
<span id="cb824-10"><a href="12-multiple-regression.html#cb824-10"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb824-11"><a href="12-multiple-regression.html#cb824-11"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log10_size)) <span class="op">+</span></span>
<span id="cb824-12"><a href="12-multiple-regression.html#cb824-12"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb824-13"><a href="12-multiple-regression.html#cb824-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log10 living space (square feet)&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;House size: After&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:log10-size-viz"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/log10-size-viz-1.png" alt="House size before and after log10 transformation." width="\textwidth" />
<p class="caption">
FIGURE 12.14: House size before and after log10 transformation.
</p>
</div>
<p>Observe in Figure <a href="12-multiple-regression.html#fig:log10-size-viz">12.14</a> that the log10 transformation has a similar effect of unskewing the variable. We emphasize that while in these two cases the resulting distributions are more symmetric and bell-shaped, this is not always necessarily the case.</p>
<p>Given the now symmetric nature of <code>log10_price</code> and <code>log10_size</code>, we are going to revise our multiple regression model to use our new variables:</p>
<ol style="list-style-type: decimal">
<li>The outcome variable <span class="math inline">\(y\)</span> is the sale <code>log10_price</code> of houses.</li>
<li>Two explanatory variables:
<ol style="list-style-type: decimal">
<li>A numerical explanatory variable <span class="math inline">\(x_1\)</span>: house size <code>log10_size</code> as measured in log base 10 square feet of living space.</li>
<li>A categorical explanatory variable <span class="math inline">\(x_2\)</span>: house <code>condition</code>, a categorical variable with five levels where <code>1</code> indicates “poor” and <code>5</code> indicates “excellent.”</li>
</ol></li>
</ol>
</div>
<div id="house-prices-EDA-II" class="section level3">
<h3><span class="header-section-number">12.4.2</span> Exploratory data analysis: Part II</h3>
<p>Let’s now continue our EDA by creating <em>multivariate</em> visualizations. Unlike the <em>univariate</em> histograms and barplot in the earlier Figures <a href="12-multiple-regression.html#fig:house-prices-viz">12.12</a>, <a href="12-multiple-regression.html#fig:log10-price-viz">12.13</a>, and <a href="12-multiple-regression.html#fig:log10-size-viz">12.14</a>, <em>multivariate</em> visualizations show relationships between more than one variable. This is an important step of an EDA to perform since the goal of modeling is to explore relationships between variables.</p>
<p>Since our model involves a numerical outcome variable, a numerical explanatory variable, and a categorical explanatory variable, we are in a similar regression modeling situation as in Section <a href="12-multiple-regression.html#model4">12.1</a> where we studied the UT Austin teaching scores dataset. Recall in that case the numerical outcome variable was teaching <code>score</code>, the numerical explanatory variable was instructor <code>age</code>, and the categorical explanatory variable was (binary) <code>gender</code>.</p>
<p>We thus have two choices of models we can fit: either (1) an <em>interaction model</em> where the regression line for each <code>condition</code> level will have both a different slope and a different intercept or (2) a <em>parallel slopes model</em> where the regression line for each <code>condition</code> level will have the same slope but different intercepts.</p>
<p>Recall from Subsection <a href="12-multiple-regression.html#model4table">12.1.3</a> that the <code>geom_parallel_slopes()</code> function is a special purpose function that Evgeni Chasnovski created and included in the <strong>moderndive</strong> package, since the <code>geom_smooth()</code> method in the <strong>ggplot2</strong> package does not have a convenient way to plot parallel slopes models. We plot both resulting models in Figure <a href="12-multiple-regression.html#fig:house-price-parallel-slopes">12.15</a>, with the interaction model on the left.</p>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb825-1"><a href="12-multiple-regression.html#cb825-1"></a><span class="co"># Plot interaction model</span></span>
<span id="cb825-2"><a href="12-multiple-regression.html#cb825-2"></a></span>
<span id="cb825-3"><a href="12-multiple-regression.html#cb825-3"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb825-4"><a href="12-multiple-regression.html#cb825-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log10_size, <span class="dt">y =</span> log10_price, <span class="dt">col =</span> condition)) <span class="op">+</span></span>
<span id="cb825-5"><a href="12-multiple-regression.html#cb825-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.05</span>) <span class="op">+</span></span>
<span id="cb825-6"><a href="12-multiple-regression.html#cb825-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb825-7"><a href="12-multiple-regression.html#cb825-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;log10 price&quot;</span>, </span>
<span id="cb825-8"><a href="12-multiple-regression.html#cb825-8"></a>       <span class="dt">x =</span> <span class="st">&quot;log10 size&quot;</span>, </span>
<span id="cb825-9"><a href="12-multiple-regression.html#cb825-9"></a>       <span class="dt">title =</span> <span class="st">&quot;House prices in Seattle&quot;</span>)</span>
<span id="cb825-10"><a href="12-multiple-regression.html#cb825-10"></a></span>
<span id="cb825-11"><a href="12-multiple-regression.html#cb825-11"></a><span class="co"># Plot parallel slopes model</span></span>
<span id="cb825-12"><a href="12-multiple-regression.html#cb825-12"></a></span>
<span id="cb825-13"><a href="12-multiple-regression.html#cb825-13"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb825-14"><a href="12-multiple-regression.html#cb825-14"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log10_size, <span class="dt">y =</span> log10_price, <span class="dt">col =</span> condition)) <span class="op">+</span></span>
<span id="cb825-15"><a href="12-multiple-regression.html#cb825-15"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.05</span>) <span class="op">+</span></span>
<span id="cb825-16"><a href="12-multiple-regression.html#cb825-16"></a><span class="st">  </span><span class="kw">geom_parallel_slopes</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb825-17"><a href="12-multiple-regression.html#cb825-17"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;log10 price&quot;</span>, </span>
<span id="cb825-18"><a href="12-multiple-regression.html#cb825-18"></a>       <span class="dt">x =</span> <span class="st">&quot;log10 size&quot;</span>, </span>
<span id="cb825-19"><a href="12-multiple-regression.html#cb825-19"></a>       <span class="dt">title =</span> <span class="st">&quot;House prices in Seattle&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:house-price-parallel-slopes"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/house-price-parallel-slopes-1.png" alt="Interaction and parallel slopes models." width="\textwidth" />
<p class="caption">
FIGURE 12.15: Interaction and parallel slopes models.
</p>
</div>
<p>In both cases, we see there is a positive relationship between house price and size, meaning as houses are larger, they tend to be more expensive. Furthermore, in both plots it seems that houses of condition 5 tend to be the most expensive for most house sizes as evidenced by the fact that the line for condition 5 is highest, followed by conditions 4 and 3. As for conditions 1 and 2, this pattern isn’t as clear. Recall from the univariate barplot of <code>condition</code> in Figure <a href="12-multiple-regression.html#fig:house-prices-viz">12.12</a>, there are only a few houses of condition 1 or 2.</p>
<p>Let’s also show a faceted version of just the interaction model in Figure <a href="12-multiple-regression.html#fig:house-price-interaction-2">12.16</a>. It is now much more apparent just how few houses are of condition 1 or 2.</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="12-multiple-regression.html#cb826-1"></a>house_prices <span class="op">%&gt;%</span></span>
<span id="cb826-2"><a href="12-multiple-regression.html#cb826-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log10_size, <span class="dt">y =</span> log10_price, <span class="dt">col =</span> condition)) <span class="op">+</span></span>
<span id="cb826-3"><a href="12-multiple-regression.html#cb826-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></span>
<span id="cb826-4"><a href="12-multiple-regression.html#cb826-4"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span></span>
<span id="cb826-5"><a href="12-multiple-regression.html#cb826-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;log10 price&quot;</span>, </span>
<span id="cb826-6"><a href="12-multiple-regression.html#cb826-6"></a>       <span class="dt">x =</span> <span class="st">&quot;log10 size&quot;</span>, </span>
<span id="cb826-7"><a href="12-multiple-regression.html#cb826-7"></a>       <span class="dt">title =</span> <span class="st">&quot;House prices in Seattle&quot;</span>) <span class="op">+</span></span>
<span id="cb826-8"><a href="12-multiple-regression.html#cb826-8"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>condition)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:house-price-interaction-2"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/house-price-interaction-2-1.png" alt="Faceted plot of interaction model." width="\textwidth" />
<p class="caption">
FIGURE 12.16: Faceted plot of interaction model.
</p>
</div>
<p>Which exploratory visualization of the interaction model is better, the one in the left-hand plot of Figure <a href="12-multiple-regression.html#fig:house-price-parallel-slopes">12.15</a> or the faceted version in Figure <a href="12-multiple-regression.html#fig:house-price-interaction-2">12.16</a>? There is no universal right answer. You need to make a choice depending on what you want to convey, and own that choice, with including and discussing both also as an option as needed.</p>
</div>
<div id="house-prices-regression" class="section level3">
<h3><span class="header-section-number">12.4.3</span> Regression modeling</h3>
<p>Which of the two models in Figure <a href="12-multiple-regression.html#fig:house-price-parallel-slopes">12.15</a> is “better”? The interaction model in the left-hand plot or the parallel slopes model in the right-hand plot?</p>
<p>We had a similar discussion in Subsection <a href="12-multiple-regression.html#model-selection">12.3.1</a> on <em>model selection</em>. Recall that we stated that we should only favor more complex models if the additional complexity is <em>warranted</em>. In this case, the more complex model is the interaction model since it considers five intercepts and five slopes total. This is in contrast to the parallel slopes model which considers five intercepts but only one common slope.</p>
<p>Is the additional complexity of the interaction model warranted? Looking at the left-hand plot in Figure <a href="12-multiple-regression.html#fig:house-price-parallel-slopes">12.15</a>, we’re of the opinion that it is, as evidenced by the slight x-like pattern to some of the lines. Therefore, we’ll focus the rest of this analysis only on the interaction model. This visual approach is somewhat subjective, however, so feel free to disagree! What are the five different slopes and five different intercepts for the interaction model? We can obtain these values from the regression table. Recall our two-step process for getting the regression table:</p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="12-multiple-regression.html#cb827-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb827-2"><a href="12-multiple-regression.html#cb827-2"></a></span>
<span id="cb827-3"><a href="12-multiple-regression.html#cb827-3"></a>price_interaction &lt;-<span class="st"> </span><span class="kw">lm</span>(log10_price <span class="op">~</span><span class="st"> </span>log10_size <span class="op">*</span><span class="st"> </span>condition, </span>
<span id="cb827-4"><a href="12-multiple-regression.html#cb827-4"></a>                        <span class="dt">data =</span> house_prices)</span>
<span id="cb827-5"><a href="12-multiple-regression.html#cb827-5"></a></span>
<span id="cb827-6"><a href="12-multiple-regression.html#cb827-6"></a><span class="co"># Get regression table:</span></span>
<span id="cb827-7"><a href="12-multiple-regression.html#cb827-7"></a></span>
<span id="cb827-8"><a href="12-multiple-regression.html#cb827-8"></a>price_interaction <span class="op">%&gt;%</span></span>
<span id="cb827-9"><a href="12-multiple-regression.html#cb827-9"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb827-10"><a href="12-multiple-regression.html#cb827-10"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:seattle-interaction">TABLE 12.19: </span>Regression table for interaction model
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
3.330
</td>
<td style="text-align:right;">
2.446
</td>
<td style="text-align:right;">
4.215
</td>
</tr>
<tr>
<td style="text-align:left;">
log10_size
</td>
<td style="text-align:right;">
0.690
</td>
<td style="text-align:right;">
0.399
</td>
<td style="text-align:right;">
0.980
</td>
</tr>
<tr>
<td style="text-align:left;">
condition2
</td>
<td style="text-align:right;">
0.047
</td>
<td style="text-align:right;">
-0.930
</td>
<td style="text-align:right;">
1.024
</td>
</tr>
<tr>
<td style="text-align:left;">
condition3
</td>
<td style="text-align:right;">
-0.367
</td>
<td style="text-align:right;">
-1.253
</td>
<td style="text-align:right;">
0.519
</td>
</tr>
<tr>
<td style="text-align:left;">
condition4
</td>
<td style="text-align:right;">
-0.398
</td>
<td style="text-align:right;">
-1.286
</td>
<td style="text-align:right;">
0.490
</td>
</tr>
<tr>
<td style="text-align:left;">
condition5
</td>
<td style="text-align:right;">
-0.883
</td>
<td style="text-align:right;">
-1.779
</td>
<td style="text-align:right;">
0.013
</td>
</tr>
<tr>
<td style="text-align:left;">
log10_size:condition2
</td>
<td style="text-align:right;">
-0.024
</td>
<td style="text-align:right;">
-0.344
</td>
<td style="text-align:right;">
0.295
</td>
</tr>
<tr>
<td style="text-align:left;">
log10_size:condition3
</td>
<td style="text-align:right;">
0.133
</td>
<td style="text-align:right;">
-0.158
</td>
<td style="text-align:right;">
0.424
</td>
</tr>
<tr>
<td style="text-align:left;">
log10_size:condition4
</td>
<td style="text-align:right;">
0.146
</td>
<td style="text-align:right;">
-0.146
</td>
<td style="text-align:right;">
0.437
</td>
</tr>
<tr>
<td style="text-align:left;">
log10_size:condition5
</td>
<td style="text-align:right;">
0.310
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
0.604
</td>
</tr>
</tbody>
</table>
<p>Recall we saw in Subsection <a href="12-multiple-regression.html#model4interactiontable">12.1.2</a> how to interpret a regression table when there are both numerical and categorical explanatory variables. Let’s now do the same for all 10 values in the <code>estimate</code> column of Table <a href="12-multiple-regression.html#tab:seattle-interaction">12.19</a>.</p>
<p>In this case, the “baseline for comparison” group for the categorical variable <code>condition</code> are the condition 1 houses, since “1” comes first alphanumerically. Thus, the <code>intercept</code> and <code>log10_size</code> values are the intercept and slope for <code>log10_size</code> for this baseline group. Next, the <code>condition2</code> through <code>condition5</code> terms are the <em>offsets</em> in intercepts relative to the condition 1 intercept. Finally, the <code>log10_size:condition2</code> through <code>log10_size:condition5</code> are the <em>offsets</em> in slopes for <code>log10_size</code> relative to the condition 1 slope for <code>log10_size</code>.</p>
<p>Let’s simplify this by writing out the equation of each of the five regression lines using these 10 <code>estimate</code> values. We’ll write out each line in the following format:</p>
<p><span class="math display">\[
\widehat{\log10(\text{price})} = \hat{\beta}_0 + \hat{\beta}_{\text{size}} \cdot \log10(\text{size})
\]</span></p>
<ol style="list-style-type: decimal">
<li>Condition 1:</li>
</ol>
<p><span class="math display">\[\widehat{\log10(\text{price})} = 3.33 + 0.69 \cdot \log10(\text{size})\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Condition 2:</li>
</ol>
<p><span class="math display">\[
\begin{aligned} 
\widehat{\log10(\text{price})} &amp;= (3.33 + 0.047) + (0.69 - 0.024) \cdot \log10(\text{size}) \\ 
                               &amp;= 3.377 + 0.666 \cdot \log10(\text{size})
\end{aligned}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Condition 3:</li>
</ol>
<p><span class="math display">\[
\begin{aligned} 
\widehat{\log10(\text{price})} &amp;= (3.33 - 0.367) + (0.69 + 0.133) \cdot \log10(\text{size}) \\
                               &amp;= 2.963 + 0.823 \cdot \log10(\text{size})
\end{aligned}
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Condition 4:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\widehat{\log10(\text{price})} &amp;= (3.33 - 0.398) + (0.69 + 0.146) \cdot \log10(\text{size}) \\
                               &amp;= 2.932 + 0.836 \cdot \log10(\text{size})
\end{aligned}
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Condition 5:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\widehat{\log10(\text{price})} &amp;= (3.33 - 0.883) + (0.69 + 0.31) \cdot \log10(\text{size}) \\
                               &amp;= 2.447 + 1 \cdot \log10(\text{size})
\end{aligned}
\]</span></p>
<p>These correspond to the regression lines in the left-hand plot of Figure <a href="12-multiple-regression.html#fig:house-price-parallel-slopes">12.15</a> and the faceted plot in Figure <a href="12-multiple-regression.html#fig:house-price-interaction-2">12.16</a>. For homes of all five condition types, as the size of the house increases, the price increases. This is what most would expect. However, the rate of increase of price with size is fastest for the homes with conditions 3, 4, and 5 of 0.823, 0.836, and 1, respectively. These are the three largest slopes out of the five.</p>
</div>
<div id="house-prices-making-predictions" class="section level3">
<h3><span class="header-section-number">12.4.4</span> Making predictions</h3>
<p>Say you’re a realtor and someone calls you asking you how much their home will sell for. They tell you that it’s in condition = 5 and is sized 1900 square feet. What do you tell them? Let’s use the interaction model we fit to make predictions!</p>
<p>We first make this prediction visually in Figure <a href="12-multiple-regression.html#fig:house-price-interaction-3">12.17</a>. The predicted <code>log10_price</code> of this house is marked with a black dot. This is where the following two lines intersect:</p>
<ul>
<li>The regression line for the condition = 5 homes and</li>
<li>The vertical dashed black line at <code>log10_size</code> equals 3.28, since our predictor variable is the log10 transformed square feet of living space of <span class="math inline">\(\log10(1900) = 3.28\)</span>.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:house-price-interaction-3"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/house-price-interaction-3-1.png" alt="Interaction model with prediction." width="\textwidth" />
<p class="caption">
FIGURE 12.17: Interaction model with prediction.
</p>
</div>
<p>Eyeballing it, it seems the predicted <code>log10_price</code> seems to be around 5.75. Let’s now obtain the exact numerical value for the prediction using the equation of the regression line for the condition = 5 houses, being sure to <code>log10()</code> the square footage first.</p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="12-multiple-regression.html#cb828-1"></a><span class="fl">2.45</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log10</span>(<span class="dv">1900</span>)</span></code></pre></div>
<pre><code>[1] 5.73</code></pre>
<p>This value is very close to our earlier visually made prediction of 5.75. But wait! Is our prediction for the price of this house $5.75? No! Remember that we are using <code>log10_price</code> as our outcome variable! So, if we want a prediction in dollar units of <code>price</code>, we need to unlog this by taking a power of 10.</p>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="12-multiple-regression.html#cb830-1"></a><span class="dv">10</span><span class="op">^</span>(<span class="fl">2.45</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log10</span>(<span class="dv">1900</span>))</span></code></pre></div>
<pre><code>[1] 535493</code></pre>
<p>So our predicted price for this home of condition 5 and of size 1900 square feet is $535,493.</p>
<!--
TODO: Inference for regression for Seattle house prices

### Inference for regression {#house-prices-inference-for-regression}

- Interpret offset in slope terms
- All possible partial residual plots
- Then add back LC below

-->
</div>
</div>
<div id="data-journalism" class="section level2">
<h2><span class="header-section-number">12.5</span> Case study: Effective data storytelling</h2>
<p>As we’ve progressed throughout this book, you’ve seen how to work with data in a variety of ways. You’ve learned effective strategies for plotting data by understanding which types of plots work best for which combinations of variable types. You’ve summarized data in spreadsheet form and calculated summary statistics for a variety of different variables. Furthermore, you’ve seen the value of statistical inference as a process to come to conclusions about a population by using sampling. Lastly, you’ve explored how to fit linear regression models and the importance of checking the conditions required so that all confidence intervals and hypothesis tests have valid interpretation. All throughout, you’ve learned many computational techniques and focused on writing R code that’s reproducible.</p>
<p>We now present another set of case studies, but this time on the “effective data storytelling” done by data journalists around the world. Great data stories don’t mislead the reader, but rather engulf them in understanding the importance that data plays in our lives through storytelling.</p>
<div id="bechdel-test-for-hollywood-gender-representation" class="section level3">
<h3><span class="header-section-number">12.5.1</span> Bechdel test for Hollywood gender representation</h3>
<p>We recommend you read and analyze Walt Hickey’s FiveThirtyEight.com article, <a href="http://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/">“The Dollar-And-Cents Case Against Hollywood’s Exclusion of Women.”</a> In it, Walt completed a multidecade study of how many movies pass the <a href="https://bechdeltest.com/">Bechdel test</a>, an informal test of gender representation in a movie that was created by  Alison Bechdel.</p>
<p>As you read over the article, think carefully about how Walt Hickey is using data, graphics, and analyses to tell the reader a story. In the spirit of reproducibility, FiveThirtyEight have also shared the <a href="https://github.com/fivethirtyeight/data/tree/master/bechdel">data and R code</a> that they used for this article. You can also find the data used in many more of their articles on their <a href="https://github.com/fivethirtyeight/data">GitHub</a> page.</p>
<p><em>ModernDive</em> co-authors Chester Ismay and Albert Y. Kim along with Jennifer Chunn went one step further by creating the <strong>fivethirtyeight</strong> package which provides access to these datasets more easily in R. For a complete list of all 127 datasets included in the <strong>fivethirtyeight</strong> package, check out the package webpage at <a href="https://fivethirtyeight-r.netlify.com/articles/fivethirtyeight.html" class="uri">https://fivethirtyeight-r.netlify.com/articles/fivethirtyeight.html</a>.</p>
<p>Furthermore, example “vignettes” of fully reproducible start-to-finish analyses of some of these data using <strong>dplyr</strong>, <strong>ggplot2</strong>, and other packages in the <strong>tidyverse</strong> are available <a href="https://fivethirtyeight-r.netlify.com/articles/">here</a>. For example, a vignette showing how to reproduce one of the plots at the end of the article on the Bechdel test is available <a href="https://fivethirtyeight-r.netlify.com/articles/bechdel.html">here</a>.</p>
</div>
<div id="us-births-in-1999" class="section level3">
<h3><span class="header-section-number">12.5.2</span> US Births in 1999</h3>
<p>The <code>US_births_1994_2003</code> data frame included in the <strong>fivethirtyeight</strong> package provides information about the number of daily births in the United States between 1994 and 2003. For more information on this data frame including a link to the original article on FiveThirtyEight.com, check out the help file by running <code>?US_births_1994_2003</code> in the console.</p>
<p>It’s always a good idea to preview your data, either by using RStudio’s spreadsheet <code>View()</code> function or using <code>glimpse()</code> from the <strong>dplyr</strong> package:</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="12-multiple-regression.html#cb832-1"></a><span class="kw">glimpse</span>(US_births_<span class="dv">1994</span>_<span class="dv">2003</span>)</span></code></pre></div>
<pre><code>Observations: 3,652
Variables: 6
$ year          &lt;int&gt; 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1994, 1…
$ month         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
$ date_of_month &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …
$ date          &lt;date&gt; 1994-01-01, 1994-01-02, 1994-01-03, 1994-01-04, 1994-0…
$ day_of_week   &lt;ord&gt; Sat, Sun, Mon, Tues, Wed, Thurs, Fri, Sat, Sun, Mon, Tu…
$ births        &lt;int&gt; 8096, 7772, 10142, 11248, 11053, 11406, 11251, 8653, 79…</code></pre>
<p>We’ll focus on the number of <code>births</code> for each <code>date</code>, but only for births that occurred in 1999. Recall from Section <a href="4-wrangling.html#filter">4.2</a> we can do this using the <code>filter()</code> function from the <strong>dplyr</strong> package:</p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="12-multiple-regression.html#cb834-1"></a>US_births_<span class="dv">1999</span> &lt;-<span class="st"> </span>US_births_<span class="dv">1994</span>_<span class="dv">2003</span> <span class="op">%&gt;%</span></span>
<span id="cb834-2"><a href="12-multiple-regression.html#cb834-2"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">1999</span>)</span></code></pre></div>
<p>As discussed in Section <a href="2-viz.html#linegraphs">2.3</a>, since <code>date</code> is a notion of time and thus has sequential ordering to it, a linegraph would be a more appropriate visualization to use than a scatterplot. In other words, we should use a <code>geom_line()</code> instead of <code>geom_point()</code>. Recall that such plots are called  <em>time series</em> plots.</p>
<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb835-1"><a href="12-multiple-regression.html#cb835-1"></a>US_births_<span class="dv">1999</span> <span class="op">%&gt;%</span></span>
<span id="cb835-2"><a href="12-multiple-regression.html#cb835-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> births)) <span class="op">+</span></span>
<span id="cb835-3"><a href="12-multiple-regression.html#cb835-3"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb835-4"><a href="12-multiple-regression.html#cb835-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Date&quot;</span>, </span>
<span id="cb835-5"><a href="12-multiple-regression.html#cb835-5"></a>       <span class="dt">y =</span> <span class="st">&quot;Number of births&quot;</span>, </span>
<span id="cb835-6"><a href="12-multiple-regression.html#cb835-6"></a>       <span class="dt">title =</span> <span class="st">&quot;US Births in 1999&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:us-births"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/us-births-1.png" alt="Number of births in the US in 1999." width="\textwidth" />
<p class="caption">
FIGURE 12.18: Number of births in the US in 1999.
</p>
</div>
<p>We see a big dip occurring just before January 1st, 2000, most likely due to the holiday season. However, what about the large spike of over 14,000 births occurring just before October 1st, 1999? What could be the reason for this anomalously high spike?</p>
<p>Let’s sort the rows of <code>US_births_1999</code> in descending order of the number of births. Recall from Section <a href="4-wrangling.html#arrange">4.6</a> that we can use the <code>arrange()</code> function from the <strong>dplyr</strong> function to do this, making sure to sort <code>births</code> in <code>desc</code>ending order:</p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="12-multiple-regression.html#cb836-1"></a>US_births_<span class="dv">1999</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb836-2"><a href="12-multiple-regression.html#cb836-2"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(births))</span></code></pre></div>
<pre><code># A tibble: 365 x 6
    year month date_of_month date       day_of_week births
   &lt;int&gt; &lt;int&gt;         &lt;int&gt; &lt;date&gt;     &lt;ord&gt;        &lt;int&gt;
 1  1999     9             9 1999-09-09 Thurs        14540
 2  1999    12            21 1999-12-21 Tues         13508
 3  1999     9             8 1999-09-08 Wed          13437
 4  1999     9            21 1999-09-21 Tues         13384
 5  1999     9            28 1999-09-28 Tues         13358
 6  1999     7             7 1999-07-07 Wed          13343
 7  1999     7             8 1999-07-08 Thurs        13245
 8  1999     8            17 1999-08-17 Tues         13201
 9  1999     9            10 1999-09-10 Fri          13181
10  1999    12            28 1999-12-28 Tues         13158
# … with 355 more rows</code></pre>
<p>The date with the highest number of births (14,540) is in fact 1999-09-09. If we write down this date in month/day/year format (a standard format in the US), the date with the highest number of births is 9/9/99! All nines! Could it be that parents deliberately induced labor at a higher rate on this date? Maybe? Whatever the cause may be, this fact makes a fun story!</p>
<p>Time to think with data and further tell your story with data! How could statistical modeling help you here? What types of statistical inference would be helpful? What else can you find and where can you take this analysis? What assumptions did you make in this analysis? We leave these questions to you as the reader to explore and examine.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-islr2017">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2017. <em>An Introduction to Statistical Learning: With Applications in R</em>. First. New York, NY: Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="11-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="13-classification.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
