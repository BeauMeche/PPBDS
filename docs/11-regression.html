<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Regression | Preceptor’s Primer for Bayesian Data Science</title>
  <meta name="description" content="Chapter 11 Regression | Preceptor’s Primer for Bayesian Data Science" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Regression | Preceptor’s Primer for Bayesian Data Science" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="davidkane9/PPBDS" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Regression | Preceptor’s Primer for Bayesian Data Science" />
  
  
  

<meta name="author" content="David Kane" />


<meta name="date" content="2020-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="10-confidence-intervals.html"/>
<link rel="next" href="12-multiple-regression.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="forward.html"><a href="forward.html"><i class="fa fa-check"></i>Forward</a></li>
<li class="chapter" data-level="" data-path="warning.html"><a href="warning.html"><i class="fa fa-check"></i>Warning</a></li>
<li class="chapter" data-level="" data-path="license.html"><a href="license.html"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="1" data-path="1-getting-started.html"><a href="1-getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting Started</a><ul>
<li class="chapter" data-level="1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#r-rstudio"><i class="fa fa-check"></i><b>1.1</b> What are R and RStudio?</a><ul>
<li class="chapter" data-level="1.1.1" data-path="1-getting-started.html"><a href="1-getting-started.html#installing"><i class="fa fa-check"></i><b>1.1.1</b> Installing R and RStudio</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#using-r-via-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Using R via RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-getting-started.html"><a href="1-getting-started.html#code"><i class="fa fa-check"></i><b>1.2</b> How do I code in R?</a><ul>
<li class="chapter" data-level="1.2.1" data-path="1-getting-started.html"><a href="1-getting-started.html#programming-concepts"><i class="fa fa-check"></i><b>1.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-getting-started.html"><a href="1-getting-started.html#messages"><i class="fa fa-check"></i><b>1.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-getting-started.html"><a href="1-getting-started.html#tips-code"><i class="fa fa-check"></i><b>1.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-getting-started.html"><a href="1-getting-started.html#packages"><i class="fa fa-check"></i><b>1.3</b> What are R packages?</a><ul>
<li class="chapter" data-level="1.3.1" data-path="1-getting-started.html"><a href="1-getting-started.html#package-installation"><i class="fa fa-check"></i><b>1.3.1</b> Package installation</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-getting-started.html"><a href="1-getting-started.html#package-loading"><i class="fa fa-check"></i><b>1.3.2</b> Package loading</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-getting-started.html"><a href="1-getting-started.html#package-use"><i class="fa fa-check"></i><b>1.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13"><i class="fa fa-check"></i><b>1.4</b> Explore your first datasets</a><ul>
<li class="chapter" data-level="1.4.1" data-path="1-getting-started.html"><a href="1-getting-started.html#nycflights13-package"><i class="fa fa-check"></i><b>1.4.1</b> <code>nycflights13</code> package</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-getting-started.html"><a href="1-getting-started.html#flights-data-frame"><i class="fa fa-check"></i><b>1.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-getting-started.html"><a href="1-getting-started.html#exploredataframes"><i class="fa fa-check"></i><b>1.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-getting-started.html"><a href="1-getting-started.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>1.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="1-getting-started.html"><a href="1-getting-started.html#help-files"><i class="fa fa-check"></i><b>1.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-getting-started.html"><a href="1-getting-started.html#conclusion"><i class="fa fa-check"></i><b>1.5</b> Conclusion</a><ul>
<li class="chapter" data-level="1.5.1" data-path="1-getting-started.html"><a href="1-getting-started.html#additional-resources"><i class="fa fa-check"></i><b>1.5.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-viz.html"><a href="2-viz.html"><i class="fa fa-check"></i><b>2</b> Visualization</a><ul>
<li class="chapter" data-level="" data-path="2-viz.html"><a href="2-viz.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="2.1" data-path="2-viz.html"><a href="2-viz.html#grammarofgraphics"><i class="fa fa-check"></i><b>2.1</b> The grammar of graphics</a><ul>
<li class="chapter" data-level="2.1.1" data-path="2-viz.html"><a href="2-viz.html#components-of-the-grammar"><i class="fa fa-check"></i><b>2.1.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="2.1.2" data-path="2-viz.html"><a href="2-viz.html#gapminder"><i class="fa fa-check"></i><b>2.1.2</b> Gapminder data</a></li>
<li class="chapter" data-level="2.1.3" data-path="2-viz.html"><a href="2-viz.html#other-components"><i class="fa fa-check"></i><b>2.1.3</b> Other components</a></li>
<li class="chapter" data-level="2.1.4" data-path="2-viz.html"><a href="2-viz.html#ggplot2-package"><i class="fa fa-check"></i><b>2.1.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2-viz.html"><a href="2-viz.html#scatterplots"><i class="fa fa-check"></i><b>2.2</b> Scatterplots</a><ul>
<li class="chapter" data-level="2.2.1" data-path="2-viz.html"><a href="2-viz.html#geompoint"><i class="fa fa-check"></i><b>2.2.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="2.2.2" data-path="2-viz.html"><a href="2-viz.html#overplotting"><i class="fa fa-check"></i><b>2.2.2</b> Overplotting</a></li>
<li class="chapter" data-level="2.2.3" data-path="2-viz.html"><a href="2-viz.html#summary"><i class="fa fa-check"></i><b>2.2.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2-viz.html"><a href="2-viz.html#linegraphs"><i class="fa fa-check"></i><b>2.3</b> Linegraphs</a><ul>
<li class="chapter" data-level="2.3.1" data-path="2-viz.html"><a href="2-viz.html#geomline"><i class="fa fa-check"></i><b>2.3.1</b> Linegraphs via <code>geom_line</code></a></li>
<li class="chapter" data-level="2.3.2" data-path="2-viz.html"><a href="2-viz.html#summary-1"><i class="fa fa-check"></i><b>2.3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2-viz.html"><a href="2-viz.html#histograms"><i class="fa fa-check"></i><b>2.4</b> Histograms</a><ul>
<li class="chapter" data-level="2.4.1" data-path="2-viz.html"><a href="2-viz.html#geomhistogram"><i class="fa fa-check"></i><b>2.4.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="2.4.2" data-path="2-viz.html"><a href="2-viz.html#adjustbins"><i class="fa fa-check"></i><b>2.4.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="2.4.3" data-path="2-viz.html"><a href="2-viz.html#summary-2"><i class="fa fa-check"></i><b>2.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2-viz.html"><a href="2-viz.html#facets"><i class="fa fa-check"></i><b>2.5</b> Facets</a></li>
<li class="chapter" data-level="2.6" data-path="2-viz.html"><a href="2-viz.html#boxplots"><i class="fa fa-check"></i><b>2.6</b> Boxplots</a><ul>
<li class="chapter" data-level="2.6.1" data-path="2-viz.html"><a href="2-viz.html#geomboxplot"><i class="fa fa-check"></i><b>2.6.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="2-viz.html"><a href="2-viz.html#summary-3"><i class="fa fa-check"></i><b>2.6.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2-viz.html"><a href="2-viz.html#geombar"><i class="fa fa-check"></i><b>2.7</b> Barplots</a><ul>
<li class="chapter" data-level="2.7.1" data-path="2-viz.html"><a href="2-viz.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>2.7.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="2.7.2" data-path="2-viz.html"><a href="2-viz.html#must-avoid-pie-charts"><i class="fa fa-check"></i><b>2.7.2</b> Must avoid pie charts!</a></li>
<li class="chapter" data-level="2.7.3" data-path="2-viz.html"><a href="2-viz.html#two-categ-barplot"><i class="fa fa-check"></i><b>2.7.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="2.7.4" data-path="2-viz.html"><a href="2-viz.html#summary-4"><i class="fa fa-check"></i><b>2.7.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="2-viz.html"><a href="2-viz.html#conclusion-1"><i class="fa fa-check"></i><b>2.8</b> Conclusion</a><ul>
<li class="chapter" data-level="2.8.1" data-path="2-viz.html"><a href="2-viz.html#summary-table"><i class="fa fa-check"></i><b>2.8.1</b> Summary table</a></li>
<li class="chapter" data-level="2.8.2" data-path="2-viz.html"><a href="2-viz.html#function-argument-specification"><i class="fa fa-check"></i><b>2.8.2</b> Function argument specification</a></li>
<li class="chapter" data-level="2.8.3" data-path="2-viz.html"><a href="2-viz.html#additional-resources-1"><i class="fa fa-check"></i><b>2.8.3</b> Additional resources</a></li>
<li class="chapter" data-level="2.8.4" data-path="2-viz.html"><a href="2-viz.html#whats-to-come-3"><i class="fa fa-check"></i><b>2.8.4</b> What’s to come</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-productivity.html"><a href="3-productivity.html"><i class="fa fa-check"></i><b>3</b> Productivity</a><ul>
<li class="chapter" data-level="3.1" data-path="3-productivity.html"><a href="3-productivity.html#set-up"><i class="fa fa-check"></i><b>3.1</b> Set Up</a><ul>
<li class="chapter" data-level="3.1.1" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-mac"><i class="fa fa-check"></i><b>3.1.1</b> Accessing the terminal on a Mac</a></li>
<li class="chapter" data-level="3.1.2" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-on-the-mac"><i class="fa fa-check"></i><b>3.1.2</b> Installing Git on the Mac</a></li>
<li class="chapter" data-level="3.1.3" data-path="3-productivity.html"><a href="3-productivity.html#installing-git-and-git-bash-on-windows"><i class="fa fa-check"></i><b>3.1.3</b> Installing Git and Git Bash on Windows</a></li>
<li class="chapter" data-level="3.1.4" data-path="3-productivity.html"><a href="3-productivity.html#terminal-on-windows"><i class="fa fa-check"></i><b>3.1.4</b> Accessing the terminal on Windows</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3-productivity.html"><a href="3-productivity.html#unix"><i class="fa fa-check"></i><b>3.2</b> Organizing with Unix</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-productivity.html"><a href="3-productivity.html#naming-convention"><i class="fa fa-check"></i><b>3.2.1</b> Naming convention</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-productivity.html"><a href="3-productivity.html#the-terminal"><i class="fa fa-check"></i><b>3.2.2</b> The terminal</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-productivity.html"><a href="3-productivity.html#filesystem"><i class="fa fa-check"></i><b>3.2.3</b> The filesystem</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-productivity.html"><a href="3-productivity.html#directories-and-subdirectories"><i class="fa fa-check"></i><b>3.2.4</b> Directories and subdirectories</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-productivity.html"><a href="3-productivity.html#the-home-directory"><i class="fa fa-check"></i><b>3.2.5</b> The home directory</a></li>
<li class="chapter" data-level="3.2.6" data-path="3-productivity.html"><a href="3-productivity.html#working-directory"><i class="fa fa-check"></i><b>3.2.6</b> Working directory</a></li>
<li class="chapter" data-level="3.2.7" data-path="3-productivity.html"><a href="3-productivity.html#paths"><i class="fa fa-check"></i><b>3.2.7</b> Paths</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-productivity.html"><a href="3-productivity.html#unix-commands"><i class="fa fa-check"></i><b>3.3</b> Unix commands</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-productivity.html"><a href="3-productivity.html#ls-listing-directory-content"><i class="fa fa-check"></i><b>3.3.1</b> <code>ls</code>: Listing directory content</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-productivity.html"><a href="3-productivity.html#mkdir-and-rmdir-make-and-remove-a-directory"><i class="fa fa-check"></i><b>3.3.2</b> <code>mkdir</code> and <code>rmdir</code>: make and remove a directory</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-productivity.html"><a href="3-productivity.html#cd-navigating-the-filesystem-by-changing-directories"><i class="fa fa-check"></i><b>3.3.3</b> <code>cd</code>: navigating the filesystem by changing directories</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-productivity.html"><a href="3-productivity.html#some-examples"><i class="fa fa-check"></i><b>3.3.4</b> Some examples</a></li>
<li class="chapter" data-level="3.3.5" data-path="3-productivity.html"><a href="3-productivity.html#more-unix-commands"><i class="fa fa-check"></i><b>3.3.5</b> More Unix commands</a></li>
<li class="chapter" data-level="3.3.6" data-path="3-productivity.html"><a href="3-productivity.html#advanced-unix"><i class="fa fa-check"></i><b>3.3.6</b> Advanced Unix</a></li>
<li class="chapter" data-level="3.3.7" data-path="3-productivity.html"><a href="3-productivity.html#file-manipulation-in-r"><i class="fa fa-check"></i><b>3.3.7</b> File manipulation in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-productivity.html"><a href="3-productivity.html#git"><i class="fa fa-check"></i><b>3.4</b> Git and GitHub</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-productivity.html"><a href="3-productivity.html#github-accounts"><i class="fa fa-check"></i><b>3.4.1</b> GitHub accounts</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-productivity.html"><a href="3-productivity.html#github-repos"><i class="fa fa-check"></i><b>3.4.2</b> GitHub repositories</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-productivity.html"><a href="3-productivity.html#git-overview"><i class="fa fa-check"></i><b>3.4.3</b> Overview of Git</a></li>
<li class="chapter" data-level="3.4.4" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-git"><i class="fa fa-check"></i><b>3.4.4</b> Using Git and GitHub in RStudio</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3-productivity.html"><a href="3-productivity.html#r"><i class="fa fa-check"></i><b>3.5</b> R</a><ul>
<li class="chapter" data-level="3.5.1" data-path="3-productivity.html"><a href="3-productivity.html#rstudio-projects"><i class="fa fa-check"></i><b>3.5.1</b> RStudio projects</a></li>
<li class="chapter" data-level="3.5.2" data-path="3-productivity.html"><a href="3-productivity.html#r-markdown"><i class="fa fa-check"></i><b>3.5.2</b> R markdown</a></li>
<li class="chapter" data-level="3.5.3" data-path="3-productivity.html"><a href="3-productivity.html#help-for-r"><i class="fa fa-check"></i><b>3.5.3</b> Help for R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-wrangling.html"><a href="4-wrangling.html"><i class="fa fa-check"></i><b>4</b> Wrangling</a><ul>
<li class="chapter" data-level="4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#piping"><i class="fa fa-check"></i><b>4.1</b> The pipe operator: <code>%&gt;%</code></a></li>
<li class="chapter" data-level="4.2" data-path="4-wrangling.html"><a href="4-wrangling.html#filter"><i class="fa fa-check"></i><b>4.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="4.3" data-path="4-wrangling.html"><a href="4-wrangling.html#summarize"><i class="fa fa-check"></i><b>4.3</b> <code>summarize</code> variables</a></li>
<li class="chapter" data-level="4.4" data-path="4-wrangling.html"><a href="4-wrangling.html#groupby"><i class="fa fa-check"></i><b>4.4</b> <code>group_by</code> rows</a><ul>
<li class="chapter" data-level="4.4.1" data-path="4-wrangling.html"><a href="4-wrangling.html#grouping-by-more-than-one-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouping by more than one variable</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4-wrangling.html"><a href="4-wrangling.html#mutate"><i class="fa fa-check"></i><b>4.5</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="4.6" data-path="4-wrangling.html"><a href="4-wrangling.html#arrange"><i class="fa fa-check"></i><b>4.6</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="4.7" data-path="4-wrangling.html"><a href="4-wrangling.html#factors"><i class="fa fa-check"></i><b>4.7</b> Factors</a><ul>
<li class="chapter" data-level="4.7.1" data-path="4-wrangling.html"><a href="4-wrangling.html#the-forcats-package"><i class="fa fa-check"></i><b>4.7.1</b> The <strong>forcats</strong> package</a></li>
<li class="chapter" data-level="4.7.2" data-path="4-wrangling.html"><a href="4-wrangling.html#dropping-unused-levels"><i class="fa fa-check"></i><b>4.7.2</b> Dropping unused levels</a></li>
<li class="chapter" data-level="4.7.3" data-path="4-wrangling.html"><a href="4-wrangling.html#reorder-factors"><i class="fa fa-check"></i><b>4.7.3</b> Change order of the levels, principled</a></li>
<li class="chapter" data-level="4.7.4" data-path="4-wrangling.html"><a href="4-wrangling.html#change-order-of-the-levels-because-i-said-so"><i class="fa fa-check"></i><b>4.7.4</b> Change order of the levels, “because I said so”</a></li>
<li class="chapter" data-level="4.7.5" data-path="4-wrangling.html"><a href="4-wrangling.html#recode-the-levels"><i class="fa fa-check"></i><b>4.7.5</b> Recode the levels</a></li>
<li class="chapter" data-level="4.7.6" data-path="4-wrangling.html"><a href="4-wrangling.html#grow-a-factor"><i class="fa fa-check"></i><b>4.7.6</b> Grow a factor</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors"><i class="fa fa-check"></i><b>4.8</b> Character Vectors</a><ul>
<li class="chapter" data-level="4.8.1" data-path="4-wrangling.html"><a href="4-wrangling.html#manipulating-character-vectors"><i class="fa fa-check"></i><b>4.8.1</b> Manipulating character vectors</a></li>
<li class="chapter" data-level="4.8.2" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-resources"><i class="fa fa-check"></i><b>4.8.2</b> Regular expressions resources</a></li>
<li class="chapter" data-level="4.8.3" data-path="4-wrangling.html"><a href="4-wrangling.html#character-encoding-resources"><i class="fa fa-check"></i><b>4.8.3</b> Character encoding resources</a></li>
<li class="chapter" data-level="4.8.4" data-path="4-wrangling.html"><a href="4-wrangling.html#character-vectors-that-live-in-a-data-frame"><i class="fa fa-check"></i><b>4.8.4</b> Character vectors that live in a data frame</a></li>
<li class="chapter" data-level="4.8.5" data-path="4-wrangling.html"><a href="4-wrangling.html#regex-free-string-manipulation-with-stringr-and-tidyr"><i class="fa fa-check"></i><b>4.8.5</b> Regex-free string manipulation with stringr and tidyr</a></li>
<li class="chapter" data-level="4.8.6" data-path="4-wrangling.html"><a href="4-wrangling.html#detect-or-filter-on-a-target-string"><i class="fa fa-check"></i><b>4.8.6</b> Detect or filter on a target string</a></li>
<li class="chapter" data-level="4.8.7" data-path="4-wrangling.html"><a href="4-wrangling.html#string-splitting-by-delimiter"><i class="fa fa-check"></i><b>4.8.7</b> String splitting by delimiter</a></li>
<li class="chapter" data-level="4.8.8" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-extraction-and-replacement-by-position"><i class="fa fa-check"></i><b>4.8.8</b> Substring extraction (and replacement) by position</a></li>
<li class="chapter" data-level="4.8.9" data-path="4-wrangling.html"><a href="4-wrangling.html#collapse-a-vector"><i class="fa fa-check"></i><b>4.8.9</b> Collapse a vector</a></li>
<li class="chapter" data-level="4.8.10" data-path="4-wrangling.html"><a href="4-wrangling.html#catenate-vectors"><i class="fa fa-check"></i><b>4.8.10</b> Create a character vector by catenating multiple vectors</a></li>
<li class="chapter" data-level="4.8.11" data-path="4-wrangling.html"><a href="4-wrangling.html#substring-replacement"><i class="fa fa-check"></i><b>4.8.11</b> Substring replacement</a></li>
<li class="chapter" data-level="4.8.12" data-path="4-wrangling.html"><a href="4-wrangling.html#regular-expressions-with-stringr"><i class="fa fa-check"></i><b>4.8.12</b> Regular expressions with stringr</a></li>
<li class="chapter" data-level="4.8.13" data-path="4-wrangling.html"><a href="4-wrangling.html#characters-with-special-meaning"><i class="fa fa-check"></i><b>4.8.13</b> Characters with special meaning</a></li>
<li class="chapter" data-level="4.8.14" data-path="4-wrangling.html"><a href="4-wrangling.html#character-classes"><i class="fa fa-check"></i><b>4.8.14</b> Character classes</a></li>
<li class="chapter" data-level="4.8.15" data-path="4-wrangling.html"><a href="4-wrangling.html#quantifiers"><i class="fa fa-check"></i><b>4.8.15</b> Quantifiers</a></li>
<li class="chapter" data-level="4.8.16" data-path="4-wrangling.html"><a href="4-wrangling.html#escaping"><i class="fa fa-check"></i><b>4.8.16</b> Escaping</a></li>
<li class="chapter" data-level="4.8.17" data-path="4-wrangling.html"><a href="4-wrangling.html#groups-and-backreferences"><i class="fa fa-check"></i><b>4.8.17</b> Groups and backreferences</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="4-wrangling.html"><a href="4-wrangling.html#combining-data"><i class="fa fa-check"></i><b>4.9</b> Combining Data</a><ul>
<li class="chapter" data-level="4.9.1" data-path="4-wrangling.html"><a href="4-wrangling.html#bind"><i class="fa fa-check"></i><b>4.9.1</b> Bind</a></li>
<li class="chapter" data-level="4.9.2" data-path="4-wrangling.html"><a href="4-wrangling.html#joins-in-dplyr"><i class="fa fa-check"></i><b>4.9.2</b> Joins in dplyr</a></li>
<li class="chapter" data-level="4.9.3" data-path="4-wrangling.html"><a href="4-wrangling.html#joining"><i class="fa fa-check"></i><b>4.9.3</b> Joining</a></li>
<li class="chapter" data-level="4.9.4" data-path="4-wrangling.html"><a href="4-wrangling.html#matching-key-variable-names"><i class="fa fa-check"></i><b>4.9.4</b> Matching “key” variable names</a></li>
<li class="chapter" data-level="4.9.5" data-path="4-wrangling.html"><a href="4-wrangling.html#diff-key"><i class="fa fa-check"></i><b>4.9.5</b> Different “key” variable names</a></li>
<li class="chapter" data-level="4.9.6" data-path="4-wrangling.html"><a href="4-wrangling.html#multiple-key-variables"><i class="fa fa-check"></i><b>4.9.6</b> Multiple “key” variables</a></li>
<li class="chapter" data-level="4.9.7" data-path="4-wrangling.html"><a href="4-wrangling.html#normal-forms"><i class="fa fa-check"></i><b>4.9.7</b> Normal forms</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="4-wrangling.html"><a href="4-wrangling.html#other-verbs"><i class="fa fa-check"></i><b>4.10</b> Other Verbs</a><ul>
<li class="chapter" data-level="4.10.1" data-path="4-wrangling.html"><a href="4-wrangling.html#select"><i class="fa fa-check"></i><b>4.10.1</b> <code>select</code> variables</a></li>
<li class="chapter" data-level="4.10.2" data-path="4-wrangling.html"><a href="4-wrangling.html#rename"><i class="fa fa-check"></i><b>4.10.2</b> <code>rename</code> variables</a></li>
<li class="chapter" data-level="4.10.3" data-path="4-wrangling.html"><a href="4-wrangling.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>4.10.3</b> <code>top_n</code> values of a variable</a></li>
<li class="chapter" data-level="4.10.4" data-path="4-wrangling.html"><a href="4-wrangling.html#slice-and-pull-and"><i class="fa fa-check"></i><b>4.10.4</b> <code>slice</code> and <code>pull</code> and <code>[]</code></a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="4-wrangling.html"><a href="4-wrangling.html#conclusion-2"><i class="fa fa-check"></i><b>4.11</b> Conclusion</a><ul>
<li class="chapter" data-level="4.11.1" data-path="4-wrangling.html"><a href="4-wrangling.html#summary-table-1"><i class="fa fa-check"></i><b>4.11.1</b> Summary table</a></li>
<li class="chapter" data-level="4.11.2" data-path="4-wrangling.html"><a href="4-wrangling.html#additional-resources-2"><i class="fa fa-check"></i><b>4.11.2</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-tidy.html"><a href="5-tidy.html"><i class="fa fa-check"></i><b>5</b> Tidy</a><ul>
<li class="chapter" data-level="5.1" data-path="5-tidy.html"><a href="5-tidy.html#csv"><i class="fa fa-check"></i><b>5.1</b> Importing data</a></li>
<li class="chapter" data-level="5.2" data-path="5-tidy.html"><a href="5-tidy.html#web-scraping"><i class="fa fa-check"></i><b>5.2</b> Web scraping</a><ul>
<li class="chapter" data-level="5.2.1" data-path="5-tidy.html"><a href="5-tidy.html#html"><i class="fa fa-check"></i><b>5.2.1</b> HTML</a></li>
<li class="chapter" data-level="5.2.2" data-path="5-tidy.html"><a href="5-tidy.html#the-rvest-package"><i class="fa fa-check"></i><b>5.2.2</b> The rvest package</a></li>
<li class="chapter" data-level="5.2.3" data-path="5-tidy.html"><a href="5-tidy.html#css-selectors"><i class="fa fa-check"></i><b>5.2.3</b> CSS selectors</a></li>
<li class="chapter" data-level="5.2.4" data-path="5-tidy.html"><a href="5-tidy.html#json"><i class="fa fa-check"></i><b>5.2.4</b> JSON</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5-tidy.html"><a href="5-tidy.html#tidy-data-ex"><i class="fa fa-check"></i><b>5.3</b> “Tidy” data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="5-tidy.html"><a href="5-tidy.html#tidy-definition"><i class="fa fa-check"></i><b>5.3.1</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="5.3.2" data-path="5-tidy.html"><a href="5-tidy.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>5.3.2</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="5.3.3" data-path="5-tidy.html"><a href="5-tidy.html#nycflights13-package-1"><i class="fa fa-check"></i><b>5.3.3</b> <code>nycflights13</code> package</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5-tidy.html"><a href="5-tidy.html#case-study-tidy"><i class="fa fa-check"></i><b>5.4</b> Case study: Democracy in Guatemala</a></li>
<li class="chapter" data-level="5.5" data-path="5-tidy.html"><a href="5-tidy.html#tidyverse-package"><i class="fa fa-check"></i><b>5.5</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="5.6" data-path="5-tidy.html"><a href="5-tidy.html#conclusion-3"><i class="fa fa-check"></i><b>5.6</b> Conclusion</a><ul>
<li class="chapter" data-level="5.6.1" data-path="5-tidy.html"><a href="5-tidy.html#additional-resources-3"><i class="fa fa-check"></i><b>5.6.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-functions.html"><a href="6-functions.html"><i class="fa fa-check"></i><b>6</b> Functions</a><ul>
<li class="chapter" data-level="6.1" data-path="6-functions.html"><a href="6-functions.html#part-1"><i class="fa fa-check"></i><b>6.1</b> Part 1</a><ul>
<li class="chapter" data-level="6.1.1" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works"><i class="fa fa-check"></i><b>6.1.1</b> Get something that works</a></li>
<li class="chapter" data-level="6.1.2" data-path="6-functions.html"><a href="6-functions.html#skateboard-perfectly-formed-rear-view-mirror"><i class="fa fa-check"></i><b>6.1.2</b> Skateboard &gt;&gt; perfectly formed rear-view mirror</a></li>
<li class="chapter" data-level="6.1.3" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function"><i class="fa fa-check"></i><b>6.1.3</b> Turn the working interactive code into a function</a></li>
<li class="chapter" data-level="6.1.4" data-path="6-functions.html"><a href="6-functions.html#test-your-function"><i class="fa fa-check"></i><b>6.1.4</b> Test your function</a></li>
<li class="chapter" data-level="6.1.5" data-path="6-functions.html"><a href="6-functions.html#check-the-validity-of-arguments"><i class="fa fa-check"></i><b>6.1.5</b> Check the validity of arguments</a></li>
<li class="chapter" data-level="6.1.6" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next"><i class="fa fa-check"></i><b>6.1.6</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="6-functions.html"><a href="6-functions.html#part-2"><i class="fa fa-check"></i><b>6.2</b> Part 2</a><ul>
<li class="chapter" data-level="6.2.1" data-path="6-functions.html"><a href="6-functions.html#load-the-gapminder-data"><i class="fa fa-check"></i><b>6.2.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="6.2.2" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function"><i class="fa fa-check"></i><b>6.2.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.2.3" data-path="6-functions.html"><a href="6-functions.html#generalize-our-function-to-other-quantiles"><i class="fa fa-check"></i><b>6.2.3</b> Generalize our function to other quantiles</a></li>
<li class="chapter" data-level="6.2.4" data-path="6-functions.html"><a href="6-functions.html#get-something-that-works-again"><i class="fa fa-check"></i><b>6.2.4</b> Get something that works, again</a></li>
<li class="chapter" data-level="6.2.5" data-path="6-functions.html"><a href="6-functions.html#turn-the-working-interactive-code-into-a-function-again"><i class="fa fa-check"></i><b>6.2.5</b> Turn the working interactive code into a function, again</a></li>
<li class="chapter" data-level="6.2.6" data-path="6-functions.html"><a href="6-functions.html#argument-names-freedom-and-conventions"><i class="fa fa-check"></i><b>6.2.6</b> Argument names: freedom and conventions</a></li>
<li class="chapter" data-level="6.2.7" data-path="6-functions.html"><a href="6-functions.html#what-a-function-returns"><i class="fa fa-check"></i><b>6.2.7</b> What a function returns</a></li>
<li class="chapter" data-level="6.2.8" data-path="6-functions.html"><a href="6-functions.html#default-values-freedom-to-not-specify-the-arguments"><i class="fa fa-check"></i><b>6.2.8</b> Default values: freedom to NOT specify the arguments</a></li>
<li class="chapter" data-level="6.2.9" data-path="6-functions.html"><a href="6-functions.html#wrap-up-and-whats-next-1"><i class="fa fa-check"></i><b>6.2.9</b> Wrap-up and what’s next?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="6-functions.html"><a href="6-functions.html#part-3"><i class="fa fa-check"></i><b>6.3</b> Part 3</a><ul>
<li class="chapter" data-level="6.3.1" data-path="6-functions.html"><a href="6-functions.html#load-the-gapminder-data-1"><i class="fa fa-check"></i><b>6.3.1</b> Load the Gapminder data</a></li>
<li class="chapter" data-level="6.3.2" data-path="6-functions.html"><a href="6-functions.html#restore-our-max-minus-min-function-1"><i class="fa fa-check"></i><b>6.3.2</b> Restore our max minus min function</a></li>
<li class="chapter" data-level="6.3.3" data-path="6-functions.html"><a href="6-functions.html#be-proactive-about-nas"><i class="fa fa-check"></i><b>6.3.3</b> Be proactive about <code>NA</code>s</a></li>
<li class="chapter" data-level="6.3.4" data-path="6-functions.html"><a href="6-functions.html#the-useful-but-mysterious-...-argument"><i class="fa fa-check"></i><b>6.3.4</b> The useful but mysterious <code>...</code> argument</a></li>
<li class="chapter" data-level="6.3.5" data-path="6-functions.html"><a href="6-functions.html#use-testthat-for-formal-unit-tests"><i class="fa fa-check"></i><b>6.3.5</b> Use testthat for formal unit tests</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6-functions.html"><a href="6-functions.html#list-columns-and-map_-functions"><i class="fa fa-check"></i><b>6.4</b> List columns and <code>map_*</code> functions</a><ul>
<li class="chapter" data-level="6.4.1" data-path="6-functions.html"><a href="6-functions.html#what-are-list-columns"><i class="fa fa-check"></i><b>6.4.1</b> What are list columns?</a></li>
<li class="chapter" data-level="6.4.2" data-path="6-functions.html"><a href="6-functions.html#creating-list-columns-with-mutate"><i class="fa fa-check"></i><b>6.4.2</b> Creating list columns with <code>mutate()</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="6-functions.html"><a href="6-functions.html#map_-functions"><i class="fa fa-check"></i><b>6.4.3</b> <code>map_*</code> functions</a></li>
<li class="chapter" data-level="6.4.4" data-path="6-functions.html"><a href="6-functions.html#using-map_-functions-to-create-list-columns"><i class="fa fa-check"></i><b>6.4.4</b> Using <code>map_*</code> functions to create list columns</a></li>
<li class="chapter" data-level="6.4.5" data-path="6-functions.html"><a href="6-functions.html#practice-with-map_-functions-and-list-columns"><i class="fa fa-check"></i><b>6.4.5</b> Practice with <code>map_*</code> functions and list columns</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-probability.html"><a href="7-probability.html"><i class="fa fa-check"></i><b>7</b> Probability</a><ul>
<li class="chapter" data-level="7.1" data-path="7-probability.html"><a href="7-probability.html#basicsOfProbability"><i class="fa fa-check"></i><b>7.1</b> Defining probability</a><ul>
<li class="chapter" data-level="7.1.1" data-path="7-probability.html"><a href="7-probability.html#intro-questions"><i class="fa fa-check"></i><b>7.1.1</b> Intro Questions</a></li>
<li class="chapter" data-level="7.1.2" data-path="7-probability.html"><a href="7-probability.html#probability-1"><i class="fa fa-check"></i><b>7.1.2</b> Probability</a></li>
<li class="chapter" data-level="7.1.3" data-path="7-probability.html"><a href="7-probability.html#disjoint-or-mutually-exclusive-outcomes"><i class="fa fa-check"></i><b>7.1.3</b> Disjoint or mutually exclusive outcomes</a></li>
<li class="chapter" data-level="7.1.4" data-path="7-probability.html"><a href="7-probability.html#probabilities-when-events-are-not-disjoint"><i class="fa fa-check"></i><b>7.1.4</b> Probabilities when events are not disjoint</a></li>
<li class="chapter" data-level="7.1.5" data-path="7-probability.html"><a href="7-probability.html#probability-distributions"><i class="fa fa-check"></i><b>7.1.5</b> Probability distributions</a></li>
<li class="chapter" data-level="7.1.6" data-path="7-probability.html"><a href="7-probability.html#complement-of-an-event"><i class="fa fa-check"></i><b>7.1.6</b> Complement of an event</a></li>
<li class="chapter" data-level="7.1.7" data-path="7-probability.html"><a href="7-probability.html#probabilityIndependence"><i class="fa fa-check"></i><b>7.1.7</b> Independence</a></li>
<li class="chapter" data-level="7.1.8" data-path="7-probability.html"><a href="7-probability.html#conditionalProbabilitySection"><i class="fa fa-check"></i><b>7.1.8</b> Conditional probability</a></li>
<li class="chapter" data-level="7.1.9" data-path="7-probability.html"><a href="7-probability.html#marginalAndJointProbabilities"><i class="fa fa-check"></i><b>7.1.9</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="7.1.10" data-path="7-probability.html"><a href="7-probability.html#defining-conditional-probability"><i class="fa fa-check"></i><b>7.1.10</b> Defining conditional probability</a></li>
<li class="chapter" data-level="7.1.11" data-path="7-probability.html"><a href="7-probability.html#smallpox-in-boston-1721"><i class="fa fa-check"></i><b>7.1.11</b> Smallpox in Boston, 1721</a></li>
<li class="chapter" data-level="7.1.12" data-path="7-probability.html"><a href="7-probability.html#general-multiplication-rule"><i class="fa fa-check"></i><b>7.1.12</b> General multiplication rule</a></li>
<li class="chapter" data-level="7.1.13" data-path="7-probability.html"><a href="7-probability.html#tree-diagrams"><i class="fa fa-check"></i><b>7.1.13</b> Tree diagrams</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="7-probability.html"><a href="7-probability.html#randomVariablesSection"><i class="fa fa-check"></i><b>7.2</b> Random variables</a><ul>
<li class="chapter" data-level="7.2.1" data-path="7-probability.html"><a href="7-probability.html#expectation"><i class="fa fa-check"></i><b>7.2.1</b> Expectation</a></li>
<li class="chapter" data-level="7.2.2" data-path="7-probability.html"><a href="7-probability.html#variability-in-random-variables"><i class="fa fa-check"></i><b>7.2.2</b> Variability in random variables</a></li>
<li class="chapter" data-level="7.2.3" data-path="7-probability.html"><a href="7-probability.html#linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.2.3</b> Linear combinations of random variables</a></li>
<li class="chapter" data-level="7.2.4" data-path="7-probability.html"><a href="7-probability.html#variability-in-linear-combinations-of-random-variables"><i class="fa fa-check"></i><b>7.2.4</b> Variability in linear combinations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7-probability.html"><a href="7-probability.html#appendixA"><i class="fa fa-check"></i><b>7.3</b> Statistical Background</a><ul>
<li class="chapter" data-level="7.3.1" data-path="7-probability.html"><a href="7-probability.html#appendix-stat-terms"><i class="fa fa-check"></i><b>7.3.1</b> Basic statistical terms</a></li>
<li class="chapter" data-level="7.3.2" data-path="7-probability.html"><a href="7-probability.html#appendix-normal-curve"><i class="fa fa-check"></i><b>7.3.2</b> Normal distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html"><i class="fa fa-check"></i><b>8</b> Bayes’s Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conditional-probability"><i class="fa fa-check"></i><b>8.1</b> Conditional probability</a></li>
<li class="chapter" data-level="8.2" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#conjoint-probability"><i class="fa fa-check"></i><b>8.2</b> Conjoint probability</a></li>
<li class="chapter" data-level="8.3" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-cookie-problem"><i class="fa fa-check"></i><b>8.3</b> The cookie problem</a></li>
<li class="chapter" data-level="8.4" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#bayess-theorem-1"><i class="fa fa-check"></i><b>8.4</b> Bayes’s Theorem</a></li>
<li class="chapter" data-level="8.5" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-diachronic-interpretation"><i class="fa fa-check"></i><b>8.5</b> The diachronic interpretation</a></li>
<li class="chapter" data-level="8.6" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-mm-problem"><i class="fa fa-check"></i><b>8.6</b> The M&amp;M problem</a></li>
<li class="chapter" data-level="8.7" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#the-monty-hall-problem"><i class="fa fa-check"></i><b>8.7</b> The Monty Hall problem</a></li>
<li class="chapter" data-level="8.8" data-path="8-bayess-theorem.html"><a href="8-bayess-theorem.html#discussion"><i class="fa fa-check"></i><b>8.8</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-sampling.html"><a href="9-sampling.html"><i class="fa fa-check"></i><b>9</b> Sampling</a><ul>
<li class="chapter" data-level="" data-path="9-sampling.html"><a href="9-sampling.html#needed-packages-1"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="9.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>9.1</b> Sampling bowl activity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="9-sampling.html"><a href="9-sampling.html#what-proportion-of-this-bowls-balls-are-red"><i class="fa fa-check"></i><b>9.1.1</b> What proportion of this bowl’s balls are red?</a></li>
<li class="chapter" data-level="9.1.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-shovel-once"><i class="fa fa-check"></i><b>9.1.2</b> Using the shovel once</a></li>
<li class="chapter" data-level="9.1.3" data-path="9-sampling.html"><a href="9-sampling.html#student-shovels"><i class="fa fa-check"></i><b>9.1.3</b> Using the shovel 33 times</a></li>
<li class="chapter" data-level="9.1.4" data-path="9-sampling.html"><a href="9-sampling.html#what-did-we-just-do"><i class="fa fa-check"></i><b>9.1.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>9.2</b> Virtual sampling</a><ul>
<li class="chapter" data-level="9.2.1" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-once"><i class="fa fa-check"></i><b>9.2.1</b> Using the virtual shovel once</a></li>
<li class="chapter" data-level="9.2.2" data-path="9-sampling.html"><a href="9-sampling.html#using-the-virtual-shovel-33-times"><i class="fa fa-check"></i><b>9.2.2</b> Using the virtual shovel 33 times</a></li>
<li class="chapter" data-level="9.2.3" data-path="9-sampling.html"><a href="9-sampling.html#shovel-1000-times"><i class="fa fa-check"></i><b>9.2.3</b> Using the virtual shovel 1000 times</a></li>
<li class="chapter" data-level="9.2.4" data-path="9-sampling.html"><a href="9-sampling.html#different-shovels"><i class="fa fa-check"></i><b>9.2.4</b> Using different shovels</a></li>
<li class="chapter" data-level="9.2.5" data-path="9-sampling.html"><a href="9-sampling.html#using-many-shovels-at-once"><i class="fa fa-check"></i><b>9.2.5</b> Using many shovels at once</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="9-sampling.html"><a href="9-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>9.3</b> Sampling framework</a><ul>
<li class="chapter" data-level="9.3.1" data-path="9-sampling.html"><a href="9-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>9.3.1</b> Terminology and notation</a></li>
<li class="chapter" data-level="9.3.2" data-path="9-sampling.html"><a href="9-sampling.html#sampling-definitions"><i class="fa fa-check"></i><b>9.3.2</b> Statistical definitions</a></li>
<li class="chapter" data-level="9.3.3" data-path="9-sampling.html"><a href="9-sampling.html#moral-of-the-story"><i class="fa fa-check"></i><b>9.3.3</b> The moral of the story</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9-sampling.html"><a href="9-sampling.html#sampling-case-study"><i class="fa fa-check"></i><b>9.4</b> Case study: Polls</a></li>
<li class="chapter" data-level="9.5" data-path="9-sampling.html"><a href="9-sampling.html#sampling-conclusion"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a><ul>
<li class="chapter" data-level="9.5.1" data-path="9-sampling.html"><a href="9-sampling.html#sampling-conclusion-central-limit-theorem"><i class="fa fa-check"></i><b>9.5.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="9.5.2" data-path="9-sampling.html"><a href="9-sampling.html#whats-to-come"><i class="fa fa-check"></i><b>9.5.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#needed-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="10.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>10.1</b> Pennies activity</a><ul>
<li class="chapter" data-level="10.1.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>10.1.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="10.1.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>10.1.2</b> Resampling once</a></li>
<li class="chapter" data-level="10.1.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>10.1.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="10.1.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#what-did-we-just-do-1"><i class="fa fa-check"></i><b>10.1.4</b> What did we just do?</a></li>
<li class="chapter" data-level="10.1.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>10.1.5</b> Virtually resampling once</a></li>
<li class="chapter" data-level="10.1.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-35-replicates"><i class="fa fa-check"></i><b>10.1.6</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="10.1.7" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>10.1.7</b> Virtually resampling 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>10.2</b> Measuring uncertainty with confidence intervals</a><ul>
<li class="chapter" data-level="10.2.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>10.2.1</b> Percentile method</a></li>
<li class="chapter" data-level="10.2.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>10.2.2</b> Standard error method</a></li>
<li class="chapter" data-level="10.2.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>10.2.3</b> Interpreting confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>10.3</b> Width of confidence intervals</a><ul>
<li class="chapter" data-level="10.3.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-confidence-level"><i class="fa fa-check"></i><b>10.3.1</b> Impact of confidence level</a></li>
<li class="chapter" data-level="10.3.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#fitting-multiple-models-using-map"><i class="fa fa-check"></i><b>10.3.2</b> Fitting multiple models using <code>map()</code></a></li>
<li class="chapter" data-level="10.3.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#impact-of-sample-size"><i class="fa fa-check"></i><b>10.3.3</b> Impact of sample size</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut"><i class="fa fa-check"></i><b>10.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="10.5" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>10.5</b> Case study: Is yawning contagious?</a><ul>
<li class="chapter" data-level="10.5.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>10.5.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="10.5.2" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>10.5.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="10.5.3" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>10.5.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="10.5.4" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#using-lm-and-tidy-as-a-shortcut-1"><i class="fa fa-check"></i><b>10.5.4</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>10.6</b> Conclusion</a><ul>
<li class="chapter" data-level="10.6.1" data-path="10-confidence-intervals.html"><a href="10-confidence-intervals.html#bootstrap-vs-sampling"><i class="fa fa-check"></i><b>10.6.1</b> Comparing bootstrap and sampling distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="11-regression.html"><a href="11-regression.html"><i class="fa fa-check"></i><b>11</b> Regression</a><ul>
<li class="chapter" data-level="" data-path="11-regression.html"><a href="11-regression.html#needed-packages-3"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="11.1" data-path="11-regression.html"><a href="11-regression.html#model1"><i class="fa fa-check"></i><b>11.1</b> Teaching evaluations: one numerical explanatory variable</a><ul>
<li class="chapter" data-level="11.1.1" data-path="11-regression.html"><a href="11-regression.html#model1EDA"><i class="fa fa-check"></i><b>11.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="11-regression.html"><a href="11-regression.html#model1table"><i class="fa fa-check"></i><b>11.1.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="11.1.3" data-path="11-regression.html"><a href="11-regression.html#interpreting-regression-coefficients"><i class="fa fa-check"></i><b>11.1.3</b> Interpreting regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="11-regression.html"><a href="11-regression.html#uncertainty-in-simple-linear-regressions"><i class="fa fa-check"></i><b>11.2</b> Uncertainty in simple linear regressions</a><ul>
<li class="chapter" data-level="11.2.1" data-path="11-regression.html"><a href="11-regression.html#using-lm-and-tidy-as-a-shortcut-2"><i class="fa fa-check"></i><b>11.2.1</b> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</a></li>
<li class="chapter" data-level="11.2.2" data-path="11-regression.html"><a href="11-regression.html#model1points"><i class="fa fa-check"></i><b>11.2.2</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="11-regression.html"><a href="11-regression.html#model2"><i class="fa fa-check"></i><b>11.3</b> Life expectancy: one categorical explanatory variable</a><ul>
<li class="chapter" data-level="11.3.1" data-path="11-regression.html"><a href="11-regression.html#model2EDA"><i class="fa fa-check"></i><b>11.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.3.2" data-path="11-regression.html"><a href="11-regression.html#model2table"><i class="fa fa-check"></i><b>11.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="11.3.3" data-path="11-regression.html"><a href="11-regression.html#model2points"><i class="fa fa-check"></i><b>11.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="11-regression.html"><a href="11-regression.html#case-study-2018-gubernatorial-forecasts"><i class="fa fa-check"></i><b>11.4</b> Case study: 2018 gubernatorial forecasts</a><ul>
<li class="chapter" data-level="11.4.1" data-path="11-regression.html"><a href="11-regression.html#fitting-multiple-models-using-map-1"><i class="fa fa-check"></i><b>11.4.1</b> Fitting multiple models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="11-regression.html"><a href="11-regression.html#leastsquares"><i class="fa fa-check"></i><b>11.5</b> Appendix: Best-fitting line</a></li>
<li class="chapter" data-level="11.6" data-path="11-regression.html"><a href="11-regression.html#conclusion-4"><i class="fa fa-check"></i><b>11.6</b> Conclusion</a><ul>
<li class="chapter" data-level="11.6.1" data-path="11-regression.html"><a href="11-regression.html#additional-resources-basic-regression"><i class="fa fa-check"></i><b>11.6.1</b> Additional resources</a></li>
<li class="chapter" data-level="11.6.2" data-path="11-regression.html"><a href="11-regression.html#whats-to-come-1"><i class="fa fa-check"></i><b>11.6.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html"><i class="fa fa-check"></i><b>12</b> Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#needed-packages-4"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="12.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4"><i class="fa fa-check"></i><b>12.1</b> Teaching evaluations revisited: one numerical and one categorical explanatory variable</a><ul>
<li class="chapter" data-level="12.1.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>12.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.1.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>12.1.2</b> Interaction model</a></li>
<li class="chapter" data-level="12.1.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>12.1.3</b> Parallel slopes model</a></li>
<li class="chapter" data-level="12.1.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>12.1.4</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3"><i class="fa fa-check"></i><b>12.2</b> Credit card debt: two numerical explanatory variables</a><ul>
<li class="chapter" data-level="12.2.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>12.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>12.2.2</b> Regression plane</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>12.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#seattle-house-prices"><i class="fa fa-check"></i><b>12.3</b> Case study: Seattle house prices</a><ul>
<li class="chapter" data-level="12.3.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-I"><i class="fa fa-check"></i><b>12.3.1</b> Exploratory data analysis: Part I</a></li>
<li class="chapter" data-level="12.3.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-EDA-II"><i class="fa fa-check"></i><b>12.3.2</b> Exploratory data analysis: Part II</a></li>
<li class="chapter" data-level="12.3.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-regression"><i class="fa fa-check"></i><b>12.3.3</b> Regression modeling</a></li>
<li class="chapter" data-level="12.3.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#house-prices-making-predictions"><i class="fa fa-check"></i><b>12.3.4</b> Making predictions</a></li>
<li class="chapter" data-level="12.3.5" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#fitting-many-models-using-map"><i class="fa fa-check"></i><b>12.3.5</b> Fitting many models using <code>map()</code></a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#data-journalism"><i class="fa fa-check"></i><b>12.4</b> Case studies: Effective data storytelling</a><ul>
<li class="chapter" data-level="12.4.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#bechdel-test-for-hollywood-gender-representation"><i class="fa fa-check"></i><b>12.4.1</b> Bechdel test for Hollywood gender representation</a></li>
<li class="chapter" data-level="12.4.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#us-births-in-1999"><i class="fa fa-check"></i><b>12.4.2</b> US Births in 1999</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#appendix-related-topics"><i class="fa fa-check"></i><b>12.5</b> Appendix: Related topics</a><ul>
<li class="chapter" data-level="12.5.1" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#model-selection"><i class="fa fa-check"></i><b>12.5.1</b> Model selection</a></li>
<li class="chapter" data-level="12.5.2" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#correlationcoefficient2"><i class="fa fa-check"></i><b>12.5.2</b> Correlation coefficient</a></li>
<li class="chapter" data-level="12.5.3" data-path="12-multiple-regression.html"><a href="12-multiple-regression.html#simpsonsparadox"><i class="fa fa-check"></i><b>12.5.3</b> Simpson’s Paradox</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="13-classification.html"><a href="13-classification.html"><i class="fa fa-check"></i><b>13</b> Classification</a><ul>
<li class="chapter" data-level="13.1" data-path="13-classification.html"><a href="13-classification.html#learning-objectives"><i class="fa fa-check"></i><b>13.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="13.2" data-path="13-classification.html"><a href="13-classification.html#introduction-to-logistic-regression"><i class="fa fa-check"></i><b>13.2</b> Introduction to Logistic Regression</a><ul>
<li class="chapter" data-level="13.2.1" data-path="13-classification.html"><a href="13-classification.html#logistic-regression-assumptions"><i class="fa fa-check"></i><b>13.2.1</b> Logistic Regression Assumptions</a></li>
<li class="chapter" data-level="13.2.2" data-path="13-classification.html"><a href="13-classification.html#a-graphical-look-at-logistic-regression"><i class="fa fa-check"></i><b>13.2.2</b> A Graphical Look at Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="13-classification.html"><a href="13-classification.html#case-studies-overview"><i class="fa fa-check"></i><b>13.3</b> Case Studies Overview</a></li>
<li class="chapter" data-level="13.4" data-path="13-classification.html"><a href="13-classification.html#case-study-soccer-goalkeepers"><i class="fa fa-check"></i><b>13.4</b> Case Study: Soccer Goalkeepers</a><ul>
<li class="chapter" data-level="13.4.1" data-path="13-classification.html"><a href="13-classification.html#modeling-odds"><i class="fa fa-check"></i><b>13.4.1</b> Modeling Odds</a></li>
<li class="chapter" data-level="13.4.2" data-path="13-classification.html"><a href="13-classification.html#logistic-regression-models-for-binomial-responses"><i class="fa fa-check"></i><b>13.4.2</b> Logistic Regression Models for Binomial Responses</a></li>
<li class="chapter" data-level="13.4.3" data-path="13-classification.html"><a href="13-classification.html#theoretical-rationale-for-logistic-regression-models-optional"><i class="fa fa-check"></i><b>13.4.3</b> Theoretical rationale for logistic regression models (Optional)</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="13-classification.html"><a href="13-classification.html#case-study-reconstructing-alabama"><i class="fa fa-check"></i><b>13.5</b> Case Study: Reconstructing Alabama</a><ul>
<li class="chapter" data-level="13.5.1" data-path="13-classification.html"><a href="13-classification.html#data-organization"><i class="fa fa-check"></i><b>13.5.1</b> Data Organization</a></li>
<li class="chapter" data-level="13.5.2" data-path="13-classification.html"><a href="13-classification.html#exploratory-analyses"><i class="fa fa-check"></i><b>13.5.2</b> Exploratory Analyses</a></li>
<li class="chapter" data-level="13.5.3" data-path="13-classification.html"><a href="13-classification.html#initial-models"><i class="fa fa-check"></i><b>13.5.3</b> Initial Models</a></li>
<li class="chapter" data-level="13.5.4" data-path="13-classification.html"><a href="13-classification.html#sec-logisticInf"><i class="fa fa-check"></i><b>13.5.4</b> Tests for significance of model coefficients</a></li>
<li class="chapter" data-level="13.5.5" data-path="13-classification.html"><a href="13-classification.html#confidence-intervals-for-model-coefficients"><i class="fa fa-check"></i><b>13.5.5</b> Confidence intervals for model coefficients</a></li>
<li class="chapter" data-level="13.5.6" data-path="13-classification.html"><a href="13-classification.html#testing-for-goodness-of-fit"><i class="fa fa-check"></i><b>13.5.6</b> Testing for goodness of fit</a></li>
<li class="chapter" data-level="13.5.7" data-path="13-classification.html"><a href="13-classification.html#residuals-for-binomial-regression"><i class="fa fa-check"></i><b>13.5.7</b> Residuals for Binomial Regression</a></li>
<li class="chapter" data-level="13.5.8" data-path="13-classification.html"><a href="13-classification.html#sec-logOverdispersion"><i class="fa fa-check"></i><b>13.5.8</b> Overdispersion</a></li>
<li class="chapter" data-level="13.5.9" data-path="13-classification.html"><a href="13-classification.html#summary-5"><i class="fa fa-check"></i><b>13.5.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="13-classification.html"><a href="13-classification.html#least-squares-regression-vs.-logistic-regression"><i class="fa fa-check"></i><b>13.6</b> Least Squares Regression vs. Logistic Regression</a></li>
<li class="chapter" data-level="13.7" data-path="13-classification.html"><a href="13-classification.html#case-study-trying-to-lose-weight"><i class="fa fa-check"></i><b>13.7</b> Case Study: Trying to Lose Weight</a><ul>
<li class="chapter" data-level="13.7.1" data-path="13-classification.html"><a href="13-classification.html#data-organization-1"><i class="fa fa-check"></i><b>13.7.1</b> Data Organization</a></li>
<li class="chapter" data-level="13.7.2" data-path="13-classification.html"><a href="13-classification.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>13.7.2</b> Exploratory Data Analysis</a></li>
<li class="chapter" data-level="13.7.3" data-path="13-classification.html"><a href="13-classification.html#initial-models-1"><i class="fa fa-check"></i><b>13.7.3</b> Initial Models</a></li>
<li class="chapter" data-level="13.7.4" data-path="13-classification.html"><a href="13-classification.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>13.7.4</b> Drop-in-deviance Tests</a></li>
<li class="chapter" data-level="13.7.5" data-path="13-classification.html"><a href="13-classification.html#model-discussion-and-summary"><i class="fa fa-check"></i><b>13.7.5</b> Model Discussion and Summary</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="13-classification.html"><a href="13-classification.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>13.8</b> Classification and regression trees (CART)</a><ul>
<li class="chapter" data-level="13.8.1" data-path="13-classification.html"><a href="13-classification.html#the-curse-of-dimensionality"><i class="fa fa-check"></i><b>13.8.1</b> The curse of dimensionality</a></li>
<li class="chapter" data-level="13.8.2" data-path="13-classification.html"><a href="13-classification.html#cart-motivation"><i class="fa fa-check"></i><b>13.8.2</b> CART motivation</a></li>
<li class="chapter" data-level="13.8.3" data-path="13-classification.html"><a href="13-classification.html#regression-trees"><i class="fa fa-check"></i><b>13.8.3</b> Regression trees</a></li>
<li class="chapter" data-level="13.8.4" data-path="13-classification.html"><a href="13-classification.html#classification-decision-trees"><i class="fa fa-check"></i><b>13.8.4</b> Classification (decision) trees</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="13-classification.html"><a href="13-classification.html#random-forests"><i class="fa fa-check"></i><b>13.9</b> Random forests</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="14-machine.html"><a href="14-machine.html"><i class="fa fa-check"></i><b>14</b> Machine Learning</a><ul>
<li class="chapter" data-level="14.1" data-path="14-machine.html"><a href="14-machine.html#notation"><i class="fa fa-check"></i><b>14.1</b> Notation</a></li>
<li class="chapter" data-level="14.2" data-path="14-machine.html"><a href="14-machine.html#an-example"><i class="fa fa-check"></i><b>14.2</b> An example</a></li>
<li class="chapter" data-level="14.3" data-path="14-machine.html"><a href="14-machine.html#evaluation-metrics"><i class="fa fa-check"></i><b>14.3</b> Evaluation metrics</a><ul>
<li class="chapter" data-level="14.3.1" data-path="14-machine.html"><a href="14-machine.html#training-and-test-sets"><i class="fa fa-check"></i><b>14.3.1</b> Training and test sets</a></li>
<li class="chapter" data-level="14.3.2" data-path="14-machine.html"><a href="14-machine.html#overall-accuracy"><i class="fa fa-check"></i><b>14.3.2</b> Overall accuracy</a></li>
<li class="chapter" data-level="14.3.3" data-path="14-machine.html"><a href="14-machine.html#the-confusion-matrix"><i class="fa fa-check"></i><b>14.3.3</b> The confusion matrix</a></li>
<li class="chapter" data-level="14.3.4" data-path="14-machine.html"><a href="14-machine.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.3.4</b> Sensitivity and specificity</a></li>
<li class="chapter" data-level="14.3.5" data-path="14-machine.html"><a href="14-machine.html#balanced-accuracy-and-f_1-score"><i class="fa fa-check"></i><b>14.3.5</b> Balanced accuracy and <span class="math inline">\(F_1\)</span> score</a></li>
<li class="chapter" data-level="14.3.6" data-path="14-machine.html"><a href="14-machine.html#prevalence-matters-in-practice"><i class="fa fa-check"></i><b>14.3.6</b> Prevalence matters in practice</a></li>
<li class="chapter" data-level="14.3.7" data-path="14-machine.html"><a href="14-machine.html#roc-and-precision-recall-curves"><i class="fa fa-check"></i><b>14.3.7</b> ROC and precision-recall curves</a></li>
<li class="chapter" data-level="14.3.8" data-path="14-machine.html"><a href="14-machine.html#loss-function"><i class="fa fa-check"></i><b>14.3.8</b> The loss function</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="14-machine.html"><a href="14-machine.html#conditional-probabilities-and-expectations"><i class="fa fa-check"></i><b>14.4</b> Conditional probabilities and expectations</a><ul>
<li class="chapter" data-level="14.4.1" data-path="14-machine.html"><a href="14-machine.html#conditional-probabilities"><i class="fa fa-check"></i><b>14.4.1</b> Conditional probabilities</a></li>
<li class="chapter" data-level="14.4.2" data-path="14-machine.html"><a href="14-machine.html#conditional-expectations"><i class="fa fa-check"></i><b>14.4.2</b> Conditional expectations</a></li>
<li class="chapter" data-level="14.4.3" data-path="14-machine.html"><a href="14-machine.html#conditional-expectation-minimizes-squared-loss-function"><i class="fa fa-check"></i><b>14.4.3</b> Conditional expectation minimizes squared loss function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="14-machine.html"><a href="14-machine.html#two-or-seven"><i class="fa fa-check"></i><b>14.5</b> Case study: is it a 2 or a 7?</a></li>
<li class="chapter" data-level="14.6" data-path="14-machine.html"><a href="14-machine.html#cross-validation"><i class="fa fa-check"></i><b>14.6</b> Cross validation</a></li>
<li class="chapter" data-level="14.7" data-path="14-machine.html"><a href="14-machine.html#knn-cv-intro"><i class="fa fa-check"></i><b>14.7</b> Motivation with k-nearest neighbors</a><ul>
<li class="chapter" data-level="14.7.1" data-path="14-machine.html"><a href="14-machine.html#over-training"><i class="fa fa-check"></i><b>14.7.1</b> Over-training</a></li>
<li class="chapter" data-level="14.7.2" data-path="14-machine.html"><a href="14-machine.html#over-smoothing"><i class="fa fa-check"></i><b>14.7.2</b> Over-smoothing</a></li>
<li class="chapter" data-level="14.7.3" data-path="14-machine.html"><a href="14-machine.html#picking-the-k-in-knn"><i class="fa fa-check"></i><b>14.7.3</b> Picking the <span class="math inline">\(k\)</span> in kNN</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="14-machine.html"><a href="14-machine.html#mathematical-description-of-cross-validation"><i class="fa fa-check"></i><b>14.8</b> Mathematical description of cross validation</a></li>
<li class="chapter" data-level="14.9" data-path="14-machine.html"><a href="14-machine.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>14.9</b> K-fold cross validation</a></li>
<li class="chapter" data-level="14.10" data-path="14-machine.html"><a href="14-machine.html#bootstrap"><i class="fa fa-check"></i><b>14.10</b> Bootstrap</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html"><i class="fa fa-check"></i><b>A</b> Rubin Causal Model</a><ul>
<li class="chapter" data-level="A.1" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#causal-effects"><i class="fa fa-check"></i><b>A.1</b> Causal effects</a></li>
<li class="chapter" data-level="A.2" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#potential-outcomes"><i class="fa fa-check"></i><b>A.2</b> Potential outcomes</a></li>
<li class="chapter" data-level="A.3" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#no-causation-without-manipulation"><i class="fa fa-check"></i><b>A.3</b> No causation without manipulation</a></li>
<li class="chapter" data-level="A.4" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#average-treatment-effect"><i class="fa fa-check"></i><b>A.4</b> Average treatment effect</a></li>
<li class="chapter" data-level="A.5" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>A.5</b> Stable unit treatment value assumption (SUTVA)</a></li>
<li class="chapter" data-level="A.6" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>A.6</b> The fundamental problem of causal inference</a></li>
<li class="chapter" data-level="A.7" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#the-assignment-mechanism"><i class="fa fa-check"></i><b>A.7</b> The assignment mechanism</a></li>
<li class="chapter" data-level="A.8" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#permutation-tests"><i class="fa fa-check"></i><b>A.8</b> Permutation tests</a></li>
<li class="chapter" data-level="A.9" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#confounding-and-selection-bias"><i class="fa fa-check"></i><b>A.9</b> Confounding and selection bias</a></li>
<li class="chapter" data-level="A.10" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#internal-and-external-validity"><i class="fa fa-check"></i><b>A.10</b> Internal and external validity</a></li>
<li class="chapter" data-level="A.11" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#survey-research-and-external-validity"><i class="fa fa-check"></i><b>A.11</b> Survey research and external validity</a></li>
<li class="chapter" data-level="A.12" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#conclusion-5"><i class="fa fa-check"></i><b>A.12</b> Conclusion</a></li>
<li class="chapter" data-level="A.13" data-path="A-rubin-causal-model.html"><a href="A-rubin-causal-model.html#references"><i class="fa fa-check"></i><b>A.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="B-maps.html"><a href="B-maps.html"><i class="fa fa-check"></i><b>B</b> Maps</a><ul>
<li class="chapter" data-level="B.1" data-path="B-maps.html"><a href="B-maps.html#tidycensus"><i class="fa fa-check"></i><b>B.1</b> Tidycensus</a></li>
<li class="chapter" data-level="B.2" data-path="B-maps.html"><a href="B-maps.html#conceptual-introduction-to-mapping"><i class="fa fa-check"></i><b>B.2</b> Conceptual introduction to mapping</a><ul>
<li class="chapter" data-level="B.2.1" data-path="B-maps.html"><a href="B-maps.html#vector-versus-spatial-data"><i class="fa fa-check"></i><b>B.2.1</b> Vector versus spatial data</a></li>
<li class="chapter" data-level="B.2.2" data-path="B-maps.html"><a href="B-maps.html#sf-vs-sp"><i class="fa fa-check"></i><b>B.2.2</b> <strong>sf</strong> vs <strong>sp</strong></a></li>
<li class="chapter" data-level="B.2.3" data-path="B-maps.html"><a href="B-maps.html#shapefiles"><i class="fa fa-check"></i><b>B.2.3</b> Shapefiles</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="B-maps.html"><a href="B-maps.html#mapping-with-tidycensus-and-geom_sf"><i class="fa fa-check"></i><b>B.3</b> Mapping with <strong>tidycensus</strong> and <code>geom_sf()</code></a><ul>
<li class="chapter" data-level="B.3.1" data-path="B-maps.html"><a href="B-maps.html#making-maps-pretty"><i class="fa fa-check"></i><b>B.3.1</b> Making maps pretty</a></li>
<li class="chapter" data-level="B.3.2" data-path="B-maps.html"><a href="B-maps.html#adding-back-alaska-and-hawaii"><i class="fa fa-check"></i><b>B.3.2</b> Adding back Alaska and Hawaii</a></li>
</ul></li>
<li class="chapter" data-level="B.4" data-path="B-maps.html"><a href="B-maps.html#faceting-maps"><i class="fa fa-check"></i><b>B.4</b> Faceting maps</a><ul>
<li class="chapter" data-level="B.4.1" data-path="B-maps.html"><a href="B-maps.html#transforming-and-mapping-the-data"><i class="fa fa-check"></i><b>B.4.1</b> Transforming and mapping the data</a></li>
</ul></li>
<li class="chapter" data-level="B.5" data-path="B-maps.html"><a href="B-maps.html#want-to-explore-further"><i class="fa fa-check"></i><b>B.5</b> Want to explore further?</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="C-animation.html"><a href="C-animation.html"><i class="fa fa-check"></i><b>C</b> Animation</a><ul>
<li class="chapter" data-level="C.1" data-path="C-animation.html"><a href="C-animation.html#gganimate-how-to-create-plots-with-beautiful-animation-in-r"><i class="fa fa-check"></i><b>C.1</b> gganimate: How to Create Plots with Beautiful Animation in R</a><ul>
<li class="chapter" data-level="C.1.1" data-path="C-animation.html"><a href="C-animation.html#prerequisites"><i class="fa fa-check"></i><b>C.1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="C.1.2" data-path="C-animation.html"><a href="C-animation.html#demo-dataset"><i class="fa fa-check"></i><b>C.1.2</b> Demo dataset</a></li>
<li class="chapter" data-level="C.1.3" data-path="C-animation.html"><a href="C-animation.html#static-plot"><i class="fa fa-check"></i><b>C.1.3</b> Static plot</a></li>
<li class="chapter" data-level="C.1.4" data-path="C-animation.html"><a href="C-animation.html#transition-through-distinct-states-in-time"><i class="fa fa-check"></i><b>C.1.4</b> Transition through distinct states in time</a></li>
<li class="chapter" data-level="C.1.5" data-path="C-animation.html"><a href="C-animation.html#reveal-data-along-a-given-dimension"><i class="fa fa-check"></i><b>C.1.5</b> Reveal data along a given dimension</a></li>
<li class="chapter" data-level="C.1.6" data-path="C-animation.html"><a href="C-animation.html#transition-between-several-distinct-stages-of-the-data"><i class="fa fa-check"></i><b>C.1.6</b> Transition between several distinct stages of the data</a></li>
<li class="chapter" data-level="C.1.7" data-path="C-animation.html"><a href="C-animation.html#read-more"><i class="fa fa-check"></i><b>C.1.7</b> Read more</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="C-animation.html"><a href="C-animation.html#how-to-save-your-animation"><i class="fa fa-check"></i><b>C.2</b> How to save your animation</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="D-shiny.html"><a href="D-shiny.html"><i class="fa fa-check"></i><b>D</b> Shiny</a><ul>
<li class="chapter" data-level="D.1" data-path="D-shiny.html"><a href="D-shiny.html#helpful-resources"><i class="fa fa-check"></i><b>D.1</b> Helpful Resources</a></li>
<li class="chapter" data-level="D.2" data-path="D-shiny.html"><a href="D-shiny.html#set-up-and-getting-started"><i class="fa fa-check"></i><b>D.2</b> Set Up and Getting Started</a></li>
<li class="chapter" data-level="D.3" data-path="D-shiny.html"><a href="D-shiny.html#building-your-basic-app"><i class="fa fa-check"></i><b>D.3</b> Building Your Basic App</a><ul>
<li class="chapter" data-level="D.3.1" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-basic-ui"><i class="fa fa-check"></i><b>D.3.1</b> Setting Up the Basic UI</a></li>
<li class="chapter" data-level="D.3.2" data-path="D-shiny.html"><a href="D-shiny.html#setting-up-the-server"><i class="fa fa-check"></i><b>D.3.2</b> Setting up the Server</a></li>
</ul></li>
<li class="chapter" data-level="D.4" data-path="D-shiny.html"><a href="D-shiny.html#organization"><i class="fa fa-check"></i><b>D.4</b> Organization</a></li>
<li class="chapter" data-level="D.5" data-path="D-shiny.html"><a href="D-shiny.html#customizations"><i class="fa fa-check"></i><b>D.5</b> Customizations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Preceptor’s Primer for Bayesian Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Regression</h1>
<p>The fundamental goal of data modeling is to make explicit the relationship between:</p>
<ul>
<li>an <em>outcome variable</em> <span class="math inline">\(y\)</span>, also called a <em>dependent variable</em> or response variable, and<br />
</li>
<li>an <em>explanatory/predictor variable</em> <span class="math inline">\(x\)</span>, also called an <em>independent variable</em> or covariate.</li>
</ul>
<p>Another way to state this is using mathematical terminology: we will model the outcome variable <span class="math inline">\(y\)</span> “as a function” of the explanatory/predictor variable <span class="math inline">\(x\)</span>. When we say “function” here, we aren’t referring to functions in R like the <code>ggplot()</code> function, but rather to a mathematical function. But, why do we have two different labels, explanatory and predictor, for the variable <span class="math inline">\(x\)</span>? That’s because even though the two terms are often used interchangeably, roughly speaking data modeling serves one of two purposes:</p>
<ol style="list-style-type: decimal">
<li><strong>Modeling for explanation</strong>: When you want to explicitly describe and quantify the relationship between the outcome variable <span class="math inline">\(y\)</span> and an explanatory variable <span class="math inline">\(x\)</span>, determine the importance of any relationships, have measures summarizing these relationships, and possibly identify any <em>causal</em> relationships between the variables. (What’s a causal relationship? Remember the <a href="A-rubin-causal-model.html#rubin-causal-model">Rubin Causal Model</a>! The <em>causal effect</em> of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span> is the difference in <em>potential outcomes</em> of <span class="math inline">\(y\)</span> given different values of <span class="math inline">\(x\)</span>.)</li>
<li><strong>Modeling for prediction</strong>: When you want to predict an outcome variable <span class="math inline">\(y\)</span> based on the information contained in a set of predictor variables <span class="math inline">\(x\)</span>. Unlike modeling for explanation, however, you don’t care so much about understanding how all the variables relate and interact with one another, but rather only whether you can make good predictions about <span class="math inline">\(y\)</span> using the information in <span class="math inline">\(x\)</span>.</li>
</ol>
<p>For example, say you are interested in an outcome variable <span class="math inline">\(y\)</span> of whether patients develop lung cancer and information <span class="math inline">\(x\)</span> on their risk factors, such as smoking habits, age, and socioeconomic status. If we are modeling for explanation, we would be interested in both describing and quantifying the effects of the different risk factors. One reason could be that you want to design an intervention to reduce lung cancer incidence in a population, such as targeting smokers of a specific age group with advertising for smoking cessation programs. In that case, you would want to know the causal effect of age on the incidence of lung cancer for smokers.</p>
<p>If we are modeling for prediction, however, we wouldn’t care so much about understanding how all the individual risk factors contribute to lung cancer, but rather only whether we can make good predictions of which people will contract lung cancer.</p>
<p>In this book, we’ll focus on modeling for explanation and hence refer to <span class="math inline">\(x\)</span> as <em>explanatory variables</em>. If you are interested in learning about modeling for prediction, we suggest you check out Chapter <a href="14-machine.html#machine">14</a> and other books and courses on the field of <em>machine learning</em> such as <a href="http://www-bcf.usc.edu/~gareth/ISL/"><em>An Introduction to Statistical Learning with Applications in R (ISLR)</em></a> <span class="citation">(James et al. <a href="#ref-islr2017" role="doc-biblioref">2017</a>)</span>. Furthermore, while there exist many techniques for modeling, such as tree-based models and neural networks, right now we’ll focus on one particular technique: <em>linear regression</em>.  Linear regression is one of the most commonly-used and easy-to-understand approaches to modeling.</p>
<p>Linear regression involves a <em>numerical</em> outcome variable <span class="math inline">\(y\)</span> and explanatory variables <span class="math inline">\(x\)</span> that are either <em>numerical</em> or <em>categorical</em>. Furthermore, the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is assumed to be linear, or in other words, a line. However, we’ll see that what constitutes a “line” will vary depending on the nature of your explanatory variables <span class="math inline">\(x\)</span> .</p>
<p>In Chapter <a href="11-regression.html#regression">11</a> on basic regression, we’ll only consider models with a single explanatory variable <span class="math inline">\(x\)</span>. In Section <a href="11-regression.html#model1">11.1</a>, the explanatory variable will be numerical. This scenario is known as <em>simple linear regression</em>. In Section <a href="11-regression.html#model2">11.3</a>, the explanatory variable will be categorical.</p>
<p>In Chapter <a href="12-multiple-regression.html#multiple-regression">12</a> on multiple regression, we’ll extend the ideas behind basic regression and consider models with two explanatory variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. In Section <a href="12-multiple-regression.html#model4">12.1</a>, we’ll have two numerical explanatory variables. In Section <a href="12-multiple-regression.html#model3">12.2</a>, we’ll have one numerical and one categorical explanatory variable. In particular, we’ll consider two such models: <em>interaction</em> and <em>parallel slopes</em> models.</p>
<p>Let’s now begin with basic regression,  which refers to linear regression models with a single explanatory variable <span class="math inline">\(x\)</span>. We’ll also discuss important statistical concepts like the <em>correlation coefficient</em>, that “correlation isn’t necessarily causation,” and what it means for a line to be “best-fitting.”</p>
<div id="needed-packages-3" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let’s now load all the packages needed for this chapter (this assumes you’ve already installed them). In this chapter, we introduce some new packages:</p>
<ol style="list-style-type: decimal">
<li>The <strong>tidyverse</strong> “umbrella” <span class="citation">(Wickham <a href="#ref-R-tidyverse" role="doc-biblioref">2019</a><a href="#ref-R-tidyverse" role="doc-biblioref">b</a>)</span> package. Recall from our discussion in Section <a href="5-tidy.html#tidyverse-package">5.5</a> that loading the <code>tidyverse</code> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:
<ul>
<li><strong>ggplot2</strong> for data visualization</li>
<li><strong>dplyr</strong> for data wrangling</li>
<li><strong>tidyr</strong> for converting data to “tidy” format</li>
<li><strong>readr</strong> for importing spreadsheet data into R</li>
<li>As well as the more advanced <strong>purrr</strong>, <strong>tibble</strong>, <strong>stringr</strong>, and <strong>forcats</strong> packages</li>
</ul></li>
<li>The <strong>broom</strong> <span class="citation">(Robinson and Hayes <a href="#ref-R-broom" role="doc-biblioref">2020</a>)</span> package, which provides an easy way to deal with model objects.</li>
<li>The <strong>skimr</strong> <span class="citation">(Waring et al. <a href="#ref-R-skimr" role="doc-biblioref">2019</a>)</span> package, which provides a simple-to-use function to quickly compute a wide array of commonly used summary statistics. </li>
</ol>
<p>If needed, read Section <a href="1-getting-started.html#packages">1.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="11-regression.html#cb732-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb732-2"><a href="11-regression.html#cb732-2"></a><span class="kw">library</span>(broom)</span>
<span id="cb732-3"><a href="11-regression.html#cb732-3"></a><span class="kw">library</span>(skimr)</span>
<span id="cb732-4"><a href="11-regression.html#cb732-4"></a><span class="kw">library</span>(gapminder)</span></code></pre></div>
</div>
<div id="model1" class="section level2">
<h2><span class="header-section-number">11.1</span> Teaching evaluations: one numerical explanatory variable</h2>
<p>Why do some professors and instructors at universities and colleges receive high teaching evaluations scores from students while others receive lower ones? Are there differences in teaching evaluations between instructors of different demographic groups? Could there be an impact due to student biases? These are all questions that are of interest to university/college administrators, as teaching evaluations are among the many criteria considered in determining which instructors and professors get promoted.</p>
<p>Researchers at the University of Texas in Austin, Texas (UT Austin) tried to answer the following research question: what factors explain differences in instructor teaching evaluation scores? To this end, they collected instructor and course information on 463 courses. A full description of the study can be found at <a href="https://www.openintro.org/data/index.php?data=evals">openintro.org</a>.</p>
<p>In this section, we’ll keep things simple for now and try to explain differences in instructor teaching scores as a function of one numerical variable: the instructor’s “beauty” score (we’ll describe how this score was determined shortly). Could it be that instructors with higher “beauty” scores also have higher teaching evaluations? Could it be instead that instructors with higher “beauty” scores tend to have lower teaching evaluations? Or could it be that there is no relationship between “beauty” score and teaching evaluations? We’ll answer these questions by modeling the relationship between teaching scores and “beauty” scores using <em>simple linear regression</em>  where we have:</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span> (the instructor’s teaching score) and</li>
<li>A single numerical explanatory variable <span class="math inline">\(x\)</span> (the instructor’s “beauty” score).</li>
</ol>
<div id="model1EDA" class="section level3">
<h3><span class="header-section-number">11.1.1</span> Exploratory data analysis</h3>
<p>The data on the 463 courses at UT Austin can be found in the <code>evals</code> data frame included in the <strong>moderndive</strong> package. However, to keep things simple, let’s <code>select()</code> only the subset of the variables we’ll consider in this chapter, and save this data in a new data frame called <code>evals_ch11</code>:</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="11-regression.html#cb733-1"></a><span class="kw">library</span>(moderndive)</span>
<span id="cb733-2"><a href="11-regression.html#cb733-2"></a></span>
<span id="cb733-3"><a href="11-regression.html#cb733-3"></a>evals_ch11 &lt;-<span class="st"> </span>evals <span class="op">%&gt;%</span></span>
<span id="cb733-4"><a href="11-regression.html#cb733-4"></a><span class="st">  </span><span class="kw">select</span>(ID, score, bty_avg, age)</span></code></pre></div>
<p>A crucial step before doing any kind of analysis or modeling is performing an <em>exploratory data analysis</em>,  or EDA for short. EDA gives you a sense of the distributions of the individual variables in your data, whether any potential relationships exist between variables, whether there are outliers and/or missing values, and (most importantly) how to build your model. Here are three common steps in an EDA:</p>
<ol style="list-style-type: decimal">
<li>Most crucially, looking at the raw data values.</li>
<li>Computing summary statistics, such as means, medians, and interquartile ranges.</li>
<li>Creating data visualizations.</li>
</ol>
<p>Let’s perform the first common step in an exploratory data analysis: looking at the raw data values. Because this step seems so trivial, unfortunately many data analysts ignore it. However, getting an early sense of what your raw data looks like can often prevent many larger issues down the road.</p>
<p>You can do this by using RStudio’s spreadsheet viewer or by using the <code>glimpse()</code> function as introduced in Subsection <a href="1-getting-started.html#exploredataframes">1.4.3</a> on exploring data frames:</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="11-regression.html#cb734-1"></a><span class="kw">glimpse</span>(evals_ch11)</span></code></pre></div>
<pre><code>Observations: 463
Variables: 4
$ ID      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…
$ score   &lt;dbl&gt; 4.7, 4.1, 3.9, 4.8, 4.6, 4.3, 2.8, 4.1, 3.4, 4.5, 3.8, 4.5, 4…
$ bty_avg &lt;dbl&gt; 5.00, 5.00, 5.00, 5.00, 3.00, 3.00, 3.00, 3.33, 3.33, 3.17, 3…
$ age     &lt;int&gt; 36, 36, 36, 36, 59, 59, 59, 51, 51, 40, 40, 40, 40, 40, 40, 4…</code></pre>
<p>Observe that <code>Observations: 463</code> indicates that there are 463 rows/observations in <code>evals_ch11</code>, where each row corresponds to one observed course at UT Austin. It is important to note that the <em>observational unit</em>  is an individual course and not an individual instructor. Recall from Subsection <a href="1-getting-started.html#exploredataframes">1.4.3</a> that the observational unit is the “type of thing” that is being measured by our variables. Since instructors teach more than one course in an academic year, the same instructor will appear more than once in the data. Hence there are fewer than 463 unique instructors being represented in <code>evals_ch11</code>.</p>
<p>A full description of all the variables included in <code>evals</code> can be found at <a href="https://www.openintro.org/data/index.php?data=evals">openintro.org</a> or by reading the associated help file (run <code>?evals</code> in the console). However, let’s fully describe only the 4 variables we selected in <code>evals_ch11</code>:</p>
<ol style="list-style-type: decimal">
<li><code>ID</code>: An identification variable used to distinguish between the 1 through 463 courses in the dataset.</li>
<li><code>score</code>: A numerical variable of the course instructor’s average teaching score, where the average is computed from the evaluation scores from all students in that course. Teaching scores of 1 are lowest and 5 are highest. This is the outcome variable <span class="math inline">\(y\)</span> of interest.</li>
<li><code>bty_avg</code>: A numerical variable of the course instructor’s average “beauty” score, where the average is computed from a separate panel of six students. “Beauty” scores of 1 are lowest and 10 are highest. This is the explanatory variable <span class="math inline">\(x\)</span> of interest.</li>
<li><code>age</code>: A numerical variable of the course instructor’s age.</li>
</ol>
<p>An alternative way to look at the raw data values is by choosing a random sample of the rows in <code>evals_ch11</code> by piping it into the <code>sample_n()</code>  function from the <strong>dplyr</strong> package. Here we set the <code>size</code> argument to be <code>5</code>, indicating that we want a random sample of 5 rows. We display the results below. Note that due to the random nature of the sampling, you will likely end up with a different subset of 5 rows.</p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="11-regression.html#cb736-1"></a>evals_ch11 <span class="op">%&gt;%</span></span>
<span id="cb736-2"><a href="11-regression.html#cb736-2"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-463">TABLE 11.1: </span>A random sample of 5 out of the 463 courses at UT Austin
</caption>
<thead>
<tr>
<th style="text-align:right;">
ID
</th>
<th style="text-align:right;">
score
</th>
<th style="text-align:right;">
bty_avg
</th>
<th style="text-align:right;">
age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
129
</td>
<td style="text-align:right;">
3.7
</td>
<td style="text-align:right;">
3.00
</td>
<td style="text-align:right;">
62
</td>
</tr>
<tr>
<td style="text-align:right;">
109
</td>
<td style="text-align:right;">
4.7
</td>
<td style="text-align:right;">
4.33
</td>
<td style="text-align:right;">
46
</td>
</tr>
<tr>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
4.8
</td>
<td style="text-align:right;">
5.50
</td>
<td style="text-align:right;">
62
</td>
</tr>
<tr>
<td style="text-align:right;">
434
</td>
<td style="text-align:right;">
2.8
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
62
</td>
</tr>
<tr>
<td style="text-align:right;">
330
</td>
<td style="text-align:right;">
4.0
</td>
<td style="text-align:right;">
2.33
</td>
<td style="text-align:right;">
64
</td>
</tr>
</tbody>
</table>
<p>Now that we’ve looked at the raw values in our <code>evals_ch11</code> data frame and got a preliminary sense of the data, let’s move on to the next common step in an exploratory data analysis: computing summary statistics. Let’s start by computing the mean and median of our numerical outcome variable <code>score</code> and our numerical explanatory variable “beauty” score denoted as <code>bty_avg</code>. We’ll do this by using the <code>summarize()</code> function from <code>dplyr</code> along with the <code>mean()</code> and <code>median()</code> summary functions we saw in Section <a href="4-wrangling.html#summarize">4.3</a>.</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="11-regression.html#cb737-1"></a>evals_ch11 <span class="op">%&gt;%</span></span>
<span id="cb737-2"><a href="11-regression.html#cb737-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_bty_avg =</span> <span class="kw">mean</span>(bty_avg),</span>
<span id="cb737-3"><a href="11-regression.html#cb737-3"></a>            <span class="dt">mean_score =</span> <span class="kw">mean</span>(score),</span>
<span id="cb737-4"><a href="11-regression.html#cb737-4"></a>            <span class="dt">median_bty_avg =</span> <span class="kw">median</span>(bty_avg),</span>
<span id="cb737-5"><a href="11-regression.html#cb737-5"></a>            <span class="dt">median_score =</span> <span class="kw">median</span>(score))</span></code></pre></div>
<pre><code># A tibble: 1 x 4
  mean_bty_avg mean_score median_bty_avg median_score
         &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;
1      4.41784    4.17473          4.333          4.3</code></pre>
<p>However, what if we want other summary statistics as well, such as the standard deviation (a measure of spread), the minimum and maximum values, and various percentiles?</p>
<p>Typing out all these summary statistic functions in <code>summarize()</code> would be long and tedious. Instead, let’s use the convenient <code>skim()</code> function from the <strong>skimr</strong> package. This function takes in a data frame, “skims” it, and returns commonly used summary statistics. Let’s take our <code>evals_ch11</code> data frame, <code>select()</code> only the outcome and explanatory variables teaching <code>score</code> and <code>bty_avg</code>, and pipe them into the <code>skim()</code> function:</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="11-regression.html#cb739-1"></a>evals_ch11 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb739-2"><a href="11-regression.html#cb739-2"></a><span class="st">  </span><span class="kw">select</span>(score, bty_avg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb739-3"><a href="11-regression.html#cb739-3"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
<span id="tab:unnamed-chunk-465">TABLE 11.2: </span>Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
Piped data
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
463
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
score
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.17
</td>
<td style="text-align:right;">
0.54
</td>
<td style="text-align:right;">
2.30
</td>
<td style="text-align:right;">
3.80
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
4.6
</td>
<td style="text-align:right;">
5.00
</td>
<td style="text-align:left;">
▁▁▅▇▇
</td>
</tr>
<tr>
<td style="text-align:left;">
bty_avg
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
4.42
</td>
<td style="text-align:right;">
1.53
</td>
<td style="text-align:right;">
1.67
</td>
<td style="text-align:right;">
3.17
</td>
<td style="text-align:right;">
4.33
</td>
<td style="text-align:right;">
5.5
</td>
<td style="text-align:right;">
8.17
</td>
<td style="text-align:left;">
▃▇▇▃▂
</td>
</tr>
</tbody>
</table>
<p>For the numerical variables teaching <code>score</code> and <code>bty_avg</code> it returns:</p>
<ul>
<li><code>n_missing</code>: the number of missing values</li>
<li><code>complete_rate</code>: the percentage of non-missing or complete values</li>
<li><code>mean</code>: the average</li>
<li><code>sd</code>: the standard deviation</li>
<li><code>p0</code>: the 0th percentile: the value at which 0% of observations are smaller than it (the <em>minimum</em> value)</li>
<li><code>p25</code>: the 25th percentile: the value at which 25% of observations are smaller than it (the <em>1st quartile</em>)</li>
<li><code>p50</code>: the 50th percentile: the value at which 50% of observations are smaller than it (the <em>2nd</em> quartile and more commonly called the <em>median</em>)</li>
<li><code>p75</code>: the 75th percentile: the value at which 75% of observations are smaller than it (the <em>3rd quartile</em>)</li>
<li><code>p100</code>: the 100th percentile: the value at which 100% of observations are smaller than it (the <em>maximum</em> value)</li>
</ul>
<p>Looking at this output, we can see how the values of both variables distribute. For example, the mean teaching score was 4.17 out of 5, whereas the mean “beauty” score was 4.42 out of 10. Furthermore, the middle 50% of teaching scores was between 3.80 and 4.6 (the first and third quartiles), whereas the middle 50% of “beauty” scores falls within 3.17 to 5.5 out of 10.</p>
<p>The <code>skim()</code> function only returns what are known as <em>univariate</em>  summary statistics: functions that take a single variable and return some numerical summary of that variable. However, there also exist <em>bivariate</em>  summary statistics: functions that take in two variables and return some summary of those two variables. In particular, when the two variables are numerical, we can compute the  <em>correlation coefficient</em>. Generally speaking, <em>coefficients</em> are quantitative expressions of a specific phenomenon. A <em>correlation coefficient</em> is a quantitative expression of the <em>strength of the linear relationship between two numerical variables</em>. Its value ranges between -1 and 1 where:</p>
<ul>
<li>-1 indicates a perfect <em>negative relationship</em>: As one variable increases, the value of the other variable tends to go down, following a straight line.</li>
<li>0 indicates no relationship: The values of both variables go up/down independently of each other.</li>
<li>+1 indicates a perfect <em>positive relationship</em>: As the value of one variable goes up, the value of the other variable tends to go up as well in a linear fashion.</li>
</ul>
<p>The following figure gives examples of 9 different correlation coefficient values for hypothetical numerical variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. For example, observe in the top right plot that for a correlation coefficient of -0.75 there is a negative linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, but it is not as strong as the negative linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> when the correlation coefficient is -0.9 or -1.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-466"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-466-1.png" alt="Nine different correlation coefficients." width="\textwidth" />
<p class="caption">
FIGURE 11.1: Nine different correlation coefficients.
</p>
</div>
<p>The correlation coefficient can be computed using the <code>cor()</code> summary function within a <code>summarize()</code>:</p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="11-regression.html#cb740-1"></a>evals_ch11 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb740-2"><a href="11-regression.html#cb740-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">correlation =</span> <span class="kw">cor</span>(score, bty_avg))</span></code></pre></div>
<p>In our case, the correlation coefficient of 0.187 indicates that the relationship between teaching evaluation score and “beauty” average is “weakly positive.” There is a certain amount of subjectivity in interpreting correlation coefficients, especially those that aren’t close to the extreme values of -1, 0, and 1. To develop your intuition about correlation coefficients, play the “Guess the Correlation” 1980’s style video game mentioned in Subsection <a href="11-regression.html#additional-resources-basic-regression">11.6.1</a>.</p>
<p>Let’s now perform the last of the steps in an exploratory data analysis: creating data visualizations. Since both the <code>score</code> and <code>bty_avg</code> variables are numerical, a scatterplot is an appropriate graph to visualize this data. Let’s do this using <code>geom_point()</code> and display the result. Furthermore, let’s highlight the six points in the top right of the visualization in a box.</p>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="11-regression.html#cb741-1"></a>evals_ch11 <span class="op">%&gt;%</span></span>
<span id="cb741-2"><a href="11-regression.html#cb741-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span></span>
<span id="cb741-3"><a href="11-regression.html#cb741-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb741-4"><a href="11-regression.html#cb741-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, </span>
<span id="cb741-5"><a href="11-regression.html#cb741-5"></a>       <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>,</span>
<span id="cb741-6"><a href="11-regression.html#cb741-6"></a>       <span class="dt">title =</span> <span class="st">&quot;Scatterplot of relationship of teaching and beauty scores&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-470"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-470-1.png" alt="Instructor evaluation scores at UT Austin." width="\textwidth" />
<p class="caption">
FIGURE 11.2: Instructor evaluation scores at UT Austin.
</p>
</div>
<p>Observe that most “beauty” scores lie between 2 and 8, while most teaching scores lie between 3 and 5. Furthermore, while opinions may vary, it is our opinion that the relationship between teaching score and “beauty” score is “weakly positive.” This is consistent with our earlier computed correlation coefficient of 0.187.</p>
<p>Furthermore, there appear to be six points in the top-right of this plot highlighted in the box. However, this is not actually the case, as this plot suffers from <em>overplotting</em>. Recall from Subsection <a href="2-viz.html#overplotting">2.2.2</a> that overplotting occurs when several points are stacked directly on top of each other, making it difficult to distinguish them. So while it may appear that there are only six points in the box, there are actually more. This fact is only apparent when using <code>geom_jitter()</code> in place of <code>geom_point()</code>. We display the resulting plot along with the same small box as before.</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="11-regression.html#cb742-1"></a>evals_ch11 <span class="op">%&gt;%</span></span>
<span id="cb742-2"><a href="11-regression.html#cb742-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span></span>
<span id="cb742-3"><a href="11-regression.html#cb742-3"></a><span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span></span>
<span id="cb742-4"><a href="11-regression.html#cb742-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>,</span>
<span id="cb742-5"><a href="11-regression.html#cb742-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Scatterplot of relationship of teaching and beauty scores&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-472"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-472-1.png" alt="Instructor evaluation scores at UT Austin." width="\textwidth" />
<p class="caption">
FIGURE 11.3: Instructor evaluation scores at UT Austin.
</p>
</div>
<p>It is now apparent that there are 12 points in the area highlighted in the box and not six as originally suggested. Recall from Subsection <a href="2-viz.html#overplotting">2.2.2</a> on overplotting that jittering adds a little random “nudge” to each of the points to break up these ties. Furthermore, recall that jittering is strictly a visualization tool; it does not alter the original values in the data frame <code>evals_ch11</code>. To keep things simple going forward, however, we’ll only present regular scatterplots rather than their jittered counterparts.</p>
<p>Let’s build on the unjittered scatterplot by adding a “best-fitting” line: of all possible lines we can draw on this scatterplot, it is the line that “best” fits through the cloud of points. We do this by adding a new <code>geom_smooth(method = "lm", se = FALSE)</code> layer to the <code>ggplot()</code> code that created the scatterplot. The <code>method = "lm"</code> argument sets the line to be a “<code>l</code>inear <code>m</code>odel.” The <code>se = FALSE</code>  argument suppresses <em>standard error</em> uncertainty bars. (We defined the concept of <em>standard error</em> in Subsection <a href="9-sampling.html#sampling-definitions">9.3.2</a>.)</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="11-regression.html#cb743-1"></a>evals_ch11 <span class="op">%&gt;%</span></span>
<span id="cb743-2"><a href="11-regression.html#cb743-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bty_avg, <span class="dt">y =</span> score)) <span class="op">+</span></span>
<span id="cb743-3"><a href="11-regression.html#cb743-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb743-4"><a href="11-regression.html#cb743-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Beauty Score&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Teaching Score&quot;</span>,</span>
<span id="cb743-5"><a href="11-regression.html#cb743-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Relationship between teaching and beauty scores&quot;</span>) <span class="op">+</span><span class="st">  </span></span>
<span id="cb743-6"><a href="11-regression.html#cb743-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-473"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-473-1.png" alt="Regression line." width="\textwidth" />
<p class="caption">
FIGURE 11.4: Regression line.
</p>
</div>
<p>The line in the resulting figure is called a “regression line.” The regression line  is a visual summary of the relationship between two numerical variables, in our case the outcome variable <code>score</code> and the explanatory variable <code>bty_avg</code>. The positive slope of the blue line is consistent with our earlier observed correlation coefficient of 0.187 suggesting that there is a positive relationship between these two variables: as instructors have higher “beauty” scores, so also do they receive higher teaching evaluations. We’ll see later, however, that while the correlation coefficient and the slope of a regression line always have the same sign (positive or negative), they typically do not have the same value.</p>
<p>Furthermore, a regression line is “best-fitting” in that it minimizes some mathematical criteria. We present these mathematical criteria in Section <a href="11-regression.html#leastsquares">11.5</a>, but we suggest you read this subsection only after first reading the rest of this section on regression with one numerical explanatory variable.</p>
</div>
<div id="model1table" class="section level3">
<h3><span class="header-section-number">11.1.2</span> Simple linear regression</h3>
<p>You may recall from secondary/high school algebra that the equation of a line is <span class="math inline">\(y = a + b\cdot x\)</span>. (Note that the <span class="math inline">\(\cdot\)</span> symbol is equivalent to the <span class="math inline">\(\times\)</span> “multiply by” mathematical symbol. We’ll use the <span class="math inline">\(\cdot\)</span> symbol in the rest of this book as it is more succinct.) It is defined by two coefficients <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. The intercept coefficient <span class="math inline">\(a\)</span> is the value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x = 0\)</span>. The slope coefficient <span class="math inline">\(b\)</span> for <span class="math inline">\(x\)</span> is the increase in <span class="math inline">\(y\)</span> for every increase of one in <span class="math inline">\(x\)</span>. This is also called the “rise over run.”</p>
<p>However, when defining a regression line, we use slightly different notation: the equation of the regression line is <span class="math inline">\(\widehat{y} = b_0 + b_1 \cdot x\)</span> . The intercept coefficient is <span class="math inline">\(b_0\)</span>, so <span class="math inline">\(b_0\)</span> is the value of <span class="math inline">\(\widehat{y}\)</span> when <span class="math inline">\(x = 0\)</span>. The slope coefficient for <span class="math inline">\(x\)</span> is <span class="math inline">\(b_1\)</span>, i.e., the increase in <span class="math inline">\(\widehat{y}\)</span> for every increase of one in <span class="math inline">\(x\)</span>. Why do we put a “hat” on top of the <span class="math inline">\(y\)</span>? It’s a form of notation commonly used in regression to indicate that we have a  “fitted value,” or the value of <span class="math inline">\(y\)</span> on the regression line for a given <span class="math inline">\(x\)</span> value. We’ll discuss this more in the upcoming Subsection <a href="11-regression.html#model1points">11.2.2</a>.</p>
<p>We know that the regression line we plotted has a positive slope <span class="math inline">\(b_1\)</span> corresponding to our explanatory <span class="math inline">\(x\)</span> variable <code>bty_avg</code>. Why? Because as instructors tend to have higher <code>bty_avg</code> scores, so also do they tend to have higher teaching evaluation <code>scores</code>. However, what is the numerical value of the slope <span class="math inline">\(b_1\)</span>? What about the intercept <span class="math inline">\(b_0\)</span>? Let’s not compute these two values by hand, but rather let’s use a computer!</p>
<p>We can obtain the values of the intercept <span class="math inline">\(b_0\)</span> and the slope for <code>btg_avg</code> <span class="math inline">\(b_1\)</span> by outputting a <em>linear regression table</em>. This is done in two steps:</p>
<ol style="list-style-type: decimal">
<li>We first “fit” the linear regression model using the <code>lm()</code> function and save it in <code>score_model</code>.</li>
<li>We put the name of the outcome variable on the left-hand side of the <code>~</code> “tilde” sign, while putting the name of the explanatory variable on the right-hand side. This is known as R’s  <em>formula notation</em>.</li>
<li>We get the regression table by applying the <code>tidy()</code>  function from the <strong>broom</strong> package to <code>score_model</code>.</li>
</ol>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="11-regression.html#cb744-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb744-2"><a href="11-regression.html#cb744-2"></a></span>
<span id="cb744-3"><a href="11-regression.html#cb744-3"></a>score_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, <span class="dt">data =</span> evals_ch11)</span>
<span id="cb744-4"><a href="11-regression.html#cb744-4"></a></span>
<span id="cb744-5"><a href="11-regression.html#cb744-5"></a><span class="co"># Get regression table:</span></span>
<span id="cb744-6"><a href="11-regression.html#cb744-6"></a></span>
<span id="cb744-7"><a href="11-regression.html#cb744-7"></a>score_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb744-8"><a href="11-regression.html#cb744-8"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-476">TABLE 11.3: </span>Linear regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
3.880
</td>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
50.96
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3.731
</td>
<td style="text-align:right;">
4.030
</td>
</tr>
<tr>
<td style="text-align:left;">
bty_avg
</td>
<td style="text-align:right;">
0.067
</td>
<td style="text-align:right;">
0.016
</td>
<td style="text-align:right;">
4.09
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.035
</td>
<td style="text-align:right;">
0.099
</td>
</tr>
</tbody>
</table>
<p>Note that we used the argument <code>conf.int = TRUE</code> in the <code>tidy()</code> function; that will be important for later.</p>
<p>How did this code work? First, we “fit” the linear regression model to the <code>data</code> using the <code>lm()</code>  function and save this as <code>score_model</code>. When we say “fit”, we mean “find the best fitting line to this data.” <code>lm()</code> stands for “linear model” and is used as follows: <code>lm(y ~ x, data = data_frame_name)</code> where:</p>
<ul>
<li><code>y</code> is the outcome variable, followed by a tilde <code>~</code>. In our case, <code>y</code> is set to <code>score</code>.</li>
<li><code>x</code> is the explanatory variable. In our case, <code>x</code> is set to <code>bty_avg</code>.</li>
<li>The combination of <code>y ~ x</code> is called a <em>model formula</em>. (Note the order of <code>y</code> and <code>x</code>.) In our case, the model formula is <code>score ~ bty_avg</code>.</li>
<li><code>data_frame_name</code> is the name of the data frame that contains the variables <code>y</code> and <code>x</code>. In our case, <code>data_frame_name</code> is the <code>evals_ch11</code> data frame.</li>
</ul>
<p>Second, we take the saved model in <code>score_model</code> and apply the <code>tidy()</code> function from the <strong>broom</strong> package to it to obtain the regression table.</p>
</div>
<div id="interpreting-regression-coefficients" class="section level3">
<h3><span class="header-section-number">11.1.3</span> Interpreting regression coefficients</h3>
<p>In the <code>estimate</code> column are the intercept <span class="math inline">\(b_0\)</span> = 3.88 and the slope <span class="math inline">\(b_1\)</span> = 0.067 for <code>bty_avg</code>. Thus the equation of the regression line follows:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} &amp;= b_0 + b_1 \cdot x\\
\widehat{\text{score}} &amp;= b_0 + b_{\text{bty}\_\text{avg}} \cdot\text{bty}\_\text{avg}\\
&amp;= 3.880 + 0.067\cdot\text{bty}\_\text{avg}
\end{aligned}
\]</span></p>
<p>The intercept <span class="math inline">\(b_0\)</span> = 3.88 is the average teaching score <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{score}}\)</span> for those courses where the instructor had a “beauty” score <code>bty_avg</code> of 0. Or in graphical terms, it’s where the line intersects the <span class="math inline">\(y\)</span> axis when <span class="math inline">\(x\)</span> = 0. Note, however, that while the  intercept of the regression line has a mathematical interpretation, it has no <em>practical</em> interpretation here, since observing a <code>bty_avg</code> of 0 is impossible; it is the average of six panelists’ “beauty” scores ranging from 1 to 10. Furthermore, looking at the scatterplot with the regression line, no instructors had a “beauty” score anywhere near 0.</p>
<p>Of greater interest is the  slope <span class="math inline">\(b_1\)</span> = <span class="math inline">\(b_{\text{bty_avg}}\)</span> for <code>bty_avg</code> of 0.067, as this summarizes the relationship between the teaching and “beauty” score variables. Note that the sign is positive, suggesting a positive relationship between these two variables, meaning teachers with higher “beauty” scores also tend to have higher teaching scores. Recall from earlier that the correlation coefficient is 0.187. They both have the same positive sign, but have a different value. Recall further that the correlation’s interpretation is the “strength of linear association”. The  slope’s interpretation is a little different:</p>
<blockquote>
<p>For every increase of 1 unit in <code>bty_avg</code>, there is an <em>associated</em> increase of, <em>on average</em>, 0.067 units of <code>score</code>.</p>
</blockquote>
<p>We say that this associated increase is <em>on average</em> 0.067 units of teaching <code>score</code>, because you might have two instructors whose <code>bty_avg</code> scores differ by 1 unit, but their difference in teaching scores won’t necessarily be exactly 0.067. What the slope of 0.067 is saying is that across all possible courses, the <em>average</em> difference in teaching score between two instructors whose “beauty” scores differ by one is 0.067.</p>
<p>Furthermore, we only state that there is an <em>associated</em> increase and not necessarily a <em>causal</em> increase. For example, perhaps it’s not that higher “beauty” scores directly cause higher teaching scores per se. Instead, the following could hold true: individuals from wealthier backgrounds tend to have stronger educational backgrounds and hence have higher teaching scores, while at the same time these wealthy individuals also tend to have higher “beauty” scores. In other words, just because two variables are strongly associated, it doesn’t necessarily mean that one causes the other. This is summed up in the often quoted phrase, “correlation is not necessarily causation.”</p>
<p>Here is another example: a not-so-great medical doctor goes through medical records and finds that patients who slept with their shoes on tended to wake up more with headaches. So this doctor declares, “Sleeping with shoes on causes headaches!”</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-477"></span>
<img src="images/shutterstock/shoes_headache.png" alt="Does sleeping with shoes on cause headaches?" width="60%" height="60%" />
<p class="caption">
FIGURE 11.5: Does sleeping with shoes on cause headaches?
</p>
</div>
<p>However, there is a good chance that if someone is sleeping with their shoes on, it’s potentially because they are intoxicated from alcohol. Furthermore, higher levels of drinking leads to more hangovers, and hence more headaches. The amount of alcohol consumption here is what’s known as a <em>confounding</em> variable. It lurks behind the scenes, confounding the causal relationship (if any) of “sleeping with shoes on” with “waking up with a headache.” We can summarize this with a <em>causal graph</em> where:</p>
<ul>
<li>Y is a <em>response</em> variable; here it is “waking up with a headache.” </li>
<li>X is a <em>treatment</em> variable whose causal effect we are interested in; here it is “sleeping with shoes on.”</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-478"></span>
<img src="images/flowcharts/flowchart.009-cropped.png" alt="Causal graph." width="50%" />
<p class="caption">
FIGURE 11.6: Causal graph.
</p>
</div>
<p>To study the relationship between Y and X, we could use a regression model where the outcome variable is set to Y and the explanatory variable is set to be X, as you’ve been doing throughout this chapter. However, the causal graph also includes a third variable with arrows pointing at both X and Y:</p>
<ul>
<li>Z is a <em>confounding</em> variable  that affects both X and Y, thereby “confounding” their relationship. Here the confounding variable is alcohol.</li>
</ul>
<p>Alcohol will cause people to be both more likely to sleep with their shoes on as well as be more likely to wake up with a headache. We can see why this is a problem under the potential outcomes framework: both whether you receive the treatment “sleeping with shoes on” and your potential outcome depend on whether you consumed alcohol, which means that you can’t estimate the treatment effect of “sleeping with shoes on” simply by comparing the observed outcome under treatment and the observed outcome under control. Thus any regression model of the relationship between X and Y should also use Z as an explanatory variable. In other words, our doctor needs to take into account who had been drinking the night before. In the next chapter, we’ll start covering multiple regression models that allow us to incorporate more than one variable in our regression models.</p>
<p>Establishing causation is a tricky problem and frequently takes either randomized controlled trials or methods to adjust for the effects of confounding variables. Both these approaches attempt, as best they can, either to take all possible confounding variables into account or negate their impact. This allows researchers to focus only on the relationship of interest: the relationship between the outcome variable Y and the treatment variable X.</p>
<p>As you read news stories, be careful not to fall into the trap of thinking that correlation necessarily implies causation. Check out the <a href="http://www.tylervigen.com/spurious-correlations">Spurious Correlations</a> website for some rather comical examples of variables that are correlated, but are definitely not causally related.</p>
<p>Let’s say, however, that we were confident that there is no confounding: that is, that there are no variables such as socioeconomic background that correlate both with a teacher’s “beauty” score and teaching score. (We shouldn’t be confident in this, but let’s play along for the moment.) Then, we can interpret the slope in terms of the <a href="A-rubin-causal-model.html#rubin-causal-model">Rubin Causal Model</a>. The slope coefficient on <code>bty_avg</code> of 0.067 then means that the <em>average treatment effect</em> of increasing a teacher’s “beauty” score by 1 is 0.067. In the absence of randomization, however, this is likely not a good interpretation of this regression! Adding additional variables, as we’ll do in Chapter @ref{multiple-regression}, may make it more plausible to interpret the regression causally.</p>
<p>Keeping with the causal interpretation, let’s say that a teacher named Joe had a “beauty” score of 7 and a teaching score of 4. We are curious about how much moving from a “beauty” score of 7 versus “beauty” score of 8 would have affected Joe’s teaching score. Thus, we are comparing the <em>potential outcome</em> for Joe when <code>bty_avg</code> is 7 versus the <em>potential outcome</em> when <code>bty_avg</code> is 8. Only one of these potential outcomes was observed.</p>
<table class="table table-striped" style="width: auto !important; ">
<thead>
<tr>
<th style="text-align:left;">
Subject
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 7\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 8\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;">
Joe
</td>
<td style="text-align:left;">
<span class="math inline">\(4\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(?\)</span>
</td>
</tr>
</tbody>
</table>
<p>We can use our slope coefficient from the linear regression to fill in the missing potential outcome:</p>
<table class="table table-striped" style="width: auto !important; ">
<thead>
<tr>
<th style="text-align:left;">
Subject
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 7\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 8\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(\Delta bty\_avg\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;">
Joe
</td>
<td style="text-align:left;">
<span class="math inline">\(4\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(4.067\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(0.067\)</span>
</td>
</tr>
</tbody>
</table>
<p>Thus, our best guess of Joe’s potential outcome under the “treatment” of <span class="math inline">\(score = 8\)</span> is <span class="math inline">\(4.067\)</span>.</p>
</div>
</div>
<div id="uncertainty-in-simple-linear-regressions" class="section level2">
<h2><span class="header-section-number">11.2</span> Uncertainty in simple linear regressions</h2>
<p>You might be wondering what the remaining five columns created by <code>tidy()</code> are: <code>std.error</code>, <code>statistic</code>, <code>p.value</code>, <code>conf.low</code> and <code>conf.high</code>. They are the <em>standard error</em>, <em>test statistic</em>, <em>p-value</em>, <em>lower 95% confidence interval bound</em>, and <em>upper 95% confidence interval bound</em>. We will focus on the confidence interval bounds. We have already explored the concept of confidence intervals in Chapter <a href="10-confidence-intervals.html#confidence-intervals">10</a>. These bounds are an application the same concept, but applied to the slope of our simple linear regression.</p>
<p>Let’s load the <strong>infer</strong> package. We’re going to use the function <code>rep_sample_n()</code> to reample from our data 1000 times:</p>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb745-1"><a href="11-regression.html#cb745-1"></a><span class="kw">library</span>(infer)</span>
<span id="cb745-2"><a href="11-regression.html#cb745-2"></a></span>
<span id="cb745-3"><a href="11-regression.html#cb745-3"></a>x &lt;-<span class="st"> </span>evals_ch11 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb745-4"><a href="11-regression.html#cb745-4"></a><span class="st">  </span><span class="kw">select</span>(score, bty_avg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb745-5"><a href="11-regression.html#cb745-5"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="kw">nrow</span>(evals_ch11), <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb745-6"><a href="11-regression.html#cb745-6"></a></span>
<span id="cb745-7"><a href="11-regression.html#cb745-7"></a>x</span></code></pre></div>
<pre><code># A tibble: 463,000 x 3
# Groups:   replicate [1,000]
   replicate score bty_avg
       &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;
 1         1   4.5 6.833  
 2         1   4.8 6.5    
 3         1   4.4 3.667  
 4         1   3.2 2.66700
 5         1   5   5.5    
 6         1   4.8 4.5    
 7         1   4.4 3.833  
 8         1   3.8 3.16700
 9         1   4.9 3.5    
10         1   3.7 7.167  
# … with 462,990 more rows</code></pre>
<p>For each <code>replicate</code>, we have 463 resamples of <code>score</code> and <code>bty_avg</code>.</p>
<p>Next, we are going to introduce a new function: <code>nest()</code>:</p>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="11-regression.html#cb747-1"></a>x &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb747-2"><a href="11-regression.html#cb747-2"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb747-3"><a href="11-regression.html#cb747-3"></a><span class="st">  </span><span class="kw">nest</span>()</span>
<span id="cb747-4"><a href="11-regression.html#cb747-4"></a></span>
<span id="cb747-5"><a href="11-regression.html#cb747-5"></a>x</span></code></pre></div>
<pre><code># A tibble: 1,000 x 2
# Groups:   replicate [1,000]
   replicate data              
       &lt;int&gt; &lt;list&gt;            
 1         1 &lt;tibble [463 × 2]&gt;
 2         2 &lt;tibble [463 × 2]&gt;
 3         3 &lt;tibble [463 × 2]&gt;
 4         4 &lt;tibble [463 × 2]&gt;
 5         5 &lt;tibble [463 × 2]&gt;
 6         6 &lt;tibble [463 × 2]&gt;
 7         7 &lt;tibble [463 × 2]&gt;
 8         8 &lt;tibble [463 × 2]&gt;
 9         9 &lt;tibble [463 × 2]&gt;
10        10 &lt;tibble [463 × 2]&gt;
# … with 990 more rows</code></pre>
<p><code>nest()</code> comes from the <strong>tidyr</strong> package. It’s easiest to understand what <code>nest()</code> does by looking at its output. After grouping by <code>replicate</code> and using <code>nest()</code>, we now have a dataset of 1000 rows and a list column named <code>data</code>. What’s in this list column? Each element of <code>data</code> is a tibble consisting of one of the resampled datasets we created using <code>rep_sample_n()</code>. <code>nest()</code> is thus a useful function when you have a series of bootstrapped samples and want to run the same function on each sample.</p>
<p>Now, we can use <code>map()</code> to run our linear regression for each dataset:</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="11-regression.html#cb749-1"></a>x &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb749-2"><a href="11-regression.html#cb749-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mod =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, <span class="dt">data =</span> .)))</span>
<span id="cb749-3"><a href="11-regression.html#cb749-3"></a></span>
<span id="cb749-4"><a href="11-regression.html#cb749-4"></a>x</span></code></pre></div>
<pre><code># A tibble: 1,000 x 3
# Groups:   replicate [1,000]
   replicate data               mod   
       &lt;int&gt; &lt;list&gt;             &lt;list&gt;
 1         1 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 2         2 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 3         3 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 4         4 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 5         5 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 6         6 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 7         7 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 8         8 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
 9         9 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
10        10 &lt;tibble [463 × 2]&gt; &lt;lm&gt;  
# … with 990 more rows</code></pre>
<p>Now we have a new list column, <code>mod</code>, that contains the model objects created by <code>lm()</code>. We will now want to <code>tidy()</code> the object created by <code>lm()</code>:</p>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="11-regression.html#cb751-1"></a>x &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb751-2"><a href="11-regression.html#cb751-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">reg_results =</span> <span class="kw">map</span>(mod, <span class="op">~</span><span class="st"> </span><span class="kw">tidy</span>(.)))</span>
<span id="cb751-3"><a href="11-regression.html#cb751-3"></a></span>
<span id="cb751-4"><a href="11-regression.html#cb751-4"></a>x</span></code></pre></div>
<pre><code># A tibble: 1,000 x 4
# Groups:   replicate [1,000]
   replicate data               mod    reg_results     
       &lt;int&gt; &lt;list&gt;             &lt;list&gt; &lt;list&gt;          
 1         1 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 2         2 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 3         3 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 4         4 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 5         5 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 6         6 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 7         7 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 8         8 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
 9         9 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
10        10 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt;
# … with 990 more rows</code></pre>
<p><code>tidy()</code> stores the coefficients in the <code>estimate</code> column, with each coefficient named in the <code>term</code> column. Thus, if we <code>filter()</code> by <code>term</code> and <code>pull(estimate)</code>, we can get the regression coefficient for each bootstrap sample:</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="11-regression.html#cb753-1"></a>x &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span></span>
<span id="cb753-2"><a href="11-regression.html#cb753-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">disp_coef =</span> <span class="kw">map_dbl</span>(reg_results, <span class="op">~</span><span class="st"> </span><span class="kw">filter</span>(., term <span class="op">==</span><span class="st"> &quot;bty_avg&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(estimate)))</span>
<span id="cb753-3"><a href="11-regression.html#cb753-3"></a></span>
<span id="cb753-4"><a href="11-regression.html#cb753-4"></a>x</span></code></pre></div>
<pre><code># A tibble: 1,000 x 5
# Groups:   replicate [1,000]
   replicate data               mod    reg_results      disp_coef
       &lt;int&gt; &lt;list&gt;             &lt;list&gt; &lt;list&gt;               &lt;dbl&gt;
 1         1 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0786136
 2         2 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0768437
 3         3 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0608634
 4         4 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0776020
 5         5 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0894999
 6         6 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0601213
 7         7 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0654890
 8         8 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0735311
 9         9 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0886716
10        10 &lt;tibble [463 × 2]&gt; &lt;lm&gt;   &lt;tibble [2 × 5]&gt; 0.0517023
# … with 990 more rows</code></pre>
<p>Now that we have 1000 estimates from our bootstrap samples, we can construct a percentile-based confidence interval easily:</p>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="11-regression.html#cb755-1"></a>x <span class="op">%&gt;%</span></span>
<span id="cb755-2"><a href="11-regression.html#cb755-2"></a><span class="st"> </span><span class="kw">pull</span>(disp_coef) <span class="op">%&gt;%</span></span>
<span id="cb755-3"><a href="11-regression.html#cb755-3"></a><span class="st"> </span><span class="kw">quantile</span>(<span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>  2.5%    50%  97.5% 
0.0344 0.0653 0.0986 </code></pre>
<p>Now let’s return to our example for Joe. Since our slope coefficient is measured with some uncertainty, our estimate of his potential outcome under the “treatment” of having a “beauty” score of 8 is also measured with some uncertainty, and that should be reflected in our table:</p>
<table class="table table-striped" style="width: auto !important; ">
<thead>
<tr>
<th style="text-align:left;">
Subject
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 7\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(bty\_avg = 8\)</span>
</th>
<th style="text-align:left;">
<span class="math inline">\(\Delta bty\_avg\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;">
Joe
</td>
<td style="text-align:left;">
<span class="math inline">\(4\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((4.034, 4.099)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\((0.034, 0.099)\)</span>
</td>
</tr>
</tbody>
</table>
<p>Instead of looking at confidence intervals, a common alternative approach is to conduct <em>hypothesis tests</em>, where one hypothesis is called the “null hypothesis” (in a regression context, generally that the regression coefficient is equal to zero) and the result of the test is either <em>rejecting</em> the null hypothesis (so you’d conclude that the regression coefficient probably is not zero) or <em>failing to reject</em> the null hypothesis. The decision whether to reject the null hypothesis is generally made with reference to a <em>p-value</em>, a measure of how likely one would observe results at least as extreme as the results actually observed if the null hypothesis were true. A <em>p</em>-value cutoff, often 0.05, is employed: if the <em>p</em>-value is lower, the null hypothesis is rejected, otherwise the hypothesis is not rejected.</p>
<p>We think this is a bad way to make decisions. Two very similar datasets could produce <em>p</em>-values of <span class="math inline">\(p = 0.04\)</span> and <span class="math inline">\(p = 0.06\)</span> for a coefficient of interest. If you would make one decision in the former case and a totally different decision in the latter case, then there’s something wrong with your decision-making process! Rather, we think it is more sensible to look at the data, construct models to summarize important features of the data, and make decisions based on those models that take into account the uncertainty in the models’ estimates.</p>
<div id="using-lm-and-tidy-as-a-shortcut-2" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Using <code>lm()</code> and <code>tidy()</code> as a shortcut</h3>
<p>While this process is relatively straightforward, there’s a simple shortcut we can use. Take a look at the results from <code>score_model %&gt;% tidy(conf.int = TRUE)</code>:</p>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="11-regression.html#cb757-1"></a>score_model <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb757-2"><a href="11-regression.html#cb757-2"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb757-3"><a href="11-regression.html#cb757-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;bty_avg&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb757-4"><a href="11-regression.html#cb757-4"></a><span class="st">  </span><span class="kw">select</span>(estimate, conf.low, conf.high)</span></code></pre></div>
<pre><code># A tibble: 1 x 3
   estimate  conf.low conf.high
      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1 0.0666370 0.0346229 0.0986512</code></pre>
<p>The confidence intervals reported by <code>lm()</code> and <code>tidy()</code> are very similar to our bootstrap confidence intervals. Thus, we can interpret these confidence intervals the same way we did in Chapter <a href="10-confidence-intervals.html#confidence-intervals">10</a>. In 95% of our samples, the estimate was between the lower confidence interval bound and the higher confidence interval bound; our interpretation is that the effect of <code>bty_avg</code> on <code>score</code>, which we are trying to estimate, has a 95% chance of falling within these bounds. From now on, we’ll just use <code>lm()</code> because it is simpler, but when considering how to interpret the confidence intervals, remember that you’d obtain very similar results from the bootstrap method.</p>
</div>
<div id="model1points" class="section level3">
<h3><span class="header-section-number">11.2.2</span> Observed/fitted values and residuals</h3>
<p>We just saw how to get the value of the intercept and the slope of a regression line from the <code>estimate</code> column of a regression table generated by the <code>tidy()</code> function. Now instead say we want information on individual observations. For example, let’s focus on the 21st of the 463 courses in the <code>evals_ch11</code> data frame:</p>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-489">TABLE 11.4: </span>Data for the 21st course out of 463
</caption>
<thead>
<tr>
<th style="text-align:right;">
ID
</th>
<th style="text-align:right;">
score
</th>
<th style="text-align:right;">
bty_avg
</th>
<th style="text-align:right;">
age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
4.9
</td>
<td style="text-align:right;">
7.33
</td>
<td style="text-align:right;">
31
</td>
</tr>
</tbody>
</table>
<p>What is the value <span class="math inline">\(\widehat{y}\)</span> on the regression line corresponding to this instructor’s <code>bty_avg</code> “beauty” score of 7.333? We will mark three values corresponding to the instructor for this 21st course and give their statistical names:</p>
<ul>
<li>Circle: The <em>observed value</em> <span class="math inline">\(y\)</span> = 4.9 is this course’s instructor’s actual teaching score.</li>
<li>Square: The <em>fitted value</em> <span class="math inline">\(\widehat{y}\)</span> is the value on the regression line for <span class="math inline">\(x\)</span> = <code>bty_avg</code> = 7.333. This value is computed using the intercept and slope in the previous regression table:</li>
</ul>
<p><span class="math display">\[\widehat{y} = b_0 + b_1 \cdot x = 3.88 + 0.067 \cdot 7.333 = 4.369\]</span></p>
<ul>
<li>Arrow: The length of this arrow is the <em>residual</em>  and is computed by subtracting the fitted value <span class="math inline">\(\widehat{y}\)</span> from the observed value <span class="math inline">\(y\)</span>. The residual can be thought of as a model’s error or “lack of fit” for a particular observation. In the case of this course’s instructor, it is <span class="math inline">\(y - \widehat{y}\)</span> = 4.9 - 4.369 = 0.531.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-490"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-490-1.png" alt="Example of observed value, fitted value, and residual." width="\textwidth" />
<p class="caption">
FIGURE 11.7: Example of observed value, fitted value, and residual.
</p>
</div>
<p>Now say we want to compute both the fitted value <span class="math inline">\(\widehat{y} = b_0 + b_1 \cdot x\)</span> and the residual <span class="math inline">\(y - \widehat{y}\)</span> for <em>all</em> 463 courses in the study. Recall that each course corresponds to one of the 463 rows in the <code>evals_ch11</code> data frame and also one of the 463 points in the regression plot.</p>
<p>We could repeat the previous calculations we performed by hand 463 times, but that would be tedious and time consuming. Instead, let’s do this using a computer with the <code>augment()</code> function in the <strong>broom</strong> package. Let’s apply the <code>augment()</code> function to <code>score_model</code>, which is where we saved our <code>lm()</code> model in the previous section. We present the results of only the 21st through 24th courses for brevity’s sake.</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="11-regression.html#cb759-1"></a>regression_points &lt;-<span class="st"> </span>score_model <span class="op">%&gt;%</span></span>
<span id="cb759-2"><a href="11-regression.html#cb759-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></span>
<span id="cb759-3"><a href="11-regression.html#cb759-3"></a><span class="st">  </span><span class="kw">select</span>(score, bty_avg, .fitted, .resid)</span>
<span id="cb759-4"><a href="11-regression.html#cb759-4"></a>regression_points</span></code></pre></div>
<table>
<caption>
<span id="tab:unnamed-chunk-492">TABLE 11.5: </span>Regression points (for only the 21st through 24th courses)
</caption>
<thead>
<tr>
<th style="text-align:right;">
score
</th>
<th style="text-align:right;">
bty_avg
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
4.9
</td>
<td style="text-align:right;">
7.33
</td>
<td style="text-align:right;">
4.37
</td>
<td style="text-align:right;">
0.531
</td>
</tr>
<tr>
<td style="text-align:right;">
4.6
</td>
<td style="text-align:right;">
7.33
</td>
<td style="text-align:right;">
4.37
</td>
<td style="text-align:right;">
0.231
</td>
</tr>
<tr>
<td style="text-align:right;">
4.5
</td>
<td style="text-align:right;">
7.33
</td>
<td style="text-align:right;">
4.37
</td>
<td style="text-align:right;">
0.131
</td>
</tr>
<tr>
<td style="text-align:right;">
4.4
</td>
<td style="text-align:right;">
5.50
</td>
<td style="text-align:right;">
4.25
</td>
<td style="text-align:right;">
0.153
</td>
</tr>
</tbody>
</table>
<p>Let’s inspect the individual columns and match them with the elements of our regression plot:</p>
<ul>
<li>The <code>score</code> column represents the observed outcome variable <span class="math inline">\(y\)</span>. This is the y-position of the 463 black points.</li>
<li>The <code>bty_avg</code> column represents the values of the explanatory variable <span class="math inline">\(x\)</span>. This is the x-position of the 463 black points.</li>
<li>The <code>.fitted</code> column represents the fitted values <span class="math inline">\(\widehat{y}\)</span>. This is the corresponding value on the regression line for the 463 <span class="math inline">\(x\)</span> values.</li>
<li>The <code>.resid</code> column represents the residuals <span class="math inline">\(y - \widehat{y}\)</span>. This is the 463 vertical distances between the 463 black points and the regression line.</li>
</ul>
<p>Just as we did for the instructor of the 21st course in the <code>evals_ch11</code> dataset (in the first row of the table), let’s repeat the calculations for the instructor of the 24th course (in the fourth row):</p>
<ul>
<li><code>score</code> = 4.4 is the observed teaching <code>score</code> <span class="math inline">\(y\)</span> for this course’s instructor.</li>
<li><code>bty_avg</code> = 5.50 is the value of the explanatory variable <code>bty_avg</code> <span class="math inline">\(x\)</span> for this course’s instructor.</li>
<li><code>.fitted</code> = 4.25 = 3.88 + 0.067 <span class="math inline">\(\cdot\)</span> 5.50 is the fitted value <span class="math inline">\(\widehat{y}\)</span> on the regression line for this course’s instructor.</li>
<li><code>.resid</code> = 0.153 = 4.4 - 4.25 is the value of the residual for this instructor. In other words, the model’s fitted value was off by 0.153 teaching score units for this course’s instructor.</li>
</ul>
<p>At this point, you can skip ahead if you like to Section <a href="11-regression.html#leastsquares">11.5</a> to learn about the processes behind what makes “best-fitting” regression lines. As a primer, a “best-fitting” line refers to the line that minimizes the <em>sum of squared residuals</em> out of all possible lines we can draw through the points. In Section <a href="11-regression.html#model2">11.3</a>, we’ll discuss another common scenario of having a categorical explanatory variable and a numerical outcome variable.</p>
<p>Constructing a measure of uncertainty around the fitted values can also be done using the <code>augment()</code> function. The simplest way to do this is through the standard error method that we learned in the last chapter. Note that <code>augment()</code> saves the standard errors of the fitted values in a column called <code>.se.fit</code>:</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="11-regression.html#cb760-1"></a>score_model <span class="op">%&gt;%</span></span>
<span id="cb760-2"><a href="11-regression.html#cb760-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></span>
<span id="cb760-3"><a href="11-regression.html#cb760-3"></a><span class="st">  </span><span class="kw">select</span>(score, bty_avg, .fitted, .se.fit, .resid)</span></code></pre></div>
<pre><code># A tibble: 463 x 5
   score bty_avg .fitted   .se.fit      .resid
   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
 1 4.7   5       4.21352 0.0266038  0.486477  
 2 4.100 5       4.21352 0.0266038 -0.113523  
 3 3.9   5       4.21352 0.0266038 -0.313523  
 4 4.8   5       4.21352 0.0266038  0.586477  
 5 4.600 3       4.08025 0.0339315  0.519751  
 6 4.3   3       4.08025 0.0339315  0.219751  
 7 2.8   3       4.08025 0.0339315 -1.28025   
 8 4.100 3.333   4.10244 0.0304986 -0.00243920
 9 3.4   3.333   4.10244 0.0304986 -0.702439  
10 4.5   3.16700 4.09138 0.0321413  0.408623  
# … with 453 more rows</code></pre>
<p>Now that we have the standard error of the fitted values, we can construct a confidence interval easily:</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="11-regression.html#cb762-1"></a>score_model <span class="op">%&gt;%</span></span>
<span id="cb762-2"><a href="11-regression.html#cb762-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></span>
<span id="cb762-3"><a href="11-regression.html#cb762-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">conf.low =</span> .fitted <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>.se.fit,</span>
<span id="cb762-4"><a href="11-regression.html#cb762-4"></a>         <span class="dt">conf.high =</span> .fitted <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>.se.fit) <span class="op">%&gt;%</span></span>
<span id="cb762-5"><a href="11-regression.html#cb762-5"></a><span class="st">  </span><span class="kw">select</span>(score, bty_avg, .fitted, conf.low, conf.high, .resid)</span></code></pre></div>
<pre><code># A tibble: 463 x 6
   score bty_avg .fitted conf.low conf.high      .resid
   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
 1 4.7   5       4.21352  4.16032   4.26673  0.486477  
 2 4.100 5       4.21352  4.16032   4.26673 -0.113523  
 3 3.9   5       4.21352  4.16032   4.26673 -0.313523  
 4 4.8   5       4.21352  4.16032   4.26673  0.586477  
 5 4.600 3       4.08025  4.01239   4.14811  0.519751  
 6 4.3   3       4.08025  4.01239   4.14811  0.219751  
 7 2.8   3       4.08025  4.01239   4.14811 -1.28025   
 8 4.100 3.333   4.10244  4.04144   4.16344 -0.00243920
 9 3.4   3.333   4.10244  4.04144   4.16344 -0.702439  
10 4.5   3.16700 4.09138  4.02709   4.15566  0.408623  
# … with 453 more rows</code></pre>
<p>Note that the uncertainty for <em>particular predictions</em> is higher than the uncertainty for our estimate of the coefficient on <code>bty_avg</code>. We are more confident in the <em>average</em> effect of “beauty” scores on teaching evaluations than we are on any predictions we would make for a <em>particular person</em>.</p>
<!-- AR: We can't really bring Joe back in here, because we are filling in the
potential outcome table with estimates of the treatment effect + Joe's observed
outcome, not with the predicted value for a particular bty_avg.-->
</div>
</div>
<div id="model2" class="section level2">
<h2><span class="header-section-number">11.3</span> Life expectancy: one categorical explanatory variable</h2>
<p>It’s an unfortunate truth that life expectancy is not the same across all countries in the world. International development agencies are interested in studying these differences in life expectancy in the hopes of identifying where governments should allocate resources to address this problem. In this section, we’ll explore differences in life expectancy in two ways:</p>
<ol style="list-style-type: decimal">
<li>Differences between continents: Are there significant differences in average life expectancy between the five populated continents of the world: Africa, the Americas, Asia, Europe, and Oceania?</li>
<li>Differences within continents: How does life expectancy vary within the world’s five continents? For example, is the spread of life expectancy among the countries of Africa larger than the spread of life expectancy among the countries of Asia?</li>
</ol>
<p>To answer such questions, we’ll use the <code>gapminder</code> data frame included in the <strong>gapminder</strong>  package. This dataset has international development statistics such as life expectancy, GDP per capita, and population for 142 countries for 5-year intervals between 1952 and 2007. Recall we visualized some of this data in Figure <a href="2-viz.html#fig:gapminder">2.1</a> in Subsection <a href="2-viz.html#gapminder">2.1.2</a> on the grammar of graphics.</p>
<p>We’ll use this data for basic regression again, but now using an explanatory variable <span class="math inline">\(x\)</span> that is categorical, as opposed to the numerical explanatory variable model we used in the previous Section <a href="11-regression.html#model1">11.1</a>.</p>
<ol style="list-style-type: decimal">
<li>A numerical outcome variable <span class="math inline">\(y\)</span> (a country’s life expectancy) and</li>
<li>A single categorical explanatory variable <span class="math inline">\(x\)</span> (the continent that the country is a part of).</li>
</ol>
<p>When the explanatory variable <span class="math inline">\(x\)</span> is categorical, the concept of a “best-fitting” regression line is a little different than the one we saw previously in Section <a href="11-regression.html#model1">11.1</a> where the explanatory variable <span class="math inline">\(x\)</span> was numerical. We’ll study these differences shortly in Subsection <a href="11-regression.html#model2table">11.3.2</a>, but first we conduct an exploratory data analysis.</p>
<div id="model2EDA" class="section level3">
<h3><span class="header-section-number">11.3.1</span> Exploratory data analysis</h3>
<p>The data on the 142 countries can be found in the <code>gapminder</code> data frame included in the <strong>gapminder</strong> package. However, to keep things simple, let’s <code>filter()</code> for only those observations/rows corresponding to the year 2007. Additionally, let’s <code>select()</code> only the subset of the variables we’ll consider in this chapter. We’ll save this data in a new data frame called <code>gapminder2007</code>:</p>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="11-regression.html#cb764-1"></a><span class="kw">library</span>(gapminder)</span>
<span id="cb764-2"><a href="11-regression.html#cb764-2"></a>gapminder2007 &lt;-<span class="st"> </span>gapminder <span class="op">%&gt;%</span></span>
<span id="cb764-3"><a href="11-regression.html#cb764-3"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2007</span>) <span class="op">%&gt;%</span></span>
<span id="cb764-4"><a href="11-regression.html#cb764-4"></a><span class="st">  </span><span class="kw">select</span>(country, lifeExp, continent, gdpPercap)</span></code></pre></div>
<p>Let’s perform the first common step in an exploratory data analysis: looking at the raw data values. You can do this by using RStudio’s spreadsheet viewer or by using the <code>glimpse()</code> command as introduced in Subsection <a href="1-getting-started.html#exploredataframes">1.4.3</a> on exploring data frames:</p>
<div class="sourceCode" id="cb765"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb765-1"><a href="11-regression.html#cb765-1"></a><span class="kw">glimpse</span>(gapminder2007)</span></code></pre></div>
<pre><code>Observations: 142
Variables: 4
$ country   &lt;fct&gt; Afghanistan, Albania, Algeria, Angola, Argentina, Australia…
$ lifeExp   &lt;dbl&gt; 43.8, 76.4, 72.3, 42.7, 75.3, 81.2, 79.8, 75.6, 64.1, 79.4,…
$ continent &lt;fct&gt; Asia, Europe, Africa, Africa, Americas, Oceania, Europe, As…
$ gdpPercap &lt;dbl&gt; 975, 5937, 6223, 4797, 12779, 34435, 36126, 29796, 1391, 33…</code></pre>
<p>Observe that <code>Observations: 142</code> indicates that there are 142 rows/observations in <code>gapminder2007</code>, where each row corresponds to one country. In other words, the <em>observational unit</em> is an individual country. Furthermore, observe that the variable <code>continent</code> is of type <code>&lt;fct&gt;</code>, which stands for <em>factor</em>, which is R’s way of encoding categorical variables.</p>
<p>A full description of all the variables included in <code>gapminder</code> can be found by reading the associated help file (run <code>?gapminder</code> in the console). However, let’s fully describe only the 4 variables we selected in <code>gapminder2007</code>:</p>
<ol style="list-style-type: decimal">
<li><code>country</code>: An identification variable of type character/text used to distinguish the 142 countries in the dataset.</li>
<li><code>lifeExp</code>: A numerical variable of that country’s life expectancy at birth. This is the outcome variable <span class="math inline">\(y\)</span> of interest.</li>
<li><code>continent</code>: A categorical variable with five levels. Here “levels” correspond to the possible categories: Africa, Asia, Americas, Europe, and Oceania. This is the explanatory variable <span class="math inline">\(x\)</span> of interest.</li>
<li><code>gdpPercap</code>: A numerical variable of that country’s GDP per capita in US inflation-adjusted dollars.</li>
</ol>
<p>Let’s look at a random sample of five out of the 142 countries.</p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb767-1"><a href="11-regression.html#cb767-1"></a>gapminder2007 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">5</span>)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-499">TABLE 11.6: </span>Random sample of 5 out of 142 countries
</caption>
<thead>
<tr>
<th style="text-align:left;">
country
</th>
<th style="text-align:right;">
lifeExp
</th>
<th style="text-align:left;">
continent
</th>
<th style="text-align:right;">
gdpPercap
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Togo
</td>
<td style="text-align:right;">
58.4
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
883
</td>
</tr>
<tr>
<td style="text-align:left;">
Sao Tome and Principe
</td>
<td style="text-align:right;">
65.5
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
1598
</td>
</tr>
<tr>
<td style="text-align:left;">
Congo, Dem. Rep. 
</td>
<td style="text-align:right;">
46.5
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
278
</td>
</tr>
<tr>
<td style="text-align:left;">
Lesotho
</td>
<td style="text-align:right;">
42.6
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
1569
</td>
</tr>
<tr>
<td style="text-align:left;">
Bulgaria
</td>
<td style="text-align:right;">
73.0
</td>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
10681
</td>
</tr>
</tbody>
</table>
<p>Note that random sampling will likely produce a different subset of 5 rows for you than what’s shown. Now that we’ve looked at the raw values in our <code>gapminder2007</code> data frame and got a sense of the data, let’s move on to computing summary statistics. Let’s once again apply the <code>skim()</code> function from the <strong>skimr</strong> package. Recall from our previous EDA that this function takes in a data frame, “skims” it, and returns commonly used summary statistics. Let’s take our <code>gapminder2007</code> data frame, <code>select()</code> only the outcome and explanatory variables <code>lifeExp</code> and <code>continent</code>, and pipe them into the <code>skim()</code> function:</p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="11-regression.html#cb768-1"></a>gapminder2007 <span class="op">%&gt;%</span></span>
<span id="cb768-2"><a href="11-regression.html#cb768-2"></a><span class="st">  </span><span class="kw">select</span>(lifeExp, continent) <span class="op">%&gt;%</span></span>
<span id="cb768-3"><a href="11-regression.html#cb768-3"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<table style='width: auto;'
        class='table table-condensed'>
<caption>
<span id="tab:unnamed-chunk-500">TABLE 11.7: </span>Data summary
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
Piped data
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
142
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
factor
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:left;">
ordered
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:left;">
top_counts
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
continent
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
FALSE
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
Afr: 52, Asi: 33, Eur: 30, Ame: 25
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
lifeExp
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
12.1
</td>
<td style="text-align:right;">
39.6
</td>
<td style="text-align:right;">
57.2
</td>
<td style="text-align:right;">
71.9
</td>
<td style="text-align:right;">
76.4
</td>
<td style="text-align:right;">
82.6
</td>
<td style="text-align:left;">
▂▃▃▆▇
</td>
</tr>
</tbody>
</table>
<p>The <code>skim()</code> output now reports summaries for categorical variables (<code>Variable type:factor</code>) separately from the numerical variables (<code>Variable type:numeric</code>). For the categorical variable <code>continent</code>, it reports:</p>
<ul>
<li><code>n_missing</code> and <code>complete_rate</code>, which are the number of missing and the completion rate, respectively.</li>
<li><code>n_unique</code>: The number of unique levels to this variable, corresponding to Africa, Asia, Americas, Europe, and Oceania. This refers to how many countries are in the data for each continent.</li>
<li><code>top_counts</code>: In this case, the top four counts: <code>Africa</code> has 52 countries, <code>Asia</code> has 33, <code>Europe</code> has 30, and <code>Americas</code> has 25. Not displayed is <code>Oceania</code> with 2 countries.</li>
<li><code>ordered</code>: This tells us whether the categorical variable is “ordinal”: whether there is an encoded hierarchy (like low, medium, high). In this case, <code>continent</code> is not ordered.</li>
</ul>
<p>Turning our attention to the summary statistics of the numerical variable <code>lifeExp</code>, we observe that the global median life expectancy in 2007 was 71.94. Thus, half of the world’s countries (71 countries) had a life expectancy less than 71.94. The mean life expectancy of 67.01 is lower, however. Why is the mean life expectancy lower than the median?</p>
<p>We can answer this question by performing the last of the three common steps in an exploratory data analysis: creating data visualizations. Let’s visualize the distribution of our outcome variable <span class="math inline">\(y\)</span> = <code>lifeExp</code>.</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb769-1"><a href="11-regression.html#cb769-1"></a>gapminder2007 <span class="op">%&gt;%</span></span>
<span id="cb769-2"><a href="11-regression.html#cb769-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lifeExp)) <span class="op">+</span></span>
<span id="cb769-3"><a href="11-regression.html#cb769-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb769-4"><a href="11-regression.html#cb769-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Life expectancy&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of countries&quot;</span>,</span>
<span id="cb769-5"><a href="11-regression.html#cb769-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Histogram of distribution of worldwide life expectancies&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-501"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-501-1.png" alt="Histogram of life expectancy in 2007." width="\textwidth" />
<p class="caption">
FIGURE 11.8: Histogram of life expectancy in 2007.
</p>
</div>
<p>We see that this data is <em>left-skewed</em>, also known as <em>negatively</em>  skewed: there are a few countries with low life expectancy that are bringing down the mean life expectancy. However, the median is less sensitive to the effects of such outliers; hence, the median is greater than the mean in this case.</p>
<p>Remember, however, that we want to compare life expectancies both between continents and within continents. In other words, our visualizations need to incorporate some notion of the variable <code>continent</code>. We can do this easily with a faceted histogram. Recall from Section <a href="2-viz.html#facets">2.5</a> that facets allow us to split a visualization by the different values of another variable. We display the resulting visualization by adding a  <code>facet_wrap(~ continent, nrow = 2)</code> layer.</p>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="11-regression.html#cb770-1"></a>gapminder2007 <span class="op">%&gt;%</span></span>
<span id="cb770-2"><a href="11-regression.html#cb770-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lifeExp)) <span class="op">+</span></span>
<span id="cb770-3"><a href="11-regression.html#cb770-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb770-4"><a href="11-regression.html#cb770-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Life expectancy&quot;</span>, </span>
<span id="cb770-5"><a href="11-regression.html#cb770-5"></a>       <span class="dt">y =</span> <span class="st">&quot;Number of countries&quot;</span>,</span>
<span id="cb770-6"><a href="11-regression.html#cb770-6"></a>       <span class="dt">title =</span> <span class="st">&quot;Histogram of distribution of worldwide life expectancies&quot;</span>) <span class="op">+</span></span>
<span id="cb770-7"><a href="11-regression.html#cb770-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>continent, <span class="dt">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-503"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-503-1.png" alt="Life expectancy in 2007." width="\textwidth" />
<p class="caption">
FIGURE 11.9: Life expectancy in 2007.
</p>
</div>
<p>Observe that unfortunately the distribution of African life expectancies is much lower than the other continents, while in Europe life expectancies tend to be higher and furthermore do not vary as much. On the other hand, both Asia and Africa have the most variation in life expectancies. There is the least variation in Oceania, but keep in mind that there are only two countries in Oceania: Australia and New Zealand.</p>
<p>Recall that an alternative method to visualize the distribution of a numerical variable split by a categorical variable is by using a side-by-side boxplot. We shall map the categorical variable <code>continent</code> to the <span class="math inline">\(x\)</span>-axis and the different life expectancies within each continent on the <span class="math inline">\(y\)</span>-axis.</p>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="11-regression.html#cb771-1"></a>gapminder2007 <span class="op">%&gt;%</span></span>
<span id="cb771-2"><a href="11-regression.html#cb771-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> continent, <span class="dt">y =</span> lifeExp)) <span class="op">+</span></span>
<span id="cb771-3"><a href="11-regression.html#cb771-3"></a><span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span></span>
<span id="cb771-4"><a href="11-regression.html#cb771-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Continent&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Life expectancy&quot;</span>,</span>
<span id="cb771-5"><a href="11-regression.html#cb771-5"></a>       <span class="dt">title =</span> <span class="st">&quot;Life expectancy by continent&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-504"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-504-1.png" alt="Life expectancy in 2007." width="\textwidth" />
<p class="caption">
FIGURE 11.10: Life expectancy in 2007.
</p>
</div>
<p>Some people prefer comparing the distributions of a numerical variable between different levels of a categorical variable using a boxplot instead of a faceted histogram. This is because we can make quick comparisons between the categorical variable’s levels with imaginary horizontal lines. For example, observe that we can quickly convince ourselves that Oceania has the highest median life expectancies by drawing an imaginary horizontal line at <span class="math inline">\(y\)</span> = 80. Furthermore, as we observed in the faceted histogram, Africa and Asia have the largest variation in life expectancy as evidenced by their large interquartile ranges (the heights of the boxes).</p>
<p>It’s important to remember, however, that the solid lines in the middle of the boxes correspond to the medians (the middle value) rather than the mean (the average). So, for example, if you look at Asia, the solid line denotes the median life expectancy of around 72 years. This tells us that half of all countries in Asia have a life expectancy below 72 years, whereas half have a life expectancy above 72 years.</p>
<p>Let’s compute the median and mean life expectancy for each continent with a little more data wrangling and display the results.</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="11-regression.html#cb772-1"></a>lifeExp_by_continent &lt;-<span class="st"> </span>gapminder2007 <span class="op">%&gt;%</span></span>
<span id="cb772-2"><a href="11-regression.html#cb772-2"></a><span class="st">  </span><span class="kw">group_by</span>(continent) <span class="op">%&gt;%</span></span>
<span id="cb772-3"><a href="11-regression.html#cb772-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median =</span> <span class="kw">median</span>(lifeExp), </span>
<span id="cb772-4"><a href="11-regression.html#cb772-4"></a>            <span class="dt">mean =</span> <span class="kw">mean</span>(lifeExp))</span></code></pre></div>
<table>
<caption>
<span id="tab:unnamed-chunk-506">TABLE 11.8: </span>Life expectancy by continent
</caption>
<thead>
<tr>
<th style="text-align:left;">
continent
</th>
<th style="text-align:right;">
median
</th>
<th style="text-align:right;">
mean
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
52.9
</td>
<td style="text-align:right;">
54.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Americas
</td>
<td style="text-align:right;">
72.9
</td>
<td style="text-align:right;">
73.6
</td>
</tr>
<tr>
<td style="text-align:left;">
Asia
</td>
<td style="text-align:right;">
72.4
</td>
<td style="text-align:right;">
70.7
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
78.6
</td>
<td style="text-align:right;">
77.6
</td>
</tr>
<tr>
<td style="text-align:left;">
Oceania
</td>
<td style="text-align:right;">
80.7
</td>
<td style="text-align:right;">
80.7
</td>
</tr>
</tbody>
</table>
<p>Observe the order of the second column <code>median</code> life expectancy: Africa is lowest, the Americas and Asia are next with similar medians, then Europe, then Oceania. This ordering corresponds to the ordering of the solid black lines inside the boxes in our side-by-side boxplot.</p>
<p>Let’s now turn our attention to the values in the third column <code>mean</code>. Using Africa’s mean life expectancy of 54.8 as a <em>baseline for comparison</em>, let’s start making comparisons to the mean life expectancies of the other four continents and put these values in a table, which we’ll revisit later on in this section.</p>
<ol style="list-style-type: decimal">
<li>For the Americas, it is 73.6 - 54.8 = 18.8 years higher.</li>
<li>For Asia, it is 70.7 - 54.8 = 15.9 years higher.</li>
<li>For Europe, it is 77.6 - 54.8 = 22.8 years higher.</li>
<li>For Oceania, it is 80.7 - 54.8 = 25.9 years higher.</li>
</ol>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-507">TABLE 11.9: </span>Mean life expectancy by continent and relative differences from mean for Africa
</caption>
<thead>
<tr>
<th style="text-align:left;">
continent
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
Difference versus Africa
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:left;">
Americas
</td>
<td style="text-align:right;">
73.6
</td>
<td style="text-align:right;">
18.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Asia
</td>
<td style="text-align:right;">
70.7
</td>
<td style="text-align:right;">
15.9
</td>
</tr>
<tr>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
77.6
</td>
<td style="text-align:right;">
22.8
</td>
</tr>
<tr>
<td style="text-align:left;">
Oceania
</td>
<td style="text-align:right;">
80.7
</td>
<td style="text-align:right;">
25.9
</td>
</tr>
</tbody>
</table>
</div>
<div id="model2table" class="section level3">
<h3><span class="header-section-number">11.3.2</span> Linear regression</h3>
<p>In Subsection <a href="11-regression.html#model1table">11.1.2</a> we introduced simple linear regression, which involves modeling the relationship between a numerical outcome variable <span class="math inline">\(y\)</span> and a numerical explanatory variable <span class="math inline">\(x\)</span>. In our life expectancy example, we now instead have a categorical explanatory variable <code>continent</code>. Our model will not yield a “best-fitting” regression line, but rather <em>offsets</em> relative to a baseline for comparison.</p>
<p>As we did in Subsection <a href="11-regression.html#model1table">11.1.2</a> when studying the relationship between teaching scores and “beauty” scores, let’s output the regression table for this model. Recall that this is done in two steps:</p>
<ol style="list-style-type: decimal">
<li>We first “fit” the linear regression model using the <code>lm(y ~ x, data)</code> function and save it in <code>lifeExp_model</code>.</li>
<li>We get the regression table by applying the <code>tidy()</code> function from the <strong>broom</strong> package to <code>lifeExp_model</code>. We’ll print the <code>term</code>, <code>estimate</code>, <code>conf.low</code>, and <code>conf.high</code> columns.</li>
</ol>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb773-1"><a href="11-regression.html#cb773-1"></a>lifeExp_model &lt;-<span class="st"> </span><span class="kw">lm</span>(lifeExp <span class="op">~</span><span class="st"> </span>continent, <span class="dt">data =</span> gapminder2007)</span>
<span id="cb773-2"><a href="11-regression.html#cb773-2"></a>lifeExp_model <span class="op">%&gt;%</span></span>
<span id="cb773-3"><a href="11-regression.html#cb773-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb773-4"><a href="11-regression.html#cb773-4"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:unnamed-chunk-510">TABLE 11.10: </span>Linear regression table
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
56.8
</td>
</tr>
<tr>
<td style="text-align:left;">
continentAmericas
</td>
<td style="text-align:right;">
18.8
</td>
<td style="text-align:right;">
15.2
</td>
<td style="text-align:right;">
22.4
</td>
</tr>
<tr>
<td style="text-align:left;">
continentAsia
</td>
<td style="text-align:right;">
15.9
</td>
<td style="text-align:right;">
12.7
</td>
<td style="text-align:right;">
19.2
</td>
</tr>
<tr>
<td style="text-align:left;">
continentEurope
</td>
<td style="text-align:right;">
22.8
</td>
<td style="text-align:right;">
19.5
</td>
<td style="text-align:right;">
26.2
</td>
</tr>
<tr>
<td style="text-align:left;">
continentOceania
</td>
<td style="text-align:right;">
25.9
</td>
<td style="text-align:right;">
15.4
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
</tbody>
</table>
<p>Why are there now 5 rows? Let’s break them down one-by-one:</p>
<ol style="list-style-type: decimal">
<li><code>intercept</code> corresponds to the mean life expectancy of countries in Africa of 54.8 years (from the <code>estimate</code> column).</li>
<li><code>continentAmericas</code> corresponds to countries in the Americas and the value +18.8 is the same difference in mean life expectancy relative to Africa we previously saw. In other words, the mean life expectancy of countries in the Americas is <span class="math inline">\(54.8 + 18.8 = 73.6\)</span>.</li>
<li><code>continentAsia</code> corresponds to countries in Asia and the value +15.9 is the same difference in mean life expectancy relative to Africa we previously saw. In other words, the mean life expectancy of countries in Asia is <span class="math inline">\(54.8 + 15.9 = 70.7\)</span>.</li>
<li><code>continentEurope</code> corresponds to countries in Europe and the value +22.8 is the same difference in mean life expectancy relative to Africa we previously saw. In other words, the mean life expectancy of countries in Europe is <span class="math inline">\(54.8 + 22.8 = 77.6\)</span>.</li>
<li><code>continentOceania</code> corresponds to countries in Oceania and the value +25.9 is the same difference in mean life expectancy relative to Africa we previously saw. In other words, the mean life expectancy of countries in Oceania is <span class="math inline">\(54.8 + 25.9 = 80.7\)</span>.</li>
</ol>
<p>To summarize, the 5 values in the <code>estimate</code> column correspond to the “baseline for comparison” continent Africa (the intercept) as well as four “offsets” from this baseline for the remaining 4 continents: the Americas, Asia, Europe, and Oceania.</p>
<p>You might be asking at this point why was Africa chosen as the “baseline for comparison” group. This is the case for no other reason than it comes first alphabetically of the five continents; by default R arranges factors/categorical variables in alphanumeric order. You can change this baseline group to be another continent if you manipulate the variable <code>continent</code>’s factor “levels” using the <strong>forcats</strong> package. See <a href="https://r4ds.had.co.nz/factors.html">Chapter 15</a> of <em>R for Data Science</em> <span class="citation">(Grolemund and Wickham <a href="#ref-rds2016" role="doc-biblioref">2017</a>)</span> for examples.</p>
<p>It is also important to take a look at the confidence intervals to get a sense of how uncertain our estimates are. Note that the confidence interval for the Oceania estimate is the widest. Why is that? There are only two countries in Oceania (Australia and New Zealand), and thus we have a great deal of uncertainty around these estimates. In contrast, there are 52 countries in Africa, and thus it has the narrowest confidence interval.</p>
<p>Let’s now write the equation for our fitted values <span class="math inline">\(\widehat{y} = \widehat{\text{life exp}}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{y} = \widehat{\text{life exp}} &amp;= b_0 + b_{\text{Amer}}\cdot\mathbb{1}_{\text{Amer}}(x) + b_{\text{Asia}}\cdot\mathbb{1}_{\text{Asia}}(x) + \\
&amp; \qquad b_{\text{Euro}}\cdot\mathbb{1}_{\text{Euro}}(x) + b_{\text{Ocean}}\cdot\mathbb{1}_{\text{Ocean}}(x)\\
&amp;= 54.8 + 18.8\cdot\mathbb{1}_{\text{Amer}}(x) + 15.9\cdot\mathbb{1}_{\text{Asia}}(x) + \\
&amp; \qquad 22.8\cdot\mathbb{1}_{\text{Euro}}(x) + 25.9\cdot\mathbb{1}_{\text{Ocean}}(x)
\end{aligned}
\]</span></p>
<p>Whoa! That looks daunting! Don’t fret, however, as once you understand what all the elements mean, things simplify greatly. First, <span class="math inline">\(\mathbb{1}_{A}(x)\)</span> is what’s known in mathematics as an “indicator function.” It returns only one of two possible values, 0 and 1, where</p>
<p><span class="math display">\[
\mathbb{1}_{A}(x) = \left\{
\begin{array}{ll}
1 &amp; \text{if } x \text{ is in } A \\
0 &amp; \text{if } \text{otherwise} \end{array}
\right.
\]</span></p>
<p>In a statistical modeling context, this is also known as a <em>dummy variable</em>.  In our case, let’s consider the first such indicator variable <span class="math inline">\(\mathbb{1}_{\text{Amer}}(x)\)</span>. This indicator function returns 1 if a country is in the Americas, 0 otherwise:</p>
<p><span class="math display">\[
\mathbb{1}_{\text{Amer}}(x) = \left\{
\begin{array}{ll}
1 &amp; \text{if } \text{country } x \text{ is in the Americas} \\
0 &amp; \text{otherwise}\end{array}
\right.
\]</span></p>
<p>Second, <span class="math inline">\(b_0\)</span> corresponds to the intercept as before; in this case, it’s the mean life expectancy of all countries in Africa. Third, the <span class="math inline">\(b_{\text{Amer}}\)</span>, <span class="math inline">\(b_{\text{Asia}}\)</span>, <span class="math inline">\(b_{\text{Euro}}\)</span>, and <span class="math inline">\(b_{\text{Ocean}}\)</span> represent the 4 “offsets relative to the baseline for comparison” in the regression table output: <code>continentAmericas</code>, <code>continentAsia</code>, <code>continentEurope</code>, and <code>continentOceania</code>.</p>
<p>Let’s put this all together and compute the fitted value <span class="math inline">\(\widehat{y} = \widehat{\text{life exp}}\)</span> for a country in Africa. Since the country is in Africa, all four indicator functions <span class="math inline">\(\mathbb{1}_{\text{Amer}}(x)\)</span>, <span class="math inline">\(\mathbb{1}_{\text{Asia}}(x)\)</span>, <span class="math inline">\(\mathbb{1}_{\text{Euro}}(x)\)</span>, and <span class="math inline">\(\mathbb{1}_{\text{Ocean}}(x)\)</span> will equal 0, and thus:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{life exp}} &amp;= b_0 + b_{\text{Amer}}\cdot\mathbb{1}_{\text{Amer}}(x) + b_{\text{Asia}}\cdot\mathbb{1}_{\text{Asia}}(x)
+ \\
&amp; \qquad b_{\text{Euro}}\cdot\mathbb{1}_{\text{Euro}}(x) + b_{\text{Ocean}}\cdot\mathbb{1}_{\text{Ocean}}(x)\\
&amp;= 54.8 + 18.8\cdot\mathbb{1}_{\text{Amer}}(x) + 15.9\cdot\mathbb{1}_{\text{Asia}}(x)
+ \\
&amp; \qquad 22.8\cdot\mathbb{1}_{\text{Euro}}(x) + 25.9\cdot\mathbb{1}_{\text{Ocean}}(x)\\
&amp;= 54.8 + 18.8\cdot 0 + 15.9\cdot 0 + 22.8\cdot 0 + 25.9\cdot 0\\
&amp;= 54.8
\end{aligned}
\]</span></p>
<p>In other words, all that’s left is the intercept <span class="math inline">\(b_0\)</span>, corresponding to the average life expectancy of African countries of 54.8 years. Next, say we are considering a country in the Americas. In this case, only the indicator function <span class="math inline">\(\mathbb{1}_{\text{Amer}}(x)\)</span> for the Americas will equal 1, while all the others will equal 0, and thus:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{life exp}} &amp;= 54.8 + 18.8\cdot\mathbb{1}_{\text{Amer}}(x) + 15.9\cdot\mathbb{1}_{\text{Asia}}(x)
+ 22.8\cdot\mathbb{1}_{\text{Euro}}(x) + \\
&amp; \qquad 25.9\cdot\mathbb{1}_{\text{Ocean}}(x)\\
&amp;= 54.8 + 18.8\cdot 1 + 15.9\cdot 0 + 22.8\cdot 0 + 25.9\cdot 0\\
&amp;= 54.8 + 18.8 \\
&amp; = 73.6
\end{aligned}
\]</span></p>
<p>which is the mean life expectancy for countries in the Americas of 73.6 years. Note the “offset from the baseline for comparison” is +18.8 years.</p>
<p>Let’s do one more. Say we are considering a country in Asia. In this case, only the indicator function <span class="math inline">\(\mathbb{1}_{\text{Asia}}(x)\)</span> for Asia will equal 1, while all the others will equal 0, and thus:</p>
<p><span class="math display">\[
\begin{aligned}
\widehat{\text{life exp}} &amp;= 54.8 + 18.8\cdot\mathbb{1}_{\text{Amer}}(x) + 15.9\cdot\mathbb{1}_{\text{Asia}}(x)
+ 22.8\cdot\mathbb{1}_{\text{Euro}}(x) + \\
&amp; \qquad 25.9\cdot\mathbb{1}_{\text{Ocean}}(x)\\
&amp;= 54.8 + 18.8\cdot 0 + 15.9\cdot 1 + 22.8\cdot 0 + 25.9\cdot 0\\
&amp;= 54.8 + 15.9 \\
&amp; = 70.7
\end{aligned}
\]</span></p>
<p>which is the mean life expectancy for Asian countries of 70.7 years. The “offset from the baseline for comparison” here is +15.9 years.</p>
<p>Let’s generalize this idea a bit. If we fit a linear regression model using a categorical explanatory variable <span class="math inline">\(x\)</span> that has <span class="math inline">\(k\)</span> possible categories, the regression table will return an intercept and <span class="math inline">\(k - 1\)</span> “offsets.” In our case, since there are <span class="math inline">\(k = 5\)</span> continents, the regression model returns an intercept corresponding to the baseline for comparison group of Africa and <span class="math inline">\(k - 1 = 4\)</span> offsets corresponding to the Americas, Asia, Europe, and Oceania.</p>
<!--Phew! That was a lot of work! -->
<p>Understanding a regression table output when you’re using a categorical explanatory variable is a topic those new to regression often struggle with. The only real remedy for these struggles is practice, practice, practice. However, once you equip yourselves with an understanding of how to create regression models using categorical explanatory variables, you’ll be able to incorporate many new variables into your models, given the large amount of the world’s data that is categorical. If you feel like you’re still struggling at this point, however, we suggest you closely compare the group means and the linear regression output and note how you can compute all the values from one table using the values in the other.</p>
<p>Can we interpret these coefficients causally, using the <a href="A-rubin-causal-model.html#rubin-causal-model">Rubin Causal Model</a>? Remember the phrase <em>no causation without manipulation</em>. If we interpreted the coefficient on Asia causally, we would be saying that a country being in Asia (rather than Africa) has a <em>causal effect</em> of 15.9 years on life expectancy: the potential outcome when “treatment” is Asia is 15.9 years higher than when “treatment” is Africa. But does this make sense? It’s hard to imagine manipulating the continent a country is in. Thus, it is hard to conceptualize these estimates as being the “causal effect” of being in one continent versus another. Instead, we should think of these estimates in terms of prediction. They attempt to answer the following question: given that we know a country’s continent, what’s our best guess of its average life expectancy?</p>
</div>
<div id="model2points" class="section level3">
<h3><span class="header-section-number">11.3.3</span> Observed/fitted values and residuals</h3>
<p>Recall in Subsection <a href="11-regression.html#model1points">11.2.2</a>, we defined the following three concepts:</p>
<ol style="list-style-type: decimal">
<li>Observed values <span class="math inline">\(y\)</span>, or the observed value of the outcome variable </li>
<li>Fitted values <span class="math inline">\(\widehat{y}\)</span>, or the value on the regression line for a given <span class="math inline">\(x\)</span> value</li>
<li>Residuals <span class="math inline">\(y - \widehat{y}\)</span>, or the error between the observed value and the fitted value</li>
</ol>
<p>We obtained these values and other values using the <code>augment()</code> function from the <strong>broom</strong> package. This time, however, let’s add an argument setting <code>ID = "country"</code>: this is telling the function to use the variable <code>country</code> in <code>gapminder2007</code> as an <em>identification variable</em> in the output. This will help contextualize our analysis by matching values to countries.</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="11-regression.html#cb774-1"></a>regression_points &lt;-<span class="st"> </span>lifeExp_model <span class="op">%&gt;%</span></span>
<span id="cb774-2"><a href="11-regression.html#cb774-2"></a><span class="st">  </span><span class="kw">augment</span>(<span class="dt">ID =</span> <span class="st">&quot;country&quot;</span>)</span>
<span id="cb774-3"><a href="11-regression.html#cb774-3"></a>regression_points</span></code></pre></div>
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:model2-residuals">TABLE 11.11: </span>Regression points (First 10 out of 142 countries)
</caption>
<thead>
<tr>
<th style="text-align:right;">
lifeExp
</th>
<th style="text-align:left;">
continent
</th>
<th style="text-align:right;">
.fitted
</th>
<th style="text-align:right;">
.se.fit
</th>
<th style="text-align:right;">
.resid
</th>
<th style="text-align:right;">
.hat
</th>
<th style="text-align:right;">
.sigma
</th>
<th style="text-align:right;">
.cooksd
</th>
<th style="text-align:right;">
.std.resid
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
43.8
</td>
<td style="text-align:left;">
Asia
</td>
<td style="text-align:right;">
70.7
</td>
<td style="text-align:right;">
1.29
</td>
<td style="text-align:right;">
-26.900
</td>
<td style="text-align:right;">
0.030
</td>
<td style="text-align:right;">
7.04
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
-3.694
</td>
</tr>
<tr>
<td style="text-align:right;">
76.4
</td>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
77.6
</td>
<td style="text-align:right;">
1.35
</td>
<td style="text-align:right;">
-1.226
</td>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
7.42
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
-0.169
</td>
</tr>
<tr>
<td style="text-align:right;">
72.3
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
1.02
</td>
<td style="text-align:right;">
17.495
</td>
<td style="text-align:right;">
0.019
</td>
<td style="text-align:right;">
7.27
</td>
<td style="text-align:right;">
0.022
</td>
<td style="text-align:right;">
2.389
</td>
</tr>
<tr>
<td style="text-align:right;">
42.7
</td>
<td style="text-align:left;">
Africa
</td>
<td style="text-align:right;">
54.8
</td>
<td style="text-align:right;">
1.02
</td>
<td style="text-align:right;">
-12.075
</td>
<td style="text-align:right;">
0.019
</td>
<td style="text-align:right;">
7.35
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-1.649
</td>
</tr>
<tr>
<td style="text-align:right;">
75.3
</td>
<td style="text-align:left;">
Americas
</td>
<td style="text-align:right;">
73.6
</td>
<td style="text-align:right;">
1.48
</td>
<td style="text-align:right;">
1.712
</td>
<td style="text-align:right;">
0.040
</td>
<td style="text-align:right;">
7.42
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.236
</td>
</tr>
<tr>
<td style="text-align:right;">
81.2
</td>
<td style="text-align:left;">
Oceania
</td>
<td style="text-align:right;">
80.7
</td>
<td style="text-align:right;">
5.23
</td>
<td style="text-align:right;">
0.515
</td>
<td style="text-align:right;">
0.500
</td>
<td style="text-align:right;">
7.42
</td>
<td style="text-align:right;">
0.002
</td>
<td style="text-align:right;">
0.099
</td>
</tr>
<tr>
<td style="text-align:right;">
79.8
</td>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
77.6
</td>
<td style="text-align:right;">
1.35
</td>
<td style="text-align:right;">
2.180
</td>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
7.42
</td>
<td style="text-align:right;">
0.001
</td>
<td style="text-align:right;">
0.300
</td>
</tr>
<tr>
<td style="text-align:right;">
75.6
</td>
<td style="text-align:left;">
Asia
</td>
<td style="text-align:right;">
70.7
</td>
<td style="text-align:right;">
1.29
</td>
<td style="text-align:right;">
4.907
</td>
<td style="text-align:right;">
0.030
</td>
<td style="text-align:right;">
7.41
</td>
<td style="text-align:right;">
0.003
</td>
<td style="text-align:right;">
0.674
</td>
</tr>
<tr>
<td style="text-align:right;">
64.1
</td>
<td style="text-align:left;">
Asia
</td>
<td style="text-align:right;">
70.7
</td>
<td style="text-align:right;">
1.29
</td>
<td style="text-align:right;">
-6.666
</td>
<td style="text-align:right;">
0.030
</td>
<td style="text-align:right;">
7.40
</td>
<td style="text-align:right;">
0.005
</td>
<td style="text-align:right;">
-0.916
</td>
</tr>
<tr>
<td style="text-align:right;">
79.4
</td>
<td style="text-align:left;">
Europe
</td>
<td style="text-align:right;">
77.6
</td>
<td style="text-align:right;">
1.35
</td>
<td style="text-align:right;">
1.792
</td>
<td style="text-align:right;">
0.033
</td>
<td style="text-align:right;">
7.42
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
0.247
</td>
</tr>
</tbody>
</table>
<p>Observe that <code>.fitted</code> contains the fitted values <span class="math inline">\(\widehat{y}\)</span> = <span class="math inline">\(\widehat{\text{lifeExp}}\)</span>. If you look closely, there are only 5 possible values for <code>.fitted</code>. These correspond to the five mean life expectancies for the 5 continents that we computed using the values in the <code>estimate</code> column of the regression table.</p>
<p>The <code>.resid</code> column is simply <span class="math inline">\(y - \widehat{y}\)</span> = <code>lifeExp - .fitted</code>. These values can be interpreted as the deviation of a country’s life expectancy from its continent’s average life expectancy. For example, look at the residual for Afghanistan. The residual of <span class="math inline">\(y - \widehat{y} = 43.8 - 70.7 = -26.9\)</span> is telling us that Afghanistan’s life expectancy is a whopping 26.9 years lower than the mean life expectancy of all Asian countries. This can in part be explained by the many years of war that country has suffered.</p>
</div>
</div>
<div id="case-study-2018-gubernatorial-forecasts" class="section level2">
<h2><span class="header-section-number">11.4</span> Case study: 2018 gubernatorial forecasts</h2>
<!-- AR: beginning of working with list columns -->
<p>Now that we know how to run simple linear regressions, let’s run many at once!</p>
<p>We’ll use the <code>governor_state_forecast</code> data from the <strong>fivethirtyeight</strong> package. This dataset has the day-by-day forecasts FiveThirtyEight published in the 2018 gubernatorial races from October 11 to November 6. Which Republican candidate saw his or her probability of winning increase the most during that time? We can get a sense of this by running a series of linear models, with the outcome variable being FiveThirtyEight’s predicted probability of the Republican candidate winning and the explanatory variable being the number of days since the forecast began.</p>
<p>Let’s first load the <code>governor_state_forecast</code> data and get it in the form we’ll need:</p>
<div class="sourceCode" id="cb775"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb775-1"><a href="11-regression.html#cb775-1"></a><span class="kw">library</span>(fivethirtyeight)</span>
<span id="cb775-2"><a href="11-regression.html#cb775-2"></a></span>
<span id="cb775-3"><a href="11-regression.html#cb775-3"></a>gov &lt;-<span class="st"> </span>governor_state_forecast <span class="op">%&gt;%</span></span>
<span id="cb775-4"><a href="11-regression.html#cb775-4"></a><span class="st">  </span><span class="kw">filter</span>(model <span class="op">==</span><span class="st"> &quot;classic&quot;</span>,</span>
<span id="cb775-5"><a href="11-regression.html#cb775-5"></a>         party <span class="op">==</span><span class="st"> &quot;R&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb775-6"><a href="11-regression.html#cb775-6"></a><span class="st">  </span><span class="kw">select</span>(forecastdate, state, candidate, party, win_probability) <span class="op">%&gt;%</span></span>
<span id="cb775-7"><a href="11-regression.html#cb775-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">days =</span> <span class="kw">as.numeric</span>(forecastdate) <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(<span class="kw">as.numeric</span>(forecastdate)),</span>
<span id="cb775-8"><a href="11-regression.html#cb775-8"></a>         <span class="dt">statecand =</span> <span class="kw">paste</span>(candidate, <span class="st">&quot; (&quot;</span>, state, <span class="st">&quot;)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))</span>
<span id="cb775-9"><a href="11-regression.html#cb775-9"></a></span>
<span id="cb775-10"><a href="11-regression.html#cb775-10"></a><span class="kw">glimpse</span>(gov)</span></code></pre></div>
<pre><code>Observations: 900
Variables: 7
$ forecastdate    &lt;date&gt; 2018-10-11, 2018-10-11, 2018-10-11, 2018-10-11, 2018…
$ state           &lt;fct&gt; AK, AL, AR, AZ, CA, CO, CT, FL, GA, HI, IA, ID, IL, K…
$ candidate       &lt;fct&gt; Mike Dunleavy, Kay Ivey, Asa Hutchinson, Doug Ducey, …
$ party           &lt;fct&gt; R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R,…
$ win_probability &lt;dbl&gt; 0.7413, 0.9866, 0.9990, 0.9549, 0.0206, 0.0927, 0.147…
$ days            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ statecand       &lt;chr&gt; &quot;Mike Dunleavy (AK)&quot;, &quot;Kay Ivey (AL)&quot;, &quot;Asa Hutchinso…</code></pre>
<p>We <code>filter</code>ed to Republicans as well as to <code>model == "classic"</code> because FiveThirtyEight presented three versions of their model and we want to limit our analysis to one. We also <code>mutate</code>d to create a variable <code>days</code> that is the number of days since the forecast began (October 11) and <code>statecand</code> which combines the name of the Republican candidate with the state abbreviation, which will be useful for plotting.</p>
<div id="fitting-multiple-models-using-map-1" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Fitting multiple models using <code>map()</code></h3>
<p>Next, we need to use <code>nest()</code> like we did when creating bootstrapped confidence intervals, except this time we are <code>nest</code>ing the data by <code>statecand</code>:</p>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="11-regression.html#cb777-1"></a>gov &lt;-<span class="st"> </span>gov <span class="op">%&gt;%</span></span>
<span id="cb777-2"><a href="11-regression.html#cb777-2"></a><span class="st">  </span><span class="kw">group_by</span>(statecand) <span class="op">%&gt;%</span></span>
<span id="cb777-3"><a href="11-regression.html#cb777-3"></a><span class="st">  </span><span class="kw">nest</span>()</span></code></pre></div>
<p>Now each observation in our dataset is a candidate and we have a list column <code>data</code> that consists of the rest of the data for each candidate. We can use <code>map_*</code> functions just as in the bootstrapping example to get the coefficient on <code>days</code> for each candidate:</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="11-regression.html#cb778-1"></a>gov &lt;-<span class="st"> </span>gov <span class="op">%&gt;%</span></span>
<span id="cb778-2"><a href="11-regression.html#cb778-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mod =</span> <span class="kw">map</span>(data, <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(win_probability <span class="op">~</span><span class="st"> </span>days, <span class="dt">data =</span> .)),</span>
<span id="cb778-3"><a href="11-regression.html#cb778-3"></a>         <span class="dt">reg_results =</span> <span class="kw">map</span>(mod, <span class="op">~</span><span class="st"> </span><span class="kw">tidy</span>(.)),</span>
<span id="cb778-4"><a href="11-regression.html#cb778-4"></a>         <span class="dt">disp_coef =</span> <span class="kw">map_dbl</span>(reg_results, <span class="op">~</span><span class="st"> </span><span class="kw">filter</span>(., term <span class="op">==</span><span class="st"> &quot;days&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(estimate)))</span>
<span id="cb778-5"><a href="11-regression.html#cb778-5"></a></span>
<span id="cb778-6"><a href="11-regression.html#cb778-6"></a><span class="kw">glimpse</span>(gov)</span></code></pre></div>
<pre><code>Observations: 36
Variables: 5
Groups: statecand [36]
$ statecand   &lt;chr&gt; &quot;Mike Dunleavy (AK)&quot;, &quot;Kay Ivey (AL)&quot;, &quot;Asa Hutchinson (A…
$ data        &lt;list&gt; [&lt;tbl_df[25 x 6]&gt;, &lt;tbl_df[25 x 6]&gt;, &lt;tbl_df[25 x 6]&gt;, &lt;…
$ mod         &lt;list&gt; [&lt;0.77631, -0.00535, -0.03501, 0.05805, 0.06060, 0.08066…
$ reg_results &lt;list&gt; [&lt;tbl_df[2 x 5]&gt;, &lt;tbl_df[2 x 5]&gt;, &lt;tbl_df[2 x 5]&gt;, &lt;tbl…
$ disp_coef   &lt;dbl&gt; -0.005353355, -0.000052529, -0.000000446, 0.001647172, -0…</code></pre>
<p>We now have the data to answer the question about which candidate saw his or her estimated probability go up the most. Let’s use the <code>slice()</code> function in the <strong>dplyr</strong> package to answer this. Note that because we have grouped data, we’ll have to <code>ungroup()</code> before we can <code>slice()</code>:</p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="11-regression.html#cb780-1"></a>gov_top5 &lt;-<span class="st"> </span>gov <span class="op">%&gt;%</span></span>
<span id="cb780-2"><a href="11-regression.html#cb780-2"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb780-3"><a href="11-regression.html#cb780-3"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(disp_coef)) <span class="op">%&gt;%</span></span>
<span id="cb780-4"><a href="11-regression.html#cb780-4"></a><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)</span>
<span id="cb780-5"><a href="11-regression.html#cb780-5"></a></span>
<span id="cb780-6"><a href="11-regression.html#cb780-6"></a>gov_top5 <span class="op">%&gt;%</span></span>
<span id="cb780-7"><a href="11-regression.html#cb780-7"></a><span class="st">  </span><span class="kw">select</span>(statecand, disp_coef)</span></code></pre></div>
<pre><code># A tibble: 5 x 2
  statecand             disp_coef
  &lt;chr&gt;                     &lt;dbl&gt;
1 Kim Reynolds (IA)    0.0100582 
2 Brian Kemp (GA)      0.00291355
3 Kevin Stitt (OK)     0.00277343
4 Bob Stefanowski (CT) 0.00277255
5 Knute Buehler (OR)   0.00262730</code></pre>
<p>We can show so much more, however, if we presented the results graphically. To do this, we’ll need to learn the companion function to <code>nest()</code>: <code>unnest()</code>. While <code>nest()</code> collapsed the data so that each observation was a <code>statecand</code>, <code>unnest(data)</code> will return the data to its original unit of analysis, with each row one day’s forecast for a particular candidate:</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="11-regression.html#cb782-1"></a>gov_top5 <span class="op">%&gt;%</span></span>
<span id="cb782-2"><a href="11-regression.html#cb782-2"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb782-3"><a href="11-regression.html#cb782-3"></a><span class="st">  </span><span class="kw">glimpse</span>()</span></code></pre></div>
<pre><code>Observations: 125
Variables: 10
$ statecand       &lt;chr&gt; &quot;Kim Reynolds (IA)&quot;, &quot;Kim Reynolds (IA)&quot;, &quot;Kim Reynol…
$ forecastdate    &lt;date&gt; 2018-10-11, 2018-10-12, 2018-10-13, 2018-10-16, 2018…
$ state           &lt;fct&gt; IA, IA, IA, IA, IA, IA, IA, IA, IA, IA, IA, IA, IA, I…
$ candidate       &lt;fct&gt; Kim Reynolds, Kim Reynolds, Kim Reynolds, Kim Reynold…
$ party           &lt;fct&gt; R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R, R,…
$ win_probability &lt;dbl&gt; 0.166, 0.163, 0.166, 0.153, 0.150, 0.154, 0.152, 0.14…
$ days            &lt;dbl&gt; 0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
$ mod             &lt;list&gt; [&lt;0.0740, 0.0101, 0.09235, 0.07889, 0.07203, 0.02836…
$ reg_results     &lt;list&gt; [&lt;tbl_df[2 x 5]&gt;, &lt;tbl_df[2 x 5]&gt;, &lt;tbl_df[2 x 5]&gt;, …
$ disp_coef       &lt;dbl&gt; 0.01006, 0.01006, 0.01006, 0.01006, 0.01006, 0.01006,…</code></pre>
<p>Note that <code>unnest</code>ing flattens out the <code>data</code> list column but keeps everything else we’ve created. With the data in this form, it’s easy to use <code>ggplot()</code> to create a scatterplot for each of the five candidates with the greatest <code>disp_coef</code>:</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="11-regression.html#cb784-1"></a>gov_top5 <span class="op">%&gt;%</span></span>
<span id="cb784-2"><a href="11-regression.html#cb784-2"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb784-3"><a href="11-regression.html#cb784-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> days, <span class="dt">y =</span> win_probability)) <span class="op">+</span></span>
<span id="cb784-4"><a href="11-regression.html#cb784-4"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb784-5"><a href="11-regression.html#cb784-5"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb784-6"><a href="11-regression.html#cb784-6"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>statecand) <span class="op">+</span></span>
<span id="cb784-7"><a href="11-regression.html#cb784-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Days since forecast began&quot;</span>,</span>
<span id="cb784-8"><a href="11-regression.html#cb784-8"></a>       <span class="dt">y =</span> <span class="st">&quot;FiveThirtyEight&#39;s win probability&quot;</span>,</span>
<span id="cb784-9"><a href="11-regression.html#cb784-9"></a>       <span class="dt">caption =</span> <span class="st">&quot;Data source: FiveThirtyEight&quot;</span>) <span class="op">+</span></span>
<span id="cb784-10"><a href="11-regression.html#cb784-10"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-517-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
<p>We could easily replicate this process if we wanted to find the five candidates who saw their fortunes decline the most:</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="11-regression.html#cb785-1"></a>gov <span class="op">%&gt;%</span></span>
<span id="cb785-2"><a href="11-regression.html#cb785-2"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb785-3"><a href="11-regression.html#cb785-3"></a><span class="st">  </span><span class="kw">arrange</span>(disp_coef) <span class="op">%&gt;%</span></span>
<span id="cb785-4"><a href="11-regression.html#cb785-4"></a><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="op">%&gt;%</span></span>
<span id="cb785-5"><a href="11-regression.html#cb785-5"></a><span class="st">  </span><span class="kw">unnest</span>(data) <span class="op">%&gt;%</span></span>
<span id="cb785-6"><a href="11-regression.html#cb785-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> days, <span class="dt">y =</span> win_probability)) <span class="op">+</span></span>
<span id="cb785-7"><a href="11-regression.html#cb785-7"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb785-8"><a href="11-regression.html#cb785-8"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb785-9"><a href="11-regression.html#cb785-9"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>statecand) <span class="op">+</span></span>
<span id="cb785-10"><a href="11-regression.html#cb785-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Days since forecast began&quot;</span>,</span>
<span id="cb785-11"><a href="11-regression.html#cb785-11"></a>       <span class="dt">y =</span> <span class="st">&quot;FiveThirtyEight&#39;s win probability&quot;</span>,</span>
<span id="cb785-12"><a href="11-regression.html#cb785-12"></a>       <span class="dt">caption =</span> <span class="st">&quot;Data source: FiveThirtyEight&quot;</span>) <span class="op">+</span></span>
<span id="cb785-13"><a href="11-regression.html#cb785-13"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-518-1.png" width="\textwidth" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="leastsquares" class="section level2">
<h2><span class="header-section-number">11.5</span> Appendix: Best-fitting line</h2>
<p>Regression lines are also known as “best-fitting” lines. But what do we mean by “best”? Let’s unpack the criteria that is used in regression to determine “best.” Recall the plot where for an instructor with a beauty score of <span class="math inline">\(x = 7.333\)</span> we mark the <em>observed value</em> <span class="math inline">\(y\)</span> with a circle, the <em>fitted value</em> <span class="math inline">\(\widehat{y}\)</span> with a square, and the <em>residual</em> <span class="math inline">\(y - \widehat{y}\)</span> with an arrow. We re-display that plot in the top-left plot of the next figure in addition to three more arbitrarily chosen course instructors:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-519"></span>
<img src="Preceptor%E2%80%99s-Primer-for-Bayesian-Data-Science_files/figure-html/unnamed-chunk-519-1.png" alt="Example of observed value, fitted value, and residual." width="\textwidth" />
<p class="caption">
FIGURE 11.11: Example of observed value, fitted value, and residual.
</p>
</div>
<p>The three other plots refer to:</p>
<ol style="list-style-type: decimal">
<li>A course whose instructor had a “beauty” score <span class="math inline">\(x\)</span> = 2.333 and teaching score <span class="math inline">\(y\)</span> = 2.7. The residual in this case is <span class="math inline">\(2.7 - 4.036 = -1.336\)</span>, which we mark with a new blue arrow in the top-right plot.</li>
<li>A course whose instructor had a “beauty” score <span class="math inline">\(x = 3.667\)</span> and teaching score <span class="math inline">\(y = 4.4\)</span>. The residual in this case is <span class="math inline">\(4.4 - 4.125 = 0.2753\)</span>, which we mark with a new blue arrow in the bottom-left plot.</li>
<li>A course whose instructor had a “beauty” score <span class="math inline">\(x = 6\)</span> and teaching score <span class="math inline">\(y = 3.8\)</span>. The residual in this case is <span class="math inline">\(3.8 - 4.28 = -0.4802\)</span>, which we mark with a new blue arrow in the bottom-right plot.</li>
</ol>
<p>Now say we repeated this process of computing residuals for all 463 courses’ instructors, then we squared all the residuals, and then we summed them. We call this quantity the <em>sum of squared residuals</em>; it is a measure of the <em>lack of fit</em> of a model. Larger values of the sum of squared residuals indicate a bigger lack of fit. This corresponds to a worse fitting model.</p>
<p>If the regression line fits all the points perfectly, then the sum of squared residuals is 0. This is because if the regression line fits all the points perfectly, then the fitted value <span class="math inline">\(\widehat{y}\)</span> equals the observed value <span class="math inline">\(y\)</span> in all cases, and hence the residual <span class="math inline">\(y-\widehat{y}\)</span> = 0 in all cases, and the sum of even a large number of 0’s is still 0.</p>
<p>Furthermore, of all possible lines we can draw through the cloud of 463 points, the regression line minimizes this value. In other words, the regression and its corresponding fitted values <span class="math inline">\(\widehat{y}\)</span> minimizes the sum of the squared residuals:</p>
<p><span class="math display">\[
\sum_{i=1}^{n}(y_i - \widehat{y}_i)^2
\]</span></p>
<p>Let’s use our data wrangling tools from Chapter <a href="4-wrangling.html#wrangling">4</a> to compute the sum of squared residuals exactly:</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="11-regression.html#cb786-1"></a><span class="co"># Fit regression model:</span></span>
<span id="cb786-2"><a href="11-regression.html#cb786-2"></a></span>
<span id="cb786-3"><a href="11-regression.html#cb786-3"></a>score_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>bty_avg, </span>
<span id="cb786-4"><a href="11-regression.html#cb786-4"></a>                  <span class="dt">data =</span> evals_ch11)</span>
<span id="cb786-5"><a href="11-regression.html#cb786-5"></a></span>
<span id="cb786-6"><a href="11-regression.html#cb786-6"></a><span class="co"># Get regression points:</span></span>
<span id="cb786-7"><a href="11-regression.html#cb786-7"></a></span>
<span id="cb786-8"><a href="11-regression.html#cb786-8"></a>regression_points &lt;-<span class="st"> </span>score_model <span class="op">%&gt;%</span></span>
<span id="cb786-9"><a href="11-regression.html#cb786-9"></a><span class="st">  </span><span class="kw">augment</span>()</span>
<span id="cb786-10"><a href="11-regression.html#cb786-10"></a>regression_points</span></code></pre></div>
<pre><code># A tibble: 463 x 9
   score bty_avg .fitted   .se.fit      .resid       .hat   .sigma    .cooksd
   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;
 1 4.7   5       4.21352 0.0266038  0.486477   0.00247427 0.534934 1.02862e-3
 2 4.100 5       4.21352 0.0266038 -0.113523   0.00247427 0.535390 5.60142e-5
 3 3.9   5       4.21352 0.0266038 -0.313523   0.00247427 0.535216 4.27236e-4
 4 4.8   5       4.21352 0.0266038  0.586477   0.00247427 0.534716 1.49496e-3
 5 4.600 3       4.08025 0.0339315  0.519751   0.00402501 0.534865 1.91598e-3
 6 4.3   3       4.08025 0.0339315  0.219751   0.00402501 0.535318 3.42501e-4
 7 2.8   3       4.08025 0.0339315 -1.28025    0.00402501 0.532065 1.16249e-2
 8 4.100 3.333   4.10244 0.0304986 -0.00243920 0.00325177 0.535416 3.40387e-8
 9 3.4   3.333   4.10244 0.0304986 -0.702439   0.00325177 0.534410 2.82290e-3
10 4.5   3.16700 4.09138 0.0321413  0.408623   0.00361151 0.535076 1.06171e-3
# … with 453 more rows, and 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="11-regression.html#cb788-1"></a><span class="co"># Compute sum of squared residuals</span></span>
<span id="cb788-2"><a href="11-regression.html#cb788-2"></a></span>
<span id="cb788-3"><a href="11-regression.html#cb788-3"></a>regression_points <span class="op">%&gt;%</span></span>
<span id="cb788-4"><a href="11-regression.html#cb788-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">squared_residuals =</span> .resid<span class="op">^</span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb788-5"><a href="11-regression.html#cb788-5"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sum_of_squared_residuals =</span> <span class="kw">sum</span>(squared_residuals))</span></code></pre></div>
<pre><code># A tibble: 1 x 1
  sum_of_squared_residuals
                     &lt;dbl&gt;
1                  131.868</code></pre>
<p>Any other straight line drawn in the figure would yield a sum of squared residuals greater than 132. This is a mathematically guaranteed fact that you can prove using calculus and linear algebra. That’s why alternative names for the linear regression line are the <em>best-fitting line</em> and the <em>least-squares line</em>. Why do we square the residuals (i.e., the arrow lengths)? So that both positive and negative deviations of the same amount are treated equally.</p>
</div>
<div id="conclusion-4" class="section level2">
<h2><span class="header-section-number">11.6</span> Conclusion</h2>
<div id="additional-resources-basic-regression" class="section level3">
<h3><span class="header-section-number">11.6.1</span> Additional resources</h3>
<p>As we suggested in Subsection <a href="11-regression.html#model1EDA">11.1.1</a>, interpreting coefficients that are not close to the extreme values of -1, 0, and 1 can be somewhat subjective. To help develop your sense of correlation coefficients, we suggest you play the 80s-style video game called, “Guess the Correlation”, at <a href="http://guessthecorrelation.com/" class="uri">http://guessthecorrelation.com/</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-521"></span>
<img src="images/copyright/guess_the_correlation.png" alt="Preview of “Guess the Correlation” game." width="70%" />
<p class="caption">
FIGURE 11.12: Preview of “Guess the Correlation” game.
</p>
</div>
</div>
<div id="whats-to-come-1" class="section level3">
<h3><span class="header-section-number">11.6.2</span> What’s to come?</h3>
<p>In this chapter, you’ve studied the term <em>basic regression</em>, where you fit models that only have one explanatory variable. In Chapter <a href="12-multiple-regression.html#multiple-regression">12</a>, we’ll study <em>multiple regression</em>, where our regression models can now have more than one explanatory variable! In particular, we’ll consider two scenarios: regression models with one numerical and one categorical explanatory variable and regression models with two numerical explanatory variables. This will allow you to construct more sophisticated and more powerful models, all in the hopes of better explaining your outcome variable <span class="math inline">\(y\)</span>.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-rds2016">
<p>Grolemund, Garrett, and Hadley Wickham. 2017. <em>R for Data Science</em>. First. Sebastopol, CA: O’Reilly Media. <a href="https://r4ds.had.co.nz/">https://r4ds.had.co.nz/</a>.</p>
</div>
<div id="ref-islr2017">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2017. <em>An Introduction to Statistical Learning: With Applications in R</em>. First. New York, NY: Springer.</p>
</div>
<div id="ref-R-broom">
<p>Robinson, David, and Alex Hayes. 2020. <em>Broom: Convert Statistical Analysis Objects into Tidy Tibbles</em>. <a href="https://CRAN.R-project.org/package=broom">https://CRAN.R-project.org/package=broom</a>.</p>
</div>
<div id="ref-R-skimr">
<p>Waring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, and Shannon Ellis. 2019. <em>Skimr: Compact and Flexible Summaries of Data</em>. <a href="https://CRAN.R-project.org/package=skimr">https://CRAN.R-project.org/package=skimr</a>.</p>
</div>
<div id="ref-R-tidyverse">
<p>Wickham, Hadley. 2019b. <em>Tidyverse: Easily Install and Load the ’Tidyverse’</em>. <a href="https://CRAN.R-project.org/package=tidyverse">https://CRAN.R-project.org/package=tidyverse</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="10-confidence-intervals.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="12-multiple-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
