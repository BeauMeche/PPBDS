# Next meeting.


# Weekly Priorities

April 13: Second pass on Chapter 14

Remove the tune package from chap 13.

Add binary example at end, from CCES.

Add a conclusion with one or two paragraph discussion about how we make decisions.

"In this chapter, as in the Primer as a whole, we have been making models to better understand the world. But we need to act, as well as to understand."

Add material to RCM appendix. See below for some discussion. How do we fill in the question marks? One answer: Take the mean of the column. Consider the control group. You have their blood pressure. If I find a new person, whose blood pressure you don't know, what would you guess? The mean, obviously. Fill those in. Now you can estimate the causal effect for each person, and the average causal effect. Cool!

Is that a good model? No! It sucks, because you have information for each person you are not using: their blood pressure under the other outcome. How to use it? Make a new model in which there is a single parameter, tau, which is the constant treatment effect for everyone. Estimate that. Fill in the ?. But what about uncertainty? How sure are you are the ?'s you have filled in? Two sources: model uncertainty, which goes away with big N, and individual variation which does not. Fill in the ? with those confidence intervals, the second much wider than the first.


April 20: RCM

What is the next set of stuff worth covering after students understand the Rubin Causal Model? Key issue is that every problem can be framed in terms of potential outcomes, always with some things we can observe and some things we can't.

* With the Enos train example, we want to make claims about the true average effect of treatment, not just for the 115 people in the experiment, but for the 100,000 people who could have been in the experiment. They are units also! But they are units for which we don't observe the outcome for either treatment or control.

* One framing might be, when confronted with a new problem, first make your standard Rubin Table, with the question marks. Then, the purpose of a statistical model is to fill in those question marks. For the simplest case, we fill in the outcome under control (for those who received the treatment) as the average outcome for all control cases. Doing this explicitly is useful!

* These tables provide great framing for assumptions like taking a random sample from the population and homogenous treatment effects.

* We need to take slow steps from the basic Rubin Table --- I just coined that phrase --- to more complex versions. For example, we need a table that starts from treatment/control and then points out that there are many causal effects which one might measure, starting from just that case. Not just the difference, but also the ratio, the percentage change and so on. That may seem trivial but it helps the next step.

  Next step is three potential outcomes, like control versus 2 possible treatments. There are 3, obvious, causal effects we might want in that case. Spell them out clearly, even in the case in which we are just looking at simple differences.
  
  Next step is are a limited set numeric treatments, like taking one pill, two pills, ... up to 5 pills. This looks at lot like 3 categorial treatments, but it is different since the treatments have a numeric relationship with each other.
  
* If looking at more than one treatment is one direction in which to to take slow steps from the basic Rubin Table, another direction is how you fill in the question marks, but starting with just the treatment/control. Start case is that you can't fill them in. You can never know! Next step is that, even if you could know, everyone is different, so every causal effect is different. But not much you can do with that easier. So, we start making assumptions. And "assumption" means a "model," and all models have parameters. 

  One model might be that the causal effect is the same for everyone. There is a single parameter t which we then estimate. Once we have an estimate, we can fill in the Rubin Table because, knowing t, we know what the unseen potential outcome is for each person. 
  
  One model might be that the potential outcomes are the same for everyone for treatment and control. (Plus some random noise, since they obviously differ?) In that case, we can fill in the ? with the average numbers for each column.
  
  One model might be that the causal effect is the same within categories. That is, it is t_1 for men and t_2 for women. 

* Point of these last two is to extend the Rubin Table until it is flexible enough to use in the context of regression. More complex statistical models, like regression, just provide a different way of imputing the values of those question marks. And we should show this clearly.

* Need to add uncertainty into the mix, both the uncertainty in estimating t and the uncertainty in predicting the ? for specific individuals.

* Maybe there are three parts to the RCM Appenix. The first part is what we have now, with goes along with part 1 of the course. The second part is all about replacing the question marks with mean values. And also estimating uncertainty in that imputation. The third part, as above, using a more complex model to imput the question marks.

All done!

## Albert Advice

The world confronts us. We must make decisions. For that, we need models. 

WHAT IS THE ESTIMAND? That is a question which belongs center stage.

(All of which reminds me that it might be a good idea to go back to multivariate regression and show other approaches to the problem of modeling a continuous variable, at least in passing. Or maybe we need a chapter called "Prediction" after Classificantion and before Machine Learning. Or maybe the Machine Learning chapter begins with a section on prediction, both in-sample and out-of-sample.)

## Other Topics

I am not even sure what those topics are. Perhaps all the ways we deal with observational data. What sorts of material do other intro books cover? Here are some relevant concepts:

unit/item nonresponse
ignorability
treat potential outcomes as fixed (can we do this with regression?)
missing data
regresssion towards the mean
prediction/classification
map/network/text
natural experiments
Conditional random assignment
Difference in differences
Regression discontinuity

other key themes: like causal inference versus prediction. Indeed, the entire book needs to be infused with discussions of this issue. Spend a week on that?




# Summer People

Miro Bergram

Kayla Manning, Cameron Reaves, Yao Yu, 


# Bok Center Write Up

Visualizing Data Science

There are a dozen or more data science courses at Harvard, scattered across our schools and departments. All seeek to draw meaning from data. My project, "Visualizing Data Science," seeks to build a collection of open-source vignettes, each explaining a different aspect of data science in a pedagogically sophisticated way, almost always via the use of visualizations. My textbook, Preceptor's Primer for Bayesian Data Science, is an basic example of what is possible. See, for example, the appendices devoted to mapping and animation.  Working with students from the Bok Center, I hope to create dozens of these lessons, each freely available for use in other Harvad classes and around the world.


David Kane is the Precetor in Statistical Methods and Mathemtics in the Department of Government. His courses, Gov 1005: Data and Gov 1006: Models, are two of the highest-rated lecture courses at the College.


# Potential Projects

Combine Bayes and Probability chapters. There is only enough material here form one chapter. I don't like the mash up of two chapters, from two different original sources. Two approaches: interweave the Bayesian stuff into the probability chapter or the reverse. I like the reverse. The Bayes chapter is nice. It just needs more probability placed into it. Indeed, on some dimensions the probability chapter is overkill, even after I deleted some stuff. Chapter is still called Probability but it becomes an appendix, I think. Should have all political sciency examples.

Maybe this one chapter uses decision trees as its central organizing metaphor. *Bayes Theorem: A Visual Introduction for Beginners* does a nice job of teaching Bayesian inference with decision trees. Works really well! And easy (?) to simulate. Maybe we do that? Fits naturally (?) into list-columns and map functions. A natural (?) way to teach/show unconditional, conditional and marginal probability. Leafs on the tree are the possible outcomes.

Meld the material on functions and purrr into the concepts in the Probability/Bayes Chapters. We are not changing, I think, many of the words in these chapters, most of which are quite good. Instead, we are using these topics as an excuse to provide more lessons in functions/purrr. Also, edit Bayes chapter to make sense after probability chapter. Consider adding in intuition from Bayes for Beginner Book, especially decision trees, which map nicely to our simulation approach. 

Brief appendix about Tufte and other graphics luminaries?

Brief appendix about Leamer?

Appendix on permutation tests using Lady Tasting Tea

Use tidybayes package for better graphics throughout?

When discussing map/network/text data, make sure to link to these blog posts and provide a paragraph of discussion. Maybe turn each into a brief appendix?

Paul Revere [social network](https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/) 

Federalist Papers [authorship](https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/)



=================

# Things for Me

Add discussion of allowed variable names, the use of ``, and janitor::clean_names() early in the book. skimr() also. This is needed as background before we use tidy::broom() and similar functions.

Only use high quality packages, and recommend the same to readers.

12 chapters only. Productivity goes to an Appendix; Bayes/Probability combined.

Fix sampling/CI chapters to discuss hypothesis tests and why we hate them. Should do this in every chapter through the core of the book.

# Random Notes and Questions

Looks like we can use sections from R4DS as long as we use the entire section, unchanged.

https://r4ds.had.co.nz/index.html
https://creativecommons.org/faq/#can-i-reuse-an-excerpt-of-a-larger-work-that-is-licensed-with-the-noderivs-restriction

How do references work in MD chapters?

I like the PDF version of Rafa's book available from Lean Pub. How hard is that to make?

Replace DS Unix stuff with unix stuff from UNIX workbench? Perhaps we introduce the **fs** package at the same time, showing how you can accomplish similar things from the terminal and the R console.

We should not need library(moderndive) at all. (But need to check on any data used from there.)

Make our own PPBDS package, just to hold our datasets?

Get rid of use of infer library. Do all this the hard way, via the bootstrap and specific calculation of the test statistic.

Lots of pandoc-citeproc errors.

Replace all uses of kable with gt?

Fix "No additional resources" in Chapter 6 and 7. Standardize this section across all chapters. 545 is different.

Requires internet when using read_mnist() in some DS chapters. Annoying! Fix by including copy of mnist? By getting rid of these sections?

Why isn't preview_chapter() working with MD chapters? Why can't I simply knit one of the MD chapters? Gives weird error message about "Error in files2[[format]] : 
  attempt to select less than one element in get1index"
  

Links in STAT 545 not working despite addition of links.md file. How fix?


Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY


Or should each of these be separate chapters so that we might mix and match things? Maybe we need 100+ chapters, each of which do simple things, largely unconnected to each other, or with explicit prerequisites. Maybe call these "sections" or "vignettes" or "lessons". Maybe each comes with a little video? And a learnr tutorial? Then, our chapters could be combinations of them? 

Too early to start thinking about two versions: 1005 and 1006, with 1006 as extra advanced sections in each chapter? Or maybe just astericked chapters for advanced material, not required for 1005.

Add 545 and DS data download code to chapter 5?



========= Large Projects

## R Packages

Square away R packages. There should be one location with all the requirements. Here is a listing of the R packages used my MD, from their index.Rmd:

CRAN packages needed: "nycflights13", "ggplot2movies", "fivethirtyeight", "gapminder", "ISLR",tidyverse", "rmarkdown", "knitr", "janitor", "skimr","infer", "moderndive", "webshot", "mvtnorm", "remotes", "devtools", "dygraphs", "gridExtra", "kableExtra", "scales", "viridis", "ggrepel", "patchwork",

But what good is this, given that other packages are loaded elsewhere? Is there some standard way of handling this, perhaps with a DESCRIPTION file? Main annoyance is that new contributors have to try to compile the book a dozen times before it will work.

==
## Set Up Script

Consider the use of before_chapter_script: "_common.R" in the DS _bookdown.yml as well as the associated _common.R file. Is this an approach we should copy? The lack of this why I can't get all the DS chapters to work.

Broadening Your Statistical Horizons is a very cleanly put together book. We should make our book look like that. Also HOML (https://bradleyboehmke.github.io/HOML/) is very cleanly and simply constructed. Use that as a base structure?

Combine _common.R, common.R and index.Rmd information into one place. Need to figure out how this works in bookdown. I think we need one file which only runs once when you make the book. That files does a bunch of stuff involving copying over files. But you don't maintain state after running that file, so any new functions are lost. Then you have a second file, like _common.R, which is run at the start of compiling each chapter.

==
## Bibiography

Deal with bibliography. Our source books use very different approaches.

I like the way that MD writes out new versions of citations associated with R packages that have been updated.

Note that logistic regression chapter has a bunch of entries we need from BYSH.

==
## References and Footnotes

The book has lots of references, especially to other chapters. Many of these don't work because the referred-to chapters don't exist. We need a thorough clean up.

Some chapters, like 03-productivity.Rmd have a lot of footnotes. Good or bad?

Seems like all chapters generate references at the end. That is fine, but it should be standardized. Or do all those references belong at the end.

==
## Specific Chapters

04-wrangling is a mess, especially in the way that the join material from MD and from 545 do not go well together. Should some of it be moved to 05?

Need to introduce lists early, But when?

========= Thoughts

Revisit the Prediction Game. Love this:

“The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at 10 he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred.”

— Immanuel Kant, Critique of Pure Reason



````markdown
`r ''````{r}
plot(cars)
```
````

Key concepts which need to be put everywhere:

decisions need models
potential outcomes and causal effects
units, treatments, outcomes
randomization is magic: assignment to estimate causal effects, bootstrap to estimate uncertainty

Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

Bias/Variance == Underfitting/Overfitting

No Tests! Null hypthosis testing is a mistake. There is only the data, the models and the summaries therefrom.

heterogenous treatment effects; interaction terms

(See [modelDown](https://github.com/MI2DataLab/modelDown).) *[Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression/)* provides several examples of how to create, and document your creation of, such a model, e.g., section 13.5 (gun control) and section X (wells in Bangladesh).


# Standards

Follow MD as much as possible.

* R terms and objects (anything you might type in the console) in backticks.

* Functions names always include ().

* Package names are **bolded**.

# Summer

## Themes to confirm over the summer

Chapters from sampling through machine learning should be parallel. To the greatest extent possible, they all do all these things.

Show the results of each step. Show what each column (mod, data, etc) looks like as it is added to the tibble.

Everything is Bayesian. The confidence interval for a regression means that there is a 95% chance that the true value lies within that interval. Use Rubin Causal Model and potentional outcomes to define precisely what "true value" you are talking about. And so on. We use the bootstrap to show that lm() produces the same answers, and then just use lm() because it is quicker.

Discuss RCM, assuming that we are estimating a causal effect of some type. And, if we are not estimating causal effects (i.e., all we care about is prediction), then the mechanics of lm are the same, but the interpretation of the regression coefficient has no causal implications.  We want a series of tables illustrating potential outcomes and our estmation of them. Start with a table with ?, just as in the Appendix. We use linear regression to fill in these questions marks. Show table with question marks and then show table with question marks filled in with best guess. Then show table with question marks filled in with a confidence interval for the mean and then for a distribution of predicted values. The closer we can tie RCM to the different parts of a regression, the better. But do this each chapter, not just regression.

Avoid discussion about hypothesis tests, except to dismiss them. But maybe we discuss and then dismiss them each chapter. Motto: No tests! There is only the data, and models we create from the data, and the decisions we make with those models. But we still need to explain what hypothesis tests are, and why we don't care about them. Explain what a test is, and why we think it is a waste of time to do them, and why people do them anyway. Key issue: If p = 0.04 really makes you do something totally different than p = 0.06, then either you (or the system within which you are operating) is stupid.

Each chapter should finish with a new section which uses list-columns plus broom to estimate scores of models, and then pull out interesting models. See the gapminder examples from https://r4ds.had.co.nz/many-models.html#gapminder. We need the full tool set: nest, unnest and so on.


## Other summer issues

Should we move the whole thing to Netifly and use Github Actions to deploy? https://www.hvitfeldt.me/blog/bookdown-netlify-github-actions/

Should make Productivity chapter more connected to the lectures on Days 3 and 4. Cut material which is not directly relevant. Introduce the material in the same way that I introduce it in class. Someone who reads the chapter should find the lecture a simple repeat of what they have already seen.


Add more fancy plotting details to chapter 2. Key is to include all the necessary steps toward making the 538 plot. Discussion of the key parts of a graphic, especially title, subtitle and sources. themes(), starting with theme_minimal() but going on to cool stuff like fivethirtyeight and TV themes. ggtext. axis ajustments. Links to relevant readings in Healy. Also add a section on how to put a graphic in Rpubs. And also saving graphics.

Use almost every single one of these illustrations: https://github.com/allisonhorst/stats-illustrations

Consider this: https://github.com/tinystats/teacups-giraffes-and-statistics

Lists show up in Chapter 4 without any previous discussion. We need a short intro to the major variable types before this. Also put characters ahead of factors. 

Does chapter 4 belong ahead of chapter 3? 

Should Productivity come right after Chapter 1? Should Chapter 1 have more fun stuff in it? That is, you make a fun plot or two at the end of Chapter 1, so you are motivated to get set up correctly, then you do the hard work of doing so in the Productivity chapter. Then the real work begins.

Chapter 2 should have faceting and other graphics fun.

https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.


https://committedtotape.shinyapps.io/freeR/

Clean up and organize images/ directory.

What is our plan for loading libraries and removing them when they are no longer need? Chapter 11 contained an annoying bug: rvest and purrr both have pluck() as a function. Need to ensure that you get the purrr version if you need it. Bug only showed up when Chapter 5 (with rvest loaded) was used in the build.


ifelse (and other similar commands?) belongs earlier in the book, like when we first use mutate(). What else might be introduced with the initial usages of mutate?

Figure out links in Chapter 4 and elsewhere . . .

Replace all photos of activities with photos from Harvard, using Tsai.

When are different packages introduced? Where is this written down? Need to be intentional about what we introduced outside of the tidyverse --- janitor, ggthemes, reprex, fs, skimr, gt, googlesheets4, infer, gtsummary --- and when we do it.

Probabity/Bayes chapter should discuss null model, testing and p-values. This would allow us to add a (simple!) list-column, map function example at the end, very similar to the one we use in class. 

Revisit the list-column and map function portion of chapter 6. It is too hard and goes too fast.

## Reorganize

Would to have a book in which there is one chapter per week. Leads to a nice rythm. Could also have appendices which could be assigned when and as-if needed.

That would mean that anything which other chapters assume has been done must be in an earlier chapter, not an appendix. (or maybe not.) Good example of this is RCM, which later chapters definitely assume. Then again, I like having appendices that are short and self-contained, like mapping. Maybe we need more appendices! Maybe a better framework is that appedices have information that either a) a prof might reasonably decide not to assign or b) often contain material that students already know.

Perhaps Productivity belongs as an appendix, not least because so much is irrelevant (like Windows tips for Mac users). Also, it could be made much shorter, with pointers to good info, like Happy Git for the UseR. 

Getting Started and Visualization could be the first chapter, due for week 2.

Wrangling and Tidy could be the second chapter, due for week 3, with RCM appedix.

Week 4 has appendices maps, probabilty and Bayes. Easier week because of them exam.

Functions could be week 5 to 10 could be Sampling through Machine Learning. This 6 week sequence seems very solid to me. Only trick part is when to start it. Maybe begin it in week 6, so that it ends in week 11, leaving week 12 for demo day. That would give us an extra week before week 6 to re-allocate.

## Other Stuff

Albert points out a difficulty in combining the RCM with regression. You can't easily put in a distribution for the unknown potential outcome, even if you have a good regression model. You can't just add to the observed outcome because . . . actually I am confused about this!

There should be on causal and one non-causal example in each chapter. This is most obviously not-done in the multivariate chapter, where there are three clearly non-causal chapters. Perhaps use trains throughout? Create a logistic regression example in which the dependent variable is moved X units more conservative, or did not.

Maybe the functions chapter should introduce map functions independent of list-columns. For example, if you want to simulate dice throws in a tibble, you need (?) map function to enure that you get a different value for each row.

This textbook looks interesting, and the guy has some cool graphics, but I don't think he is open sourcing it: http://nickchk.com/chapter5.pdf

googlesheet4 examples. Perhaps there is an Appendix with cool packages and a brief introduction?

## Sampling Chapter

Need to incorporate some notion of betting. The over/under line for percentage of red balls in the bowl. Can you show (maybe a problem set?) that the mean is the best place to put the over/under line? Play the prediction game. 

Can we incorporate some notion of uncertainty, even before we see the bootstrap in the next chapter? And, along with that notion of uncertainty, discuss a Bayesian interpretation.

Without what range would you offer 50/50 odds that the true percentage lies?

Perhaps the Confidence Intervals chapter should be called Uncertainty.

Standard number formating. 2400 or 2,400 or $2400$ or . . . .

## Every Chapter from Sampling Forward

Begin with a decision. What real world problem are you trying to solve? What are the costs and benefits of different approaches? What unknown thing are you trying to estimate? With Sampling, it might be: How many people should I call?

Or maybe there are always two decisions: one forecasting and one causal.

Include discussion of RCM and potential outcomes, both in the context of this statistical technique and in the context of the empirical example.

Include a NHST and then a discussion of why NHST is stupid and full data/models are best for decision making.

Play the prediction game. That, perhaps, provides a useful framework for why NHST is stupid. Or, rather, you play the prediction game to figure out which statistical procedures are best --- and or, how well procedure X works --- and then use that information to make a decision.

Is there a way to print out messages during the book building process so that you know where the process is?

There is a lot of garbage in this project. Do we really need all the random files in data/ and rds/? Probably not. Figure out which we need and delete the rest. Perhaps combine them all in one directory? And try to do more calculations on the fly.

Is there really no discussion of p-values? There should be! And what about permutation tests? Maybe that is a useful early statistical programing exercise. Or maybe it would make a nice appendix, a second read after the Rubin Causal Model appendix.

Every model has a table highlighting what God would know, what we know, and then how we form a pdf about the truth. This is even so with sampling! I can think of two ways to thinking about this. One is with each row meaning a bead, and there are two potential outcomes, red and white. Until we pick that bead, both our "?". When we sample that bead, one column becomes TRUE and one becomes FALSE. And then we make inferences about the bead we can't see. Or, second way, it is a table with one column. (I think this is better.) Until we sample a bead, it is a "?". Then, it resolves to red/white. After drawing our sample, we make inferences about the other beads. In one sense, we are infering the value of p. In another, we are guessing what each of the "?" is, at least in expectation. But we can then also capture uncertainty! Each bead might be red or white, regardless of p. And there is uncertainty about p as well. This is the first time we are seeing both model uncertainty --- what is p? --- and predictive uncertainty --- what color is the next bead?

Also interesting to think about tables which we know are finite but we don't ever know how many rows, like number of living people in US right now (i.e., includes planes landing? someone whose heart has stopped beating but has not been "pronounced" dead?) 

Maybe we should restructure? Instead of thinking in terms of a chapter devoted to a specific model, like the regression chapters, we should instead think about chapters devoted to a problem. One problem is a right hand side variable that is continuous. One other problem is a right hand side variable that is 0/1. Of course, those chapters are too big! So, how to break them down? Maybe a chapter is defined as right hand size variable type (like continuous or 0/1) crossed with other factors. One such factor is left hand side available varibles: one continuous, one discrete, multiple and multiple with interactions. That would be eight chapters right there! Another factor might be modeling for causation or prediction. Hmm. But, lots of times, models are the same.

Think in terms of replacing our current 4 chapters from last third of the course. Ought to discuss causal versus predictive each time. Ought to discuss RCM each time. Ought to discuss over-fitting versus under-fitting each time. Ought to think about in-sample and out-of-sample. Ought to think in terms of decisions, and utilities each time. Those are the central themes, and should be repeated over-and-over again. We could use tidymodels syntax each time. Each model would have both a many-small-models example and a machine learning example. Predicted (or fitted) values and residuals (or errors). 

So, chap 1 continuous variables with one continuous covariate. Two models: lm and loess. chap 2 dichotomous variable with discrete convariate (first two categories, then several) and then also continuous. Two models: logistic and CART. chap 3 continuous variable with several covariates, both continuous and discrete. Two models: lm and ?. chap 4 other stuff, now that you understand all the key examples. Maybe federalist or social networks?

Or maybe: 1) continuous outcome, one covariate (lm and loess); 2) continuous outcome, multiple covariates (lm and neural network); 3) binary outcome, multiple covariates (glm and random forest), 4) multiple outcomes (like mnst?), multiple covariates (glm and deep learning). Concept of "machine learning" is used throughout, including tidymodels nomenclature. (Or should we do a time series chapter?)

Each chapter, at least in the last four, should only have one dataset. The cognitive load of switching is to high.

Put example in map appendix from Blackwell's slavery work.

### Big Changes

There is no need for Shiny/Animation in week 8. Put that stuff in week 4. Instead, once we start sampling, we are doing statistics each week.

Get rid of uncertainty/confidence interval chapter. That was always a stupid framing. Instead, each chapter is defined by a left hand side variable type, right hand side variables and/or models. 

Each chapter uses the bootstrap for two reasons. First, to build intution and provide justification for functions like lm. Second, to solve problems which can't be solved by standard functions. Each chapter begins with a real example, a decision we must make (if only the prediction game), and then creates a model which we will use to help us. Bets are always offered. RCM discussed. Bias scenarios demonstrated. The secret weapon --- a model for each state or each year --- used.  Explicit machine learning is used in 11 and 12, if not earlier.

assigment mechanism applies to both the assignment of treatment, as we know, and to the assignment of sampling. What mechanism caused us to, for example, sample this commuter and not that commuter? Ought to mention "assignment" every week, right next to potential outcomes. These are the two key parts of the RCM. 

The problem we are trying to solve, not the tool we are using to solve it.

6. Sampling
7. One Parameter (similar to current chapter, but also estimate median, 3rd biggest, IQR)
8. Two Parameter (two means, two medians, ratio of medians, difference in means)
9. Continuous left, discrete right (another way to do difference in means)
10. Continuous left, continuous right 
11. Continuous left, multivariate
12. Discrete left, multivariate

## Summer Jobs

Data Maven: Maintain script which creates our data sets, adds them to our package, maintains that as well. Reads *R Packages*. 

Book Builder: Make the book build nicely. Where does it go? How do we view it? How do we print it? Reads *Bookdown* book.

Illustrator: Figures out which of April's cartoons we can use, and puts them in the book. Maybe collects lots of other cartoons and images. And videos? It is an on-line book, so space is no object!

Animator: Why not have animations for almost everything? Check out the ones by that economist. One showing how loess works. How logistic curve changes. How regression lines can be made parallel and then have different slopes. Lots of possibilities.

Writer: There are a lot of words to write, especially new appendix items like Leamer, Tufte and others.

RCM Expert: Someone ought to understand this better than me, and then weave it throughout the book.

Humor: Find xkcd cartoons and similar.


