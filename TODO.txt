# Weekly Priorities

Jan 20: rubin-causal-model.Rmd

Jan 27: The purrr package, map_* functions and list columns at end of 06-functions.Rmd

Feb 3: maps-Rmd. 

Feb 10: The regression and multiple regresssion chapters, both from MD, are excellent. But, we need two kinds of major surgery. First, we do not want to use any of the MD-specific functions, like get_regression_table() or the other get_* hacks. Students should only use widely-used functions. Fortunately, the get_* functions are just wrapper for broom functions, so we will beed to use tidy(), glance() and augment() instead. This will require changes in the text which explains the output. Second, the text descriptions are frequentist. For us, everything is Bayesian. The confidence interval for a regression means that there is a 95% chance that the true value lies within that interval. And so on.

Feb 24: 13-classification.Rmd has two major flaws, each requiring 10 hours of work. First, the logistic regression section comes from a different source than MD. Which is fine. But we want it to have the same look-and-feel as chapters 11 and 12, as if the MD authors had written it. We can use the same data/examples as currently (or we can change them). The style/wording should be as similar to chapters 11 and 12 as 11/12 are to each other.

March 1: The second flaw of 13-classification.Rmd is that the sections about CART and random forest are disconnected from logistic regression. (And they came from a different source.) We want the chapter as a whole to work together. There should be a brief intro to the chapter discussing all the different ways we can handle classification problems, and mentioning the three that we will be using. (Indeed, it might be nice to use the same data across the three approaches!) Then, at the end, there should be some discussion about how they connect to each other, and how they connect to other key themes: like causal inference versus prediction. Indeed, the entire book needs to be infused with discussions of this issue.

Week ?: animation.Rmd. 


Week ?: What is the next set of stuff worth covering after students understand the Rubin Causal Model? Good question! I am not even sure what those topics are. Perhaps all the ways we deal with observational data. What sorts of material do other intro books cover? Here are some relevant concepts:

unit/item nonresponse
ignorability
treat potential outcomes as fixed (can we do this with regression?)
missing data
regresssion towards the mean
prediction/classification
map/network/text

When discussing map/network/text data, make sure to link to these blog posts and provide a paragraph of discussion.

Paul Revere [social network](https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/) 
Federalist Papers [authorship](https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/)
Lady Tasting Tea


# Other rough topics. 

Don't do anything with these till we talk.

Meld the material on functions and purrr into the concepts in the Probability/Bayes Chapters. We are not changing, I think, many of the words in these chapters, most of which are quite good. Instead, we are using these topics as an excuse to provide more lessons in functions/purrr. Also, edit Bayes chapter to make sense after probability chapter. Consider adding in intuition from Bayes for Beginner Book, especially decision trees, which map nicely to our simulation approach. 


=================

# Random Notes and Questions

Add tidycensus to end of tidy chapter, both a good example and sets the stage for mapping.

Create an Appendix section, like in MD, where separate concepts live: Shiny, Maps, Animation, Rubin Causal Model, et cetera.

Edit Bayes chapter, especially the end.

I like the PDF version of Rafa's book available from Lean Pub. How hard is that to make?


Replace DS Unix stuff with unix stuff from UNIX workbench?

Add discussion of allowed variable names, the use of ``, and janitor::clean_names() early in the book. This is needed as background before we use tidy::broom() and similar functions.

Remove use of get_* speciality ModernDive commands. Replace with broom:tidy() and friends. We should not need library(moderndive) at all. (But need to check on any data used from there.) 

Get rid of use of infer library. Do all this the hard way, via the bootstrap and specific calculation of the test statistic.

Remove all hypothesis testing from MD chapters. Motto: No tests! There is only the data, and models we create from the data, and the decisions we make with those models.

Lots of pandoc-citeproc errors.

Replace all uses of kable with gt?

Fix "No additional resources" in Chapter 6 and 7. Standardize this section across all chapters. 545 is different.

Requires internet when using read_mnist() in some DS chapters. Annoying! Fix by including copy of mnist? By getting rid of these sections?

Why isn't preview_chapter() working with MD chapters? Why can't I simply knit one of the MD chapters? Gives weird error message about "Error in files2[[format]] : 
  attempt to select less than one element in get1index"
  

Links in STAT 545 not working despite addition of links.md file. How fix?


Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY


Or should each of these be separate chapters so that we might mix and match things? Maybe we need 100+ chapters, each of which do simple things, largely unconnected to each other.

Add cookie photo to front

Add 545 and DS data download code to chapter 5?



========= Large Projects

## R Packages

Square away R packages. There should be one location with all the requirements. Here is a listing of the R packages used my MD, from their index.Rmd:

CRAN packages needed: "nycflights13", "ggplot2movies", "fivethirtyeight", "gapminder", "ISLR",tidyverse", "rmarkdown", "knitr", "janitor", "skimr","infer", "moderndive", "webshot", "mvtnorm", "remotes", "devtools", "dygraphs", "gridExtra", "kableExtra", "scales", "viridis", "ggrepel", "patchwork",

But what good is this, given that other packages are loaded elsewhere? Is there some standard way of handling this, perhaps with a DESCRIPTION file? Main annoyance is that new contributors have to try to compile the book a dozen times before it will work.

==
## Set Up Script

Consider the use of before_chapter_script: "_common.R" in the DS _bookdown.yml as well as the associated _common.R file. Is this an approach we should copy? The lack of this why I can't get all the DS chapters to work.

Combine _common.R, common.R and index.Rmd information into one place. Need to figure out how this works in bookdown. I think we need one file which only runs once when you make the book. That files does a bunch of stuff involving copying over files. But you don't maintain state after running that file, so any new functions are lost. Then you have a second file, like _common.R, which is run at the start of compiling each chapter.

==
## Bibiography

Deal with bibliography. Our source books use very different approaches.

I like the way that MD writes out new versions of citations associated with R packages that have been updated.

Note that logistic regression chapter has a bunch of entries we need from BYSH.

==
## References and Footnotes

The book has lots of references, especially to other chapters. Many of these don't work because the referred-to chapters don't exist. We need a thorough clean up.

Some chapters, like 03-productivity.Rmd have a lot of footnotes. Good or bad?

Seems like all chapters generate references at the end. That is fine, but it should be standardized. Or do all those references belong at the end.

==
## Specific Chapters

04-wrangling is a mess, especially in the way that the join material from MD and from 545 do not go well together. Should some of it be moved to 05?

06-functions last section in map_ functions and list columns should be created. We don't need to understand everything about these concepts, just enough to do what we need in the next few chapters.

 
========= Thoughts

Revisit the Prediction Game. Love this:

“The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at 10 he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred.”

— Immanuel Kant, Critique of Pure Reason

Broadening Your Statistical Horizons is a very cleanly put together book. We should make our book look like that.

````markdown
`r ''````{r}
plot(cars)
```
````

Key concepts which need to be put everywhere:

decisions need models
potential outcomes and causal effects
units, treatments, outcomes
randomization is magic: assignment to estimate causal effects, bootstrap to estimate uncertainty

Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

Bias/Variance == Underfitting/Overfitting

No Tests! Null hypthosis testing is a mistake. There is only the data, the models and the summaries therefrom.

heterogenous treatment effects; interaction terms

(See [modelDown](https://github.com/MI2DataLab/modelDown).) *[Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression/)* provides several examples of how to create, and document your creation of, such a model, e.g., section 13.5 (gun control) and section X (wells in Bangladesh).




