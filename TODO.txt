# Summer 

## Book Building

* [*Bookdown*](https://bookdown.org/yihui/bookdown/) is the key reference. [Hands-On Machine Learning with R](https://github.com/koalaverse/homlr) does the nicest job that I have seen in making clean Rmd go to clean html. See their [repo](https://bradleyboehmke.github.io/HOML/).


* Is there an easy way to knit a single chapter? There ought to be, but I can't find it. Why doesn't bookdown::preview_chapter() work? We need a way for chapter-writers like Jessica to work, and, right now their chapter will not build. ANSWER: bookdown::preview_chapter("01-visualization.Rmd", "bookdown::gitbook")

* Where does the book go? We currently use [Github pages](https://pages.github.com/). We should use a better location for the permanent version. We need separate locations: a permanent released version which does not change all semester and a development version which we work on live. Explore how ModernDive does things: [here](https://moderndive.com/) and [here](https://github.com/moderndive/ModernDive_book).  Come up with a plan to move the whole thing to Netifly and use [Github Actions](https://github.com/davidkane9/PPBDS/actions/new) [to deploy](https://www.hvitfeldt.me/blog/bookdown-netlify-github-actions/). I have a Netifly account. Sign up for a free account yourself and experiment.  

* While pondering the above, experiment by setting up a release version using the code as of the [one release](https://github.com/davidkane9/PPBDS/releases/tag/v1.0) which I tagged. We can do this "by hand" the first time. The [545 book](https://github.com/rstudio-education/stat545) may handle this intelligently. Maybe we need to create a branch for such a release?

* Get Github Actions working. Explore how to use Github actions to check that the book is working each time someone makes a change. Continuous integration is the nectar of the Gods.

* `knitr::include_graphics()` does not seem to produce an error when we build the book, even if the file is missing. How can we make sure it does error? And what should our standard use of this tool look like? One approach: [Using Images in Figures](http://zevross.com/blog/2017/06/19/tips-and-tricks-for-working-with-images-and-figures-in-r-markdown-documents/).  Related: Offer an opinion about the best way to include Allison's [cartoons](https://github.com/allisonhorst/stats-illustrations). We don't want to include all these and then have to edit them all.


* What default options do we need, and where are they set. The index.Rmd file used to include:

# options(width = 80, digits = 7, bookdown.clean_book = TRUE, knitr.kable.NA = 'NA')
# 
# knitr::opts_chunk$set(
#   tidy = FALSE, 
#   out.width = '\\textwidth', 
#   fig.align = "center", 
#   comment = NA) 

I just deleted it. Does it matter? This seems like a hack, especially for when you want to compile a single chapter. What is the cool way to handle that?

* How can we make the book build faster? Maybe we should use cache=TRUE for the slow chunks. But which chunks are those?

* Build it under 4.0.

* How do we print it? I like the PDF version of Rafa's [book](https://leanpub.com/datasciencebook) available from Lean Pub. How hard is that to make?  

* Is there a way to print out messages during the book building process so that you know where the process is? Recall that we can't (?) use R code chunk names because duplicate code chunk names cause (still?) the process to blow up.

* Think about the data directory. Do we really need all these files? Couldn't we create them on the fly? What do we do when we need to update them?

* Think about the images directory. What a pile of crap! Do we need all these? How can we re-organize to make it more maintainable in the future. Maybe start by making a new img/ directory and then just moving over the images we are currently using?

* Think about the bib/ directory. We need to fix our citations. Automate the citation of whatever packages we are using. The references are a mess, put together from 3 different original sources. First, there a bib directory, with three files in it. Second, within index.Rmd there was a call to knitr::write_bib, which is a famously dangerous and confusing function. I guess that this creates packages.bib. (I have since deleted this.) Third, there is the links.md file, which is supposed to replace a lot of the references like @R-readr, mainly in chapter 2. That seems not to work at all. Come up with a plan to deal with all these.

* Think about packages. Note that the [545 book](https://github.com/rstudio-education/stat545) uses a fairly sophisticated plan, involving the new **renv** package.


* Can you rebuild just a single chapter and then commit/push it? Right now, I have to rebuild the whole thing each time I want to make a single change. Takes too long.


* How do we centralize the loading of packages? What is our plan for loading libraries and removing them when they are no longer need? Chapter 11 contained an annoying bug: rvest and purrr both have pluck() as a function. Need to ensure that you get the purrr version if you need it. Bug only showed up when Chapter 5 (with rvest loaded) was used in the build. Organize packages. What are all the packages we need? How do we ensure that we cite them all, as we should? Where do we load them? Again, there must be best practices for stuff like this. Only use high quality packages, and recommend the same to readers. When are different packages introduced? Where is this written down? Need to be intentional about what we introduced outside of the tidyverse --- janitor, ggthemes, reprex, fs, skimr, gt, googlesheets4, infer, gtsummary --- and when we do it. One annoyance is that new contributors have to try to compile the book a dozen times before it will work because there is no way to know, ahead of time, which packages are required. Make the book an R package?

* Consider the use of before_chapter_script: "_common.R" in the DS _bookdown.yml as well as the associated _common.R file. Is this an approach we should copy? The lack of this why I can't get all the DS chapters to work. Combine _common.R, common.R and index.Rmd information into one place. Need to figure out how this works in bookdown. I think we need one file which only runs once when you make the book. That files does a bunch of stuff involving copying over files. But you don't maintain state after running that file, so any new functions are lost. Then you have a second file, like _common.R, which is run at the start of compiling each chapter.

* The book has lots of references, especially to other chapters. Many of these don't work because the referred-to chapters don't exist. We need a thorough clean up.

* Deal with bibliography. Our source books use very different approaches. write_bib() is infamous for making trouble. I like the way that MD writes out new versions of citations associated with R packages that have been updated.

* Seems like all chapters generate references at the end. That is fine, but it should be standardized. Or do all those references belong at the end?



## Other Items


The world confronts us. We must make decisions. The data we want is missing. So, we create models, make estimates, admit to our uncertainty, and then decide. 

## Unclassified Items

* Use tidybayes package for better graphics throughout?

* Remove library(moderndive)  everywhere.

* Remove library(infer) --- which means rep_sample_n() --- and replace with rsample::? Here is a nice example: https://juliasilge.com/blog/beer-production/

* Replace all uses of kable with gt.

* Fix "No additional resources" in Chapter 6 and 7. Standardize this section across all chapters. 545 is different. Delete everywhere?

* Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY

* Some chapters, like productivity.Rmd have a lot of footnotes. Good or bad?

* Revisit the Prediction Game. 


````markdown
`r ''````{r}
plot(cars)
```
````

### From the Bookdown book

preview_chapter() and serve_book() as aid to chapter writers. 

webshot() tool for including images taken from webpages. Everytime we mention how cool source X is, we should provide a webshot of it. (And we should test that it exists.) Make the productivity chapter include way less of our prose.

switch to tufte() style, ask Healy.

Kindle book

put the book on bookdown.org, or class assignments


Key concepts which need to be put everywhere:

decisions need models
potential outcomes and causal effects
units, treatments, outcomes
randomization is magic: assignment to estimate causal effects, bootstrap to estimate uncertainty

Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

Bias/Variance == Underfitting/Overfitting

No Tests! Null hypthosis testing is a mistake. There is only the data, the models and the summaries therefrom

Describe an hypothesis test each chapter, and then dismiss it.

heterogenous treatment effects; interaction terms

(See [modelDown](https://github.com/MI2DataLab/modelDown).) *[Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression/)* provides several examples of how to create, and document your creation of, such a model, e.g., section 13.5 (gun control) and section X (wells in Bangladesh).


# Standards

Follow MD as much as possible.

* R terms and objects (anything you might type in the console) in backticks.

* Functions names always include ().

* Package names are **bolded**.

# Summer

## Themes to confirm over the summer

Drop all the frequentist nonsense except for a footnote at the first use with a confidence interval and an appendix which walks students through the Kuske arguments.

Chapters from sampling through machine learning should be parallel. To the greatest extent possible, they all do all these things.

Show the results of each step. Show what each column (mod, data, etc) looks like as it is added to the tibble.

Everything is Bayesian. The confidence interval for a regression means that there is a 95% chance that the true value lies within that interval. Use Rubin Causal Model and potentional outcomes to define precisely what "true value" you are talking about. And so on. We use the bootstrap to show that lm() produces the same answers, and then just use lm() because it is quicker.

Discuss RCM, assuming that we are estimating a causal effect of some type. And, if we are not estimating causal effects (i.e., all we care about is prediction), then the mechanics of lm are the same, but the interpretation of the regression coefficient has no causal implications.  We want a series of tables illustrating potential outcomes and our estmation of them. Start with a table with ?, just as in the Appendix. We use linear regression to fill in these questions marks. Show table with question marks and then show table with question marks filled in with best guess. Then show table with question marks filled in with a confidence interval for the mean and then for a distribution of predicted values. The closer we can tie RCM to the different parts of a regression, the better. But do this each chapter, not just regression.

Avoid discussion about hypothesis tests, except to dismiss them. But maybe we discuss and then dismiss them each chapter. Motto: No tests! There is only the data, and models we create from the data, and the decisions we make with those models. But we still need to explain what hypothesis tests are, and why we don't care about them. Explain what a test is, and why we think it is a waste of time to do them, and why people do them anyway. Key issue: If p = 0.04 really makes you do something totally different than p = 0.06, then either you (or the system within which you are operating) is stupid.

Each chapter should finish with a new section which uses list-columns plus broom to estimate scores of models, and then pull out interesting models. See the gapminder examples from https://r4ds.had.co.nz/many-models.html#gapminder. We need the full tool set: nest, unnest and so on.


## Other summer issues


https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.


https://committedtotape.shinyapps.io/freeR/

Clean up and organize images/ directory.


Replace all photos of activities with photos from Harvard, using Tsai.


There should be on causal and one non-causal example in each chapter. Perhaps use trains throughout? Create a logistic regression example in which the dependent variable is moved X units more conservative, or did not.

googlesheet4 examples. Perhaps there is an Appendix with cool packages and a brief introduction?

Standard number formating. 2400 or 2,400 or $2400$ or . . . .

## Every Chapter from Sampling Forward

Begin with a decision. What real world problem are you trying to solve? What are the costs and benefits of different approaches? What unknown thing are you trying to estimate? With Sampling, it might be: How many people should I call?

Or maybe there are always two decisions: one forecasting and one causal.

Include discussion of RCM and potential outcomes, both in the context of this statistical technique and in the context of the empirical example.

Include a NHST and then a discussion of why NHST is stupid and full data/models are best for decision making.

Play the prediction game. That, perhaps, provides a useful framework for why NHST is stupid. Or, rather, you play the prediction game to figure out which statistical procedures are best --- and or, how well procedure X works --- and then use that information to make a decision.


There is a lot of garbage in this project. Do we really need all the random files in data/ and data/? Probably not. Figure out which we need and delete the rest. Perhaps combine them all in one directory? And try to do more calculations on the fly.

Is there really no discussion of p-values? There should be! And what about permutation tests? Maybe that is a useful early statistical programing exercise. Or maybe it would make a nice appendix, a second read after the Rubin Causal Model appendix.




Think in terms of replacing our current 4 chapters from last third of the course. Ought to discuss causal versus predictive each time. Ought to discuss RCM each time. Ought to discuss over-fitting versus under-fitting each time. Ought to think about in-sample and out-of-sample. Ought to think in terms of decisions, and utilities each time. Those are the central themes, and should be repeated over-and-over again. We could use tidymodels syntax each time. Each model would have both a many-small-models example and a machine learning example. Predicted (or fitted) values and residuals (or errors). 




Each chapter, at least in the last four, should only have one dataset. The cognitive load of switching is to high.




Chapters 7, 8 and 9 use the bootstrap for two reasons. First, to build intution and provide justification for functions like lm. Second, to solve problems which can't be solved by standard functions. 

Machine learning in 10, 11 and 12.

Each chapter begins with a real example, a decision we must make (if only the prediction game), and then creates a model which we will use to help us. Bets are always offered. RCM discussed. Bias scenarios demonstrated. The secret weapon --- a model for each state or each year --- used.  


The problem we are trying to solve, not the tool we are using to solve it.

http://statprep.org/

## Other Topics

I am not even sure what those topics are. Perhaps all the ways we deal with observational data. What sorts of material do other intro books cover? Here are some relevant concepts:

unit/item nonresponse
ignorability
treat potential outcomes as fixed (can we do this with regression?)
missing data
regresssion towards the mean
prediction/classification
map/network/text
natural experiments
Conditional random assignment
Difference in differences
Regression discontinuity

other key themes: like causal inference versus prediction. Indeed, the entire book needs to be infused with discussions of this issue. Spend a week on that?



