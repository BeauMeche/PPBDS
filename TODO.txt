# Next meeting.

# Weekly Priorities

March 1: 13-classification.Rmd has two major flaws. First, the logistic regression section comes from a different source than MD. Which is fine. But we want it to have the same look-and-feel as chapters 11 and 12, as if the MD authors had written it. We can use the same data/examples as currently (or we can change them). The style/wording should be as similar to chapters 11 and 12 as 11/12 are to each other. Each time, we show how boostrap justifies the use of lm/glm and, therefore, allows our Bayesian interpretation. Each time, we end with an example which runs 100 models and then pulls out and graphs an interesting subset. We need the same 6 part surgery here.

March 8: The second flaw of 13-classification.Rmd is that the sections about CART and random forest are disconnected from logistic regression. (And they came from a different source.) We want the chapter as a whole to work together. There should be a brief intro to the chapter discussing all the different ways we can handle classification problems, and mentioning the three that we will be using. (Indeed, it might be nice to use the same data across the three approaches!) Then, at the end, there should be some discussion about how they connect to each other, and how they connect to other key themes: like causal inference versus prediction. Indeed, the entire book needs to be infused with discussions of this issue.

March 15: The machine learning chapter is a mess, derived mostly from DS. A much better book is: https://bradleyboehmke.github.io/HOML/. But that won't be open for another year. And, it is too advanced. And it does not quite use all the latest machine learning approaches in R. But the style is nice, and perhaps worth emulating. A related issue is tying this work back to the last three weeks. After all, in each of the last three weeks we fitted hundreds of models. Isn't that what machine learning is? Sort of! Big difference is that, previously, the separate models have shared no data with each other. With machine learning, they will! How can we teach this in a way which is closest to the approaches they have learned? Are parsnip and recipe the packages to use? Here are other useful sources:

https://dnield.com/posts/tidymodels-intro/
https://github.com/rstudio-conf-2020/applied-ml

March 23: Nothing. You were on Spring Break!

March 30:

April 6:

April 13:

April 20:

All done!


Week ?: What is the next set of stuff worth covering after students understand the Rubin Causal Model? Good question! I am not even sure what those topics are. Perhaps all the ways we deal with observational data. What sorts of material do other intro books cover? Here are some relevant concepts:

unit/item nonresponse
ignorability
treat potential outcomes as fixed (can we do this with regression?)
missing data
regresssion towards the mean
prediction/classification
map/network/text
natural experiments
Conditional random assignment
Difference in differences
Regression discontinuity

other key themes: like causal inference versus prediction. Indeed, the entire book needs to be infused with discussions of this issue. Spend a week on that?


# Potential Projects

Combine Bayes and Probability chapters. There is only enough material here from one chapter. I don't like the mash up of two chapters, from two different original sources. Two approaches: interweave the Bayesian stuff into the probability chapter or the reverse. I like the reverse. The Bayes chapter is nice. It just needs more probability placed into it. Indeed, on some dimensions the probability chapter is overkill, even after I deleted some stuff. Chapter is still called Probability but it becomes an appendix, I think.

Maybe this one chapter uses decision trees as its central organizing metaphor. *Bayes Theorem: A Visual Introduction for Beginners* does a nice job of teaching Bayesian inference with decision trees. Works really well! And easy (?) to simulate. Maybe we do that? Fits naturally (?) into list-columns and map functions. A natural (?) way to teach/show unconditional, conditional and marginal probability. Leafs on the tree are the possible outcomes.

Meld the material on functions and purrr into the concepts in the Probability/Bayes Chapters. We are not changing, I think, many of the words in these chapters, most of which are quite good. Instead, we are using these topics as an excuse to provide more lessons in functions/purrr. Also, edit Bayes chapter to make sense after probability chapter. Consider adding in intuition from Bayes for Beginner Book, especially decision trees, which map nicely to our simulation approach. 

Brief appendix about Tufte and other graphics luminaries?

Brief appendix about Leamer?

Use tidybayes package for better graphics throughout?

When discussing map/network/text data, make sure to link to these blog posts and provide a paragraph of discussion.

Paul Revere [social network](https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/) 
Federalist Papers [authorship](https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/)
Lady Tasting Tea

=================

# Things for Me

Add discussion of allowed variable names, the use of ``, and janitor::clean_names() early in the book. skimr() also. This is needed as background before we use tidy::broom() and similar functions.

Fix sampling/CI chapters to discuss hypothesis tests and why we hate them. Should do this in every chapter through the core of the book.

# Random Notes and Questions

Looks like we can use sections from R4DS as long as we use the entire section, unchanged.

https://r4ds.had.co.nz/index.html
https://creativecommons.org/faq/#can-i-reuse-an-excerpt-of-a-larger-work-that-is-licensed-with-the-noderivs-restriction

How do references work in MD chapters?

I like the PDF version of Rafa's book available from Lean Pub. How hard is that to make?

Replace DS Unix stuff with unix stuff from UNIX workbench? Perhaps we introduce the **fs** package at the same time, showing how you can accomplish similar things from the terminal and the R console.

We should not need library(moderndive) at all. (But need to check on any data used from there.)

Get rid of use of infer library. Do all this the hard way, via the bootstrap and specific calculation of the test statistic.

Lots of pandoc-citeproc errors.

Replace all uses of kable with gt?

Fix "No additional resources" in Chapter 6 and 7. Standardize this section across all chapters. 545 is different.

Requires internet when using read_mnist() in some DS chapters. Annoying! Fix by including copy of mnist? By getting rid of these sections?

Why isn't preview_chapter() working with MD chapters? Why can't I simply knit one of the MD chapters? Gives weird error message about "Error in files2[[format]] : 
  attempt to select less than one element in get1index"
  

Links in STAT 545 not working despite addition of links.md file. How fix?


Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY


Or should each of these be separate chapters so that we might mix and match things? Maybe we need 100+ chapters, each of which do simple things, largely unconnected to each other, or with explicit prerequisites. 

Too early to start thinking about two versions: 1005 and 1006, with 1006 as extra advanced sections in each chapter?

Add 545 and DS data download code to chapter 5?



========= Large Projects

## R Packages

Square away R packages. There should be one location with all the requirements. Here is a listing of the R packages used my MD, from their index.Rmd:

CRAN packages needed: "nycflights13", "ggplot2movies", "fivethirtyeight", "gapminder", "ISLR",tidyverse", "rmarkdown", "knitr", "janitor", "skimr","infer", "moderndive", "webshot", "mvtnorm", "remotes", "devtools", "dygraphs", "gridExtra", "kableExtra", "scales", "viridis", "ggrepel", "patchwork",

But what good is this, given that other packages are loaded elsewhere? Is there some standard way of handling this, perhaps with a DESCRIPTION file? Main annoyance is that new contributors have to try to compile the book a dozen times before it will work.

==
## Set Up Script

Consider the use of before_chapter_script: "_common.R" in the DS _bookdown.yml as well as the associated _common.R file. Is this an approach we should copy? The lack of this why I can't get all the DS chapters to work.

Combine _common.R, common.R and index.Rmd information into one place. Need to figure out how this works in bookdown. I think we need one file which only runs once when you make the book. That files does a bunch of stuff involving copying over files. But you don't maintain state after running that file, so any new functions are lost. Then you have a second file, like _common.R, which is run at the start of compiling each chapter.

==
## Bibiography

Deal with bibliography. Our source books use very different approaches.

I like the way that MD writes out new versions of citations associated with R packages that have been updated.

Note that logistic regression chapter has a bunch of entries we need from BYSH.

==
## References and Footnotes

The book has lots of references, especially to other chapters. Many of these don't work because the referred-to chapters don't exist. We need a thorough clean up.

Some chapters, like 03-productivity.Rmd have a lot of footnotes. Good or bad?

Seems like all chapters generate references at the end. That is fine, but it should be standardized. Or do all those references belong at the end.

==
## Specific Chapters

04-wrangling is a mess, especially in the way that the join material from MD and from 545 do not go well together. Should some of it be moved to 05?

Need to introduce lists early, But when?

========= Thoughts

Revisit the Prediction Game. Love this:

“The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at 10 he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred.”

— Immanuel Kant, Critique of Pure Reason

Broadening Your Statistical Horizons is a very cleanly put together book. We should make our book look like that.

````markdown
`r ''````{r}
plot(cars)
```
````

Key concepts which need to be put everywhere:

decisions need models
potential outcomes and causal effects
units, treatments, outcomes
randomization is magic: assignment to estimate causal effects, bootstrap to estimate uncertainty

Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

Bias/Variance == Underfitting/Overfitting

No Tests! Null hypthosis testing is a mistake. There is only the data, the models and the summaries therefrom.

heterogenous treatment effects; interaction terms

(See [modelDown](https://github.com/MI2DataLab/modelDown).) *[Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression/)* provides several examples of how to create, and document your creation of, such a model, e.g., section 13.5 (gun control) and section X (wells in Bangladesh).


# Standards

Follow MD as much as possible.

* R terms and objects (anything you might type in the console) in backticks.

* Functions names always include ().

* Package names are **bolded**.

# Summer

## Themes to confirm over the summer

Chapters from sampling through machine learning should be parallel. To the greatest extent possible, they all do all these things.

Use tidy() and pull out regression results which you want to manipulate. Use no functions from moderndive.
 
Show the results of each step. Show what each column (mod, data, etc) looks like as it is added to the tibble.

Everything is Bayesian. The confidence interval for a regression means that there is a 95% chance that the true value lies within that interval. And so on. We use the bootstrap to show that lm() produces the same answers, and then just use lm() because it is quicker.

Discuss RCM, assuming that we are estimating a causal effect of some type. And, if we are not estimating causal effects (i.e., all we care about is prediction), then the mechanics of lm are the same, but the interpretation of the regression coefficient has no causal implications.  We want a series of tables illustrating potential outcomes and our estmation of them. Start with a table with ?, just as in the Appendix. We use linear regression to fill in these questions marks. Show table with question marks and then show table with question marks filled in with best guess. Then show table with question marks filled in with a confidence interval for the mean and then for a distribution of predicted values. The closer we can tie RCM to the different parts of a regression, the better. But do this each chapter, not just regression.

Avoid discussion about hypothesis tests, except to dismiss them. But maybe we discuss and then dismiss them each chapter. Motto: No tests! There is only the data, and models we create from the data, and the decisions we make with those models. But we still need to explain what hypothesis tests are, and why we don't care about them. Explain what a test is, and why we think it is a waste of time to do them, and why people do them anyway. Key issue: If p = 0.04 really makes you do something totally different than p = 0.06, then either you (or the system within which you are operating) is stupid.

Each chapter should finish with a new section which uses list-columns plus broom to estimate scores of models, and then pull out interesting models. See the gapminder examples from https://r4ds.had.co.nz/many-models.html#gapminder. We need the full tool set: nest, unnest and so on.


## Other summer issues

Should we move the whole thing to Netifly and use Github Actions to deploy? https://www.hvitfeldt.me/blog/bookdown-netlify-github-actions/

Should make Productivity chapter more connected to the lectures on Days 3 and 4. Cut material which is not directly relevant. Introduce the material in the same way that I introduce it in class. Someone who reads the chapter should find the lecture a simple repeat of what they have already seen.


Add more fancy plotting details to chapter 2. Key is to include all the necessary steps toward making the 538 plot. Discussion of the key parts of a graphic, especially title, subtitle and sources. themes(), starting with theme_minimal() but going on to cool stuff like fivethirtyeight and TV themes. ggtext. axis ajustments. Links to relevant readings in Healy. Also add a section on how to put a graphic in Rpubs. And also saving graphics.

Use almost every single one of these illustrations: https://github.com/allisonhorst/stats-illustrations

Consider this: https://github.com/tinystats/teacups-giraffes-and-statistics

Lists show up in Chapter 4 without any previous discussion. We need a short intro to the major variable types before this. Also put characters ahead of factors. 

Does chapter 4 belong ahead of chapter 3? 

Should Productivity come right after Chapter 1? Should Chapter 1 have more fun stuff in it? That is, you make a fun plot or two at the end of Chapter 1, so you are motivated to get set up correctly, then you do the hard work of doing so in the Productivity chapter. Then the real work begins.

Chapter 2 should have faceting and other graphics fun.

https://github.com/yonicd/carbonate -- perhaps useful for some nicer formatting of source code.


https://committedtotape.shinyapps.io/freeR/

Clean up and organize images/ directory.

What is our plan for loading libraries and removing them when they are no longer need? Chapter 11 contained an annoying bug: rvest and purrr both have pluck() as a function. Need to ensure that you get the purrr version if you need it. Bug only showed up when Chapter 5 (with rvest loaded) was used in the build.


ifelse (and other similar commands?) belongs earlier in the book, like when we first use mutate(). What else might be introduced with the initial usages of mutate?

Figure out links in Chapter 4 and elsewhere . . .

Replace all photos of activities with photos from Harvard, using Tsai.

When are different packages introduced? Where is this written down? Need to be intentional about what we introduced outside of the tidyverse --- janitor, ggthemes, reprex, fs, skimr, gt, googlesheets4, infer, gtsummary --- and when we do it.

## Reorganize

Would to have a book in which there is one chapter per week. Leads to a nice rythm. Could also have appendices which could be assigned when and as-if needed.

That would mean that anything which other chapters assume has been done must be in an earlier chapter, not an appendix. (or maybe not.) Good example of this is RCM, which later chapters definitely assume. Then again, I like having appendices that are short and self-contained, like mapping. Maybe we need more appendices! Maybe a better framework is that appedices have information that either a) a prof might reasonably decide not to assign or b) often contain material that students already know.

Perhaps Productivity belongs as an appendix, not least because so much is irrelevant (like Windows tips for Mac users). Also, it could be made much shorter, with pointers to good info, like Happy Git for the UseR. 

Getting Started and Visualization could be the first chapter, due for week 2.

Wrangling and Tidy could be the second chapter, due for week 3, with RCM appedix.

Week 4 has appendices maps, probabilty and Bayes. Easier week because of them exam.

Functions could be week 5 to 10 could be Sampling through Machine Learning. This 6 week sequence seems very solid to me. Only trick part is when to start it. Maybe begin it in week 6, so that it ends in week 11, leaving week 12 for demo day. That would give us an extra week before week 6 to re-allocate.

## Other Stuff

Albert points out a difficulty in combining the RCM with regression. You can't easily put in a distribution for the unknown potential outcome, even if you have a good regression model. You can't just add to the observed outcome because . . . actually I am confused about this!

There should be on causal and one non-causal example in each chapter. This is most obviously not-done in the multivariate chapter, where there are three clearly non-causal chapters. Perhaps use trains throughout? Create a logistic regression example in which the dependent variable is moved X units more conservative, or did not.

Maybe the functions chapter should introduce map functions independent of list-columns. For example, if you want to simulate dice throws in a tibble, you need (?) map function to enure that you get a different value for each row.




