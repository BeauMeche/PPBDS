# Weekly Priorities

Jan 20: RCM

Jan 27: Write unfinished end of 06-functions.Rmd, portion devoted to list columns and map_ functions. Start with problem set 5, question 5 from last semester. These are the key concepts I want students to have. Steal that example for this chapter and walk students slowly through it, with extra backgound information. At the end, show how the use of tibble() to start is a hack which can be replaced with imap. See https://r4ds.had.co.nz/many-models.html for a discussion about list columns. This topic is also difficult, first because we are teaching it in week 5 of the semester. Second, because it is hard! Third, because we only need to understand a subset of its usage --- the part that is useful for simple simulation exercises. R4DS is good: https://r4ds.had.co.nz/iteration.html. Maybe this: https://htmlpreview.github.io/?https://github.com/JoeyBernhardt/stat545-purrr/blob/master/purrr-lesson.html but it is all about extraction when our purrr use is simulation. RStudio Webinar titled "[How to Work with List Columns](https://resources.rstudio.com/webinars/how-to-work-with-list-columns-garrett-grolemund)" by Garrett Grolemund is useful. Maybe the this purrr tutorial: https://jennybc.github.io/purrr-tutorial/index.html?

Feb 3: Chapter "Maps". Self-contained introduction to mapping. Only uses geom_sf(). Check out DataCamp assignment on maps: [Spatial Analysis in R with sf and raster](https://www.datacamp.com/courses/spatial-analysis-in-r-with-sf-and-raster). Chapter 1, Vector and Raster Spatial Data in R. Only care about geom_sf stuff. No raster. I won't assign this DataCamp. So, maybe cover the geom_sf stuff from several chapters in it?  Maybe use: [Andrew Tran](https://github.com/andrewbtran/NICAR-2019-mapping). This chapter is important because there is no simple, modern self-contained introduction to mapping that I can find. And lots of students will want to use maps in their final project. But this does need to be simple since students will be going through it during week 4. Can we get students using tidycensus? https://walkerke.github.io/tidycensus/articles/spatial-data.html Maybe this should form the core of our examples? Maybe we introduce the tidycensus package the week before in the syllabus? For purposes of this chapter, you may assume that students already understand tidycensus.


Feb 10: Chapter "Animation". Self-contained introduction to animation.  We will only be using gganimate. Start with this introduction: https://www.datanovia.com/en/blog/gganimate-how-to-create-plots-with-beautiful-animation-in-r/. Make sure o cover anim_save() since students need to save their anmations and then deply them to Shiny. The gganimate official page is OK: https://gganimate.com/index.html. The section "Where is my animation?" is definitely important, as is understanding that the default creation is a gif. Should also cover how to post one's gif on Facebook/Twitter/etc.


Week ?: What is the next set of stuff worth covering after students understand the Rubin Causal Model? Good question! I am not even sure what those topics are. Perhaps all the ways we deal with observational data. What sorts of material do other intro books cover? Here are some relevant concepts:

unit/item nonresponse
ignorability
treat potential outcomes as fixed (can we do this with regression?)
missing data
regresssion towards the mean
prediction/classification
map/network/text

When discussing map/network/text data, make sure to link to these blog posts and provide a paragraph of discussion.

Paul Revere [social network](https://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/) 
Federalist Papers [authorship](https://www.hvitfeldt.me/blog/authorship-classification-with-tidymodels-and-textrecipes/)
Lady Tasting Tea


# Other rough topics. 

Don't do anything with these till we talk.

Meld the material on functions and purrr into the concepts in the Probability/Bayes Chapters. We are not changing, I think, many of the words in these chapters, most of which are quite good. Instead, we are using these topics as an excuse to provide more lessons in functions/purrr. Also, edit Bayes chapter to make sense after probability chapter. Consider adding in intuition from Bayes for Beginner Book, especially decision trees, which map nicely to our simulation approach. 


=================

# Random Notes and Questions

Add tidycensus to end of tidy chapter, both a good example and sets the stage for mapping.

Create an Appendix section, like in MD, where separate concepts live: Shiny, Maps, Animation, Rubin Causal Model, et cetera.

Edit Bayes chapter, especially the end.

I like the PDF version of Rafa's book available from Lean Pub. How hard is that to make?


Replace DS Unix stuff with unix stuff from UNIX workbench?

Add discussion of allowed variable names, the use of ``, and janitor::clean_names() early in the book. This is needed as background before we use tidy::broom() and similar functions.

Remove use of get_* speciality ModernDive commands. Replace with broom:tidy() and friends. We should not need library(moderndive) at all. (But need to check on any data used from there.) 

Get rid of use of infer library. Do all this the hard way, via the bootstrap and specific calculation of the test statistic.

Remove all hypothesis testing from MD chapters. Motto: No tests! There is only the data, and models we create from the data, and the decisions we make with those models.

Lots of pandoc-citeproc errors.

Replace all uses of kable with gt?

Fix "No additional resources" in Chapter 6 and 7. Standardize this section across all chapters. 545 is different.

Requires internet when using read_mnist() in some DS chapters. Annoying! Fix by including copy of mnist? By getting rid of these sections?

Why isn't preview_chapter() working with MD chapters? Why can't I simply knit one of the MD chapters? Gives weird error message about "Error in files2[[format]] : 
  attempt to select less than one element in get1index"
  

Links in STAT 545 not working despite addition of links.md file. How fix?


Take (?) material from: https://chabefer.github.io/STCI/; https://github.com/chabefer/SKY


Or should each of these be separate chapters so that we might mix and match things? Maybe we need 100+ chapters, each of which do simple things, largely unconnected to each other.

Add cookie photo to front

Add 545 and DS data download code to chapter 5?



========= Large Projects

## R Packages

Square away R packages. There should be one location with all the requirements. Here is a listing of the R packages used my MD, from their index.Rmd:

CRAN packages needed: "nycflights13", "ggplot2movies", "fivethirtyeight", "gapminder", "ISLR",tidyverse", "rmarkdown", "knitr", "janitor", "skimr","infer", "moderndive", "webshot", "mvtnorm", "remotes", "devtools", "dygraphs", "gridExtra", "kableExtra", "scales", "viridis", "ggrepel", "patchwork",

But what good is this, given that other packages are loaded elsewhere? Is there some standard way of handling this, perhaps with a DESCRIPTION file? Main annoyance is that new contributors have to try to compile the book a dozen times before it will work.

==
## Set Up Script

Consider the use of before_chapter_script: "_common.R" in the DS _bookdown.yml as well as the associated _common.R file. Is this an approach we should copy? The lack of this why I can't get all the DS chapters to work.

Combine _common.R, common.R and index.Rmd information into one place. Need to figure out how this works in bookdown. I think we need one file which only runs once when you make the book. That files does a bunch of stuff involving copying over files. But you don't maintain state after running that file, so any new functions are lost. Then you have a second file, like _common.R, which is run at the start of compiling each chapter.

==
## Bibiography

Deal with bibliography. Our source books use very different approaches.

I like the way that MD writes out new versions of citations associated with R packages that have been updated.

Note that logistic regression chapter has a bunch of entries we need from BYSH.

==
## References and Footnotes

The book has lots of references, especially to other chapters. Many of these don't work because the referred-to chapters don't exist. We need a thorough clean up.

Some chapters, like 03-productivity.Rmd have a lot of footnotes. Good or bad?

Seems like all chapters generate references at the end. That is fine, but it should be standardized. Or do all those references belong at the end.

==
## Specific Chapters

04-wrangling is a mess, especially in the way that the join material from MD and from 545 do not go well together. Should some of it be moved to 05?

06-functions last section in map_ functions and list columns should be created. We don't need to understand everything about these concepts, just enough to do what we need in the next few chapters.

 
========= Thoughts

Revisit the Prediction Game. Love this:

“The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at 10 he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred.”

— Immanuel Kant, Critique of Pure Reason

Broadening Your Statistical Horizons is a very cleanly put together book. We should make our book look like that.

````markdown
`r ''````{r}
plot(cars)
```
````

Key concepts which need to be put everywhere:

decisions need models
potential outcomes and causal effects
units, treatments, outcomes
randomization is magic: assignment to estimate causal effects, bootstrap to estimate uncertainty

Describe, predict, infer. Description of things you can see, prediction for things you will see and inference about things you will never see.

Prediction checks.

Bias/Variance == Underfitting/Overfitting

No Tests! Null hypthosis testing is a mistake. There is only the data, the models and the summaries therefrom.

heterogenous treatment effects; interaction terms

(See [modelDown](https://github.com/MI2DataLab/modelDown).) *[Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression/)* provides several examples of how to create, and document your creation of, such a model, e.g., section 13.5 (gun control) and section X (wells in Bangladesh).




