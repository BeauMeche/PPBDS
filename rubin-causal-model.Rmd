# (APPENDIX) Appendix {-}

# Rubin Causal Model {#rubin-causal-model}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gt)
library(tidyverse)
```

The Rubin Causal Model (RCM) is an approach to the statistical analysis of cause and effect based on the framework of potential outcomes, named after Donald Rubin.^[This chapter remixes some material from [Rubin Causal Model (Wikipedia)](https://en.wikipedia.org/wiki/Rubin_causal_model). <br /> The name "Rubin Causal Model" was first coined by Paul W. Holland (1986).]  

<!-- AR: Perhaps the credit to Wikipedia should be added to the attributions page
rather than here.-->

The Rubin Causal Model (RCM) is based on the idea of **potential outcomes.**  For example, let's say you took aspirin and now no longer have a headache. To measure the causal effect of taking the aspirin, we need to compare the outcome for you in one alternative future (where you took the aspirin) to another (where you did not). Since it is impossible to see both potential outcomes at once, one of the potential outcomes is always missing. This dilemma is the "fundamental problem of causal inference."

## What is a causal effect?

<!-- DK: Get rid of quote. Start with FDA example. Or something political? -->

Rubin defines a "causal effect": 

> Intuitively, the causal effect of one treatment, E, over another, C, for a particular unit and an interval of time from $t_1$ to $t_2$ is the difference between what would have happened at time $t_2$ if the unit had been exposed to E initiated at $t_1$ and what would have happened at $t_2$ if the unit had been exposed to C initiated at $t_1$: 'If an hour ago I had taken two aspirins instead of just a glass of water, my headache would now be gone,' or 'because an hour ago I took two aspirins instead of just a glass of water, my headache is now gone.' Our definition of the causal effect of the E versus C treatment will reflect this intuitive meaning.^[Rubin 1974.]

Thus, according to the RCM, the causal effect of your taking or not taking aspirin one hour ago is the difference between how your head would have felt in case 1 (taking the aspirin) and case 2 (not taking the aspirin). If your headache would remain without aspirin but disappear if you took aspirin, then the causal effect of taking aspirin is headache relief.

In most circumstances, we are interested in comparing two futures, one generally termed "treatment" and the other "control." These labels are somewhat arbitrary. The difference between the potential outcome under treatment and the potential outcome under control is called a "causal effect" or a "treatment effect."  The scenario that didn't actually happen, and thus that we didn't observe, is called a "counterfactual."


### Everything is a missing data problem

<!-- DK: Section here outlining simple average income in the US. The mechanisms by which you find out some things and don't find out other things are critical to understand when trying to make statistical inferences. -->

### Potential outcomes

Suppose that Joe is participating in an FDA test for a new hypertension drug. If we were omniscient, we would know the outcomes for Joe under both treatment (the new drug) and control (either no treatment or the current standard treatment). The causal effect, or treatment effect, is the difference between these two potential outcomes. 

<!-- AR: Should we stick with this notation? -->

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = "Joe",
       ytreat = "130",
       ycontrol = "135",
       ydiff = "-5") %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```


$Y_{t}(u)$ is Joe's systolic blood pressure if he takes the new pill. In general, this notation expresses the potential outcome which results from a treatment, $t$, on a unit, $u$. Similarly, $Y_{c}(u)$ is the effect of a different treatment, $c$ or control, on a unit, $u$. In this case, $Y_{c}(u)$ is Joe's blood pressure if he doesn't take the pill. $Y_{t}(u)-Y_{c}(u)$ is the causal effect of taking the new drug.  Thus, Joe would have a blood pressure of $130$ if he took the pill and $135$ if he did not; the causal effect of taking the pill is $-5$.  Joe should take the pill!

From this table we only know the causal effect on Joe. Everyone else in the study might have an increase in blood pressure if they take the pill. However, regardless of what the causal effect is for the other subjects, the causal effect for Joe is lower blood pressure, relative to what his blood pressure would have been if he had not taken the pill.

### No causation without manipulation

In order for a potential outcome to make sense, it must be possible, at least *a priori*. For example, if there is no way for Joe, under any circumstance, to obtain the new drug, then $Y_{t}(u)$ is impossible for him. It can never happen. And if $Y_{t}(u)$ can never be observed, even in theory, then the causal effect of treatment on Joe's blood pressure is not defined. 

The causal effect of new drug is well defined because it is the simple difference of two potential outcomes, both of which might happen. In this case, we (or something else) can manipulate the world, at least conceptually, so that it is possible that one thing or a different thing might happen.

This definition of causal effects becomes much more problematic if there is no way for one of the potential outcomes to happen, ever. For example, what is the causal effect of Joe's height on his weight? Naively, this seems similar to our other examples. We just need to compare two potential outcomes: what would Joe's weight be under the treatment (where treatment is defined as being 3 inches taller) and what would Joe's weight be under the control (where control is defined as his current height).

A moment's reflection highlights the problem: we can't increase Joe's height. There is no way to observe, even conceptually, what Joe's weight would be if he were taller because there is no way to make him taller. We can't manipulate Joe's height, so it makes no sense to investigate the causal effect of height on weight. Hence the slogan: **No causation without manipulation.**


<!-- DK: We need to take slow steps from the basic Rubin Table --- I just coined that phrase --- to more complex versions. For example, we need a table that starts from treatment/control and then points out that there are many causal effects which one might measure, starting from just that case. Not just the difference, but also the ratio, the percentage change and so on. That may seem trivial but it helps the next step. Add a section named "Estimand" here. Of course, all these estimands can be derived from the primitives of the potential outcomes, but they are still useful when we make more complex models later. Obviously, we need to refer back to this concept. -->


### Average treatment effect

<!-- AR: Calling this the "average treatment effect" rather than "average causal
effect" throughout -->

<!-- DK: I think that this transition is a little rough. We want to do two things. First, we want to go from one person to 6 people. There is a lot to talk about in just that step, before we go into a concept like ATE. Specifically, we can now expand the concept of Estimand and discuss it again. The more that I think about it, the more important this concept becomes. We need a precise definition. Let's do the following. First, add the notion of 6 people above, before the first explanation of Estimand. Now, you can talk about Estimands. There are a lot of them! Starting with the unobserved potential outcome for one person, to the causal effect for one person (which, of course, is just subtraction, but, still walk through it slowly), to the most positive and most negative causal effect. The median causal effect. The median percentage change. The total number of people for whom the causal effect is positive. And so on. There are a lot of things one might care about! -->

<!-- Again, all of these can be derived if you know the full Rubin Table. -->

<!-- Second, after going through this, put the survey section here. That is, we never care about just 6 people. They are always a sample from a larger population that we care about. Explain, in fact, that Joe this week is not the same as Joe next year. The causal effect might be different. Show the full Rubin Table, which includes rows for people we don't know and rows for the same people in the future. Indeed, it includes a row for Joe now, Joe in a year, Joe in two years, et cetera. This provides an excuse to talk about sampling, stability, et cetera. -->

<!-- In fact, because time is continuous, there is a row for Joe now, Joe one second from now, Joe one day from now and so on. The Rubin Table extends downward forever. Which is why we need assumptions, most specifically that the causal effect for Joe now is the same as all the ones for Joe in the future. Is that plausible? Sort of. Joe now and Joe in one second are pretty similar! Joe now and Joe in 30 years are less so. -->

<!-- DK: So far, we have extended RCM by adding rows to our Rubin Table. Now we add columns. Provie an example with three potential outcomes, like control versus 2 possible treatments. (Still keep the table you have. Same people. Still FDA.) There are 3, obvious, causal effects we might want in that case. Spell them out clearly, even in the case in which we are just looking at simple differences. Revisit the concept of an estimand. -->

<!-- Next step is are a limited set numeric treatments, like taking one pill, two pills, ... up to 5 pills. This looks at lot like 3 categorical treatments, but it is different since the treatments have a numeric relationship with each other. Hint at how that may provide more modeling options later. -->

<!-- Final step is the extension to continuous treatments. Instead of a whole pill, how about 1000 mg (milligrams)? How about 1001? And so on. Indeed, there are an infinite number of possible treatments. The Rubin Table extends to the right forever. Again, assumptions come to our rescue. Or rather, we just throw up our hands and only try to estimate a few things. -->

<!-- DK: One cool way to think about this is to start with the infinite RT. First we throw out the rows that we thing are duplicates. Second, we throw out the columns that we don't care about. (Not sure what to do with rows/columns that we do care about --- like people not in the sample, or outcomes in the future ---  but which we have no data for.) Now, we have something limited with which we can work. But the infinite RT is always there! -->


<!-- All the above starts with the introduction of the 6 person example. Are we ready, at this point, to talk about estimation? No! Right now, I think it goes a little quickly. Too early to start talking about ATE. Instead: -->

<!-- Talk about how you fill in the question marks, but going back to the 6 people and just the treatment/control. Start case is that you can't fill them in. You can never know! Next step is that, even if you could know, everyone is different, so every causal effect is different. But not much you can do with that easier. So, we start making assumptions. And "assumption" means a "model," and all models have parameters.  -->

<!-- One model might be that the causal effect is the same for everyone. There is a single parameter, tau, which we then estimate. Once we have an estimate, we can fill in the Rubin Table because, knowing it, we know what the unseen potential outcome is for each person. This provides another opportunity to introduce the concept of estimand, which is tau in this case. -->
  
<!-- A second model might be that the causal effect is the same within categories. That is, it is tau_1 for men and tau_2 for women.  A third model might be . . . The key concept is that we can't make any progress unless we make some assumptions. That is an inescapable result of the fundamental problem of causal inference. So we make some assumptions, which give us some models. -->



<!-- DK: And now, finally, we can estimate ATE, as we do below. But we should highlight that this is just one model. A different model, like tau varies by gender, would require a different thing to estimate. ATE is not really special. It is just one model which allows us to fill in the question marks. So, we do this twice. Filling in the question marks differently each time. And this highlights the dilemma. We can never really know what Joe's outcome under control would have been. In fact, with just two different models, we have two different guesses. -->

<!-- And now revisit the concept of estimand. Because things get a bit circular here! Let's say that the estimand we really care about is --- What is the lowest blood pressure after treatment? That is not an unreasonable thing to want to know. But we are not, under either of our two models, estimating that directly! Instead, we are estimating tau (or tau_1 and tau_2) and then using those estimates to populate the table. Then, with the complete table, we can get the number we really care about. We use one estimand (tau) to get another estimand (lowest blood pressure under treatment), rather than going for the second estimand immediately.  This is important. -->

<!-- DK: Leftover discussion. Not sure it still matters.  How do we fill in the question marks? One answer: Take the mean of the column. Consider the control group. You have their blood pressure. If I find a new person, whose blood pressure you don't know, what would you guess? The mean, obviously. Fill those in. Now you can estimate the causal effect for each person, and the average causal effect. Cool! Is that a good model? No! It sucks, because you have information for each person you are not using: their blood pressure under the other outcome. How to use it? Make a new model in which there is a single parameter, tau, which is the constant treatment effect for everyone. Estimate that. Fill in the ?.  -->

<!-- Only at the very end of this discussion to we mention that, even though there are a lot of estimands that one might be interested in, some, like ATE, are very popular. Then, go through ATE as an example. -->

<!-- DK: At this point, we have Need to add uncertainty into the mix, both the uncertainty in estimating t and the uncertainty in predicting the ? for specific individuals. Maybe mention measurement error? Evn though we pretend that the potential outcomes are fixed (a long with pre-treatment covariates), we never know them exactly. Someone's blood pressure is never exactly 130. There is uncertainty, perhaps best considered as a PDF. And different people might have different amounts of uncertainty.  -->

<!-- With that clear --- and is there a way to add a little normal distribution density to a RT? or something like that? --- we can go on to talk about the uncertainty in the unobserved potential outcome. Indeed, even if we could magically see it, there would still be a PDF because of measurement error. That is the minimum amount of uncertainty we deal with. There are two sources: model uncertainty, which goes away with big N, and individual variation which does not. Fill in the ? with those confidence intervals, the second much wider than the first. In explaining this, you may assume that someone has read the probability and Bayesian chapter of the book. -->



Consider a larger sample of patients: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "130", "130", "140", "145", "135"),
       ycontrol = c("135", "145", "145", "150", "140", "143"),
       ydiff = c("-5", "-15", "-15", "-10", "+5", "-8")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

The causal effect is different for every subject, but the drug works for Joe, Mary, Sally and Bob because the causal effect is negative. Their blood pressure is lower with the drug than it would have been if each did not take the drug. For James, however, the drug causes an *increase* in blood pressure. 

One may calculate the **average treatment effect** (often abbreviated ATE) by taking the mean of all the causal effects.  Here, the mean is $-8$.

Note that we can calculate the average treatment effect in this case because we are omniscient and know all the potential outcomes under both treatment and control.  We will soon see what assumptions we need to make in order to calculate the average treatment effect in the real world where only one potential outcome can ever be observed.  In particular, while we cannot estimate individual causal effects without very strong assumptions, randomized experiments can allow for good estimates of the ATE, as we will see later in this chapter.

## The fundamental problem of causal inference

The results we have seen up to this point could never be measured in practice. It is impossible, by definition, to observe the effects of more than one treatment on a single subject. Joe cannot both take the pill and not take the pill at the same time! Therefore, the data we actually observe would look something like this: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "?", "?", "115", "121.67"),
       ycontrol = c("?", "?", "125", "130", "?", "127.5"),
       ydiff = c("?", "?", "?", "?", "?", "-5.83")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Question marks are responses that could not be observed. The **Fundamental Problem of Causal Inference**^[Holland 1986.] is that directly observing unit-level causal effects is impossible. However, this does not make *causal inference* impossible. Certain techniques and assumptions allow the fundamental problem to be overcome.

One way we could solve this problem is by filling in the missing values for treatment and control with the mean values.  That is, let's say we wanted to know what Joe's outcome would have been under control.  We then just plug in the observed mean ($127.5$) of the control observations for Joe's outcome:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "121.67", "121.67", "115", "121.67"),
       ycontrol = c("127.5", "127.5", "125", "130", "127.5", "127.5"),
       ydiff = c("2.5", "-7.5", "-3.33", "-8.33", "-12.5", "-5.83")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

We see that this method doesn't change our estimate of the treatment mean ($121.67$), the control mean ($127.5$), or the mean difference between treatment and control ($-5.83$).  However, it does allow us to make predictions for individual observations.  For example, now we predict that Joe's systolic blood pressure under control would have been $127.5$.

But how confident should we be that Joe's outcome under control is $127.5$?  Not very!  Even if plugging in the average outcome value for the control observations is a good prediction for Joe (and it may well not be), we should recognize that we have a great deal of *uncertainty* about that value.  In Chapter \@ref(confidence-intervals), we show how to construct a *confidence interval* around a quantity of interest; later in this chapter we'll discuss *permutation tests*, a way of quantifying uncertainty for randomized experiences.

However, with only two observations in the control group, we can simply note that we've observed values under control as low as $125$ and as high as $130$, so we don't have good reason to think that Joe's value will be precisely $127.5$.  Here's the same table, but with some makeshift confidence intervals, taken from the lowest and highest values observed under treatment and control:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "121.67 (115, 130)", "121.67 (115, 130)", "115", "121.67"),
       ycontrol = c("127.5 (125, 130)", "127.5 (125, 130)", "125", "130", "127.5 (125, 130)", "127.5"),
       ydiff = c("2.5", "-7.5", "-3.33", "-8.33", "-12.5", "-5.83")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```


We may wonder still whether this is a good estimate for Joe.  After all, we are guessing here that the treatment is likely to *raise* his blood pressure, given that his observed blood pressure under treatment was still higher than the average blood pressure under control ($130 > 127.5$).

A way to make a better prediction for Joe is to use an estimate of the average treatment effect.  If we knew that the drug lowered blood pressure on average, that would help us make decisions even if we can't observe the causal effect of the drug on individual people (because we don't observe counterfactuals).

The most natural place to start is with the difference in the sample mean outcomes between treatment and control, $-5.83$.  Note that unlike earlier, this is an *estimate* of the ATE, not the ATE itself.  Why?  Because we have missing data!  For each unit, we only observe one of the potential outcomes.

Thus, another way we can fill in our missing values is by adding our estimate of the ATE to the observed value under control (for units in the control group) or by subtracting our estimate of the ATE from the observed value under treatment (for units in the treatment group), like so:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "119.17", "124.17", "115", "121.67"),
       ycontrol = c("135.83", "125.83", "125", "130", "120.83", "127.5"),
       ydiff = c("-5.83", "-5.83", "-5.83", "-5.83", "-5.83", "-5.83")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Do we think that if Joe didn't take the drug, his systolic blood pressure would be exactly $135.83$? Of course not! We have some uncertainty around these numbers, as well.  There are two main sources of uncertainty we have to take into account when making a prediction for Joe:

1. **Uncertainty in estimating the ATE**.  Especially with five subjects, we may not have a good estimate of the ATE.  With this miniscule sample, the uncertainty might be gigantic, like ($-25$, $13$), which would lead to a prediction for Joe of ($117, 155$).  As we get a larger sample size, this uncertainty decreases.
1. **Individual variation**.  Even if we have a perfect estimate of the *average* treatment effect, it still may be the case that the effect *for Joe* is higher or lower than average.  We can assume this away if we say that the treatment effect is constant for everyone, but that is not likely to be true in the real world -- and this source of uncertainty does not go away simply by collecting more observations.  So with a large sample, let's say that we calculated a confidence interval around the ATE of ($-6, -5.67$), leading to an interval for Joe's outcome under control of ($135.67, 136$).  The uncertainty due to individual variation may still be a great deal higher---say ($120, 152$).  These numbers are simply illustrative, but they highlight an important point: even if you have a good estimate of the ATE, you should still be much more uncertain about the causal effect for any *particular individual*.

### The assignment mechanism

<!-- DK: Everything is a missing data problem. -->

<!-- DK: Perhaps the best way to introduce this topic is to talk about just measuring a single outcome, like, say, income in the world. The Rubin Table for this just has a single column: income. If we were God, we could see all the values and calculate the the true median. (Even this is harder than it sounds because it is only for a given point in time. One day later some rows in the RT have disappeared (with someone's death) while other rows have been added, with someone turing 18.) But we don't get to see all the values. First, our sample, even if perfectly random, only includes X number of people, so we never had the chance to see 99.9% of the rows. Second, some of the sample refused to answer the question. They are also missing.  -->

<!-- How was it that some people (and not others) were sampled and some of the sample (but not others) did not report a number. In both cases, we want to know what process led to these outcomes. What was the "assignment mechanism" to sampling that led to Joe being included and Sarah not? For those included, what was the "assignment mechanism" to answering which led X to report her income and Y to not? -->

<!-- Once those ideas are explained, in the simplest possible context, we can move on to the normal assignment mechanism, which is a much trickier concept. -->


Is the difference in sample means between treated units and control units a good estimate of the average treatment effect?  That depends entirely on the method by which units are assigned treatment, which is called the **assignment mechanism**.

One such assignment mechanism is **randomization**. For each subject we could flip a coin to determine if she receives treatment. If we wanted five subjects to receive treatment, we could assign treatment to the first five names we pick out of a hat.

Randomized assignment is the best assignment mechanism for inferring average treatment effects because if the sample is large enough, the difference in sample means between treated and control units will be very close to the true average treatment effect in that sample.

However, when the sample size is small, our estimated average treatment effect may deviate considerably from the truth.  For example, the data in the last section were from just one possible random assignment, where Joe, Mary and James receive the treatment.  Here's another possible random assignment, where Joe, Mary and Sally receive the treatment:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "100", "?", "?", "115"),
       ycontrol = c("?", "?", "?", "130", "120", "123"),
       ydiff = c("?", "?", "?", "?", "?", "-8.33")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Note that with one assignment, the estimate of the ATE is $-5.83$, while with another it is $-8.33$.  Assume that these data are the truth: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("130", "120", "100", "110", "115", "115"),
       ycontrol = c("115", "125", "130", "130", "120", "123"),
       ydiff = c("+15", "-5", "-25", "-20", "-5", "-8")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Thus, the true average treatment effect is $-8$.  However, our estimates of the average treatment effect vary because our sample is small and the responses have a large variance. If the sample were larger and the variance were less, the average treatment effect would be closer to the true average treatment effect regardless of the specific units randomly assigned to treatment.

### Permutation tests

<!-- AR: This section attempts to describe permutation tests in a non-frequentist
way; thus, there are no references to a "test statistic" or to the "sharp null." Worth keeping?
-->

Let's say we observed the following results, which we know came from a random treatment assignment:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Mary", "Sally", "Bob", "James", "MEAN"),
       ytreat = c("120", "100", "?", "?", "110"),
       ycontrol = c("?", "?", "130", "120", "125"),
       ydiff = c("?", "?", "?", "?", "-15")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

The drug looks very useful!  However, how likely is it that we would observe these results if the drug did nothing at all?  That is, how confident should we be that the drug is actually helpful?

To answer this question, we can use a **permutation test**.^[See [this post](https://www.r-bloggers.com/what-is-a-permutation-test/) for a longer discussion.]  The intuition behind a permutation test is simple.  We observed four outcomes, two of which were assigned to treatment and two that were assigned to control.  To conduct a permutation test, we calculate our quantity of interest (here, the difference in means between treated and control) for every possible arrangement of the labels "treatment" and "control" across these four numbers.

This is easiest to understand visually:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(Permutation = c("#1", "#2", "#3", "#4", "#5", "#6"),
       `120` = c("T", "T", "T", "C", "C", "C"),
       `100` = c("T", "C", "C", "T", "T", "C"),
       `130` = c("C", "T", "C", "T", "C", "T"),
       `120 ` = c("C", "C", "T", "C", "T", "T"),
       ATE = c("-15", "+15", "+5", "-5", "-15", "+15")) %>%
       
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(Permutation = md("**Permutation**")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(Permutation))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(Permutation)))
```

Here, permutation #1 is what we actually observed, and permutations #2-6 are all the possible rearrangement of the two "treatment" labels and the two "control" labels.  What do we see?  4/6 (67%) of the permutations produce calculated ATEs are at least as large as the effect we actually observed ($-15$), and two of them are the opposite sign!  We therefore should not have much confidence from these data alone that the drug really lowers blood pressure, even though the effect size appeared large.  The moral of the story?  Don't conduct an experiment on only four people!

Let's say that we had a larger experiment.  We can no longer calculate the results of the permutation test by hand, since the number of possible permutations will quickly become very large.  However, you can use R to calculate far more permutations than you can do by hand.  Furthermore, if the number of permutations becomes too much even for your computer, you can take a random sample of all the possible permutations instead; if the random sample is large enough, this will give you a result very close to what you would get if you considered all the permutations.

<!-- DK: Ideally, we extend the Rubin Table until it is flexible enough to use in the context of regression. More complex statistical models, like regression, just provide a different way of imputing the values of those question marks. And we should show this clearly. -->

<!-- DK: Connect causal inference to prediction, even if only briefly.  -->

### Confounding and selection bias

With a large enough sample and randomized assignment, we can get a good estimate of the ATE.  Other assignment mechanisms, however, can make it difficult or impossible to engage in causal inference.

Why is that?  Consider the use of the *perfect doctor* as an assignment mechanism. The perfect doctor knows how each subject will respond to the drug or the control and assigns each subject to the treatment that will most benefit her. The perfect doctor knows this information about a sample of patients: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "Susie", "MEAN"),
       ytreat = c("130", "120", "100", "115", "125", "135", "120"),
       ycontrol = c("115", "125", "150", "125", "130", "105", "125"),
       ydiff = c("+15", "-5", "-50", "-10", "-10", "+30", "-15")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Based on this knowledge she would make the following treatment assignments: 

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe", "Mary", "Sally", "Bob", "James", "Susie", "MEAN"),
       ytreat = c("?", "120", "100", "115", "125", "?", "113.75"),
       ycontrol = c("115", "?", "?", "?", "?", "105", "110"),
       ydiff = c("?", "?", "?", "?", "?", "?", "+3.75")) %>%
  
  # Then, we use the gt function to make it pretty
  
  gt() %>%
  cols_label(subject = md("$$\\mathbf{Subject}$$"),
                ytreat = md("$$Y_t(u)$$"),
                ycontrol = md("$$Y_c(u)$$"),
                ydiff = md("$$Y_t(u) - Y_c(u)$$")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

The perfect doctor distorts the averages of both $Y_t(u)$ and $Y_c(u)$ by filtering out poor responses to both the treatment and control. The difference in means thus is distorted in a direction that depends on the details. For instance, a subject like Susie who is harmed by taking the drug would be assigned to the control group by the perfect doctor and thus the negative effect of the drug would be masked.

Therefore, the difference in means is no longer a good estimate of the ATE. In fact, in this case it has the wrong sign! This is not merely a consequence of our small sample: even if the perfect doctor saw a million patients, we could not get a good estimate of the ATE.

This is an extreme example of a problem called **selection bias**.  The perfect doctor is not choosing which patients are receiving the drug at random. Rather, the perfect doctor is making treatment decisions based directly on the patient's potential outcomes.  Whenever the assignment mechanism is correlated with the potential outcomes, we say that there is **confounding**.  Confounding is a problem, since it means that our simple estimate of the ATE is biased.

Thus, if you are interested in causal inference, randomized trials are the best approach. In many circumstances, however, randomized trials are not possible due to ethical or practical concerns. In such scenarios there is by necessity a non-random assignment mechanism.

For instance, let's say you were interested in the effect of college attendence on earnings. People are not randomly assigned to attend college. Rather, people may choose to attend college based on their financial situation, parents' education, and so on.  This can introduce confounding if the assignment mechanism affects future earnings.  For example, if people choose to go to college at higher rates when they are on career paths where a college degree is particularly beneficial  -- or, in RCM language, whose potential outcomes are on average higher under treatment -- that would introduce confounding.

Many statistical methods have been developed for causal inference when there is a non-random assignment mechanism, such as propensity score matching. These methods attempt to correct for the assignment mechanism by finding control units similar to treatment units. What you should not do is naively compare the sample means under treatment and control and assume that is a good estimate of the ATE.  Without randomization, this could be very misleading!

## Other issues with causal inference


### Stable unit treatment value assumption (SUTVA)

One important assumption for causal inference is that "the [potential outcome] observation on one unit should be unaffected by the particular assignment of treatments to the other units."^[Cox 1958, §2.4.] This is called the **Stable Unit Treatment Value Assumption** (**SUTVA**). 

In the context of our example, Joe's blood pressure should not depend on whether Mary receives the drug. But what if it does? Suppose that Joe and Mary live in the same house and Mary always cooks. The drug causes Mary to crave salty foods, so if she takes the drug she will cook with more salt than she would have otherwise. A high salt diet increases Joe's blood pressure. Therefore, his outcome will depend on both which treatment he received and which treatment Mary receives.

SUTVA violation makes causal inference more difficult. We can account for dependent observations by considering more treatments. We create 4 treatments by taking into account whether or not Mary receives treatment:

```{r, echo = FALSE}
# First, we create a tibble with the values we want for the table

tibble(subject = c("Joe"),
       ct = "140",
       tt = "130",
       cc = "125",
       tc = "120") %>%
  
  # Then, we use the gt function to make it pretty.
  
  gt() %>%
  cols_label(subject = md("**Subject**"),
             ct = html("Joe = c,<br />Mary = t"),
             tt = html("Joe = t,<br />Mary = t"),
             cc = html("Joe = c,<br />Mary = c"),
             tc = html("Joe = t,<br />Mary = c")) %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(subject))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(subject)))
```

Recall that a causal effect is defined as the difference between two potential outcomes. In this case, there are multiple causal effects because there are more than two potential outcomes:

- One is the causal effect of the drug on Joe when Mary receives treatment ($130-140$).
- Another is the causal effect of the drug on Joe when Mary does not receive treatment ($120-125$).
- A third is the causal effect of Mary's treatment on Joe when Joe is not treated ($140-125$). In other words, we can define a causal effect on Joe even in situation in which Joe's treatment is identical in both situations.

Note that Mary taking the drug has a larger causal effect on Joe than Joe himself taking the drug, and what's more, the effect is in the opposite dierction!

By considering more potential outcomes in this way, we can cause SUTVA to hold. However, if any units other than Joe are dependent on Mary, then we must consider further potential outcomes. The greater the number of dependent units, the more potential outcomes we must consider and the more complex the calculations become (consider an experiment with 20 different people, each of whose treatment status can affect outcomes for every one else). In order (easily) to estimate the causal effect of a single treatment relative to a control, SUTVA should hold. 

### Internal and external validity

If we have randomized assignment and a large sample, we can be confident that we have a good estimate of the average treatment effect *in that sample*.  We say that the experiment has high **internal validity**: the inferences we are making are likely to reflect the truth about that sample.

However, we may be interested in a population beyond our particular sample.  For example, consider the hypertension drug example discussed above.  Let's say that we ran a randomized trial on 10,000 patients, with 5,000 receiving the new drug and 5,000 in the contol group.  We estimate an average treatment effect of $-5$ units of systolic blood pressure.  Should we recommend this new drug?

The answer to that question depends in part on the **external validity** of the study.  Are the 10,000 people in the study similar to the people for whom we will be making recommendations?  Let's say that the 10,000 study participants were chosen because they all lived near the location that the study took place. That's one example of **selection bias**, where the sample is not a random sample of the population in which we are interested.  Why is that a problem?  Those people may differ systematically from other people, including in ways that affect their response to blood pressure medicine. For example, what if the people in this area are younger on average than most people who take blood pressure medicine?

This concern can be expressed in terms of the assignment mechanism.  People who live far away from the location of the study have a 0% chance of receiving the treatment.  Thus, the study *can't* directly speak to whether the treatment is effective for them; the only way we can make such claims is by making additional assumptions, such as that the non-participants will respond the same on average to the drug as the participants.

The circumstances of the experiment may also affect the external validity of the study.  Perhaps the study participants were all eating a diet that was controlled by the experimenters.  Then, while we have variation in one aspect of the treatment (whether the participants received the blood pressure medicine), we don't have variation in another (diet).  It may be that the blood pressure medicine works when on the controlled diet but doesn't work otherwise.

When dealing with human subjects, there is a particular concern regarding external validity: the [**Hawthorne effect**](https://en.wikipedia.org/wiki/Hawthorne_effect).  When human subjects know that they are part of an experiment, they may change their behavior.

This can lead to a version of the above concern.  Suppose again that the blood pressure drug works when combined with a controlled diet, say a low-salt diet, but it doesn't work for those who have a high-salt diet.  If the subjects in the experiment are paying greater attention to their blood pressure than they otherwise would and thus are eating lower sodium diets than other people, one could make the mistaken inference that it was the blood pressure drug alone that led to a decrease in blood pressure, and not the combination of the drug and the experimental subjects' changing behavior.

### Survey research and external validity

<!-- DK: Move this higher. -->

In political science and other social sciences, survey research poses some particular problems of external validity.  Let's say that you want to measure presidential approval among all U.S. voters.  How can you make sure that the sample you collect is representative of your sampling frame?  (In the language of survey sampling, the "sampling frame" is the population you want to study: here, voters in the United States.)

The most natural approach is to engage in a simple random sample: each U.S. voter has the same probability of being in the survey.  This would ensure that one's sample was on average representative of the population, although there will still be some sampling error because the sample is finite.  About 139 million people voted in the 2016 general election,^[See [here](http://www.electproject.org/2016g).] so if one wanted a sample of 1,390 voters, one would like a sampling method that gives each voter an equivalent 0.001% chance of being surveyed.

But of course, there's no method of assuring that each voter has an equivalent chance of being in your survey!  Let's say that you decided to conduct your survey via random digit dialing, where you call possible phone numbers at random and give your survey to those who answer.  There are many possible sources of bias in this measure:

- Some voters may not have telephone numbers
- Some voters may be more likely to answer the phone and take your survey than others
- Some people may lie or misremember about whether they voted in the 2016 general election
- More subtly, respondents' presidential approval may be affected by other questions you ask in the survey. (Perhaps this is what you are studying, for instance if you were testing the effect of a particular message on presidential approval, but if not, you need to be careful in interpreting your results.)

And these are just the most obvious!  If you take a course in survey research, you'll learn more about the ways in which pollsters attempt to deal with these problems.

With the growing popularity of survey experiments in social research, it is always worth considering how the sampling was conducted.

## Conclusion

The causal effect of a treatment on a single unit at a point in time is the difference between the outcome variable with the treatment and without the treatment. The Fundamental Problem of Causal Inference is that it is impossible to observe the causal effect on a single unit. You either take the aspirin now or you don't. As a consequence, assumptions must be made in order to estimate the missing counterfactuals.

## References

<!-- AR: Need to integrate this with the rest of the book -->

Cox, D. R. (1958). *Planning of Experiments.* Wiley.

Holland, Paul W. (1986). "Statistics and Causal Inference." *J. Amer. Statist. Assoc.* 81 (396): 945–960. doi:10.1080/01621459.1986.10478354.

Rubin, Donald (1974). "Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies." *J. Educ. Psychol.* 66 (5): 688–701 [p. 689]. doi:10.1037/h0037350.